[
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nactivations module: DO NOT EDIT.\nactivations\napplications module: DO NOT EDIT.\napplications\nbackend module: DO NOT EDIT.\nbackend\ncallbacks module: DO NOT EDIT.\ncallbacks\nconfig module: DO NOT EDIT.\nconfig\nconstraints module: DO NOT EDIT.\nconstraints\ndatasets module: DO NOT EDIT.\ndatasets\ndistribution module: DO NOT EDIT.\ndistribution\ndtype_policies module: DO NOT EDIT.\ndtype_policies\nexport module: DO NOT EDIT.\nexport\ninitializers module: DO NOT EDIT.\ninitializers\nlayers module: DO NOT EDIT.\nlayers\nlegacy module: DO NOT EDIT.\nlegacy\nlosses module: DO NOT EDIT.\nlosses\nmetrics module: DO NOT EDIT.\nmetrics\nmixed_precision module: DO NOT EDIT.\nmixed_precision\nmodels module: DO NOT EDIT.\nmodels\nops module: DO NOT EDIT.\nops\noptimizers module: DO NOT EDIT.\noptimizers\npreprocessing module: DO NOT EDIT.\npreprocessing\nquantizers module: DO NOT EDIT.\nquantizers\nrandom module: DO NOT EDIT.\nrandom\nregularizers module: DO NOT EDIT.\nregularizers\ntree module: DO NOT EDIT.\ntree\nutils module: DO NOT EDIT.\nutils\nClasses\nclass DTypePolicy : A dtype policy for a Keras layer.\nclass DTypePolicy\nclass FloatDTypePolicy : A dtype policy for a Keras layer.\nclass FloatDTypePolicy\nclass Function : Class that encapsulates a computation graph of Keras operations.\nclass Function\nclass Initializer : Initializer base class: all Keras initializers inherit from this class.\nclass Initializer\nclass InputSpec : Specifies the rank, dtype and shape of every input to a layer.\nclass InputSpec\nclass KerasTensor : Symbolic tensor -- encapsulates a shape and a dtype.\nclass KerasTensor\nclass Layer : This is the class from which all layers inherit.\nclass Layer\nclass Loss : Loss base class.\nclass Loss\nclass Metric : Encapsulates metric logic and state.\nclass Metric\nclass Model : A model grouping layers into an object with training/inference features.\nclass Model\nclass Operation\nclass Operation\nclass Optimizer : A class for Tensorflow specific optimizer logic.\nclass Optimizer\nclass Quantizer\nclass Quantizer\nclass Regularizer : Regularizer base class.\nclass Regularizer\nclass Sequential : Sequential groups a linear stack of layers into a Model .\nclass Sequential\nSequential\nModel\nclass StatelessScope : Scope to prevent any update to Keras Variables.\nclass StatelessScope\nclass Variable : Represents a backend-agnostic variable in Keras.\nclass Variable\nclass name_scope : Creates a sub-namespace for variable paths.\nclass name_scope\nFunctions\nInput(...) : Used to instantiate a Keras tensor.\nInput(...)\ndevice(...)\ndevice(...)\nversion(...)\nversion(...)\nOther Members\nOther Members\nversion '3.3.3'\n'3.3.3'"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/deserialize",
    "content": "Deserializes a serialized metric class/function instance.\ntf . keras . metrics . deserialize ( config , custom_objects = None )\ntf . keras . metrics . deserialize ( config , custom_objects = None )\nArgs\nArgs\nconfig Metric configuration. custom_objects Optional dictionary mapping names (strings)\nto custom objects (classes and functions) to be\nconsidered during deserialization.\nconfig\ncustom_objects\nReturns A Keras Metric instance or a metric function.\nReturns\nMetric"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2S",
    "content": "Instantiates the EfficientNetV2S architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2S\ntf.keras.applications.efficientnet_v2.EfficientNetV2S\ntf.keras.applications.efficientnet_v2.EfficientNetV2S\ntf . keras . applications . EfficientNetV2S ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2S ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/foldl",
    "content": "DEPRECATED.\ntf . keras . backend . foldl ( fn , elems , initializer = None , name = None )\ntf . keras . backend . foldl ( fn , elems , initializer = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/is_traceback_filtering_enabled",
    "content": "Check if traceback filtering is enabled.\ntf . keras . config . is_traceback_filtering_enabled ()\ntf . keras . config . is_traceback_filtering_enabled ()\nRaw Keras tracebacks (also known as stack traces)\ninvolve many internal frames, which can be\nchallenging to read through, while not being actionable for end users.\nBy default, Keras filters internal frames in most exceptions that it\nraises, to keep traceback short, readable, and focused on what's\nactionable for you (your own code).\nSee also keras.config.enable_traceback_filtering() and keras.config.disable_traceback_filtering() .\nkeras.config.enable_traceback_filtering()\nkeras.config.disable_traceback_filtering()\nIf you have previously disabled traceback filtering via keras.config.disable_traceback_filtering() , you can re-enable it via keras.config.enable_traceback_filtering() .\nkeras.config.disable_traceback_filtering()\nkeras.config.enable_traceback_filtering()\nReturns Boolean, True if traceback filtering is enabled,\nand False otherwise.\nReturns\nTrue\nFalse"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet101",
    "content": "Instantiates the ResNet101 architecture.\nMain aliases tf.keras.applications.resnet.ResNet101\ntf.keras.applications.resnet.ResNet101\ntf.keras.applications.resnet.ResNet101\ntf . keras . applications . ResNet101 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet101 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nDeep Residual Learning for Image Recognition (CVPR 2015)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet.preprocess_input\nresnet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/binomial",
    "content": "Draw samples from a Binomial distribution.\ntf . keras . random . binomial ( shape , counts , probabilities , dtype = None , seed = None )\ntf . keras . random . binomial ( shape , counts , probabilities , dtype = None , seed = None )\nThe values are drawn from a Binomial distribution with\nspecified trial count and probability of success.\nArgs\nArgs\nshape The shape of the random values to generate. counts A number or array of numbers representing the\nnumber of trials. It must be broadcastable with probabilities . probabilities A float or array of floats representing the\nprobability of success of an individual event.\nIt must be broadcastable with counts . dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ). seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\ncounts\nprobabilities\nprobabilities\ncounts\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/clip",
    "content": "Clip (limit) the values in a tensor.\nMain aliases tf.keras.ops.numpy.clip\ntf.keras.ops.numpy.clip\ntf.keras.ops.numpy.clip\ntf . keras . ops . clip ( x , x_min , x_max )\ntf . keras . ops . clip ( x , x_min , x_max )\nGiven an interval, values outside the interval are clipped to the\ninterval edges. For example, if an interval of [0, 1] is specified,\nvalues smaller than 0 become 0, and values larger than 1 become 1.\n[0, 1]\nArgs\nArgs\nx Input tensor. x_min Minimum value. x_max Maximum value.\nx\nx_min\nx_max\nReturns The clipped tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/abs",
    "content": "DEPRECATED.\ntf . keras . backend . abs ( x )\ntf . keras . backend . abs ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/SquaredHinge",
    "content": "Computes the squared hinge loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . SquaredHinge ( reduction = 'sum_over_batch_size' , name = 'squared_hinge' )\ntf . keras . losses . SquaredHinge ( reduction = 'sum_over_batch_size' , name = 'squared_hinge' )\nloss = square ( maximum ( 1 - y_true * y_pred , 0 ))\nloss = square ( maximum ( 1 - y_true * y_pred , 0 ))\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\ny_true\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsolutePercentageError",
    "content": "Computes mean absolute percentage error between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . MeanAbsolutePercentageError ( name = 'mean_absolute_percentage_error' , dtype = None )\ntf . keras . metrics . MeanAbsolutePercentageError ( name = 'mean_absolute_percentage_error' , dtype = None )\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ))\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ))\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . MeanAbsolutePercentageError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 250000000.0 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 500000000.0\nm = keras . metrics . MeanAbsolutePercentageError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n250000000.0\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n500000000.0\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanAbsolutePercentageError ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanAbsolutePercentageError ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/pad",
    "content": "Pad a tensor.\nMain aliases tf.keras.ops.numpy.pad\ntf.keras.ops.numpy.pad\ntf.keras.ops.numpy.pad\ntf . keras . ops . pad ( x , pad_width , mode = 'constant' , constant_values = None )\ntf . keras . ops . pad ( x , pad_width , mode = 'constant' , constant_values = None )\nArgs\nArgs\nx Tensor to pad. pad_width Number of values padded to the edges of each axis. ((before_1, after_1), ...(before_N, after_N)) unique pad\nwidths for each axis. ((before, after),) yields same before and after pad for\neach axis. (pad,) or int is a shortcut for before = after = pad width for all axes. mode One of \"constant\" , \"edge\" , \"linear_ramp\" , \"maximum\" , \"mean\" , \"median\" , \"minimum\" , \"reflect\" , \"symmetric\" , \"wrap\" , \"empty\" , \"circular\" . Defaults to \"constant\" . constant_values value to pad with if mode == \"constant\" .\nDefaults to 0 . A ValueError is raised if not None and mode != \"constant\" .\nx\npad_width\n((before_1, after_1), ...(before_N, after_N))\n((before, after),)\n(pad,)\nint\nbefore = after = pad\nmode\n\"constant\"\n\"edge\"\n\"linear_ramp\"\n\"maximum\"\n\"mean\"\n\"median\"\n\"minimum\"\n\"reflect\"\n\"symmetric\"\n\"wrap\"\n\"empty\"\n\"circular\"\n\"constant\"\nconstant_values\nmode == \"constant\"\n0\nValueError\nmode != \"constant\"\nNote Torch backend only supports modes \"constant\" , \"reflect\" , \"symmetric\" and \"circular\" .\nOnly Torch backend supports \"circular\" mode.\nNote\n\"constant\"\n\"reflect\"\n\"symmetric\"\n\"circular\"\n\"circular\"\nNote Tensorflow backend only supports modes \"constant\" , \"reflect\" and \"symmetric\" .\nNote\n\"constant\"\n\"reflect\"\n\"symmetric\"\nReturns Padded tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay",
    "content": "A LearningRateSchedule that uses an exponential decay schedule.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate , staircase = False , name = 'ExponentialDecay' )\ntf . keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps , decay_rate , staircase = False , name = 'ExponentialDecay' )\nUsed in the notebooks\nImport a JAX model using JAX2TF\nMigration examples: Canned Estimators\nWhen training a model, it is often useful to lower the learning rate as\nthe training progresses. This schedule applies an exponential decay function\nto an optimizer step, given a provided initial learning rate.\nThe schedule is a 1-arg callable that produces a decayed learning\nrate when passed the current optimizer step. This can be useful for changing\nthe learning rate value across different invocations of optimizer functions.\nIt is computed as:\ndef decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps )\ndef decayed_learning_rate ( step ): return initial_learning_rate * decay_rate ^ ( step / decay_steps )\nIf the argument staircase is True , then step / decay_steps is\nan integer division and the decayed learning rate follows a\nstaircase function.\nstaircase\nTrue\nstep / decay_steps\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate.\nExample: When fitting a Keras model, decay every 100000 steps with a base\nof 0.96:\nkeras.optimizers.Optimizer\ninitial_learning_rate = 0.1 lr_schedule = keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps = 100000 , decay_rate = 0.96 , staircase = True ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = lr_schedule ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\ninitial_learning_rate = 0.1 lr_schedule = keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate , decay_steps = 100000 , decay_rate = 0.96 , staircase = True ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = lr_schedule ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\nThe learning rate schedule is also serializable and deserializable using keras.optimizers.schedules.serialize and keras.optimizers.schedules.deserialize .\nkeras.optimizers.schedules.serialize\nkeras.optimizers.schedules.deserialize\nArgs\nArgs\ninitial_learning_rate A Python float. The initial learning rate. decay_steps A Python integer. Must be positive. See the decay\ncomputation above. decay_rate A Python float. The decay rate. staircase Boolean.  If True decay the learning rate at discrete\nintervals. name String.  Optional name of the operation.  Defaults to \"ExponentialDecay \".\ninitial_learning_rate\ndecay_steps\ndecay_rate\nstaircase\nTrue\nname\n\"ExponentialDecay\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as initial_learning_rate .\nReturns\ninitial_learning_rate\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_zoom",
    "content": "DEPRECATED.\ntf . keras . preprocessing . image . random_zoom ( x , zoom_range , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )\ntf . keras . preprocessing . image . random_zoom ( x , zoom_range , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/tversky",
    "content": "Computes the Tversky loss value between y_true and y_pred .\ny_true\ny_pred\ntf . keras . losses . tversky ( y_true , y_pred , alpha = 0.5 , beta = 0.5 )\ntf . keras . losses . tversky ( y_true , y_pred , alpha = 0.5 , beta = 0.5 )\nThis loss function is weighted by the alpha and beta coefficients\nthat penalize false positives and false negatives.\nWith alpha=0.5 and beta=0.5 , the loss value becomes equivalent to\nDice Loss.\nalpha=0.5\nbeta=0.5\nArgs\nArgs\ny_true tensor of true targets. y_pred tensor of predicted targets. alpha coefficient controlling incidence of false positives. beta coefficient controlling incidence of false negatives.\ny_true\ny_pred\nalpha\nbeta\nReturns Tversky loss value.\nReturns\nSalehi et al., 2017"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ones",
    "content": "Return a new tensor of given shape and type, filled with ones.\nMain aliases tf.keras.ops.numpy.ones\ntf.keras.ops.numpy.ones\ntf.keras.ops.numpy.ones\ntf . keras . ops . ones ( shape , dtype = None )\ntf . keras . ops . ones ( shape , dtype = None )\nArgs\nArgs\nshape Shape of the new tensor. dtype Desired data type of the tensor.\nshape\ndtype\nReturns Tensor of ones with the given shape and dtype.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/HashedCrossing",
    "content": "A preprocessing layer which crosses features using the \"hashing trick\".\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . HashedCrossing ( num_bins , output_mode = 'int' , sparse = False , name = None , dtype = None , ** kwargs )\ntf . keras . layers . HashedCrossing ( num_bins , output_mode = 'int' , sparse = False , name = None , dtype = None , ** kwargs )\nThis layer performs crosses of categorical features using the \"hashing\ntrick\". Conceptually, the transformation can be thought of as:\n`hash(concatenate(features)) % num_bins.\nThis layer currently only performs crosses of scalar inputs and batches of\nscalar inputs. Valid input shapes are (batch_size, 1) , (batch_size,) and () .\n(batch_size, 1)\n(batch_size,)\n()\ntf.keras.layers.HashedCrossing\ntf.data\nArgs\nArgs\nnum_bins Number of hash bins. output_mode Specification for the output of the layer. Values can be \"int\" , or \"one_hot\" configuring the layer as follows:\nnum_bins\noutput_mode\n\"int\"\n\"one_hot\"\n\"int\" : Return the integer bin indices directly.\n\"int\"\n\"one_hot\" : Encodes each individual element in the input into an\narray the same size as num_bins , containing a 1 at the input's\nbin index. Defaults to \"int\" . sparse Boolean. Only applicable to \"one_hot\" mode and only valid\nwhen using the TensorFlow backend. If True , returns\na SparseTensor instead of a dense Tensor . Defaults to False . **kwargs Keyword arguments to construct a layer.\n\"one_hot\"\nnum_bins\n\"int\"\nsparse\n\"one_hot\"\nTrue\nSparseTensor\nTensor\nFalse\n**kwargs\nCrossing two scalar features.\nlayer = keras . layers . HashedCrossing ( num_bins = 5 ) feat1 = np . array ([ 'A' , 'B' , 'A' , 'B' , 'A' ]) feat2 = np . array ([ 101 , 101 , 101 , 102 , 102 ]) layer (( feat1 , feat2 )) array ([ 1 , 4 , 1 , 1 , 3 ])\nlayer = keras . layers . HashedCrossing (\nnum_bins = 5 )\nfeat1 = np . array ([ 'A' , 'B' , 'A' , 'B' , 'A' ])\nfeat2 = np . array ([ 101 , 101 , 101 , 102 , 102 ])\nlayer (( feat1 , feat2 ))\narray ([ 1 , 4 , 1 , 1 , 3 ])\nCrossing and one-hotting two scalar features.\nlayer = keras . layers . HashedCrossing ( num_bins = 5 , output_mode = 'one_hot' ) feat1 = np . array ([ 'A' , 'B' , 'A' , 'B' , 'A' ]) feat2 = np . array ([ 101 , 101 , 101 , 102 , 102 ]) layer (( feat1 , feat2 )) array ([[ 0. , 1. , 0. , 0. , 0. ], [ 0. , 0. , 0. , 0. , 1. ], [ 0. , 1. , 0. , 0. , 0. ], [ 0. , 1. , 0. , 0. , 0. ], [ 0. , 0. , 0. , 1. , 0. ]], dtype = float32 )\nlayer = keras . layers . HashedCrossing (\nnum_bins = 5 , output_mode = 'one_hot' )\nfeat1 = np . array ([ 'A' , 'B' , 'A' , 'B' , 'A' ])\nfeat2 = np . array ([ 101 , 101 , 101 , 102 , 102 ])\nlayer (( feat1 , feat2 ))\narray ([[ 0. , 1. , 0. , 0. , 0. ],\n[ 0. , 0. , 0. , 0. , 1. ],\n[ 0. , 1. , 0. , 0. , 0. ],\n[ 0. , 1. , 0. , 0. , 0. ],\n[ 0. , 0. , 0. , 1. , 0. ]], dtype = float32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/abs_max_quantize",
    "content": "tf . keras . quantizers . abs_max_quantize ( inputs , axis , value_range = ( - 127 , 127 ), dtype = 'int8' , epsilon = backend . epsilon () )\ntf . keras . quantizers . abs_max_quantize ( inputs , axis , value_range = ( - 127 , 127 ), dtype = 'int8' , epsilon = backend . epsilon () )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth",
    "content": "DEPRECATED.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomWidth ( factor , interpolation = 'bilinear' , seed = None , ** kwargs )\ntf . keras . layers . RandomWidth ( factor , interpolation = 'bilinear' , seed = None , ** kwargs )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision",
    "content": "Computes the precision of the predictions with respect to the labels.\nInherits From: Metric\nMetric\ntf . keras . metrics . Precision ( thresholds = None , top_k = None , class_id = None , name = None , dtype = None )\ntf . keras . metrics . Precision ( thresholds = None , top_k = None , class_id = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nClient-efficient large-model federated learning via `federated_select` and sparse aggregation\nThe metric creates two local variables, true_positives and false_positives that are used to compute the precision. This value is\nultimately returned as precision , an idempotent operation that simply\ndivides true_positives by the sum of true_positives and false_positives .\ntrue_positives\nfalse_positives\nprecision\ntrue_positives\ntrue_positives\nfalse_positives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf top_k is set, we'll calculate precision as how often on average a class\namong the top-k classes with the highest predicted values of a batch entry\nis correct and can be found in the label for that entry.\ntop_k\nIf class_id is specified, we calculate precision by considering only the\nentries in the batch for which class_id is above the threshold and/or in\nthe top-k highest predictions, and computing the fraction of them for which class_id is indeed a correct label.\nclass_id\nclass_id\nclass_id\nArgs\nArgs\nthresholds (Optional) A float value, or a Python list/tuple of float\nthreshold values in [0, 1] . A threshold is compared with\nprediction values to determine the truth value of predictions (i.e.,\nabove the threshold is True , below is False ). If used with a\nloss function that sets from_logits=True (i.e. no sigmoid applied\nto predictions), thresholds should be set to 0. One metric value\nis generated for each threshold value. If neither thresholds nor top_k are set, the default is to calculate precision with thresholds=0.5 . top_k (Optional) Unset by default. An int value specifying the top-k\npredictions to consider when calculating precision. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nthresholds\ntop_k\nthresholds=0.5\ntop_k\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . Precision () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ]) m . result () 0.6666667\nm = keras . metrics . Precision ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ])\nm . result ()\n0.6666667\nm . reset_state () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\n# With top_k=2, it will calculate precision over y_true[:2] # and y_pred[:2] m = keras . metrics . Precision ( top_k = 2 ) m . update_state ([ 0 , 0 , 1 , 1 ], [ 1 , 1 , 1 , 1 ]) m . result () 0.0\n# With top_k=2, it will calculate precision over y_true[:2]\n# and y_pred[:2]\nm = keras . metrics . Precision ( top_k = 2 )\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 1 , 1 , 1 , 1 ])\nm . result ()\n0.0\n# With top_k=4, it will calculate precision over y_true[:4] # and y_pred[:4] m = keras . metrics . Precision ( top_k = 4 ) m . update_state ([ 0 , 0 , 1 , 1 ], [ 1 , 1 , 1 , 1 ]) m . result () 0.5\n# With top_k=4, it will calculate precision over y_true[:4]\n# and y_pred[:4]\nm = keras . metrics . Precision ( top_k = 4 )\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 1 , 1 , 1 , 1 ])\nm . result ()\n0.5\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Precision ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Precision ()])\nUsage with a loss with from_logits=True :\nfrom_logits=True\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . Precision ( thresholds = 0 )])\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . Precision ( thresholds = 0 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates true positive and false positive statistics.\nArgs\ny_true The ground truth values, with the same dimensions as y_pred . Will be cast to bool . y_pred The predicted values. Each element must be in the range [0, 1] . sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nbool\ny_pred\n[0, 1]\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/divide",
    "content": "Divide arguments element-wise.\nMain aliases tf.keras.ops.numpy.divide\ntf.keras.ops.numpy.divide\ntf.keras.ops.numpy.divide\ntf . keras . ops . divide ( x1 , x2 )\ntf . keras . ops . divide ( x1 , x2 )\nkeras.ops.true_divide is an alias for this function.\nkeras.ops.true_divide\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, the quotient x1/x2 , element-wise.\nReturns\nx1/x2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler",
    "content": "Learning rate scheduler.\nInherits From: Callback\nCallback\ntf . keras . callbacks . LearningRateScheduler ( schedule , verbose = 0 )\ntf . keras . callbacks . LearningRateScheduler ( schedule , verbose = 0 )\nUsed in the notebooks\nDistributed training with Keras\nTensorBoard Scalars: Logging training metrics in Keras\nAt the beginning of every epoch, this callback gets the updated learning\nrate value from schedule function provided at __init__ , with the current\nepoch and current learning rate, and applies the updated learning rate on\nthe optimizer.\nschedule\n__init__\nArgs\nArgs\nschedule A function that takes an epoch index (integer, indexed from 0)\nand current learning rate (float) as inputs and returns a new\nlearning rate as output (float). verbose Integer. 0: quiet, 1: log update messages.\nschedule\nverbose\n# This function keeps the initial learning rate for the first ten epochs # and decreases it exponentially after that. def scheduler ( epoch , lr ): if epoch < 10 : return lr else : return lr * ops . exp ( - 0.1 ) model = keras . models . Sequential ([ keras . layers . Dense ( 10 )]) model . compile ( keras . optimizers . SGD (), loss = 'mse' ) round ( model . optimizer . learning_rate , 5 ) 0.01\n# This function keeps the initial learning rate for the first ten epochs\n# and decreases it exponentially after that.\ndef scheduler ( epoch , lr ):\nif epoch < 10 :\nreturn lr\nelse :\nreturn lr * ops . exp ( - 0.1 )\nmodel = keras . models . Sequential ([ keras . layers . Dense ( 10 )])\nmodel . compile ( keras . optimizers . SGD (), loss = 'mse' )\nround ( model . optimizer . learning_rate , 5 )\n0.01\ncallback = keras . callbacks . LearningRateScheduler ( scheduler ) history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 15 , callbacks = [ callback ], verbose = 0 ) round ( model . optimizer . learning_rate , 5 ) 0.00607\ncallback = keras . callbacks . LearningRateScheduler ( scheduler )\nhistory = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ),\nepochs = 15 , callbacks = [ callback ], verbose = 0 )\nround ( model . optimizer . learning_rate , 5 )\n0.00607\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_accuracy",
    "content": "tf . keras . metrics . sparse_categorical_accuracy ( y_true , y_pred )\ntf . keras . metrics . sparse_categorical_accuracy ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . efficientnet . decode_predictions ( preds , top = 5 )\ntf . keras . applications . efficientnet . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/dropout",
    "content": "DEPRECATED.\ntf . keras . backend . dropout ( x , level , noise_shape = None , seed = None )\ntf . keras . backend . dropout ( x , level , noise_shape = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ELU",
    "content": "Applies an Exponential Linear Unit function to an output.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ELU ( alpha = 1.0 , ** kwargs )\ntf . keras . layers . ELU ( alpha = 1.0 , ** kwargs )\nf ( x ) = alpha * ( exp ( x ) - 1. ) for x < 0 f ( x ) = x for x > = 0\nf ( x ) = alpha * ( exp ( x ) - 1. ) for x < 0 f ( x ) = x for x > = 0\nArgs\nArgs\nalpha float, slope of negative section. Defaults to 1.0 . **kwargs Base layer keyword arguments, such as name and dtype .\nalpha\n1.0\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_resnet_v2/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . inception_resnet_v2 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . inception_resnet_v2 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/max",
    "content": "Return the maximum of a tensor or maximum along an axis.\nMain aliases tf.keras.ops.numpy.max\ntf.keras.ops.numpy.max\ntf.keras.ops.numpy.max\ntf . keras . ops . max ( x , axis = None , keepdims = False , initial = None )\ntf . keras . ops . max ( x , axis = None , keepdims = False , initial = None )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which to operate. By default, flattened input\nis used. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one. Defaults to False . initial The minimum value of an output element. Defaults to None .\nx\naxis\nkeepdims\nTrue\nFalse\ninitial\nNone\nReturns Maximum of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/separable_conv2d",
    "content": "DEPRECATED.\ntf . keras . backend . separable_conv2d ( x , depthwise_kernel , pointwise_kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )\ntf . keras . backend . separable_conv2d ( x , depthwise_kernel , pointwise_kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logaddexp",
    "content": "Logarithm of the sum of exponentiations of the inputs.\nMain aliases tf.keras.ops.numpy.logaddexp\ntf.keras.ops.numpy.logaddexp\ntf.keras.ops.numpy.logaddexp\ntf . keras . ops . logaddexp ( x1 , x2 )\ntf . keras . ops . logaddexp ( x1 , x2 )\nCalculates log(exp(x1) + exp(x2)) .\nlog(exp(x1) + exp(x2))\nArgs\nArgs\nx1 Input tensor. x2 Input tensor.\nx1\nx2\nReturns Output tensor, element-wise logarithm of the sum of exponentiations\nof the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar100/load_data",
    "content": "Loads the CIFAR100 dataset.\ntf . keras . datasets . cifar100 . load_data ( label_mode = 'fine' )\ntf . keras . datasets . cifar100 . load_data ( label_mode = 'fine' )\nThis is a dataset of 50,000 32x32 color training images and\n10,000 test images, labeled over 100 fine-grained classes that are\ngrouped into 20 coarse-grained classes. See more info at the CIFAR homepage .\nArgs\nArgs\nlabel_mode one of \"fine\" , \"coarse\" .\nIf it is \"fine\" , the category labels\nare the fine-grained labels, and if it is \"coarse\" ,\nthe output labels are the coarse-grained superclasses.\nlabel_mode\n\"fine\"\n\"coarse\"\n\"fine\"\n\"coarse\"\nReturns Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train : uint8 NumPy array of grayscale image data with shapes (50000, 32, 32, 3) , containing the training data. Pixel values range\n  from 0 to 255.\nx_train\nuint8\n(50000, 32, 32, 3)\ny_train : uint8 NumPy array of labels (integers in range 0-99)\n  with shape (50000, 1) for the training data.\ny_train\nuint8\n(50000, 1)\nx_test : uint8 NumPy array of grayscale image data with shapes (10000, 32, 32, 3) , containing the test data. Pixel values range\n  from 0 to 255.\nx_test\nuint8\n(10000, 32, 32, 3)\ny_test : uint8 NumPy array of labels (integers in range 0-99)\n  with shape (10000, 1) for the test data.\ny_test\nuint8\n(10000, 1)\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . cifar100 . load_data () assert x_train . shape == ( 50000 , 32 , 32 , 3 ) assert x_test . shape == ( 10000 , 32 , 32 , 3 ) assert y_train . shape == ( 50000 , 1 ) assert y_test . shape == ( 10000 , 1 )\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . cifar100 . load_data () assert x_train . shape == ( 50000 , 32 , 32 , 3 ) assert x_test . shape == ( 10000 , 32 , 32 , 3 ) assert y_train . shape == ( 50000 , 1 ) assert y_test . shape == ( 10000 , 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/TimeseriesGenerator",
    "content": "Utility class for generating batches of temporal data.\nInherits From: PyDataset\nPyDataset\ntf . keras . preprocessing . sequence . TimeseriesGenerator ( data , targets , length , sampling_rate = 1 , stride = 1 , start_index = 0 , end_index = None , shuffle = False , reverse = False , batch_size = 128 )\ntf . keras . preprocessing . sequence . TimeseriesGenerator ( data , targets , length , sampling_rate = 1 , stride = 1 , start_index = 0 , end_index = None , shuffle = False , reverse = False , batch_size = 128 )\nDEPRECATED.\nThis class takes in a sequence of data-points gathered at\nequal intervals, along with time series parameters such as\nstride, length of history, etc., to produce batches for\ntraining/validation.\nArguments\nArguments\ndata Indexable generator (such as list or Numpy array)\ncontaining consecutive data points (timesteps).\nThe data should be at 2D, and axis 0 is expected\nto be the time dimension. targets Targets corresponding to timesteps in data .\nIt should have same length as data . length Length of the output sequences (in number of timesteps). sampling_rate Period between successive individual timesteps\nwithin sequences. For rate r , timesteps data[i] , data[i-r] , ... data[i - length] are used for create a sample sequence. stride Period between successive output sequences.\nFor stride s , consecutive output samples would\nbe centered around data[i] , data[i+s] , data[i+2*s] , etc. start_index Data points earlier than start_index will not be used\nin the output sequences. This is useful to reserve part of the\ndata for test or validation. end_index Data points later than end_index will not be used\nin the output sequences. This is useful to reserve part of the\ndata for test or validation. shuffle Whether to shuffle output samples,\nor instead draw them in chronological order. reverse Boolean: if true , timesteps in each output sample will be\nin reverse chronological order. batch_size Number of timeseries samples in each batch\n(except maybe the last one).\ndata\ntargets\ndata\ndata\nlength\nsampling_rate\nr\ndata[i]\ndata[i-r]\ndata[i - length]\nstride\ns\ndata[i]\ndata[i+s]\ndata[i+2*s]\nstart_index\nstart_index\nend_index\nend_index\nshuffle\nreverse\ntrue\nbatch_size\nReturns A PyDataset instance.\nReturns\nAttributes\nAttributes\nmax_queue_size\nmax_queue_size\nnum_batches Number of batches in the PyDataset. use_multiprocessing\nnum_batches\nuse_multiprocessing\nworkers\nworkers\nMethods\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the TimeseriesGenerator configuration as Python dictionary.\nReturns A Python dictionary with the TimeseriesGenerator configuration.\non_epoch_end\non_epoch_end\nView source\non_epoch_end ()\non_epoch_end ()\nMethod called at the end of every epoch.\nto_json\nto_json\nView source\nto_json ( ** kwargs )\nto_json ( ** kwargs )\nReturns a JSON string containing the generator's configuration.\nArgs\n**kwargs Additional keyword arguments to be passed\nto json.dumps() .\n**kwargs\njson.dumps()\nReturns A JSON string containing the tokenizer configuration.\n__getitem__\n__getitem__\nView source\n__getitem__ ( index )\n__getitem__ ( index )\nGets batch at position index .\nindex\nArgs\nindex position of the batch in the PyDataset.\nindex\nReturns A batch\n__len__\n__len__\nView source\n__len__ ()\n__len__ ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSLE",
    "content": "Computes the mean squared logarithmic error between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.losses.msle , tf.keras.metrics.MSLE , tf.keras.metrics.msle\ntf.keras.losses.msle , tf.keras.metrics.MSLE , tf.keras.metrics.msle\ntf.keras.losses.msle\ntf.keras.metrics.MSLE\ntf.keras.metrics.msle\ntf . keras . losses . MSLE ( y_true , y_pred )\ntf . keras . losses . MSLE ( y_true , y_pred )\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )), axis =- 1 )\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )), axis =- 1 )\nNote that y_pred and y_true cannot be less or equal to 0. Negative\nvalues and 0 values will be replaced with keras.backend.epsilon() (default to 1e-7 ).\ny_pred\ny_true\nkeras.backend.epsilon()\n1e-7\nArgs\nArgs\ny_true Ground truth values with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Mean squared logarithmic error values with shape = [batch_size, d0, ..\ndN-1] .\nReturns\n[batch_size, d0, ..\ndN-1]\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . mean_squared_logarithmic_error ( y_true , y_pred )\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . mean_squared_logarithmic_error ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data",
    "content": "Loads the MNIST dataset.\ntf . keras . datasets . mnist . load_data ( path = 'mnist.npz' )\ntf . keras . datasets . mnist . load_data ( path = 'mnist.npz' )\nUsed in the notebooks\nImport a JAX model using JAX2TF\nMixed precision\nMulti-GPU and distributed training\nWeight clustering in Keras example\nPruning in Keras example\nCustom training loop with Keras and MultiWorkerMirroredStrategy\nMulti-worker training with Keras\nConvolutional Variational Autoencoder\nDeep Convolutional Generative Adversarial Network\nSave and load models\nThis is a dataset of 60,000 28x28 grayscale images of the 10 digits,\nalong with a test set of 10,000 images.\nMore info can be found at the MNIST homepage .\nArgs\nArgs\npath path where to cache the dataset locally\n(relative to ~/.keras/datasets ).\npath\n~/.keras/datasets\nReturns Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train : uint8 NumPy array of grayscale image data with shapes (60000, 28, 28) , containing the training data. Pixel values range\n  from 0 to 255.\nx_train\nuint8\n(60000, 28, 28)\ny_train : uint8 NumPy array of digit labels (integers in range 0-9)\n  with shape (60000,) for the training data.\ny_train\nuint8\n(60000,)\nx_test : uint8 NumPy array of grayscale image data with shapes (10000, 28, 28) , containing the test data. Pixel values range\n  from 0 to 255.\nx_test\nuint8\n(10000, 28, 28)\ny_test : uint8 NumPy array of digit labels (integers in range 0-9)\n  with shape (10000,) for the test data.\ny_test\nuint8\n(10000,)\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . mnist . load_data () assert x_train . shape == ( 60000 , 28 , 28 ) assert x_test . shape == ( 10000 , 28 , 28 ) assert y_train . shape == ( 60000 ,) assert y_test . shape == ( 10000 ,)\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . mnist . load_data () assert x_train . shape == ( 60000 , 28 , 28 ) assert x_test . shape == ( 10000 , 28 , 28 ) assert y_train . shape == ( 60000 ,) assert y_test . shape == ( 10000 ,)\nYann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\nwhich is a derivative work from original NIST datasets.\nMNIST dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/scatter",
    "content": "Returns a tensor of shape shape where indices are set to values .\nshape\nindices\nvalues\ntf . keras . ops . scatter ( indices , values , shape )\ntf . keras . ops . scatter ( indices , values , shape )\nAt a high level, this operation does zeros[indices] = updates and\nreturns the output. It is equivalent to:\nzeros[indices] = updates\nzeros = keras . ops . zeros ( shape ) output = keras . ops . scatter_update ( zeros , indices , values )\nzeros = keras . ops . zeros ( shape ) output = keras . ops . scatter_update ( zeros , indices , values )\nArgs\nArgs\nindices A tensor or list/tuple specifying\nindices for the values in values . values A tensor, the values to be set at indices . shape Shape of the output tensor.\nindices\nvalues\nvalues\nindices\nshape\nindices = [[ 0 , 1 ], [ 1 , 1 ]] values = np . array ([ 1. , 1. ]) keras . ops . scatter ( indices , values , shape = ( 2 , 2 )) array ([[ 0. , 1. ], [ 0. , 1. ]])\nindices = [[ 0 , 1 ], [ 1 , 1 ]]\nvalues = np . array ([ 1. , 1. ])\nkeras . ops . scatter ( indices , values , shape = ( 2 , 2 ))\narray ([[ 0. , 1. ],\n[ 0. , 1. ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Poisson",
    "content": "Computes the Poisson metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . Poisson ( name = 'poisson' , dtype = None )\ntf . keras . metrics . Poisson ( name = 'poisson' , dtype = None )\nmetric = y_pred - y_true * log ( y_pred )\nmetric = y_pred - y_true * log ( y_pred )\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . Poisson () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.49999997\nm = keras . metrics . Poisson ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.49999997\nm . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 0.99999994\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.99999994\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . Poisson ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . Poisson ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/einsum",
    "content": "Evaluates the Einstein summation convention on the operands.\nMain aliases tf.keras.ops.numpy.einsum\ntf.keras.ops.numpy.einsum\ntf.keras.ops.numpy.einsum\ntf . keras . ops . einsum ( subscripts , * operands )\ntf . keras . ops . einsum ( subscripts , * operands )\nArgs\nArgs\nsubscripts Specifies the subscripts for summation as comma separated\nlist of subscript labels. An implicit (classical Einstein\nsummation) calculation is performed unless the explicit indicator -> is included as well as subscript labels of the precise\noutput form. operands The operands to compute the Einstein sum of.\nsubscripts\n->\noperands\nReturns The calculation based on the Einstein summation convention.\nReturns\nfrom keras.src import ops a = ops . arange ( 25 ) . reshape ( 5 , 5 ) b = ops . arange ( 5 ) c = ops . arange ( 6 ) . reshape ( 2 , 3 )\nfrom keras.src import ops\na = ops . arange ( 25 ) . reshape ( 5 , 5 )\nb = ops . arange ( 5 )\nc = ops . arange ( 6 ) . reshape ( 2 , 3 )\nops . einsum ( \"ii\" , a ) 60 ops . einsum ( a , [ 0 , 0 ]) 60 ops . trace ( a ) 60\nops . einsum ( \"ii\" , a )\n60\nops . einsum ( a , [ 0 , 0 ])\n60\nops . trace ( a )\n60\nops . einsum ( \"ii -> i\" , a ) array ([ 0 , 6 , 12 , 18 , 24 ]) ops . einsum ( a , [ 0 , 0 ], [ 0 ]) array ([ 0 , 6 , 12 , 18 , 24 ]) ops . diag ( a ) array ([ 0 , 6 , 12 , 18 , 24 ])\nops . einsum ( \"ii -> i\" , a )\narray ([ 0 , 6 , 12 , 18 , 24 ])\nops . einsum ( a , [ 0 , 0 ], [ 0 ])\narray ([ 0 , 6 , 12 , 18 , 24 ])\nops . diag ( a )\narray ([ 0 , 6 , 12 , 18 , 24 ])\nops . einsum ( \"ij -> i\" , a ) array ([ 10 , 35 , 60 , 85 , 110 ]) ops . einsum ( a , [ 0 , 1 ], [ 0 ]) array ([ 10 , 35 , 60 , 85 , 110 ]) ops . sum ( a , axis = 1 ) array ([ 10 , 35 , 60 , 85 , 110 ])\nops . einsum ( \"ij -> i\" , a )\narray ([ 10 , 35 , 60 , 85 , 110 ])\nops . einsum ( a , [ 0 , 1 ], [ 0 ])\narray ([ 10 , 35 , 60 , 85 , 110 ])\nops . sum ( a , axis = 1 )\narray ([ 10 , 35 , 60 , 85 , 110 ])\nFor higher dimensional tensors summing a single axis can be done\nwith ellipsis:\nops . einsum ( \"...j -> ...\" , a ) array ([ 10 , 35 , 60 , 85 , 110 ]) np . einsum ( a , [ ... , 1 ], [ ... ]) array ([ 10 , 35 , 60 , 85 , 110 ])\nops . einsum ( \"...j -> ...\" , a )\narray ([ 10 , 35 , 60 , 85 , 110 ])\nnp . einsum ( a , [ ... , 1 ], [ ... ])\narray ([ 10 , 35 , 60 , 85 , 110 ])\nCompute a matrix transpose or reorder any number of axes:\nops . einsum ( \"ji\" , c ) array ([[ 0 , 3 ], [ 1 , 4 ], [ 2 , 5 ]]) ops . einsum ( \"ij -> ji\" , c ) array ([[ 0 , 3 ], [ 1 , 4 ], [ 2 , 5 ]]) ops . einsum ( c , [ 1 , 0 ]) array ([[ 0 , 3 ], [ 1 , 4 ], [ 2 , 5 ]]) ops . transpose ( c ) array ([[ 0 , 3 ], [ 1 , 4 ], [ 2 , 5 ]])\nops . einsum ( \"ji\" , c )\narray ([[ 0 , 3 ],\n[ 1 , 4 ],\n[ 2 , 5 ]])\nops . einsum ( \"ij -> ji\" , c )\narray ([[ 0 , 3 ],\n[ 1 , 4 ],\n[ 2 , 5 ]])\nops . einsum ( c , [ 1 , 0 ])\narray ([[ 0 , 3 ],\n[ 1 , 4 ],\n[ 2 , 5 ]])\nops . transpose ( c )\narray ([[ 0 , 3 ],\n[ 1 , 4 ],\n[ 2 , 5 ]])\nMatrix vector multiplication:\nops . einsum ( \"ij, j\" , a , b ) array ([ 30 , 80 , 130 , 180 , 230 ]) ops . einsum ( a , [ 0 , 1 ], b , [ 1 ]) array ([ 30 , 80 , 130 , 180 , 230 ]) ops . einsum ( \"...j, j\" , a , b ) array ([ 30 , 80 , 130 , 180 , 230 ])\nops . einsum ( \"ij, j\" , a , b )\narray ([ 30 , 80 , 130 , 180 , 230 ])\nops . einsum ( a , [ 0 , 1 ], b , [ 1 ])\narray ([ 30 , 80 , 130 , 180 , 230 ])\nops . einsum ( \"...j, j\" , a , b )\narray ([ 30 , 80 , 130 , 180 , 230 ])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/KerasTensor",
    "content": "Symbolic tensor -- encapsulates a shape and a dtype.\nCompat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.KerasTensor\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.KerasTensor\ntf.compat.v1.keras.KerasTensor\ntf . keras . KerasTensor ( shape , dtype = 'float32' , sparse = False , record_history = True , name = None )\ntf . keras . KerasTensor ( shape , dtype = 'float32' , sparse = False , record_history = True , name = None )\nYou can use KerasTensor instances to build computation\ngraphs of Keras operations, such as keras.Function objects or Functional keras.models.Model objects.\nKerasTensor\nkeras.Function\nkeras.models.Model\nx = keras . KerasTensor ( shape = ( 3 , 4 ), dtype = \"float32\" ) x . shape ( 3 , 4 ) x . dtype float32\nx = keras . KerasTensor ( shape = ( 3 , 4 ), dtype = \"float32\" )\nx . shape\n( 3 , 4 )\nx . dtype\nfloat32\nCalling a Keras operation (including a layer or a model)\non a KerasTensor instance will return another KerasTensor instance with the appropriate shape and dtype. This is\ncalled a \"symbolic call\" (since there is no actual data\ninvolved). The computation of the correct output shape and\ndtype is called \"static shape inference\".\nKerasTensor\nKerasTensor\nAttributes\nAttributes\nndim\nndim\nMethods\nreshape\nreshape\nView source\nreshape ( newshape )\nreshape ( newshape )\nsqueeze\nsqueeze\nView source\nsqueeze ( axis = None )\nsqueeze ( axis = None )\n__abs__\n__abs__\nView source\n__abs__ ()\n__abs__ ()\n__add__\n__add__\nView source\n__add__ ( other )\n__add__ ( other )\n__and__\n__and__\nView source\n__and__ ( other )\n__and__ ( other )\n__array__\n__array__\nView source\n__array__ ()\n__array__ ()\n__bool__\n__bool__\nView source\n__bool__ ()\n__bool__ ()\n__div__\n__div__\nView source\n__div__ ( other )\n__div__ ( other )\n__floordiv__\n__floordiv__\nView source\n__floordiv__ ( other )\n__floordiv__ ( other )\n__ge__\n__ge__\nView source\n__ge__ ( other )\n__ge__ ( other )\nReturn self>=value.\n__getitem__\n__getitem__\nView source\n__getitem__ ( key )\n__getitem__ ( key )\n__gt__\n__gt__\nView source\n__gt__ ( other )\n__gt__ ( other )\nReturn self>value.\n__invert__\n__invert__\nView source\n__invert__ ()\n__invert__ ()\n__iter__\n__iter__\nView source\n__iter__ ()\n__iter__ ()\n__le__\n__le__\nView source\n__le__ ( other )\n__le__ ( other )\nReturn self<=value.\n__lt__\n__lt__\nView source\n__lt__ ( other )\n__lt__ ( other )\nReturn self<value.\n__matmul__\n__matmul__\nView source\n__matmul__ ( other )\n__matmul__ ( other )\n__mod__\n__mod__\nView source\n__mod__ ( other )\n__mod__ ( other )\n__mul__\n__mul__\nView source\n__mul__ ( other )\n__mul__ ( other )\n__ne__\n__ne__\nView source\n__ne__ ( other )\n__ne__ ( other )\nReturn self!=value.\n__neg__\n__neg__\nView source\n__neg__ ()\n__neg__ ()\n__or__\n__or__\nView source\n__or__ ( other )\n__or__ ( other )\n__pow__\n__pow__\nView source\n__pow__ ( other )\n__pow__ ( other )\n__radd__\n__radd__\nView source\n__radd__ ( other )\n__radd__ ( other )\n__rand__\n__rand__\nView source\n__rand__ ( other )\n__rand__ ( other )\n__rdiv__\n__rdiv__\nView source\n__rdiv__ ( other )\n__rdiv__ ( other )\n__rfloordiv__\n__rfloordiv__\nView source\n__rfloordiv__ ( other )\n__rfloordiv__ ( other )\n__rmatmul__\n__rmatmul__\nView source\n__rmatmul__ ( other )\n__rmatmul__ ( other )\n__rmod__\n__rmod__\nView source\n__rmod__ ( other )\n__rmod__ ( other )\n__rmul__\n__rmul__\nView source\n__rmul__ ( other )\n__rmul__ ( other )\n__ror__\n__ror__\nView source\n__ror__ ( other )\n__ror__ ( other )\n__rpow__\n__rpow__\nView source\n__rpow__ ( other )\n__rpow__ ( other )\n__rsub__\n__rsub__\nView source\n__rsub__ ( other )\n__rsub__ ( other )\n__rtruediv__\n__rtruediv__\nView source\n__rtruediv__ ( other )\n__rtruediv__ ( other )\n__rxor__\n__rxor__\nView source\n__rxor__ ( other )\n__rxor__ ( other )\n__sub__\n__sub__\nView source\n__sub__ ( other )\n__sub__ ( other )\n__truediv__\n__truediv__\nView source\n__truediv__ ( other )\n__truediv__ ( other )\n__xor__\n__xor__\nView source\n__xor__ ( other )\n__xor__ ( other )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Layer",
    "content": "This is the class from which all layers inherit.\nInherits From: Operation\nOperation\nMain aliases tf.keras.layers.Layer Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Layer\ntf.keras.layers.Layer\ntf.keras.layers.Layer\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Layer\ntf.compat.v1.keras.Layer\ntf . keras . Layer ( * , activity_regularizer = None , trainable = True , dtype = None , autocast = True , name = None , ** kwargs )\ntf . keras . Layer ( * , activity_regularizer = None , trainable = True , dtype = None , autocast = True , name = None , ** kwargs )\nUsed in the notebooks\nUse TF1.x models in TF2 workflows\nValidating correctness & numerical equivalence\nIntroduction to modules, layers, and models\nExtension types\nDebug a TensorFlow 2 migrated training pipeline\nLoad text\nScalable model compression\nTransfer learning with YAMNet for environmental sound classification\nCustom layers\nData augmentation\nA layer is a callable object that takes as input one or more tensors and\nthat outputs one or more tensors. It involves computation , defined\nin the call() method, and a state (weight variables). State can be\ncreated:\ncall()\nin __init__() , for instance via self.add_weight() ;\n__init__()\nself.add_weight()\nin the optional build() method, which is invoked by the first __call__() to the layer, and supplies the shape(s) of the input(s),\nwhich may not have been known at initialization time.\nbuild()\n__call__()\nLayers are recursively composable: If you assign a Layer instance as an\nattribute of another Layer, the outer layer will start tracking the weights\ncreated by the inner layer. Nested layers should be instantiated in the __init__() method or build() method.\n__init__()\nbuild()\nUsers will just instantiate a layer and then treat it as a callable.\nArgs\nArgs\ntrainable Boolean, whether the layer's variables should be trainable. name String name of the layer. dtype The dtype of the layer's computations and weights. Can also be a keras.DTypePolicy ,\nwhich allows the computation and\nweight dtype to differ. Defaults to None . None means to use keras.config.dtype_policy() ,\nwhich is a float32 policy unless set to different value\n(via keras.config.set_dtype_policy() ).\ntrainable\nname\ndtype\nkeras.DTypePolicy\nNone\nNone\nkeras.config.dtype_policy()\nfloat32\nkeras.config.set_dtype_policy()\nWe recommend that descendants of Layer implement the following methods:\nLayer\n__init__() : Defines custom layer attributes, and creates layer weights\nthat do not depend on input shapes, using add_weight() ,\nor other state.\n__init__()\nadd_weight()\nbuild(self, input_shape) : This method can be used to create weights that\ndepend on the shape(s) of the input(s), using add_weight() , or other\nstate. __call__() will automatically build the layer\n(if it has not been built yet) by calling build() .\nbuild(self, input_shape)\nadd_weight()\n__call__()\nbuild()\ncall(self, *args, **kwargs) : Called in __call__ after making\nsure build() has been called. call() performs the logic of applying\nthe layer to the input arguments.\nTwo reserved keyword arguments you can optionally use in call() are:\n    1. training (boolean, whether the call is in inference mode or\n        training mode).\n    2. mask (boolean tensor encoding masked timesteps in the input,\n        used e.g. in RNN layers).\nA typical signature for this method is call(self, inputs) , and user\ncould optionally add training and mask if the layer need them.\ncall(self, *args, **kwargs)\n__call__\nbuild()\ncall()\ncall()\ntraining\nmask\ncall(self, inputs)\ntraining\nmask\nget_config(self) : Returns a dictionary containing the configuration\nused to initialize this layer. If the keys differ from the arguments\nin __init__() , then override from_config(self) as well.\nThis method is used when saving\nthe layer or a model that contains this layer.\nget_config(self)\n__init__()\nfrom_config(self)\nHere's a basic example: a layer with two variables, w and b ,\nthat returns y = w . x + b .\nIt shows how to implement build() and call() .\nVariables set as attributes of a layer are tracked as weights\nof the layers (in layer.weights ).\nw\nb\ny = w . x + b\nbuild()\ncall()\nlayer.weights\nclass SimpleDense ( Layer ): def __init__ ( self , units = 32 ): super () . __init__ () self . units = units # Create the state of the layer (weights) def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = \"glorot_uniform\" , trainable = True , name = \"kernel\" , ) self . bias = self . add_weight ( shape = ( self . units ,), initializer = \"zeros\" , trainable = True , name = \"bias\" , ) # Defines the computation def call ( self , inputs ): return ops . matmul ( inputs , self . kernel ) + self . bias # Instantiates the layer. linear_layer = SimpleDense ( 4 ) # This will also call `build(input_shape)` and create the weights. y = linear_layer ( ops . ones (( 2 , 2 ))) assert len ( linear_layer . weights ) == 2 # These weights are trainable, so they're listed in `trainable_weights`: assert len ( linear_layer . trainable_weights ) == 2\nclass SimpleDense ( Layer ): def __init__ ( self , units = 32 ): super () . __init__ () self . units = units # Create the state of the layer (weights) def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = \"glorot_uniform\" , trainable = True , name = \"kernel\" , ) self . bias = self . add_weight ( shape = ( self . units ,), initializer = \"zeros\" , trainable = True , name = \"bias\" , ) # Defines the computation def call ( self , inputs ): return ops . matmul ( inputs , self . kernel ) + self . bias # Instantiates the layer. linear_layer = SimpleDense ( 4 ) # This will also call `build(input_shape)` and create the weights. y = linear_layer ( ops . ones (( 2 , 2 ))) assert len ( linear_layer . weights ) == 2 # These weights are trainable, so they're listed in `trainable_weights`: assert len ( linear_layer . trainable_weights ) == 2\nBesides trainable weights, updated via backpropagation during training,\nlayers can also have non-trainable weights. These weights are meant to\nbe updated manually during call() . Here's a example layer that computes\nthe running sum of its inputs:\ncall()\nclass ComputeSum ( Layer ): def __init__ ( self , input_dim ): super ( ComputeSum , self ) . __init__ () # Create a non-trainable weight. self . total = self . add_weight ( shape = (), initializer = \"zeros\" , trainable = False , name = \"total\" , ) def call ( self , inputs ): self . total . assign ( self . total + ops . sum ( inputs )) return self . total my_sum = ComputeSum ( 2 ) x = ops . ones (( 2 , 2 )) y = my_sum ( x ) assert my_sum . weights == [ my_sum . total ] assert my_sum . non_trainable_weights == [ my_sum . total ] assert my_sum . trainable_weights == []\nclass ComputeSum ( Layer ): def __init__ ( self , input_dim ): super ( ComputeSum , self ) . __init__ () # Create a non-trainable weight. self . total = self . add_weight ( shape = (), initializer = \"zeros\" , trainable = False , name = \"total\" , ) def call ( self , inputs ): self . total . assign ( self . total + ops . sum ( inputs )) return self . total my_sum = ComputeSum ( 2 ) x = ops . ones (( 2 , 2 )) y = my_sum ( x ) assert my_sum . weights == [ my_sum . total ] assert my_sum . non_trainable_weights == [ my_sum . total ] assert my_sum . trainable_weights == []\nAttributes\nAttributes\nname The name of the layer (string). dtype Dtype of the layer's weights. Alias of layer.variable_dtype . variable_dtype Dtype of the layer's weights. compute_dtype The dtype of the layer's computations.\nLayers automatically cast inputs to this dtype, which causes\nthe computations and output to also be in this dtype.\nWhen mixed precision is used with a keras.DTypePolicy , this will be different\nthan variable_dtype . trainable_weights List of variables to be included in backprop. non_trainable_weights List of variables that should not be\nincluded in backprop. weights The concatenation of the lists trainable_weights and\nnon_trainable_weights (in this order). trainable Whether the layer should be trained (boolean), i.e.\nwhether its potentially-trainable weights should be returned\nas part of layer.trainable_weights . input_spec Optional (list of) InputSpec object(s) specifying the\nconstraints on inputs that can be accepted by the layer. dtype_policy\nname\ndtype\nlayer.variable_dtype\nvariable_dtype\ncompute_dtype\nkeras.DTypePolicy\nvariable_dtype\ntrainable_weights\nnon_trainable_weights\nweights\ntrainable\nlayer.trainable_weights\ninput_spec\nInputSpec\ndtype_policy\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. input_dtype The dtype layer inputs should be converted to. losses List of scalar losses from add_loss , regularizers and sublayers. metrics List of all metrics. metrics_variables List of all metric variables. non_trainable_variables List of all non-trainable layer state.\ninput_dtype\nlosses\nadd_loss\nmetrics\nmetrics_variables\nnon_trainable_variables\nThis extends layer.non_trainable_weights to include all state used by\nthe layer including state for metrics and SeedGenerator s. output Retrieves the output tensor(s) of a layer.\nlayer.non_trainable_weights\nSeedGenerator\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. supports_masking Whether this layer supports computing a mask using compute_mask . trainable_variables List of all trainable layer state.\nsupports_masking\ncompute_mask\ntrainable_variables\nThis is equivalent to layer.trainable_weights . variables List of all layer state, including random seeds.\nlayer.trainable_weights\nvariables\nThis extends layer.weights to include all state used by the layer\nincluding SeedGenerator s.\nlayer.weights\nSeedGenerator\nNote that metrics variables are not included here, use metrics_variables to visit all the metric variables.\nmetrics_variables\nMethods\nadd_loss\nadd_loss\nView source\nadd_loss ( loss )\nadd_loss ( loss )\nCan be called inside of the call() method to add a scalar loss.\ncall()\nclass MyLayer ( Layer ): ... def call ( self , x ): self . add_loss ( ops . sum ( x )) return x\nclass MyLayer ( Layer ): ... def call ( self , x ): self . add_loss ( ops . sum ( x )) return x\nadd_metric\nadd_metric\nView source\nadd_metric ()\nadd_metric ()\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , trainable = True , autocast = True , regularizer = None , constraint = None , name = None )\nadd_variable ( shape , initializer , dtype = None , trainable = True , autocast = True , regularizer = None , constraint = None , name = None )\nAdd a weight variable to the layer.\nAlias of add_weight() .\nadd_weight()\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = None , initializer = None , dtype = None , trainable = True , autocast = True , regularizer = None , constraint = None , aggregation = 'mean' , name = None )\nadd_weight ( shape = None , initializer = None , dtype = None , trainable = True , autocast = True , regularizer = None , constraint = None , aggregation = 'mean' , name = None )\nAdd a weight variable to the layer.\nArgs\nshape Shape tuple for the variable. Must be fully-defined\n(no None entries). Defaults to () (scalar) if unspecified. initializer Initializer object to use to populate the initial\nvariable value, or string name of a built-in initializer\n(e.g. \"random_normal\" ). If unspecified, defaults to \"glorot_uniform\" for floating-point variables and to \"zeros\" for all other types (e.g. int, bool). dtype Dtype of the variable to create, e.g. \"float32\" . If\nunspecified, defaults to the layer's variable dtype\n(which itself defaults to \"float32\" if unspecified). trainable Boolean, whether the variable should be trainable via\nbackprop or whether its updates are managed manually. Defaults\nto True . autocast Boolean, whether to autocast layers variables when\naccessing them. Defaults to True . regularizer Regularizer object to call to apply penalty on the\nweight. These penalties are summed into the loss function\nduring optimization. Defaults to None . constraint Contrainst object to call on the variable after any\noptimizer update, or string name of a built-in constraint.\nDefaults to None . aggregation String, one of 'mean' , 'sum' , 'only_first_replica' . Annotates the variable with the type\nof multi-replica aggregation to be used for this variable\nwhen writing custom data parallel training loops. name String name of the variable. Useful for debugging purposes.\nshape\nNone\n()\ninitializer\n\"random_normal\"\n\"glorot_uniform\"\n\"zeros\"\ndtype\n\"float32\"\n\"float32\"\ntrainable\nTrue\nautocast\nTrue\nregularizer\nNone\nconstraint\nNone\naggregation\n'mean'\n'sum'\n'only_first_replica'\nname\nbuild\nbuild\nView source\nbuild ( input_shape )\nbuild ( input_shape )\nbuild_from_config\nbuild_from_config\nView source\nbuild_from_config ( config )\nbuild_from_config ( config )\nBuilds the layer's states with the supplied config dict.\nBy default, this method calls the build(config[\"input_shape\"]) method,\nwhich creates weights based on the layer's input shape in the supplied\nconfig. If your config contains other information needed to load the\nlayer's state, you should override this method.\nbuild(config[\"input_shape\"])\nArgs\nconfig Dict containing the input shape associated with this layer.\nconfig\ncall\ncall\nView source\ncall ( * args , ** kwargs )\ncall ( * args , ** kwargs )\ncompute_mask\ncompute_mask\nView source\ncompute_mask ( inputs , previous_mask )\ncompute_mask ( inputs , previous_mask )\ncompute_output_shape\ncompute_output_shape\nView source\ncompute_output_shape ( * args , ** kwargs )\ncompute_output_shape ( * args , ** kwargs )\ncompute_output_spec\ncompute_output_spec\nView source\ncompute_output_spec ( * args , ** kwargs )\ncompute_output_spec ( * args , ** kwargs )\ncount_params\ncount_params\nView source\ncount_params ()\ncount_params ()\nCount the total number of scalars composing the weights.\nReturns An integer count.\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_build_config\nget_build_config\nView source\nget_build_config ()\nget_build_config ()\nReturns a dictionary with the layer's input shape.\nThis method returns a config dict that can be used by build_from_config(config) to create all states (e.g. Variables and\nLookup tables) needed by the layer.\nbuild_from_config(config)\nBy default, the config only contains the input shape that the layer\nwas built with. If you're writing a custom layer that creates state in\nan unusual way, you should override this method to make sure this state\nis already created when Keras attempts to load its value upon model\nloading.\nReturns A dict containing the input shape associated with the layer.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the object.\nAn object config is a Python dictionary (serializable)\ncontaining the information needed to re-instantiate it.\nget_weights\nget_weights\nView source\nget_weights ()\nget_weights ()\nReturn the values of layer.weights as a list of NumPy arrays.\nlayer.weights\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nLoads the state of the layer.\nYou can override this method to take full control of how the state of\nthe layer is loaded upon calling keras.models.load_model() .\nkeras.models.load_model()\nArgs\nstore Dict from which the state of the model will be loaded.\nstore\nquantize\nquantize\nView source\nquantize ( mode )\nquantize ( mode )\nquantized_call\nquantized_call\nView source\nquantized_call ( * args , ** kwargs )\nquantized_call ( * args , ** kwargs )\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nSaves the state of the layer.\nYou can override this method to take full control of how the state of\nthe layer is saved upon calling model.save() .\nmodel.save()\nArgs\nstore Dict where the state of the model will be saved.\nstore\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSets the values of layer.weights from a list of NumPy arrays.\nlayer.weights\nstateless_call\nstateless_call\nView source\nstateless_call ( trainable_variables , non_trainable_variables , * args , return_losses = False , ** kwargs )\nstateless_call ( trainable_variables , non_trainable_variables , * args , return_losses = False , ** kwargs )\nCall the layer without any side effects.\nArgs\ntrainable_variables List of trainable variables of the model. non_trainable_variables List of non-trainable variables of the\nmodel. *args Positional arguments to be passed to call() . return_losses If True , stateless_call() will return the list of\nlosses created during call() as part of its return values. **kwargs Keyword arguments to be passed to call() .\ntrainable_variables\nnon_trainable_variables\n*args\ncall()\nreturn_losses\nTrue\nstateless_call()\ncall()\n**kwargs\ncall()\nReturns A tuple. By default, returns (outputs, non_trainable_variables) .\nIf return_losses = True , then returns (outputs, non_trainable_variables, losses) .\n(outputs, non_trainable_variables)\nreturn_losses = True\n(outputs, non_trainable_variables, losses)\nnon_trainable_variables\nBatchNormalization\nMetric\nmodel = ... data = ... trainable_variables = model . trainable_variables non_trainable_variables = model . non_trainable_variables # Call the model with zero side effects outputs , non_trainable_variables = model . stateless_call ( trainable_variables , non_trainable_variables , data , ) # Attach the updated state to the model # (until you do this, the model is still in its pre-call state). for ref_var , value in zip ( model . non_trainable_variables , non_trainable_variables ): ref_var . assign ( value )\nmodel = ... data = ... trainable_variables = model . trainable_variables non_trainable_variables = model . non_trainable_variables # Call the model with zero side effects outputs , non_trainable_variables = model . stateless_call ( trainable_variables , non_trainable_variables , data , ) # Attach the updated state to the model # (until you do this, the model is still in its pre-call state). for ref_var , value in zip ( model . non_trainable_variables , non_trainable_variables ): ref_var . assign ( value )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the CIFAR10 dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/text_to_word_sequence",
    "content": "DEPRECATED.\ntf . keras . preprocessing . text . text_to_word_sequence ( input_text , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' )\ntf . keras . preprocessing . text . text_to_word_sequence ( input_text , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception",
    "content": "Instantiates the Xception architecture.\nMain aliases tf.keras.applications.xception.Xception\ntf.keras.applications.xception.Xception\ntf.keras.applications.xception.Xception\ntf . keras . applications . Xception ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . Xception ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nXception: Deep Learning with Depthwise Separable Convolutions (CVPR 2017)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe default input image size for this model is 299x299.\nkeras.applications.xception.preprocess_input\nxception.preprocess_input\nArgs\nArgs\ninclude_top whether to include the 3 fully-connected\nlayers at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (299, 299, 3) .\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 71.\nE.g. (150, 150, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(299, 299, 3)\n(150, 150, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\"\nlayer.  When loading pretrained weights, classifier_activation can\nonly be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/serialize",
    "content": "tf . keras . constraints . serialize ( constraint )\ntf . keras . constraints . serialize ( constraint )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/maximum",
    "content": "Functional interface to the keras.layers.Maximum layer.\nkeras.layers.Maximum\ntf . keras . layers . maximum ( inputs , ** kwargs )\ntf . keras . layers . maximum ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors , all of the same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the element-wise product of the inputs with the same\nshape as the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . maximum ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . maximum ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) y = keras . layers . maximum ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\ny = keras . layers . maximum ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/min",
    "content": "DEPRECATED.\ntf . keras . backend . min ( x , axis = None , keepdims = False )\ntf . keras . backend . min ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arange",
    "content": "Return evenly spaced values within a given interval.\nMain aliases tf.keras.ops.numpy.arange\ntf.keras.ops.numpy.arange\ntf.keras.ops.numpy.arange\ntf . keras . ops . arange ( start , stop = None , step = 1 , dtype = None )\ntf . keras . ops . arange ( start , stop = None , step = 1 , dtype = None )\narange can be called with a varying number of positional arguments:\narange\narange(stop) : Values are generated within the half-open interval [0, stop) (in other words, the interval including start but excluding\nstop).\narange(stop)\n[0, stop)\narange(start, stop) : Values are generated within the half-open interval [start, stop) .\narange(start, stop)\n[start, stop)\narange(start, stop, step) : Values are generated within the half-open\ninterval [start, stop) , with spacing between values given by step.\narange(start, stop, step)\n[start, stop)\nArgs\nArgs\nstart Integer or real, representing the start of the interval. The\ninterval includes this value. stop Integer or real, representing the end of the interval. The\ninterval does not include this value, except in some cases where step is not an integer and floating point round-off affects the\nlength of out . Defaults to None . step Integer or real, represent the spacing between values. For any\noutput out , this is the distance between two adjacent values, out[i+1] - out[i] . The default step size is 1. If step is\nspecified as a position argument, start must also be given. dtype The type of the output array. If dtype is not given, infer the\ndata type from the other input arguments.\nstart\nstop\nstep\nout\nNone\nstep\nout\nout[i+1] - out[i]\nstep\nstart\ndtype\ndtype\nReturns Tensor of evenly spaced values.\nFor floating point arguments, the length of the result is ceil((stop - start)/step) . Because of floating point overflow, this\nrule may result in the last element of out being greater than stop.\nReturns\nceil((stop - start)/step)\nkeras . ops . arange ( 3 ) array ([ 0 , 1 , 2 ], dtype = int32 )\nkeras . ops . arange ( 3 )\narray ([ 0 , 1 , 2 ], dtype = int32 )\nkeras . ops . arange ( 3.0 ) array ([ 0. , 1. , 2. ], dtype = float32 )\nkeras . ops . arange ( 3.0 )\narray ([ 0. , 1. , 2. ], dtype = float32 )\nkeras . ops . arange ( 3 , 7 ) array ([ 3 , 4 , 5 , 6 ], dtype = int32 )\nkeras . ops . arange ( 3 , 7 )\narray ([ 3 , 4 , 5 , 6 ], dtype = int32 )\nkeras . ops . arange ( 3 , 7 , 2 ) array ([ 3 , 5 ], dtype = int32 )\nkeras . ops . arange ( 3 , 7 , 2 )\narray ([ 3 , 5 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/dot",
    "content": "DEPRECATED.\ntf . keras . backend . dot ( x , y )\ntf . keras . backend . dot ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D",
    "content": "Upsampling layer for 3D inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . UpSampling3D ( size = ( 2 , 2 , 2 ), data_format = None , ** kwargs )\ntf . keras . layers . UpSampling3D ( size = ( 2 , 2 , 2 ), data_format = None , ** kwargs )\nRepeats the 1st, 2nd and 3rd dimensions\nof the data by size[0] , size[1] and size[2] respectively.\nsize[0]\nsize[1]\nsize[2]\ninput_shape = ( 2 , 1 , 2 , 1 , 3 ) x = np . ones ( input_shape ) y = keras . layers . UpSampling3D ( size = ( 2 , 2 , 2 ))( x ) y . shape ( 2 , 2 , 4 , 2 , 3 )\ninput_shape = ( 2 , 1 , 2 , 1 , 3 )\nx = np . ones ( input_shape )\ny = keras . layers . UpSampling3D ( size = ( 2 , 2 , 2 ))( x )\ny . shape\n( 2 , 2 , 4 , 2 , 3 )\nArgs\nArgs\nsize Int, or tuple of 3 integers.\nThe upsampling factors for dim1, dim2 and dim3. data_format A string,\none of \"channels_last\" (default) or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nWhen unspecified, uses image_data_format value found in your Keras config file at ~/.keras/keras.json (if exists) else \"channels_last\" .\nDefaults to \"channels_last\" .\nsize\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\n\"channels_last\"\nInput shape 5D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, dim1, dim2, dim3, channels)\ndata_format\n\"channels_last\"\n(batch_size, dim1, dim2, dim3, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, dim1, dim2, dim3)\ndata_format\n\"channels_first\"\n(batch_size, channels, dim1, dim2, dim3)\nOutput shape 5D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\nchannels)\ndata_format\n\"channels_last\"\n(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\nchannels)\nIf data_format is \"channels_first\" : (batch_size, channels, upsampled_dim1, upsampled_dim2,\nupsampled_dim3)\ndata_format\n\"channels_first\"\n(batch_size, channels, upsampled_dim1, upsampled_dim2,\nupsampled_dim3)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/is_nested",
    "content": "Checks if a given structure is nested.\ntf . keras . tree . is_nested ( structure )\ntf . keras . tree . is_nested ( structure )\nkeras . tree . is_nested ( 42 ) False keras . tree . is_nested ({ \"foo\" : 42 }) True\nkeras . tree . is_nested ( 42 )\nFalse\nkeras . tree . is_nested ({ \"foo\" : 42 })\nTrue\nArgs\nArgs\nstructure A structure to check.\nstructure\nReturns True if a given structure is nested, i.e. is a sequence, a mapping,\nor a namedtuple, and False otherwise.\nReturns\nTrue\nFalse"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/deserialize",
    "content": "Returns a Keras initializer object via its configuration.\ntf . keras . initializers . deserialize ( config , custom_objects = None )\ntf . keras . initializers . deserialize ( config , custom_objects = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass TimeseriesGenerator : Utility class for generating batches of temporal data.\nclass TimeseriesGenerator\nFunctions\nmake_sampling_table(...) : Generates a word rank-based probabilistic sampling table.\nmake_sampling_table(...)\npad_sequences(...) : Pads sequences to the same length.\npad_sequences(...)\nskipgrams(...) : Generates skipgram word pairs.\nskipgrams(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/abs",
    "content": "Shorthand for keras.ops.absolute .\nkeras.ops.absolute\nMain aliases tf.keras.ops.numpy.abs\ntf.keras.ops.numpy.abs\ntf.keras.ops.numpy.abs\ntf . keras . ops . abs ( x )\ntf . keras . ops . abs ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/serialize",
    "content": "Returns the initializer configuration as a Python dict.\ntf . keras . initializers . serialize ( initializer )\ntf . keras . initializers . serialize ( initializer )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalHinge",
    "content": "Computes the categorical hinge metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . CategoricalHinge ( name = 'categorical_hinge' , dtype = None )\ntf . keras . metrics . CategoricalHinge ( name = 'categorical_hinge' , dtype = None )\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . CategoricalHinge () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]) m . result () . numpy () 1.4000001 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]], sample_weight = [ 1 , 0 ]) m . result () 1.2\nm = keras . metrics . CategoricalHinge ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]])\nm . result () . numpy ()\n1.4000001\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n1.2\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/not_equal",
    "content": "Return (x1 != x2) element-wise.\n(x1 != x2)\nMain aliases tf.keras.ops.numpy.not_equal\ntf.keras.ops.numpy.not_equal\ntf.keras.ops.numpy.not_equal\ntf . keras . ops . not_equal ( x1 , x2 )\ntf . keras . ops . not_equal ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise comparsion of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . resnet_v2 . preprocess_input ( x , data_format = None )\ntf . keras . applications . resnet_v2 . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_focal_crossentropy",
    "content": "Computes the categorical focal crossentropy loss.\nMain aliases tf.keras.metrics.categorical_focal_crossentropy\ntf.keras.metrics.categorical_focal_crossentropy\ntf.keras.metrics.categorical_focal_crossentropy\ntf . keras . losses . categorical_focal_crossentropy ( y_true , y_pred , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\ntf . keras . losses . categorical_focal_crossentropy ( y_true , y_pred , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\nArgs\nArgs\ny_true Tensor of one-hot true targets. y_pred Tensor of predicted targets. alpha A weight balancing factor for all classes, default is 0.25 as\nmentioned in the reference. It can be a list of floats or a scalar.\nIn the multi-class case, alpha may be set by inverse class\nfrequency by using compute_class_weight from sklearn.utils . gamma A focusing parameter, default is 2.0 as mentioned in the\nreference. It helps to gradually reduce the importance given to\nsimple examples in a smooth manner. When gamma = 0, there is\nno focal effect on the categorical crossentropy. from_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability\ndistribution. label_smoothing Float in [0, 1]. If > 0 then smooth the labels. For\nexample, if 0.1 , use 0.1 / num_classes for non-target labels\nand 0.9 + 0.1 / num_classes for target labels. axis Defaults to -1 . The dimension along which the entropy is\ncomputed.\ny_true\ny_pred\nalpha\n0.25\ncompute_class_weight\nsklearn.utils\ngamma\n2.0\ngamma\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\n0\n0.1\n0.1 / num_classes\n0.9 + 0.1 / num_classes\naxis\n-1\nReturns Categorical focal crossentropy loss value.\nReturns\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.9 , 0.05 ], [ 0.1 , 0.85 , 0.05 ]] loss = keras . losses . categorical_focal_crossentropy ( y_true , y_pred ) assert loss . shape == ( 2 ,) loss array ([ 2.63401289e-04 , 6.75912094e-01 ], dtype = float32 )\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]\ny_pred = [[ 0.05 , 0.9 , 0.05 ], [ 0.1 , 0.85 , 0.05 ]]\nloss = keras . losses . categorical_focal_crossentropy ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\nloss\narray ([ 2.63401289e-04 , 6.75912094e-01 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/top_k_categorical_accuracy",
    "content": "tf . keras . metrics . top_k_categorical_accuracy ( y_true , y_pred , k = 5 )\ntf . keras . metrics . top_k_categorical_accuracy ( y_true , y_pred , k = 5 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/deserialize",
    "content": "Returns a Keras optimizer object via its configuration.\ntf . keras . optimizers . deserialize ( config , custom_objects = None )\ntf . keras . optimizers . deserialize ( config , custom_objects = None )\nArgs\nArgs\nconfig Optimizer configuration dictionary. custom_objects Optional dictionary mapping names (strings) to custom\nobjects (classes and functions) to be considered during\ndeserialization.\nconfig\ncustom_objects\nReturns A Keras Optimizer instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/any",
    "content": "Test whether any array element along a given axis evaluates to True .\nTrue\nMain aliases tf.keras.ops.numpy.any\ntf.keras.ops.numpy.any\ntf.keras.ops.numpy.any\ntf . keras . ops . any ( x , axis = None , keepdims = False )\ntf . keras . ops . any ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis An integer or tuple of integers that represent the axis along\nwhich a logical OR reduction is performed. The default\n( axis=None ) is to perform a logical OR over all the dimensions\nof the input array. axis may be negative, in which case it counts\nfor the last to the first axis. keepdims If True , axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will\nbroadcast correctly against the input array. Defaults to False .\nx\naxis\naxis=None\naxis\nkeepdims\nTrue\nFalse\nReturns The tensor containing the logical OR reduction over the axis .\nReturns\naxis\nx = keras . ops . convert_to_tensor ([ True , False ]) keras . ops . any ( x ) array ( True , shape = (), dtype = bool )\nx = keras . ops . convert_to_tensor ([ True , False ])\nkeras . ops . any ( x )\narray ( True , shape = (), dtype = bool )\nx = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) keras . ops . any ( x , axis = 0 ) array ([ True True ], shape = ( 2 ,), dtype = bool )\nx = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]])\nkeras . ops . any ( x , axis = 0 )\narray ([ True True ], shape = ( 2 ,), dtype = bool )\nkeepdims=True outputs a tensor with dimensions reduced to one.\nkeepdims=True\n>>> x = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) >>> keras . ops . all ( x , keepdims = True ) array ([[ False ]], shape = ( 1 , 1 ), dtype = bool )\n>>> x = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) >>> keras . ops . all ( x , keepdims = True ) array ([[ False ]], shape = ( 1 , 1 ), dtype = bool )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sigmoid",
    "content": "Sigmoid activation function.\nMain aliases tf.keras.ops.nn.sigmoid\ntf.keras.ops.nn.sigmoid\ntf.keras.ops.nn.sigmoid\ntf . keras . ops . sigmoid ( x )\ntf . keras . ops . sigmoid ( x )\nIt is defined as f(x) = 1 / (1 + exp(-x)) .\nf(x) = 1 / (1 + exp(-x))\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 6.0 , 1.0 , 0.0 , 1.0 , 6.0 ]) keras . ops . sigmoid ( x ) array ([ 0.00247262 , 0.7310586 , 0.5 , 0.7310586 , 0.9975274 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 6.0 , 1.0 , 0.0 , 1.0 , 6.0 ])\nkeras . ops . sigmoid ( x )\narray ([ 0.00247262 , 0.7310586 , 0.5 , 0.7310586 , 0.9975274 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/nonzero",
    "content": "Return the indices of the elements that are non-zero.\nMain aliases tf.keras.ops.numpy.nonzero\ntf.keras.ops.numpy.nonzero\ntf.keras.ops.numpy.nonzero\ntf . keras . ops . nonzero ( x )\ntf . keras . ops . nonzero ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Indices of elements that are non-zero.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/deserialize",
    "content": "Return a Keras activation function via its config.\ntf . keras . activations . deserialize ( config , custom_objects = None )\ntf . keras . activations . deserialize ( config , custom_objects = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/densenet/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . densenet . preprocess_input ( x , data_format = None )\ntf . keras . applications . densenet . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe input pixels values are scaled between 0 and 1 and each channel is\nnormalized with respect to the ImageNet dataset.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/export/ExportArchive",
    "content": "ExportArchive is used to write SavedModel artifacts (e.g. for inference).\ntf . keras . export . ExportArchive ()\ntf . keras . export . ExportArchive ()\nIf you have a Keras model or layer that you want to export as SavedModel for\nserving (e.g. via TensorFlow-Serving), you can use ExportArchive to configure the different serving endpoints you need to make available,\nas well as their signatures. Simply instantiate an ExportArchive ,\nuse track() to register the layer(s) or model(s) to be used,\nthen use the add_endpoint() method to register a new serving endpoint.\nWhen done, use the write_out() method to save the artifact.\nExportArchive\nExportArchive\ntrack()\nadd_endpoint()\nwrite_out()\nThe resulting artifact is a SavedModel and can be reloaded via tf.saved_model.load .\ntf.saved_model.load\nHere's how to export a model for inference.\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . write_out ( \"path/to/location\" ) # Elsewhere, we can reload the artifact and serve it. # The endpoint we added is available as a method: serving_model = tf . saved_model . load ( \"path/to/location\" ) outputs = serving_model . serve ( inputs )\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . write_out ( \"path/to/location\" ) # Elsewhere, we can reload the artifact and serve it. # The endpoint we added is available as a method: serving_model = tf . saved_model . load ( \"path/to/location\" ) outputs = serving_model . serve ( inputs )\nHere's how to export a model with one endpoint for inference and one\nendpoint for a training-mode forward pass (e.g. with dropout on).\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"call_inference\" , fn = lambda x : model . call ( x , training = False ), input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . add_endpoint ( name = \"call_training\" , fn = lambda x : model . call ( x , training = True ), input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . write_out ( \"path/to/location\" )\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"call_inference\" , fn = lambda x : model . call ( x , training = False ), input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . add_endpoint ( name = \"call_training\" , fn = lambda x : model . call ( x , training = True ), input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) export_archive . write_out ( \"path/to/location\" )\nNote on resource tracking:\nExportArchive is able to automatically track all tf.Variables used\nby its endpoints, so most of the time calling .track(model) is not strictly required. However, if your model uses lookup layers such\nas IntegerLookup , StringLookup , or TextVectorization ,\nit will need to be tracked explicitly via .track(model) .\nExportArchive\ntf.Variables\n.track(model)\nIntegerLookup\nStringLookup\nTextVectorization\n.track(model)\nExplicit tracking is also required if you need to be able to access\nthe properties variables , trainable_variables , or non_trainable_variables on the revived archive.\nvariables\ntrainable_variables\nnon_trainable_variables\nAttributes\nAttributes\nnon_trainable_variables\nnon_trainable_variables\ntrainable_variables\ntrainable_variables\nvariables\nvariables\nMethods\nadd_endpoint\nadd_endpoint\nView source\nadd_endpoint ( name , fn , input_signature = None , jax2tf_kwargs = None )\nadd_endpoint ( name , fn , input_signature = None , jax2tf_kwargs = None )\nRegister a new serving endpoint.\nArguments\nname Str, name of the endpoint. fn A function. It should only leverage resources\n(e.g. tf.Variable objects or tf.lookup.StaticHashTable objects) that are available on the models/layers\ntracked by the ExportArchive (you can call .track(model) to track a new model).\nThe shape and dtype of the inputs to the function must be\nknown. For that purpose, you can either 1) make sure that fn is a tf.function that has been called at least once, or\nname\nfn\ntf.Variable\ntf.lookup.StaticHashTable\nExportArchive\n.track(model)\nfn\ntf.function\n2) provide an input_signature argument that specifies the\nshape and dtype of the inputs (see below). input_signature Used to specify the shape and dtype of the\ninputs to fn . List of tf.TensorSpec objects (one\nper positional input argument of fn ). Nested arguments are\nallowed (see below for an example showing a Functional model\nwith 2 input arguments). jax2tf_kwargs Optional. A dict for arguments to pass to jax2tf .\nSupported only when the backend is JAX. See documentation for jax2tf.convert .\nThe values for native_serialization and polymorphic_shapes ,\nif not provided, are automatically computed.\ninput_signature\ninput_signature\nfn\ntf.TensorSpec\nfn\njax2tf_kwargs\njax2tf\njax2tf.convert\nnative_serialization\npolymorphic_shapes\nReturns The tf.function wrapping fn that was added to the archive.\ntf.function\nfn\nAdding an endpoint using the input_signature argument when the\nmodel has a single input argument:\ninput_signature\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], )\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], )\nAdding an endpoint using the input_signature argument when the\nmodel has two positional input arguments:\ninput_signature\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), ], )\nexport_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), ], )\nAdding an endpoint using the input_signature argument when the\nmodel has one input argument that is a list of 2 tensors (e.g.\na Functional model with 2 inputs):\ninput_signature\nmodel = keras . Model ( inputs = [ x1 , x2 ], outputs = outputs ) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), ], ], )\nmodel = keras . Model ( inputs = [ x1 , x2 ], outputs = outputs ) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), ], ], )\nThis also works with dictionary inputs:\nmodel = keras . Model ( inputs = { \"x1\" : x1 , \"x2\" : x2 }, outputs = outputs ) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ { \"x1\" : tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), \"x2\" : tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), }, ], )\nmodel = keras . Model ( inputs = { \"x1\" : x1 , \"x2\" : x2 }, outputs = outputs ) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ { \"x1\" : tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 ), \"x2\" : tf . TensorSpec ( shape = ( None , 4 ), dtype = tf . float32 ), }, ], )\nAdding an endpoint that is a tf.function :\ntf.function\n@tf . function () def serving_fn ( x ): return model ( x ) # The function must be traced, i.e. it must be called at least once. serving_fn ( tf . random . normal ( shape = ( 2 , 3 ))) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = serving_fn )\n@tf . function () def serving_fn ( x ): return model ( x ) # The function must be traced, i.e. it must be called at least once. serving_fn ( tf . random . normal ( shape = ( 2 , 3 ))) export_archive = ExportArchive () export_archive . track ( model ) export_archive . add_endpoint ( name = \"serve\" , fn = serving_fn )\nadd_variable_collection\nadd_variable_collection\nView source\nadd_variable_collection ( name , variables )\nadd_variable_collection ( name , variables )\nRegister a set of variables to be retrieved after reloading.\nArguments\nname The string name for the collection. variables A tuple/list/set of tf.Variable instances.\nname\nvariables\ntf.Variable\nexport_archive = ExportArchive () export_archive . track ( model ) # Register an endpoint export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) # Save a variable collection export_archive . add_variable_collection ( name = \"optimizer_variables\" , variables = model . optimizer . variables ) export_archive . write_out ( \"path/to/location\" ) # Reload the object revived_object = tf . saved_model . load ( \"path/to/location\" ) # Retrieve the variables optimizer_variables = revived_object . optimizer_variables\nexport_archive = ExportArchive () export_archive . track ( model ) # Register an endpoint export_archive . add_endpoint ( name = \"serve\" , fn = model . call , input_signature = [ tf . TensorSpec ( shape = ( None , 3 ), dtype = tf . float32 )], ) # Save a variable collection export_archive . add_variable_collection ( name = \"optimizer_variables\" , variables = model . optimizer . variables ) export_archive . write_out ( \"path/to/location\" ) # Reload the object revived_object = tf . saved_model . load ( \"path/to/location\" ) # Retrieve the variables optimizer_variables = revived_object . optimizer_variables\ntrack\ntrack\nView source\ntrack ( resource )\ntrack ( resource )\nTrack the variables (and other assets) of a layer or model.\nBy default, all variables used by an endpoint function\nare automatically tracked when you call add_endpoint() .\nHowever, non-variables assets such as lookup tables\nneed to be tracked manually. Note that lookup tables\nused by built-in Keras layers\n( TextVectorization , IntegerLookup , StringLookup )\nare automatically tracked in add_endpoint() .\nadd_endpoint()\nTextVectorization\nIntegerLookup\nStringLookup\nadd_endpoint()\nArguments\nresource A trackable TensorFlow resource.\nresource\nwrite_out\nwrite_out\nView source\nwrite_out ( filepath , options = None )\nwrite_out ( filepath , options = None )\nWrite the corresponding SavedModel to disk.\nArguments\nfilepath str or pathlib.Path object.\nPath where to save the artifact. options tf.saved_model.SaveOptions object that specifies\nSavedModel saving options.\nfilepath\nstr\npathlib.Path\noptions\ntf.saved_model.SaveOptions\nNote on TF-Serving : all endpoints registered via add_endpoint() are made visible for TF-Serving in the SavedModel artifact. In addition,\nthe first endpoint registered is made visible under the alias \"serving_default\" (unless an endpoint with the name \"serving_default\" was already registered manually),\nsince TF-Serving requires this endpoint to be set.\nadd_endpoint()\n\"serving_default\"\n\"serving_default\""
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape",
    "content": "Layer that reshapes inputs into the given shape.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Reshape ( target_shape , ** kwargs )\ntf . keras . layers . Reshape ( target_shape , ** kwargs )\nUsed in the notebooks\nCustomizing what happens in `fit()`\nUsing Counterfactual Logit Pairing with Keras\nTime series forecasting\nCustom training loop with Keras and MultiWorkerMirroredStrategy\nMulti-worker training with Keras\nIntro to Autoencoders\nConvolutional Variational Autoencoder\nArgs\nArgs\ntarget_shape Target shape. Tuple of integers, does not include the\nsamples dimension (batch size).\ntarget_shape\nInput shape Arbitrary, although all dimensions in the input shape must be\nknown/fixed. Use the keyword argument input_shape (tuple of integers,\ndoes not include the samples/batch size axis) when using this layer as\nthe first layer in a model.\nInput shape\ninput_shape\nOutput shape (batch_size, *target_shape)\nOutput shape\n(batch_size, *target_shape)\nx = keras . Input ( shape = ( 12 ,)) y = keras . layers . Reshape (( 3 , 4 ))( x ) y . shape ( None , 3 , 4 )\nx = keras . Input ( shape = ( 12 ,))\ny = keras . layers . Reshape (( 3 , 4 ))( x )\ny . shape\n( None , 3 , 4 )\n# also supports shape inference using `-1` as dimension y = keras . layers . Reshape (( - 1 , 2 , 2 ))( x ) y . shape ( None , 3 , 2 , 2 )\n# also supports shape inference using `-1` as dimension\ny = keras . layers . Reshape (( - 1 , 2 , 2 ))( x )\ny . shape\n( None , 3 , 2 , 2 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sort",
    "content": "Sorts the elements of x along a given axis in ascending order.\nx\nMain aliases tf.keras.ops.numpy.sort\ntf.keras.ops.numpy.sort\ntf.keras.ops.numpy.sort\ntf . keras . ops . sort ( x , axis =- 1 )\ntf . keras . ops . sort ( x , axis =- 1 )\nArgs\nArgs\nx Input tensor. axis Axis along which to sort. If None , the tensor is flattened\nbefore sorting. Defaults to -1 ; the last axis.\nx\naxis\nNone\n-1\nReturns Sorted tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/huber",
    "content": "Computes Huber loss value.\nMain aliases tf.keras.metrics.huber\ntf.keras.metrics.huber\ntf.keras.metrics.huber\ntf . keras . losses . huber ( y_true , y_pred , delta = 1.0 )\ntf . keras . losses . huber ( y_true , y_pred , delta = 1.0 )\nfor x in error : if abs ( x ) < = delta : loss . append ( 0.5 * x ^ 2 ) elif abs ( x ) > delta : loss . append ( delta * abs ( x ) - 0.5 * delta ^ 2 ) loss = mean ( loss , axis =- 1 )\nfor x in error : if abs ( x ) < = delta : loss . append ( 0.5 * x ^ 2 ) elif abs ( x ) > delta : loss . append ( delta * abs ( x ) - 0.5 * delta ^ 2 ) loss = mean ( loss , axis =- 1 )\nSee: Huber loss .\ny_true = [[ 0 , 1 ], [ 0 , 0 ]] y_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]] loss = keras . losses . huber ( y_true , y_pred ) 0.155\ny_true = [[ 0 , 1 ], [ 0 , 0 ]]\ny_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]\nloss = keras . losses . huber ( y_true , y_pred )\n0.155\nArgs\nArgs\ny_true tensor of true targets. y_pred tensor of predicted targets. delta A float, the point where the Huber loss function changes from a\nquadratic to linear. Defaults to 1.0 .\ny_true\ny_pred\ndelta\n1.0\nReturns Tensor with one scalar loss entry per sample.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet152",
    "content": "Instantiates the ResNet152 architecture.\nMain aliases tf.keras.applications.resnet.ResNet152\ntf.keras.applications.resnet.ResNet152\ntf.keras.applications.resnet.ResNet152\ntf . keras . applications . ResNet152 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet152 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nDeep Residual Learning for Image Recognition (CVPR 2015)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet.preprocess_input\nresnet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Constraint : Base class for weight constraints.\nclass Constraint\nclass MaxNorm : MaxNorm weight constraint.\nclass MaxNorm\nclass MinMaxNorm : MinMaxNorm weight constraint.\nclass MinMaxNorm\nclass NonNeg : Constrains the weights to be non-negative.\nclass NonNeg\nclass UnitNorm : Constrains the weights incident to each hidden unit to have unit norm.\nclass UnitNorm\nclass max_norm : MaxNorm weight constraint.\nclass max_norm\nclass min_max_norm : MinMaxNorm weight constraint.\nclass min_max_norm\nclass non_neg : Constrains the weights to be non-negative.\nclass non_neg\nclass unit_norm : Constrains the weights incident to each hidden unit to have unit norm.\nclass unit_norm\nFunctions\ndeserialize(...) : Return a Keras constraint object via its config.\ndeserialize(...)\nget(...) : Retrieve a Keras constraint object via an identifier.\nget(...)\nserialize(...)\nserialize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/load_data",
    "content": "Loads the Reuters newswire classification dataset.\ntf . keras . datasets . reuters . load_data ( path = 'reuters.npz' , num_words = None , skip_top = 0 , maxlen = None , test_split = 0.2 , seed = 113 , start_char = 1 , oov_char = 2 , index_from = 3 )\ntf . keras . datasets . reuters . load_data ( path = 'reuters.npz' , num_words = None , skip_top = 0 , maxlen = None , test_split = 0.2 , seed = 113 , start_char = 1 , oov_char = 2 , index_from = 3 )\nThis is a dataset of 11,228 newswires from Reuters, labeled over 46 topics.\nThis was originally generated by parsing and preprocessing the classic\nReuters-21578 dataset, but the preprocessing code is no longer packaged\nwith Keras. See this GitHub discussion for more info.\nEach newswire is encoded as a list of word indexes (integers).\nFor convenience, words are indexed by overall frequency in the dataset,\nso that for instance the integer \"3\" encodes the 3rd most frequent word in\nthe data. This allows for quick filtering operations such as:\n\"only consider the top 10,000 most\ncommon words, but eliminate the top 20 most common words\".\nAs a convention, \"0\" does not stand for a specific word, but instead is used\nto encode any unknown word.\nArgs\nArgs\npath where to cache the data (relative to ~/.keras/dataset ). num_words integer or None. Words are\nranked by how often they occur (in the training set) and only\nthe num_words most frequent words are kept. Any less frequent word\nwill appear as oov_char value in the sequence data. If None,\nall words are kept. Defaults to None . skip_top skip the top N most frequently occurring words\n(which may not be informative). These words will appear as oov_char value in the dataset. 0 means no words are\nskipped. Defaults to 0 . maxlen int or None. Maximum sequence length.\nAny longer sequence will be truncated. None means no truncation.\nDefaults to None . test_split Float between 0. and 1. . Fraction of the dataset to be\nused as test data. 0.2 means that 20% of the dataset is used as\ntest data. Defaults to 0.2 . seed int. Seed for reproducible data shuffling. start_char int. The start of a sequence will be marked with this\ncharacter. 0 is usually the padding character. Defaults to 1 . oov_char int. The out-of-vocabulary character.\nWords that were cut out because of the num_words or skip_top limits will be replaced with this character. index_from int. Index actual words with this index and higher.\npath\n~/.keras/dataset\nnum_words\nnum_words\noov_char\nNone\nskip_top\noov_char\n0\nmaxlen\nNone\ntest_split\n0.\n1.\n0.2\n0.2\nseed\nstart_char\n1\noov_char\nnum_words\nskip_top\nindex_from\nReturns Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train , x_test : lists of sequences, which are lists of indexes\n  (integers). If the num_words argument was specific, the maximum\n  possible index value is num_words - 1 . If the maxlen argument was\n  specified, the largest possible sequence length is maxlen .\nx_train\nx_test\nnum_words - 1\nmaxlen\nmaxlen\ny_train , y_test : lists of integer labels (1 or 0).\ny_train\ny_test\nnum_words"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight",
    "content": "DEPRECATED.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomHeight ( factor , interpolation = 'bilinear' , seed = None , ** kwargs )\ntf . keras . layers . RandomHeight ( factor , interpolation = 'bilinear' , seed = None , ** kwargs )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/numpy",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nabs(...) : Shorthand for keras.ops.absolute .\nabs(...)\nkeras.ops.absolute\nabsolute(...) : Compute the absolute value element-wise.\nabsolute(...)\nadd(...) : Add arguments element-wise.\nadd(...)\nall(...) : Test whether all array elements along a given axis evaluate to True .\nall(...)\nTrue\namax(...) : Returns the maximum of an array or maximum value along an axis.\namax(...)\namin(...) : Returns the minimum of an array or minimum value along an axis.\namin(...)\nany(...) : Test whether any array element along a given axis evaluates to True .\nany(...)\nTrue\nappend(...) : Append tensor x2 to the end of tensor x1 .\nappend(...)\nx2\nx1\narange(...) : Return evenly spaced values within a given interval.\narange(...)\narccos(...) : Trigonometric inverse cosine, element-wise.\narccos(...)\narccosh(...) : Inverse hyperbolic cosine, element-wise.\narccosh(...)\narcsin(...) : Inverse sine, element-wise.\narcsin(...)\narcsinh(...) : Inverse hyperbolic sine, element-wise.\narcsinh(...)\narctan(...) : Trigonometric inverse tangent, element-wise.\narctan(...)\narctan2(...) : Element-wise arc tangent of x1/x2 choosing the quadrant correctly.\narctan2(...)\nx1/x2\narctanh(...) : Inverse hyperbolic tangent, element-wise.\narctanh(...)\nargmax(...) : Returns the indices of the maximum values along an axis.\nargmax(...)\nargmin(...) : Returns the indices of the minium values along an axis.\nargmin(...)\nargsort(...) : Returns the indices that would sort a tensor.\nargsort(...)\narray(...) : Create a tensor.\narray(...)\naverage(...) : Compute the weighted average along the specified axis.\naverage(...)\nbincount(...) : Count the number of occurrences of each value in a tensor of integers.\nbincount(...)\nbroadcast_to(...) : Broadcast a tensor to a new shape.\nbroadcast_to(...)\nceil(...) : Return the ceiling of the input, element-wise.\nceil(...)\nclip(...) : Clip (limit) the values in a tensor.\nclip(...)\nconcatenate(...) : Join a sequence of tensors along an existing axis.\nconcatenate(...)\nconj(...) : Shorthand for keras.ops.conjugate .\nconj(...)\nkeras.ops.conjugate\nconjugate(...) : Returns the complex conjugate, element-wise.\nconjugate(...)\ncopy(...) : Returns a copy of x .\ncopy(...)\nx\ncorrelate(...) : Compute the cross-correlation of two 1-dimensional tensors.\ncorrelate(...)\ncos(...) : Cosine, element-wise.\ncos(...)\ncosh(...) : Hyperbolic cosine, element-wise.\ncosh(...)\ncount_nonzero(...) : Counts the number of non-zero values in x along the given axis .\ncount_nonzero(...)\nx\naxis\ncross(...) : Returns the cross product of two (arrays of) vectors.\ncross(...)\ncumprod(...) : Return the cumulative product of elements along a given axis.\ncumprod(...)\ncumsum(...) : Returns the cumulative sum of elements along a given axis.\ncumsum(...)\ndiag(...) : Extract a diagonal or construct a diagonal array.\ndiag(...)\ndiagonal(...) : Return specified diagonals.\ndiagonal(...)\ndiff(...) : Calculate the n-th discrete difference along the given axis.\ndiff(...)\ndigitize(...) : Returns the indices of the bins to which each value in x belongs.\ndigitize(...)\nx\ndivide(...) : Divide arguments element-wise.\ndivide(...)\ndivide_no_nan(...) : Safe element-wise division which returns 0 where the denominator is 0.\ndivide_no_nan(...)\ndot(...) : Dot product of two tensors.\ndot(...)\neinsum(...) : Evaluates the Einstein summation convention on the operands.\neinsum(...)\nempty(...) : Return a tensor of given shape and type filled with uninitialized data.\nempty(...)\nequal(...) : Returns (x1 == x2) element-wise.\nequal(...)\n(x1 == x2)\nexp(...) : Calculate the exponential of all elements in the input tensor.\nexp(...)\nexpand_dims(...) : Expand the shape of a tensor.\nexpand_dims(...)\nexpm1(...) : Calculate exp(x) - 1 for all elements in the tensor.\nexpm1(...)\nexp(x) - 1\neye(...) : Return a 2-D tensor with ones on the diagonal and zeros elsewhere.\neye(...)\nflip(...) : Reverse the order of elements in the tensor along the given axis.\nflip(...)\nfloor(...) : Return the floor of the input, element-wise.\nfloor(...)\nfloor_divide(...) : Returns the largest integer smaller or equal to the division of inputs.\nfloor_divide(...)\nfull(...) : Return a new tensor of given shape and type, filled with fill_value .\nfull(...)\nfill_value\nfull_like(...) : Return a full tensor with the same shape and type as the given tensor.\nfull_like(...)\nget_item(...) : Return x[key] .\nget_item(...)\nx[key]\ngreater(...) : Return the truth value of x1 > x2 element-wise.\ngreater(...)\nx1 > x2\ngreater_equal(...) : Return the truth value of x1 >= x2 element-wise.\ngreater_equal(...)\nx1 >= x2\nhstack(...) : Stack tensors in sequence horizontally (column wise).\nhstack(...)\nidentity(...) : Return the identity tensor.\nidentity(...)\nimag(...) : Return the imaginary part of the complex argument.\nimag(...)\nisclose(...) : Return whether two tensors are element-wise almost equal.\nisclose(...)\nisfinite(...) : Return whether a tensor is finite, element-wise.\nisfinite(...)\nisinf(...) : Test element-wise for positive or negative infinity.\nisinf(...)\nisnan(...) : Test element-wise for NaN and return result as a boolean tensor.\nisnan(...)\nless(...) : Return the truth value of x1 < x2 element-wise.\nless(...)\nx1 < x2\nless_equal(...) : Return the truth value of x1 <= x2 element-wise.\nless_equal(...)\nx1 <= x2\nlinspace(...) : Return evenly spaced numbers over a specified interval.\nlinspace(...)\nlog(...) : Natural logarithm, element-wise.\nlog(...)\nlog10(...) : Return the base 10 logarithm of the input tensor, element-wise.\nlog10(...)\nlog1p(...) : Returns the natural logarithm of one plus the x , element-wise.\nlog1p(...)\nx\nlog2(...) : Base-2 logarithm of x , element-wise.\nlog2(...)\nx\nlogaddexp(...) : Logarithm of the sum of exponentiations of the inputs.\nlogaddexp(...)\nlogical_and(...) : Computes the element-wise logical AND of the given input tensors.\nlogical_and(...)\nlogical_not(...) : Computes the element-wise NOT of the given input tensor.\nlogical_not(...)\nlogical_or(...) : Computes the element-wise logical OR of the given input tensors.\nlogical_or(...)\nlogical_xor(...) : Compute the truth value of x1 XOR x2 , element-wise.\nlogical_xor(...)\nx1 XOR x2\nlogspace(...) : Returns numbers spaced evenly on a log scale.\nlogspace(...)\nmatmul(...) : Matrix product of two tensors.\nmatmul(...)\nmax(...) : Return the maximum of a tensor or maximum along an axis.\nmax(...)\nmaximum(...) : Element-wise maximum of x1 and x2 .\nmaximum(...)\nx1\nx2\nmean(...) : Compute the arithmetic mean along the specified axes.\nmean(...)\nmedian(...) : Compute the median along the specified axis.\nmedian(...)\nmeshgrid(...) : Creates grids of coordinates from coordinate vectors.\nmeshgrid(...)\nmin(...) : Return the minimum of a tensor or minimum along an axis.\nmin(...)\nminimum(...) : Element-wise minimum of x1 and x2 .\nminimum(...)\nx1\nx2\nmod(...) : Returns the element-wise remainder of division.\nmod(...)\nmoveaxis(...) : Move axes of a tensor to new positions.\nmoveaxis(...)\nmultiply(...) : Multiply arguments element-wise.\nmultiply(...)\nnan_to_num(...) : Replace NaN with zero and infinity with large finite numbers.\nnan_to_num(...)\nndim(...) : Return the number of dimensions of a tensor.\nndim(...)\nnegative(...) : Numerical negative, element-wise.\nnegative(...)\nnonzero(...) : Return the indices of the elements that are non-zero.\nnonzero(...)\nnot_equal(...) : Return (x1 != x2) element-wise.\nnot_equal(...)\n(x1 != x2)\nones(...) : Return a new tensor of given shape and type, filled with ones.\nones(...)\nones_like(...) : Return a tensor of ones with the same shape and type of x .\nones_like(...)\nx\nouter(...) : Compute the outer product of two vectors.\nouter(...)\npad(...) : Pad a tensor.\npad(...)\npower(...) : First tensor elements raised to powers from second tensor, element-wise.\npower(...)\nprod(...) : Return the product of tensor elements over a given axis.\nprod(...)\nquantile(...) : Compute the q-th quantile(s) of the data along the specified axis.\nquantile(...)\nravel(...) : Return a contiguous flattened tensor.\nravel(...)\nreal(...) : Return the real part of the complex argument.\nreal(...)\nreciprocal(...) : Return the reciprocal of the argument, element-wise.\nreciprocal(...)\nrepeat(...) : Repeat each element of a tensor after themselves.\nrepeat(...)\nreshape(...) : Gives a new shape to a tensor without changing its data.\nreshape(...)\nroll(...) : Roll tensor elements along a given axis.\nroll(...)\nround(...) : Evenly round to the given number of decimals.\nround(...)\nselect(...) : Return elements from choicelist , based on conditions in condlist .\nselect(...)\nchoicelist\ncondlist\nsign(...) : Returns a tensor with the signs of the elements of x .\nsign(...)\nx\nsin(...) : Trigonometric sine, element-wise.\nsin(...)\nsinh(...) : Hyperbolic sine, element-wise.\nsinh(...)\nsize(...) : Return the number of elements in a tensor.\nsize(...)\nslogdet(...) : Compute the sign and natural logarithm of the determinant of a matrix.\nslogdet(...)\nsort(...) : Sorts the elements of x along a given axis in ascending order.\nsort(...)\nx\nsplit(...) : Split a tensor into chunks.\nsplit(...)\nsqrt(...) : Return the non-negative square root of a tensor, element-wise.\nsqrt(...)\nsquare(...) : Return the element-wise square of the input.\nsquare(...)\nsqueeze(...) : Remove axes of length one from x .\nsqueeze(...)\nx\nstack(...) : Join a sequence of tensors along a new axis.\nstack(...)\nstd(...) : Compute the standard deviation along the specified axis.\nstd(...)\nsubtract(...) : Subtract arguments element-wise.\nsubtract(...)\nsum(...) : Sum of a tensor over the given axes.\nsum(...)\nswapaxes(...) : Interchange two axes of a tensor.\nswapaxes(...)\ntake(...) : Take elements from a tensor along an axis.\ntake(...)\ntake_along_axis(...) : Select values from x at the 1-D indices along the given axis.\ntake_along_axis(...)\nx\nindices\ntan(...) : Compute tangent, element-wise.\ntan(...)\ntanh(...) : Hyperbolic tangent, element-wise.\ntanh(...)\ntensordot(...) : Compute the tensor dot product along specified axes.\ntensordot(...)\ntile(...) : Repeat x the number of times given by repeats .\ntile(...)\nx\nrepeats\ntrace(...) : Return the sum along diagonals of the tensor.\ntrace(...)\ntranspose(...) : Returns a tensor with axes transposed.\ntranspose(...)\naxes\ntri(...) : Return a tensor with ones at and below a diagonal and zeros elsewhere.\ntri(...)\ntril(...) : Return lower triangle of a tensor.\ntril(...)\ntriu(...) : Return upper triangle of a tensor.\ntriu(...)\ntrue_divide(...) : Alias for keras.ops.divide .\ntrue_divide(...)\nkeras.ops.divide\nvar(...) : Compute the variance along the specified axes.\nvar(...)\nvdot(...) : Return the dot product of two vectors.\nvdot(...)\nvectorize(...) : Turn a function into a vectorized function.\nvectorize(...)\nvstack(...) : Stack tensors in sequence vertically (row wise).\nvstack(...)\nwhere(...) : Return elements chosen from x1 or x2 depending on condition .\nwhere(...)\nx1\nx2\ncondition\nzeros(...) : Return a new tensor of given shape and type, filled with zeros.\nzeros(...)\nzeros_like(...) : Return a tensor of zeros with the same shape and type as x .\nzeros_like(...)\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1L2",
    "content": "A regularizer that applies both L1 and L2 regularization penalties.\nInherits From: Regularizer\nRegularizer\nMain aliases tf.keras.regularizers.l1_l2\ntf.keras.regularizers.l1_l2\ntf.keras.regularizers.l1_l2\ntf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 )\ntf . keras . regularizers . L1L2 ( l1 = 0.0 , l2 = 0.0 )\nThe L1 regularization penalty is computed as: loss = l1 * reduce_sum(abs(x))\nloss = l1 * reduce_sum(abs(x))\nThe L2 regularization penalty is computed as loss = l2 * reduce_sum(square(x))\nloss = l2 * reduce_sum(square(x))\nL1L2 may be passed to a layer as a string identifier:\ndense = Dense ( 3 , kernel_regularizer = 'l1_l2' )\ndense = Dense ( 3 , kernel_regularizer = 'l1_l2' )\nIn this case, the default values used are l1=0.01 and l2=0.01 .\nl1=0.01\nl2=0.01\nArguments\nArguments\nl1 float, L1 regularization factor. l2 float, L2 regularization factor.\nl1\nl2\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a regularizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same regularizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A regularizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the regularizer.\nAn regularizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the regularizer.\nThe same regularizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a regularization penalty from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/pool3d",
    "content": "DEPRECATED.\ntf . keras . backend . pool3d ( x , pool_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , pool_mode = 'max' )\ntf . keras . backend . pool3d ( x , pool_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , pool_mode = 'max' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/reshape",
    "content": "DEPRECATED.\ntf . keras . backend . reshape ( x , shape )\ntf . keras . backend . reshape ( x , shape )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nlegacy module: DO NOT EDIT.\nlegacy\nschedules module: DO NOT EDIT.\nschedules\nClasses\nclass Adadelta : Optimizer that implements the Adadelta algorithm.\nclass Adadelta\nclass Adafactor : Optimizer that implements the Adafactor algorithm.\nclass Adafactor\nclass Adagrad : Optimizer that implements the Adagrad algorithm.\nclass Adagrad\nclass Adam : Optimizer that implements the Adam algorithm.\nclass Adam\nclass AdamW : Optimizer that implements the AdamW algorithm.\nclass AdamW\nclass Adamax : Optimizer that implements the Adamax algorithm.\nclass Adamax\nclass Ftrl : Optimizer that implements the FTRL algorithm.\nclass Ftrl\nclass Lion : Optimizer that implements the Lion algorithm.\nclass Lion\nclass LossScaleOptimizer : An optimizer that dynamically scales the loss to prevent underflow.\nclass LossScaleOptimizer\nclass Nadam : Optimizer that implements the Nadam algorithm.\nclass Nadam\nclass Optimizer : A class for Tensorflow specific optimizer logic.\nclass Optimizer\nclass RMSprop : Optimizer that implements the RMSprop algorithm.\nclass RMSprop\nclass SGD : Gradient descent (with momentum) optimizer.\nclass SGD\nFunctions\ndeserialize(...) : Returns a Keras optimizer object via its configuration.\ndeserialize(...)\nget(...) : Retrieves a Keras Optimizer instance.\nget(...)\nserialize(...) : Returns the optimizer configuration as a Python dict.\nserialize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay",
    "content": "A LearningRateSchedule that uses an inverse time decay schedule.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate , staircase = False , name = 'InverseTimeDecay' )\ntf . keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate , staircase = False , name = 'InverseTimeDecay' )\nUsed in the notebooks\nOverfit and underfit\nWhen training a model, it is often useful to lower the learning rate as\nthe training progresses. This schedule applies the inverse decay function\nto an optimizer step, given a provided initial learning rate.\nIt requires a step value to compute the decayed learning rate. You can\njust pass a backend variable that you increment at each training step.\nstep\nThe schedule is a 1-arg callable that produces a decayed learning\nrate when passed the current optimizer step. This can be useful for changing\nthe learning rate value across different invocations of optimizer functions.\nIt is computed as:\ndef decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step )\ndef decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * step / decay_step )\nor, if staircase is True , as:\nstaircase\nTrue\ndef decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * floor ( step / decay_step ))\ndef decayed_learning_rate ( step ): return initial_learning_rate / ( 1 + decay_rate * floor ( step / decay_step ))\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate.\nExample: Fit a Keras model when decaying 1/t with a rate of 0.5:\nkeras.optimizers.Optimizer\n... initial_learning_rate = 0.1 decay_steps = 1.0 decay_rate = 0.5 learning_rate_fn = keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = learning_rate_fn ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\n... initial_learning_rate = 0.1 decay_steps = 1.0 decay_rate = 0.5 learning_rate_fn = keras . optimizers . schedules . InverseTimeDecay ( initial_learning_rate , decay_steps , decay_rate ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = learning_rate_fn ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\nArgs\nArgs\ninitial_learning_rate A Python float. The initial learning rate. decay_steps How often to apply decay. decay_rate A Python number.  The decay rate. staircase Whether to apply decay in a discrete staircase, as o\npposed to continuous, fashion. name String.  Optional name of the operation.  Defaults to \"InverseTimeDecay\" .\ninitial_learning_rate\ndecay_steps\ndecay_rate\nstaircase\nname\n\"InverseTimeDecay\"\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as initial_learning_rate .\nReturns\ninitial_learning_rate\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B3",
    "content": "Instantiates the EfficientNetV2B3 architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2B3\ntf.keras.applications.efficientnet_v2.EfficientNetV2B3\ntf.keras.applications.efficientnet_v2.EfficientNetV2B3\ntf . keras . applications . EfficientNetV2B3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2B3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Permute",
    "content": "Permutes the dimensions of the input according to a given pattern.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Permute ( dims , ** kwargs )\ntf . keras . layers . Permute ( dims , ** kwargs )\nUseful e.g. connecting RNNs and convnets.\nArgs\nArgs\ndims Tuple of integers. Permutation pattern does not include the\nbatch dimension. Indexing starts at 1.\nFor instance, (2, 1) permutes the first and second dimensions\nof the input.\ndims\n(2, 1)\nInput shape Arbitrary.\nInput shape\nOutput shape Same as the input shape, but with the dimensions re-ordered according\nto the specified pattern.\nOutput shape\nx = keras . Input ( shape = ( 10 , 64 )) y = keras . layers . Permute (( 2 , 1 ))( x ) y . shape ( None , 64 , 10 )\nx = keras . Input ( shape = ( 10 , 64 ))\ny = keras . layers . Permute (( 2 , 1 ))( x )\ny . shape\n( None , 64 , 10 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/dot",
    "content": "Dot product of two tensors.\nMain aliases tf.keras.ops.numpy.dot\ntf.keras.ops.numpy.dot\ntf.keras.ops.numpy.dot\ntf . keras . ops . dot ( x1 , x2 )\ntf . keras . ops . dot ( x1 , x2 )\nIf both x1 and x2 are 1-D tensors, it is inner product of vectors\n(without complex conjugation).\nx1\nx2\nIf both x1 and x2 are 2-D tensors, it is matrix multiplication.\nx1\nx2\nIf either x1 or x2 is 0-D (scalar), it is equivalent to x1 * x2 .\nx1\nx2\nx1 * x2\nIf x1 is an N-D tensor and x2 is a 1-D tensor, it is a sum product\nover the last axis of x1 and x2 .\nx1\nx2\nx1\nx2\nIf x1 is an N-D tensor and x2 is an M-D tensor (where M>=2 ),\nit is a sum product over the last axis of x1 and the second-to-last\naxis of x2 : dot(x1, x2)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m]) .\nx1\nx2\nM>=2\nx1\nx2\ndot(x1, x2)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\nArgs\nArgs\nx1 First argument. x2 Second argument.\nx1\nx2\nNote Torch backend does not accept 0-D tensors as arguments.\nNote\nReturns Dot product of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/PrecisionAtRecall",
    "content": "Computes best precision where recall is >= specified value.\nInherits From: Metric\nMetric\ntf . keras . metrics . PrecisionAtRecall ( recall , num_thresholds = 200 , class_id = None , name = None , dtype = None )\ntf . keras . metrics . PrecisionAtRecall ( recall , num_thresholds = 200 , class_id = None , name = None , dtype = None )\nThis metric creates four local variables, true_positives , true_negatives , false_positives and false_negatives that are used to\ncompute the precision at the given recall. The threshold for the given\nrecall value is computed and used to evaluate the corresponding precision.\ntrue_positives\ntrue_negatives\nfalse_positives\nfalse_negatives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf class_id is specified, we calculate precision by considering only the\nentries in the batch for which class_id is above the threshold\npredictions, and computing the fraction of them for which class_id is\nindeed a correct label.\nclass_id\nclass_id\nclass_id\nArgs\nArgs\nrecall A scalar value in range [0, 1] . num_thresholds (Optional) Defaults to 200. The number of thresholds to\nuse for matching the given recall. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nrecall\n[0, 1]\nnum_thresholds\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . PrecisionAtRecall ( 0.5 ) m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ]) m . result () 0.5\nm = keras . metrics . PrecisionAtRecall ( 0.5 )\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ])\nm . result ()\n0.5\nm . reset_state () m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ], sample_weight = [ 2 , 2 , 2 , 1 , 1 ]) m . result () 0.33333333\nm . reset_state ()\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ],\nsample_weight = [ 2 , 2 , 2 , 1 , 1 ])\nm . result ()\n0.33333333\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . PrecisionAtRecall ( recall = 0.8 )])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . PrecisionAtRecall ( recall = 0.8 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/binary_crossentropy",
    "content": "DEPRECATED.\ntf . keras . backend . binary_crossentropy ( target , output , from_logits = False )\ntf . keras . backend . binary_crossentropy ( target , output , from_logits = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/densenet/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . densenet . decode_predictions ( preds , top = 5 )\ntf . keras . applications . densenet . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Quantizer",
    "content": "Main aliases tf.keras.quantizers.Quantizer Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Quantizer\ntf.keras.quantizers.Quantizer\ntf.keras.quantizers.Quantizer\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Quantizer\ntf.compat.v1.keras.Quantizer\ntf . keras . Quantizer ( output_dtype = 'int8' )\ntf . keras . Quantizer ( output_dtype = 'int8' )\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a quantizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same quantizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A quantizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the quantizer.\nAn quantizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the quantizer.\nThe same quantizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a quantized output from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/NASNetLarge",
    "content": "Instantiates a NASNet model in ImageNet mode.\nMain aliases tf.keras.applications.nasnet.NASNetLarge\ntf.keras.applications.nasnet.NASNetLarge\ntf.keras.applications.nasnet.NASNetLarge\ntf . keras . applications . NASNetLarge ( input_shape = None , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . NASNetLarge ( input_shape = None , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nLearning Transferable Architectures for Scalable Image Recognition (CVPR 2018)\nOptionally loads weights pre-trained on ImageNet.\nNote that the data format convention used by the model is\nthe one specified in your Keras config at ~/.keras/keras.json .\n~/.keras/keras.json\nkeras.applications.nasnet.preprocess_input\nArgs\nArgs\ninput_shape Optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (331, 331, 3) for NASNetLarge.\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 32.\nE.g. (224, 224, 3) would be one valid value. include_top Whether to include the fully-connected\nlayer at the top of the network. weights None (random initialization) or imagenet (ImageNet weights).  For loading imagenet weights, input_shape should be (331, 331, 3) input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninput_shape\ninclude_top\n(331, 331, 3)\n(224, 224, 3)\ninclude_top\nweights\nNone\nimagenet\nimagenet\ninput_shape\ninput_tensor\nlayers.Input()\npooling\ninclude_top\nFalse\nNone means that the output of the model\nwill be the 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a\n2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\"\nlayer.  When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Keras model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Hinge",
    "content": "Computes the hinge loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . Hinge ( reduction = 'sum_over_batch_size' , name = 'hinge' )\ntf . keras . losses . Hinge ( reduction = 'sum_over_batch_size' , name = 'hinge' )\nUsed in the notebooks\nMNIST classification\nloss = maximum ( 1 - y_true * y_pred , 0 )\nloss = maximum ( 1 - y_true * y_pred , 0 )\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\ny_true\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Input",
    "content": "Used to instantiate a Keras tensor.\nMain aliases tf.keras.layers.Input Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Input\ntf.keras.layers.Input\ntf.keras.layers.Input\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Input\ntf.compat.v1.keras.Input\ntf . keras . Input ( shape = None , batch_size = None , dtype = None , sparse = None , batch_shape = None , name = None , tensor = None )\ntf . keras . Input ( shape = None , batch_size = None , dtype = None , sparse = None , batch_shape = None , name = None , tensor = None )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nUse TF1.x models in TF2 workflows\nExtension types\nDebug a TensorFlow 2 migrated training pipeline\nMigrate from TPU embedding_columns to TPUEmbedding layer\nParameter server training with ParameterServerStrategy\npix2pix: Image-to-image translation with a conditional GAN\nClassify structured data using Keras preprocessing layers\nTransfer learning with YAMNet for environmental sound classification\nLoad CSV data\nA Keras tensor is a symbolic tensor-like object, which we augment with\ncertain attributes that allow us to build a Keras model just by knowing the\ninputs and outputs of the model.\nFor instance, if a , b and c are Keras tensors,\nit becomes possible to do: model = Model(input=[a, b], output=c)\na\nb\nc\nmodel = Model(input=[a, b], output=c)\nArgs\nArgs\nshape A shape tuple (tuple of integers or None objects),\nnot including the batch size.\nFor instance, shape=(32,) indicates that the expected input\nwill be batches of 32-dimensional vectors. Elements of this tuple\ncan be None ; None elements represent dimensions where the shape\nis not known and may vary (e.g. sequence length). batch_size Optional static batch size (integer). dtype The data type expected by the input, as a string\n(e.g. \"float32\" , \"int32\" ...) sparse A boolean specifying whether the expected input will be sparse\ntensors. Note that, if sparse is False , sparse tensors can still\nbe passed into the input - they will be densified with a default\nvalue of 0. This feature is only supported with the TensorFlow\nbackend. Defaults to False . name Optional name string for the layer.\nShould be unique in a model (do not reuse the same name twice).\nIt will be autogenerated if it isn't provided. tensor Optional existing tensor to wrap into the Input layer.\nIf set, the layer will use this tensor rather\nthan creating a new placeholder tensor.\nshape\nNone\nshape=(32,)\nNone\nNone\nbatch_size\ndtype\n\"float32\"\n\"int32\"\nsparse\nsparse\nFalse\nFalse\nname\ntensor\nInput\nReturns A Keras tensor.\nReturns\n# This is a logistic regression in Keras x = Input ( shape = ( 32 ,)) y = Dense ( 16 , activation = 'softmax' )( x ) model = Model ( x , y )\n# This is a logistic regression in Keras x = Input ( shape = ( 32 ,)) y = Dense ( 16 , activation = 'softmax' )( x ) model = Model ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/DeviceMesh",
    "content": "A cluster of computation devices for distributed computation.\ntf . keras . distribution . DeviceMesh ( shape , axis_names , devices = None )\ntf . keras . distribution . DeviceMesh ( shape , axis_names , devices = None )\nThis API is aligned with jax.sharding.Mesh and tf.dtensor.Mesh , which\nrepresents the computation devices in the global context.\njax.sharding.Mesh\ntf.dtensor.Mesh\nSee more details in jax.sharding.Mesh and tf.dtensor.Mesh .\nArgs\nArgs\nshape tuple of list of integers. The shape of the overall DeviceMesh , e.g. (8,) for a data parallel only distribution,\nor (4, 2) for a model+data parallel distribution. axis_names List of string. The logical name of the each axis for\nthe DeviceMesh . The length of the axis_names should match to\nthe rank of the shape . The axis_names will be used to\nmatch/create the TensorLayout when distribute the data and\nvariables. devices Optional list of devices. Defaults to all the available\ndevices locally from keras.distribution.list_devices() .\nshape\nDeviceMesh\n(8,)\n(4, 2)\naxis_names\nDeviceMesh\naxis_names\nshape\naxis_names\nTensorLayout\ndevices\nkeras.distribution.list_devices()\nAttributes\nAttributes\naxis_names\naxis_names\ndevices\ndevices\nshape\nshape"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/update",
    "content": "DEPRECATED.\ntf . keras . backend . update ( x , new_x )\ntf . keras . backend . update ( x , new_x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/get",
    "content": "Retrieve a Keras constraint object via an identifier.\ntf . keras . constraints . get ( identifier )\ntf . keras . constraints . get ( identifier )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CTC",
    "content": "CTC (Connectionist Temporal Classification) loss.\nInherits From: Loss\nLoss\ntf . keras . losses . CTC ( reduction = 'sum_over_batch_size' , name = 'ctc' )\ntf . keras . losses . CTC ( reduction = 'sum_over_batch_size' , name = 'ctc' )\nArgs\nArgs\ny_true A tensor of shape (batch_size, target_max_length) containing\nthe true labels in integer format. 0 always represents\nthe blank/mask index and should not be used for classes. y_pred A tensor of shape (batch_size, output_max_length, num_classes) containing logits (the output of your model).\nThey should not be normalized via softmax.\ny_true\n(batch_size, target_max_length)\n0\ny_pred\n(batch_size, output_max_length, num_classes)\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/poisson",
    "content": "Computes the Poisson loss between y_true and y_pred.\nMain aliases tf.keras.metrics.poisson\ntf.keras.metrics.poisson\ntf.keras.metrics.poisson\ntf . keras . losses . poisson ( y_true , y_pred )\ntf . keras . losses . poisson ( y_true , y_pred )\nloss = y_pred - y_true * log ( y_pred )\nloss = y_pred - y_true * log ( y_pred )\nArgs\nArgs\ny_true Ground truth values. shape = [batch_size, d0, .. dN] . y_pred The predicted values. shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Poisson loss values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . poisson ( y_true , y_pred ) assert loss . shape == ( 2 ,) y_pred = y_pred + 1e-7 assert np . allclose ( loss , np . mean ( y_pred - y_true * np . log ( y_pred ), axis =- 1 ), atol = 1e-5 )\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . poisson ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\ny_pred = y_pred + 1e-7\nassert np . allclose (\nloss , np . mean ( y_pred - y_true * np . log ( y_pred ), axis =- 1 ),\natol = 1e-5 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sqrt",
    "content": "DEPRECATED.\ntf . keras . backend . sqrt ( x )\ntf . keras . backend . sqrt ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/multiply",
    "content": "Functional interface to the keras.layers.Multiply layer.\nkeras.layers.Multiply\ntf . keras . layers . multiply ( inputs , ** kwargs )\ntf . keras . layers . multiply ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors , all of the same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the elementwise product of the inputs with the same\nshape as the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . multiply ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . multiply ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) y = keras . layers . multiply ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\ny = keras . layers . multiply ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout",
    "content": "DEPRECATED.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . AlphaDropout ( rate , noise_shape = None , seed = None , ** kwargs )\ntf . keras . layers . AlphaDropout ( rate , noise_shape = None , seed = None , ** kwargs )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/hstack",
    "content": "Stack tensors in sequence horizontally (column wise).\nMain aliases tf.keras.ops.numpy.hstack\ntf.keras.ops.numpy.hstack\ntf.keras.ops.numpy.hstack\ntf . keras . ops . hstack ( xs )\ntf . keras . ops . hstack ( xs )\nThis is equivalent to concatenation along the first axis for 1-D tensors,\nand along the second axis for all other tensors.\nArgs\nArgs\nxs Sequence of tensors.\nxs\nReturns The tensor formed by stacking the given tensors.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sigmoid",
    "content": "DEPRECATED.\ntf . keras . backend . sigmoid ( x )\ntf . keras . backend . sigmoid ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/get_word_index",
    "content": "Retrieves a dict mapping words to their index in the Reuters dataset.\ntf . keras . datasets . reuters . get_word_index ( path = 'reuters_word_index.json' )\ntf . keras . datasets . reuters . get_word_index ( path = 'reuters_word_index.json' )\nActual word indices starts from 3, with 3 indices reserved for:\n0 (padding), 1 (start), 2 (oov).\nE.g. word index of 'the' is 1, but the in the actual training data, the\nindex of 'the' will be 1 + 3 = 4. Vice versa, to translate word indices in\ntraining data back to words using this mapping, indices need to subtract 3.\nArgs\nArgs\npath where to cache the data (relative to ~/.keras/dataset ).\npath\n~/.keras/dataset\nReturns The word index dictionary. Keys are word strings, values are their\nindex.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/TFSMLayer",
    "content": "Reload a Keras model/layer that was saved via SavedModel / ExportArchive.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . TFSMLayer ( filepath , call_endpoint = 'serve' , call_training_endpoint = None , trainable = True , name = None , dtype = None )\ntf . keras . layers . TFSMLayer ( filepath , call_endpoint = 'serve' , call_training_endpoint = None , trainable = True , name = None , dtype = None )\nArguments\nArguments\nfilepath str or pathlib.Path object. The path to the SavedModel. call_endpoint Name of the endpoint to use as the call() method\nof the reloaded layer. If the SavedModel was created\nvia model.export() ,\nthen the default endpoint name is 'serve' . In other cases\nit may be named 'serving_default' .\nfilepath\nstr\npathlib.Path\ncall_endpoint\ncall()\nmodel.export()\n'serve'\n'serving_default'\nmodel . export ( \"path/to/artifact\" ) reloaded_layer = TFSMLayer ( \"path/to/artifact\" ) outputs = reloaded_layer ( inputs )\nmodel . export ( \"path/to/artifact\" ) reloaded_layer = TFSMLayer ( \"path/to/artifact\" ) outputs = reloaded_layer ( inputs )\nThe reloaded object can be used like a regular Keras layer, and supports\ntraining/fine-tuning of its trainable weights. Note that the reloaded\nobject retains none of the internal structure or custom methods of the\noriginal object -- it's a brand new layer created around the saved\nfunction.\nLimitations:\nOnly call endpoints with a single inputs tensor argument\n(which may optionally be a dict/tuple/list of tensors) are supported.\nFor endpoints with multiple separate input tensor arguments, consider\nsubclassing TFSMLayer and implementing a call() method with a\ncustom signature.\ninputs\nTFSMLayer\ncall()\nIf you need training-time behavior to differ from inference-time behavior\n(i.e. if you need the reloaded object to support a training=True argument\nin __call__() ), make sure that the training-time call function is\nsaved as a standalone endpoint in the artifact, and provide its name\nto the TFSMLayer via the call_training_endpoint argument.\ntraining=True\n__call__()\nTFSMLayer\ncall_training_endpoint\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/KLDivergence",
    "content": "Computes Kullback-Leibler divergence loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . KLDivergence ( reduction = 'sum_over_batch_size' , name = 'kl_divergence' )\ntf . keras . losses . KLDivergence ( reduction = 'sum_over_batch_size' , name = 'kl_divergence' )\nloss = y_true * log ( y_true / y_pred )\nloss = y_true * log ( y_true / y_pred )\ny_true and y_pred are expected to be probability\ndistributions, with values between 0 and 1. They will get\nclipped to the [0, 1] range.\ny_true\ny_pred\n[0, 1]\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/convert_to_tensor",
    "content": "Convert a NumPy array to a tensor.\ntf . keras . ops . convert_to_tensor ( x , dtype = None , sparse = None )\ntf . keras . ops . convert_to_tensor ( x , dtype = None , sparse = None )\nArgs\nArgs\nx A NumPy array. dtype The target type. sparse Whether to keep sparse tensors. False will cause sparse\ntensors to be densified. The default value of None means that\nsparse tensors are kept only if the backend supports them.\nx\ndtype\nsparse\nFalse\nNone\nReturns A tensor of the specified dtype .\nReturns\ndtype\nx = np . array ([ 1 , 2 , 3 ]) y = keras . ops . convert_to_tensor ( x )\nx = np . array ([ 1 , 2 , 3 ])\ny = keras . ops . convert_to_tensor ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/cumprod",
    "content": "DEPRECATED.\ntf . keras . backend . cumprod ( x , axis = 0 )\ntf . keras . backend . cumprod ( x , axis = 0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet152V2",
    "content": "Instantiates the ResNet152V2 architecture.\nMain aliases tf.keras.applications.resnet_v2.ResNet152V2\ntf.keras.applications.resnet_v2.ResNet152V2\ntf.keras.applications.resnet_v2.ResNet152V2\ntf . keras . applications . ResNet152V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet152V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nIdentity Mappings in Deep Residual Networks (CVPR 2016)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet_v2.preprocess_input\nresnet_v2.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/model_to_dot",
    "content": "Convert a Keras model to dot format.\ntf . keras . utils . model_to_dot ( model , show_shapes = False , show_dtype = False , show_layer_names = True , rankdir = 'TB' , expand_nested = False , dpi = 200 , subgraph = False , show_layer_activations = False , show_trainable = False , ** kwargs )\ntf . keras . utils . model_to_dot ( model , show_shapes = False , show_dtype = False , show_layer_names = True , rankdir = 'TB' , expand_nested = False , dpi = 200 , subgraph = False , show_layer_activations = False , show_trainable = False , ** kwargs )\nArgs\nArgs\nmodel A Keras model instance. show_shapes whether to display shape information. show_dtype whether to display layer dtypes. show_layer_names whether to display layer names. rankdir rankdir argument passed to PyDot,\na string specifying the format of the plot: \"TB\" creates a vertical plot; \"LR\" creates a horizontal plot. expand_nested whether to expand nested Functional models\ninto clusters. dpi Image resolution in dots per inch. subgraph whether to return a pydot.Cluster instance. show_layer_activations Display layer activations (only for layers that\nhave an activation property). show_trainable whether to display if a layer is trainable.\nmodel\nshow_shapes\nshow_dtype\nshow_layer_names\nrankdir\nrankdir\n\"TB\"\n\"LR\"\nexpand_nested\ndpi\nsubgraph\npydot.Cluster\nshow_layer_activations\nactivation\nshow_trainable\nReturns A pydot.Dot instance representing the Keras model or\na pydot.Cluster instance representing nested model if subgraph=True .\nReturns\npydot.Dot\npydot.Cluster\nsubgraph=True"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ones",
    "content": "DEPRECATED.\ntf . keras . backend . ones ( shape , dtype = None , name = None )\ntf . keras . backend . ones ( shape , dtype = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/concatenate",
    "content": "Join a sequence of tensors along an existing axis.\nMain aliases tf.keras.ops.numpy.concatenate\ntf.keras.ops.numpy.concatenate\ntf.keras.ops.numpy.concatenate\ntf . keras . ops . concatenate ( xs , axis = 0 )\ntf . keras . ops . concatenate ( xs , axis = 0 )\nArgs\nArgs\nxs The sequence of tensors to concatenate. axis The axis along which the tensors will be joined. Defaults to 0 .\nxs\naxis\n0\nReturns The concatenated tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/map_shape_structure",
    "content": "Variant of keras.tree.map_structure that operates on shape tuples.\ntf . keras . tree . map_shape_structure ( func , structure )\ntf . keras . tree . map_shape_structure ( func , structure )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arctan",
    "content": "Trigonometric inverse tangent, element-wise.\nMain aliases tf.keras.ops.numpy.arctan\ntf.keras.ops.numpy.arctan\ntf.keras.ops.numpy.arctan\ntf . keras . ops . arctan ( x )\ntf . keras . ops . arctan ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Tensor of the inverse tangent of each element in x , in the interval [-pi/2, pi/2] .\nReturns\nx\n[-pi/2, pi/2]\nx = keras . ops . convert_to_tensor ([ 0 , 1 ]) keras . ops . arctan ( x ) array ([ 0. , 0.7853982 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 0 , 1 ])\nkeras . ops . arctan ( x )\narray ([ 0. , 0.7853982 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/FalsePositives",
    "content": "Calculates the number of false positives.\nInherits From: Metric\nMetric\ntf . keras . metrics . FalsePositives ( thresholds = None , name = None , dtype = None )\ntf . keras . metrics . FalsePositives ( thresholds = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nIf sample_weight is given, calculates the sum of the weights of\nfalse positives. This metric creates one local variable, accumulator that is used to keep track of the number of false positives.\nsample_weight\naccumulator\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nthresholds (Optional) Defaults to 0.5 . A float value, or a Python\nlist/tuple of float threshold values in [0, 1] . A threshold is\ncompared with prediction values to determine the truth value of\npredictions (i.e., above the threshold is True , below is False ).\nIf used with a loss function that sets from_logits=True (i.e. no\nsigmoid applied to predictions), thresholds should be set to 0.\nOne metric value is generated for each threshold value. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n0.5\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nname\ndtype\nm = keras . metrics . FalsePositives () m . update_state ([ 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 1 ]) m . result () 2.0\nm = keras . metrics . FalsePositives ()\nm . update_state ([ 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 1 ])\nm . result ()\n2.0\nm . reset_state () m . update_state ([ 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 0 , 0 ], [ 0 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the metric statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanSquaredError",
    "content": "Computes the mean squared error between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . MeanSquaredError ( name = 'mean_squared_error' , dtype = None )\ntf . keras . metrics . MeanSquaredError ( name = 'mean_squared_error' , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nloss = mean ( square ( y_true - y_pred ))\nloss = mean ( square ( y_true - y_pred ))\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . MeanSquaredError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.25\nm = keras . metrics . MeanSquaredError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.25\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Poisson",
    "content": "Computes the Poisson loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . Poisson ( reduction = 'sum_over_batch_size' , name = 'poisson' )\ntf . keras . losses . Poisson ( reduction = 'sum_over_batch_size' , name = 'poisson' )\nloss = y_pred - y_true * log ( y_pred )\nloss = y_pred - y_true * log ( y_pred )\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/eig",
    "content": "Computes the eigenvalues and eigenvectors of a square matrix.\nMain aliases tf.keras.ops.linalg.eig\ntf.keras.ops.linalg.eig\ntf.keras.ops.linalg.eig\ntf . keras . ops . eig ( x )\ntf . keras . ops . eig ( x )\nArgs\nArgs\nx Input tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tuple of two tensors: a tensor of shape (..., M) containing\neigenvalues and a tensor of shape (..., M, M) containing eigenvectors.\nReturns\n(..., M)\n(..., M, M)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/max",
    "content": "DEPRECATED.\ntf . keras . backend . max ( x , axis = None , keepdims = False )\ntf . keras . backend . max ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nassert_same_structure(...) : Asserts that two structures are nested in the same way.\nassert_same_structure(...)\nflatten(...) : Flattens a possibly nested structure into a list.\nflatten(...)\nis_nested(...) : Checks if a given structure is nested.\nis_nested(...)\nlists_to_tuples(...)\nlists_to_tuples(...)\nmap_shape_structure(...) : Variant of keras.tree.map_structure that operates on shape tuples.\nmap_shape_structure(...)\nmap_structure(...) : Maps func through given structures.\nmap_structure(...)\nfunc\nmap_structure_up_to(...) : Maps func through given structures up to shallow_structure .\nmap_structure_up_to(...)\nfunc\nshallow_structure\npack_sequence_as(...) : Returns a given flattened sequence packed into a given structure.\npack_sequence_as(...)\ntraverse(...) : Traverses the given nested structure, applying the given function.\ntraverse(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/FlaxLayer",
    "content": "Keras Layer that wraps a Flax module.\nInherits From: JaxLayer , Layer , Operation\nJaxLayer\nLayer\nOperation\ntf . keras . layers . FlaxLayer ( module , method = None , variables = None , ** kwargs )\ntf . keras . layers . FlaxLayer ( module , method = None , variables = None , ** kwargs )\nThis layer enables the use of Flax components in the form of flax.linen.Module instances within Keras when using JAX as the backend for Keras.\nflax.linen.Module\nThe module method to use for the forward pass can be specified via the method argument and is __call__ by default. This method must take the\nfollowing arguments with these exact names:\nmethod\n__call__\nself if the method is bound to the module, which is the case for the\ndefault of __call__ , and module otherwise to pass the module.\nself\n__call__\nmodule\ninputs : the inputs to the model, a JAX array or a PyTree of arrays.\ninputs\nPyTree\ntraining (optional) : an argument specifying if we're in training mode\nor inference mode, True is passed in training mode.\ntraining\nTrue\nFlaxLayer handles the non-trainable state of your model and required RNGs\nautomatically. Note that the mutable parameter of flax.linen.Module.apply() is set to DenyList([\"params\"]) , therefore making the assumption that all\nthe variables outside of the \"params\" collection are non-trainable weights.\nFlaxLayer\nmutable\nflax.linen.Module.apply()\nDenyList([\"params\"])\nThis example shows how to create a FlaxLayer from a Flax Module with\nthe default __call__ method and no training argument:\nFlaxLayer\nModule\n__call__\nclass MyFlaxModule ( flax . linen . Module ): @flax . linen . compact def __call__ ( self , inputs ): x = inputs x = flax . linen . Conv ( features = 32 , kernel_size = ( 3 , 3 ))( x ) x = flax . linen . relu ( x ) x = flax . linen . avg_pool ( x , window_shape = ( 2 , 2 ), strides = ( 2 , 2 )) x = x . reshape (( x . shape [ 0 ], - 1 )) # flatten x = flax . linen . Dense ( features = 200 )( x ) x = flax . linen . relu ( x ) x = flax . linen . Dense ( features = 10 )( x ) x = flax . linen . softmax ( x ) return x flax_module = MyFlaxModule () keras_layer = FlaxLayer ( flax_module )\nclass MyFlaxModule ( flax . linen . Module ): @flax . linen . compact def __call__ ( self , inputs ): x = inputs x = flax . linen . Conv ( features = 32 , kernel_size = ( 3 , 3 ))( x ) x = flax . linen . relu ( x ) x = flax . linen . avg_pool ( x , window_shape = ( 2 , 2 ), strides = ( 2 , 2 )) x = x . reshape (( x . shape [ 0 ], - 1 )) # flatten x = flax . linen . Dense ( features = 200 )( x ) x = flax . linen . relu ( x ) x = flax . linen . Dense ( features = 10 )( x ) x = flax . linen . softmax ( x ) return x flax_module = MyFlaxModule () keras_layer = FlaxLayer ( flax_module )\nThis example shows how to wrap the module method to conform to the required\nsignature. This allows having multiple input arguments and a training\nargument that has a different name and values. This additionally shows how\nto use a function that is not bound to the module.\nclass MyFlaxModule ( flax . linen . Module ): @flax . linen . compact def forward ( self , input1 , input2 , deterministic ): ... return outputs def my_flax_module_wrapper ( module , inputs , training ): input1 , input2 = inputs return module . forward ( input1 , input2 , not training ) flax_module = MyFlaxModule () keras_layer = FlaxLayer ( module = flax_module , method = my_flax_module_wrapper , )\nclass MyFlaxModule ( flax . linen . Module ): @flax . linen . compact def forward ( self , input1 , input2 , deterministic ): ... return outputs def my_flax_module_wrapper ( module , inputs , training ): input1 , input2 = inputs return module . forward ( input1 , input2 , not training ) flax_module = MyFlaxModule () keras_layer = FlaxLayer ( module = flax_module , method = my_flax_module_wrapper , )\nArgs\nArgs\nmodule An instance of flax.linen.Module or subclass. method The method to call the model. This is generally a method in the Module . If not provided, the __call__ method is used. method can also be a function not defined in the Module , in which case it\nmust take the Module as the first argument. It is used for both Module.init and Module.apply . Details are documented in the method argument of flax.linen.Module.apply() . variables A dict containing all the variables of the module in the\nsame format as what is returned by flax.linen.Module.init() .\nIt should contain a \"params\" key and, if applicable, other keys for\ncollections of variables for non-trainable state. This allows\npassing trained parameters and learned non-trainable state or\ncontrolling the initialization. If None is passed, the module's init function is called at build time to initialize the variables\nof the model.\nmodule\nflax.linen.Module\nmethod\nModule\n__call__\nmethod\nModule\nModule\nModule.init\nModule.apply\nmethod\nflax.linen.Module.apply()\nvariables\ndict\nflax.linen.Module.init()\nNone\ninit\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation",
    "content": "Applies an activation function to an output.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Activation ( activation , ** kwargs )\ntf . keras . layers . Activation ( activation , ** kwargs )\nUsed in the notebooks\nMixed precision\nRagged tensors\nBasic text classification\nLoad text\nClassifying CIFAR-10 with XLA\nTFF simulations with accelerators\nParametrized Quantum Circuits for Reinforcement Learning\nArgs\nArgs\nactivation Activation function. It could be a callable, or the name of\nan activation from the keras.activations namespace. **kwargs Base layer keyword arguments, such as name and dtype .\nactivation\nkeras.activations\n**kwargs\nname\ndtype\nlayer = keras . layers . Activation ( 'relu' ) layer ([ - 3.0 , - 1.0 , 0.0 , 2.0 ]) [ 0.0 , 0.0 , 0.0 , 2.0 ] layer = keras . layers . Activation ( keras . activations . relu ) layer ([ - 3.0 , - 1.0 , 0.0 , 2.0 ]) [ 0.0 , 0.0 , 0.0 , 2.0 ]\nlayer = keras . layers . Activation ( 'relu' )\nlayer ([ - 3.0 , - 1.0 , 0.0 , 2.0 ])\n[ 0.0 , 0.0 , 0.0 , 2.0 ]\nlayer = keras . layers . Activation ( keras . activations . relu )\nlayer ([ - 3.0 , - 1.0 , 0.0 , 2.0 ])\n[ 0.0 , 0.0 , 0.0 , 2.0 ]\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/full",
    "content": "Return a new tensor of given shape and type, filled with fill_value .\nfill_value\nMain aliases tf.keras.ops.numpy.full\ntf.keras.ops.numpy.full\ntf.keras.ops.numpy.full\ntf . keras . ops . full ( shape , fill_value , dtype = None )\ntf . keras . ops . full ( shape , fill_value , dtype = None )\nArgs\nArgs\nshape Shape of the new tensor. fill_value Fill value. dtype Desired data type of the tensor.\nshape\nfill_value\ndtype\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/conv",
    "content": "General N-D convolution.\nMain aliases tf.keras.ops.nn.conv\ntf.keras.ops.nn.conv\ntf.keras.ops.nn.conv\ntf . keras . ops . conv ( inputs , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\ntf . keras . ops . conv ( inputs , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\nThis ops supports 1D, 2D and 3D convolution.\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . kernel Tensor of rank N+2. kernel has shape (kernel_spatial_shape, num_input_channels, num_output_channels) . num_input_channels should match the number of channels in inputs . strides int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the strides of the convolution along each spatial\ndimension. If strides is int, then every spatial dimension shares\nthe same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) . dilation_rate int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the dilation rate to use for dilated convolution. If dilation_rate is int, then every spatial dimension shares\nthe same dilation_rate .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\nkernel\nkernel\n(kernel_spatial_shape, num_input_channels, num_output_channels)\nnum_input_channels\ninputs\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\ndilation_rate\nlen(inputs_spatial_shape)\ndilation_rate\ndilation_rate\nReturns A tensor of rank N+2, the result of the conv operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ctc_loss",
    "content": "CTC (Connectionist Temporal Classification) loss.\nMain aliases tf.keras.ops.nn.ctc_loss\ntf.keras.ops.nn.ctc_loss\ntf.keras.ops.nn.ctc_loss\ntf . keras . ops . ctc_loss ( target , output , target_length , output_length , mask_index = 0 )\ntf . keras . ops . ctc_loss ( target , output , target_length , output_length , mask_index = 0 )\nArgs\nArgs\ntarget A tensor of shape (batch_size, max_length) containing\nthe true labels in integer format. output A tensor of shape (batch_size, max_length, num_classes) containing logits (the output of your model). target_length A tensor of shape (batch_size,) containing the\ntrue label lengths. output_length A tensor of shape (batch_size,) containing the\noutput lengths. mask_index The index of the mask character in the vocabulary.\nDefaults to 0 .\ntarget\n(batch_size, max_length)\noutput\n(batch_size, max_length, num_classes)\ntarget_length\n(batch_size,)\noutput_length\n(batch_size,)\nmask_index\n0"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/pow",
    "content": "DEPRECATED.\ntf . keras . backend . pow ( x , a )\ntf . keras . backend . pow ( x , a )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/MinMaxNorm",
    "content": "MinMaxNorm weight constraint.\nInherits From: Constraint\nConstraint\nMain aliases tf.keras.constraints.min_max_norm\ntf.keras.constraints.min_max_norm\ntf.keras.constraints.min_max_norm\ntf . keras . constraints . MinMaxNorm ( min_value = 0.0 , max_value = 1.0 , rate = 1.0 , axis = 0 )\ntf . keras . constraints . MinMaxNorm ( min_value = 0.0 , max_value = 1.0 , rate = 1.0 , axis = 0 )\nConstrains the weights incident to each hidden unit\nto have the norm between a lower bound and an upper bound.\nArgs\nArgs\nmin_value the minimum norm for the incoming weights. max_value the maximum norm for the incoming weights. rate rate for enforcing the constraint: weights will be\nrescaled to yield (1 - rate) * norm + rate * norm.clip(min_value, max_value) .\nEffectively, this means that rate=1.0 stands for strict\nenforcement of the constraint, while rate<1.0 means that\nweights will be rescaled at each step to slowly move\ntowards a value inside the desired interval. axis integer, axis along which to calculate weight norms.\nFor instance, in a Dense layer the weight matrix\nhas shape (input_dim, output_dim) ,\nset axis to 0 to constrain each weight vector\nof length (input_dim,) .\nIn a Conv2D layer with data_format=\"channels_last\" ,\nthe weight tensor has shape (rows, cols, input_depth, output_depth) ,\nset axis to [0, 1, 2] to constrain the weights of each filter tensor of size (rows, cols, input_depth) .\nmin_value\nmax_value\nrate\n(1 - rate) * norm + rate * norm.clip(min_value, max_value)\naxis\nDense\n(input_dim, output_dim)\naxis\n0\n(input_dim,)\nConv2D\ndata_format=\"channels_last\"\n(rows, cols, input_depth, output_depth)\naxis\n[0, 1, 2]\n(rows, cols, input_depth)\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a weight constraint from a configuration dictionary.\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns A keras.constraints.Constraint instance.\nkeras.constraints.Constraint\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns a Python dict of the object config.\nA constraint config is a Python dictionary (JSON-serializable) that can\nbe used to reinstantiate the same object.\nReturns Python dict containing the configuration of the constraint object.\n__call__\n__call__\nView source\n__call__ ( w )\n__call__ ( w )\nApplies the constraint to the input weight variable.\nBy default, the inputs weight variable is not modified.\nUsers should override this method to implement their own projection\nfunction.\nArgs\nw Input weight variable.\nw\nReturns Projected variable (by default, returns unmodified inputs)."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/FloatDTypePolicy",
    "content": "A dtype policy for a Keras layer.\nInherits From: DTypePolicy\nDTypePolicy\nMain aliases tf.keras.dtype_policies.FloatDTypePolicy Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.FloatDTypePolicy\ntf.keras.dtype_policies.FloatDTypePolicy\ntf.keras.dtype_policies.FloatDTypePolicy\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.FloatDTypePolicy\ntf.compat.v1.keras.FloatDTypePolicy\ntf . keras . FloatDTypePolicy ( name )\ntf . keras . FloatDTypePolicy ( name )\nA dtype policy determines a layer's computation and variable dtypes. Each\nlayer has a policy. Policies can be passed to the dtype argument of layer\nconstructors, or a global policy can be set with keras.config.set_dtype_policy .\ndtype\nkeras.config.set_dtype_policy\nArgs\nArgs\nname The policy name, which determines the compute and variable dtypes.\nCan be any dtype name, such as \"float32\" or \"float64\" ,\nwhich causes both the compute and variable dtypes\nwill be that dtype.\nCan also be the string \"mixed_float16\" or \"mixed_bfloat16\" ,\nwhich causes the compute dtype to be float16 or bfloat16 and the variable dtype to be float32 .\nname\n\"float32\"\n\"float64\"\n\"mixed_float16\"\n\"mixed_bfloat16\"\nfloat16\nbfloat16\nfloat32\nTypically you only need to interact with dtype policies when using mixed\nprecision, which is the use of float16 or bfloat16 for computations and\nfloat32 for variables. This is why the term mixed_precision appears in the\nAPI name. Mixed precision can be enabled by passing \"mixed_float16\" or \"mixed_bfloat16\" to keras.mixed_precision.set_dtype_policy() .\nmixed_precision\n\"mixed_float16\"\n\"mixed_bfloat16\"\nkeras.mixed_precision.set_dtype_policy()\nkeras . config . set_dtype_policy ( \"mixed_float16\" ) layer1 = keras . layers . Dense ( 10 ) layer1 . dtype_policy # layer1 will automatically use mixed precision < DTypePolicy \"mixed_float16\" > # Can optionally override layer to use float32 # instead of mixed precision. layer2 = keras . layers . Dense ( 10 , dtype = \"float32\" ) layer2 . dtype_policy < DTypePolicy \"float32\" > # Set policy back to initial float32. keras . config . set_dtype_policy ( 'float32' )\nkeras . config . set_dtype_policy ( \"mixed_float16\" )\nlayer1 = keras . layers . Dense ( 10 )\nlayer1 . dtype_policy # layer1 will automatically use mixed precision\n< DTypePolicy \"mixed_float16\" >\n# Can optionally override layer to use float32\n# instead of mixed precision.\nlayer2 = keras . layers . Dense ( 10 , dtype = \"float32\" )\nlayer2 . dtype_policy\n< DTypePolicy \"float32\" >\n# Set policy back to initial float32.\nkeras . config . set_dtype_policy ( 'float32' )\nIn the example above, passing dtype=\"float32\" to the layer is\nequivalent to passing dtype=keras.config.DTypePolicy(\"float32\") .\nIn general, passing a dtype policy name to a layer is equivalent\nto passing the corresponding policy, so it is never necessary\nto explicitly construct a DTypePolicy object.\ndtype=\"float32\"\ndtype=keras.config.DTypePolicy(\"float32\")\nDTypePolicy\nAttributes\nAttributes\ncompute_dtype The compute dtype of this policy.\ncompute_dtype\nThis is the dtype layers will do their computations in. Typically layers\noutput tensors with the compute dtype as well.\nNote that even if the compute dtype is float16 or bfloat16, hardware\ndevices may not do individual adds, multiplies, and other fundamental\noperations in float16 or bfloat16, but instead may do some of them in\nfloat32 for numeric stability. The compute dtype is the dtype of the\ninputs and outputs of the ops that the layer executes.\nInternally, many ops will do certain internal calculations in\nfloat32 or some other device-internal intermediate format with higher\nprecision than float16/bfloat16, to increase numeric stability. name Returns the name of this policy. variable_dtype The variable dtype of this policy.\nname\nvariable_dtype\nThis is the dtype layers will create their variables in, unless a layer\nexplicitly chooses a different dtype. If this is different than DTypePolicy.compute_dtype , Layers will cast variables to\nthe compute dtype to avoid type errors.\nDTypePolicy.compute_dtype\nVariable regularizers are run in the variable dtype, not the compute\ndtype.\nMethods\nconvert_input\nconvert_input\nView source\nconvert_input ( x , autocast , dtype )\nconvert_input ( x , autocast , dtype )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/leaky_relu",
    "content": "Leaky version of a Rectified Linear Unit activation function.\nMain aliases tf.keras.ops.nn.leaky_relu\ntf.keras.ops.nn.leaky_relu\ntf.keras.ops.nn.leaky_relu\ntf . keras . ops . leaky_relu ( x , negative_slope = 0.2 )\ntf . keras . ops . leaky_relu ( x , negative_slope = 0.2 )\nIt allows a small gradient when the unit is not active, it is defined as:\nf(x) = alpha * x for x < 0 or f(x) = x for x >= 0 .\nf(x) = alpha * x for x < 0\nf(x) = x for x >= 0\nArgs\nArgs\nx Input tensor. negative_slope Slope of the activation function at x < 0.\nDefaults to 0.2 .\nx\nnegative_slope\n0.2\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_leaky_relu = keras . ops . leaky_relu ( x ) print ( x_leaky_relu ) array ([ - 0.2 , 0. , 1. ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_leaky_relu = keras . ops . leaky_relu ( x )\nprint ( x_leaky_relu )\narray ([ - 0.2 , 0. , 1. ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear",
    "content": "Linear activation function (pass-through).\ntf . keras . activations . linear ( x )\ntf . keras . activations . linear ( x )\nA \"linear\" activation is an identity function:\nit returns the input, unmodified.\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logspace",
    "content": "Returns numbers spaced evenly on a log scale.\nMain aliases tf.keras.ops.numpy.logspace\ntf.keras.ops.numpy.logspace\ntf.keras.ops.numpy.logspace\ntf . keras . ops . logspace ( start , stop , num = 50 , endpoint = True , base = 10 , dtype = None , axis = 0 )\ntf . keras . ops . logspace ( start , stop , num = 50 , endpoint = True , base = 10 , dtype = None , axis = 0 )\nIn linear space, the sequence starts at base ** start and ends with base ** stop (see endpoint below).\nbase ** start\nbase ** stop\nendpoint\nArgs\nArgs\nstart The starting value of the sequence. stop The final value of the sequence, unless endpoint is False .\nIn that case, num + 1 values are spaced over the interval in\nlog-space, of which all but the last (a sequence of length num )\nare returned. num Number of samples to generate. Defaults to 50 . endpoint If True , stop is the last sample. Otherwise, it is not\nincluded. Defaults to True . base The base of the log space. Defaults to 10 . dtype The type of the output tensor. axis The axis in the result to store the samples. Relevant only\nif start or stop are array-like.\nstart\nstop\nendpoint\nFalse\nnum + 1\nnum\nnum\n50\nendpoint\nTrue\nstop\nTrue\nbase\n10\ndtype\naxis\nNote Torch backend does not support axis argument.\nNote\naxis\nReturns A tensor of evenly spaced samples on a log scale.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianNoise",
    "content": "Apply additive zero-centered Gaussian noise.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . GaussianNoise ( stddev , seed = None , ** kwargs )\ntf . keras . layers . GaussianNoise ( stddev , seed = None , ** kwargs )\nThis is useful to mitigate overfitting\n(you could see it as a form of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process\nfor real valued inputs.\nAs it is a regularization layer, it is only active at training time.\nArgs\nArgs\nstddev Float, standard deviation of the noise distribution. seed Integer, optional random seed to enable deterministic behavior.\nstddev\nseed\nCall arguments\nCall arguments\ninputs Input tensor (of any rank). training Python boolean indicating whether the layer should behave in\ntraining mode (adding noise) or in inference mode (doing nothing).\ninputs\ntraining\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam",
    "content": "Optimizer that implements the Adam algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , amsgrad = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adam' , ** kwargs )\ntf . keras . optimizers . Adam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , amsgrad = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adam' , ** kwargs )\nUsed in the notebooks\nBetter performance with tf.function\nTraining checkpoints\nEffective Tensorflow 2\nEstimators\nMigrate early stopping\nCycleGAN\nDistributed training with Keras\nBasic regression: Predict fuel efficiency\nLoad CSV data\nCustom training with tf.distribute.Strategy\nAdam optimization is a stochastic gradient descent method that is based on\nadaptive estimation of first-order and second-order moments.\nAccording to Kingma et al., 2014 ,\nthe method is \" computationally\nefficient, has little memory requirement, invariant to diagonal rescaling of\ngradients, and is well suited for problems that are large in terms of\ndata/parameters \".\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_1 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 1st moment estimates. Defaults to 0.9 . beta_2 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 2nd moment estimates. Defaults to 0.999 . epsilon A small constant for numerical stability. This epsilon is\n\"epsilon hat\" in the Kingma and Ba paper (in the formula just before\nSection 2.1), not the epsilon in Algorithm 1 of the paper. Defaults\nto 1e-7 . amsgrad Boolean. Whether to apply AMSGrad variant of this algorithm\nfrom the paper \"On the Convergence of Adam and beyond\". Defaults\nto False . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_1\n0.9\nbeta_2\n0.999\nepsilon\n1e-7\namsgrad\nFalse\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nAdam optimizer has 3 types of variables: momentums, velocities and\nvelocity_hat (only set when amsgrad is applied),\nArgs\nvar_list list of model variables to build Adam variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/squared_hinge",
    "content": "Computes the squared hinge loss between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.metrics.squared_hinge\ntf.keras.metrics.squared_hinge\ntf.keras.metrics.squared_hinge\ntf . keras . losses . squared_hinge ( y_true , y_pred )\ntf . keras . losses . squared_hinge ( y_true , y_pred )\nloss = mean ( square ( maximum ( 1 - y_true * y_pred , 0 )), axis =- 1 )\nloss = mean ( square ( maximum ( 1 - y_true * y_pred , 0 )), axis =- 1 )\nArgs\nArgs\ny_true The ground truth values. y_true values are expected to be -1\nor 1. If binary (0 or 1) labels are provided we will convert them\nto -1 or 1 with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Squared hinge loss values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . choice ([ - 1 , 1 ], size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . squared_hinge ( y_true , y_pred )\ny_true = np . random . choice ([ - 1 , 1 ], size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . squared_hinge ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/map_coordinates",
    "content": "Map the input array to new coordinates by interpolation..\ntf . keras . ops . image . map_coordinates ( input , coordinates , order , fill_mode = 'constant' , fill_value = 0 )\ntf . keras . ops . image . map_coordinates ( input , coordinates , order , fill_mode = 'constant' , fill_value = 0 )\nNote that interpolation near boundaries differs from the scipy function,\nbecause we fixed an outstanding bug scipy/issues/2640 .\nArgs\nArgs\ninput The input array. coordinates The coordinates at which input is evaluated. order The order of the spline interpolation. The order must be 0 or 1 . 0 indicates the nearest neighbor and 1 indicates the linear\ninterpolation. fill_mode Points outside the boundaries of the input are filled\naccording to the given mode. Available methods are \"constant\" , \"nearest\" , \"wrap\" and \"mirror\" and \"reflect\" . Defaults to \"constant\" .\ninput\ncoordinates\norder\n0\n1\n0\n1\nfill_mode\n\"constant\"\n\"nearest\"\n\"wrap\"\n\"mirror\"\n\"reflect\"\n\"constant\"\n\"constant\" : (k k k k | a b c d | k k k k) The input is extended by filling all values beyond\nthe edge with the same constant value k specified by fill_value .\n\"constant\"\n(k k k k | a b c d | k k k k)\nfill_value\n\"nearest\" : (a a a a | a b c d | d d d d) The input is extended by the nearest pixel.\n\"nearest\"\n(a a a a | a b c d | d d d d)\n\"wrap\" : (a b c d | a b c d | a b c d) The input is extended by wrapping around to the opposite edge.\n\"wrap\"\n(a b c d | a b c d | a b c d)\n\"mirror\" : (c d c b | a b c d | c b a b) The input is extended by mirroring about the edge.\n\"mirror\"\n(c d c b | a b c d | c b a b)\n\"reflect\" : (d c b a | a b c d | d c b a) The input is extended by reflecting about the edge of the last\npixel. fill_value Value used for points outside the boundaries of the input if fill_mode=\"constant\" . Defaults to 0 .\n\"reflect\"\n(d c b a | a b c d | d c b a)\nfill_value\nfill_mode=\"constant\"\n0\nReturns Output image or batch of images.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50V2",
    "content": "Instantiates the ResNet50V2 architecture.\nMain aliases tf.keras.applications.resnet_v2.ResNet50V2\ntf.keras.applications.resnet_v2.ResNet50V2\ntf.keras.applications.resnet_v2.ResNet50V2\ntf . keras . applications . ResNet50V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet50V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nIdentity Mappings in Deep Residual Networks (CVPR 2016)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet_v2.preprocess_input\nresnet_v2.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : A placeholder method for backward compatibility.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/uniform",
    "content": "Draw samples from a uniform distribution.\ntf . keras . random . uniform ( shape , minval = 0.0 , maxval = 1.0 , dtype = None , seed = None )\ntf . keras . random . uniform ( shape , minval = 0.0 , maxval = 1.0 , dtype = None , seed = None )\nThe generated values follow a uniform distribution in the range [minval, maxval) . The lower bound minval is included in the range,\nwhile the upper bound maxval is excluded.\n[minval, maxval)\nminval\nmaxval\ndtype must be a floating point type, the default range is [0, 1) .\ndtype\n[0, 1)\nArgs\nArgs\nshape The shape of the random values to generate. minval Float, defaults to 0. Lower bound of the range of\nrandom values to generate (inclusive). maxval Float, defaults to 1. Upper bound of the range of\nrandom values to generate (exclusive). dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ) seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nminval\nmaxval\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh",
    "content": "Hyperbolic tangent activation function.\ntf . keras . activations . tanh ( x )\ntf . keras . activations . tanh ( x )\ntanh(x) = sinh(x) / cosh(x) , i.e. tanh(x) = ((exp(x) - exp(-x)) / (exp(x) + exp(-x))) .\ntanh(x) = sinh(x) / cosh(x)\ntanh(x) = ((exp(x) - exp(-x)) / (exp(x) + exp(-x)))\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid",
    "content": "Sigmoid activation function.\ntf . keras . activations . sigmoid ( x )\ntf . keras . activations . sigmoid ( x )\nIt is defined as: sigmoid(x) = 1 / (1 + exp(-x)) .\nsigmoid(x) = 1 / (1 + exp(-x))\nFor small values (<-5), sigmoid returns a value close to zero, and for large values (>5)\nthe result of the function gets close to 1.\nsigmoid\nSigmoid is equivalent to a 2-element softmax, where the second element is\nassumed to be zero. The sigmoid function always returns a value between\n0 and 1.\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/spatial_3d_padding",
    "content": "DEPRECATED.\ntf . keras . backend . spatial_3d_padding ( x , padding = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None )\ntf . keras . backend . spatial_3d_padding ( x , padding = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda",
    "content": "Wraps arbitrary expressions as a Layer object.\nLayer\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None , ** kwargs )\ntf . keras . layers . Lambda ( function , output_shape = None , mask = None , arguments = None , ** kwargs )\nUsed in the notebooks\nTensorFlow basics\nTime series forecasting\nData augmentation\nGraph regularization for document classification using natural graphs\nUsing TensorFlow Recommenders with TFX\nParametrized Quantum Circuits for Reinforcement Learning\nThe Lambda layer exists so that arbitrary expressions can be used\nas a Layer when constructing Sequential\nand Functional API models. Lambda layers are best suited for simple\noperations or quick experimentation. For more advanced use cases,\nprefer writing new subclasses of Layer .\nLambda\nLayer\nLambda\nLayer\nLambda\nThe main reason to subclass Layer instead of using a Lambda layer is saving and inspecting a model. Lambda layers\nare saved by serializing the Python bytecode, which is fundamentally\nnon-portable and potentially unsafe.\nThey should only be loaded in the same environment where\nthey were saved. Subclassed layers can be saved in a more portable way\nby overriding their get_config() method. Models that rely on\nsubclassed Layers are also often easier to visualize and reason about.\nLayer\nLambda\nLambda\nget_config()\n# add a x -> x^2 layer model . add ( Lambda ( lambda x : x ** 2 ))\n# add a x -> x^2 layer model . add ( Lambda ( lambda x : x ** 2 ))\nArgs\nArgs\nfunction The function to be evaluated. Takes input tensor as first\nargument. output_shape Expected output shape from function. This argument\ncan usually be inferred if not explicitly provided.\nCan be a tuple or function. If a tuple, it only specifies\nthe first dimension onward; sample dimension is assumed\neither the same as the input: output_shape = (input_shape[0], ) + output_shape or,\nthe input is None and the sample dimension is also None : output_shape = (None, ) + output_shape .\nIf a function, it specifies the\nentire shape as a function of the input shape: output_shape = f(input_shape) . mask Either None (indicating no masking) or a callable with the same\nsignature as the compute_mask layer method, or a tensor\nthat will be returned as output mask regardless\nof what the input is. arguments Optional dictionary of keyword arguments to be passed to the\nfunction.\nfunction\noutput_shape\noutput_shape = (input_shape[0], ) + output_shape\nNone\nNone\noutput_shape = (None, ) + output_shape\noutput_shape = f(input_shape)\nmask\ncompute_mask\narguments\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None , safe_mode = None )\n@classmethod\nfrom_config ( config , custom_objects = None , safe_mode = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomUniform",
    "content": "Random uniform initializer.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.random_uniform\ntf.keras.initializers.random_uniform\ntf.keras.initializers.random_uniform\ntf . keras . initializers . RandomUniform ( minval =- 0.05 , maxval = 0.05 , seed = None )\ntf . keras . initializers . RandomUniform ( minval =- 0.05 , maxval = 0.05 , seed = None )\nUsed in the notebooks\nTrain a Deep Q Network with TF-Agents\nNetworks\nDraws samples from a uniform distribution for given parameters.\n# Standalone usage: initializer = RandomUniform ( minval = 0.0 , maxval = 1.0 ) values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = RandomUniform ( minval = 0.0 , maxval = 1.0 )\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = RandomUniform ( minval = 0.0 , maxval = 1.0 ) layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = RandomUniform ( minval = 0.0 , maxval = 1.0 )\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nminval A python scalar or a scalar keras tensor. Lower bound of the\nrange of random values to generate (inclusive). maxval A python scalar or a scalar keras tensor. Upper bound of the\nrange of random values to generate (exclusive). seed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nminval\nmaxval\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CosineSimilarity",
    "content": "Computes the cosine similarity between the labels and predictions.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . CosineSimilarity ( name = 'cosine_similarity' , dtype = None , axis =- 1 )\ntf . keras . metrics . CosineSimilarity ( name = 'cosine_similarity' , dtype = None , axis =- 1 )\nloss = sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nloss = sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nSee: Cosine Similarity .\nThis metric keeps the average cosine similarity between predictions and labels over a stream of data.\npredictions\nlabels\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. axis (Optional) Defaults to -1 . The dimension along which the cosine\nsimilarity is computed.\nname\ndtype\naxis\n-1\n# l2_norm(y_true) = [[0., 1.], [1./1.414, 1./1.414]] # l2_norm(y_pred) = [[1., 0.], [1./1.414, 1./1.414]] # l2_norm(y_true) . l2_norm(y_pred) = [[0., 0.], [0.5, 0.5]] # result = mean(sum(l2_norm(y_true) . l2_norm(y_pred), axis=1)) #        = ((0. + 0.) +  (0.5 + 0.5)) / 2 m = keras . metrics . CosineSimilarity ( axis = 1 ) m . update_state ([[ 0. , 1. ], [ 1. , 1. ]], [[ 1. , 0. ], [ 1. , 1. ]]) m . result () 0.49999997 m . reset_state () m . update_state ([[ 0. , 1. ], [ 1. , 1. ]], [[ 1. , 0. ], [ 1. , 1. ]], sample_weight = [ 0.3 , 0.7 ]) m . result () 0.6999999\n# l2_norm(y_true) = [[0., 1.], [1./1.414, 1./1.414]]\n# l2_norm(y_pred) = [[1., 0.], [1./1.414, 1./1.414]]\n# l2_norm(y_true) . l2_norm(y_pred) = [[0., 0.], [0.5, 0.5]]\n# result = mean(sum(l2_norm(y_true) . l2_norm(y_pred), axis=1))\n#        = ((0. + 0.) +  (0.5 + 0.5)) / 2\nm = keras . metrics . CosineSimilarity ( axis = 1 )\nm . update_state ([[ 0. , 1. ], [ 1. , 1. ]], [[ 1. , 0. ], [ 1. , 1. ]])\nm . result ()\n0.49999997\nm . reset_state ()\nm . update_state ([[ 0. , 1. ], [ 1. , 1. ]], [[ 1. , 0. ], [ 1. , 1. ]],\nsample_weight = [ 0.3 , 0.7 ])\nm . result ()\n0.6999999\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . CosineSimilarity ( axis = 1 )])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . CosineSimilarity ( axis = 1 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History",
    "content": "Callback that records events into a History object.\nHistory\nInherits From: Callback\nCallback\ntf . keras . callbacks . History ()\ntf . keras . callbacks . History ()\nThis callback is automatically applied to\nevery Keras model. The History object\ngets returned by the fit() method of models.\nHistory\nfit()\nmodel = Sequential ([ layers . Dense ( 10 )]) model . compile ( SGD (), loss = 'mse' ) history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 10 , verbose = 1 ) print ( history . params ) { 'verbose' : 1 , 'epochs' : 10 , 'steps' : 1 } # check the keys of history object print ( history . history . keys ()) dict_keys ([ 'loss' ])\nmodel = Sequential ([ layers . Dense ( 10 )])\nmodel . compile ( SGD (), loss = 'mse' )\nhistory = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ),\nepochs = 10 , verbose = 1 )\nprint ( history . params )\n{ 'verbose' : 1 , 'epochs' : 10 , 'steps' : 1 }\n# check the keys of history object\nprint ( history . history . keys ())\ndict_keys ([ 'loss' ])\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/deserialize",
    "content": "Returns a Keras layer object via its configuration.\ntf . keras . layers . deserialize ( config , custom_objects = None )\ntf . keras . layers . deserialize ( config , custom_objects = None )\nArgs\nArgs\nconfig A python dict containing a serialized layer configuration. custom_objects Optional dictionary mapping names (strings) to custom\nobjects (classes and functions) to be considered during\ndeserialization.\nconfig\ncustom_objects\nReturns A Keras layer instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_shear",
    "content": "DEPRECATED.\ntf . keras . preprocessing . image . random_shear ( x , intensity , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )\ntf . keras . preprocessing . image . random_shear ( x , intensity , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/floor",
    "content": "Return the floor of the input, element-wise.\nMain aliases tf.keras.ops.numpy.floor\ntf.keras.ops.numpy.floor\ntf.keras.ops.numpy.floor\ntf . keras . ops . floor ( x )\ntf . keras . ops . floor ( x )\nThe floor of the scalar x is the largest integer i , such that i <= x .\nx\ni\ni <= x\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise floor of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/any",
    "content": "DEPRECATED.\ntf . keras . backend . any ( x , axis = None , keepdims = False )\ntf . keras . backend . any ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy",
    "content": "Calculates how often predictions match one-hot labels.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . CategoricalAccuracy ( name = 'categorical_accuracy' , dtype = None )\ntf . keras . metrics . CategoricalAccuracy ( name = 'categorical_accuracy' , dtype = None )\nYou can provide logits of classes as y_pred , since argmax of\nlogits and probabilities are same.\ny_pred\nThis metric creates two local variables, total and count that are used\nto compute the frequency with which y_pred matches y_true . This\nfrequency is ultimately returned as categorical accuracy : an idempotent\noperation that simply divides total by count .\ntotal\ncount\ny_pred\ny_true\ncategorical accuracy\ntotal\ncount\ny_pred and y_true should be passed in as vectors of probabilities,\nrather than as labels. If necessary, use ops.one_hot to expand y_true as\na vector.\ny_pred\ny_true\nops.one_hot\ny_true\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . CategoricalAccuracy () m . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]]) m . result () 0.5\nm = keras . metrics . CategoricalAccuracy ()\nm . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ],\n[ 0.05 , 0.95 , 0 ]])\nm . result ()\n0.5\nm . reset_state () m . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]], sample_weight = [ 0.7 , 0.3 ]) m . result () 0.3\nm . reset_state ()\nm . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ],\n[ 0.05 , 0.95 , 0 ]],\nsample_weight = [ 0.7 , 0.3 ])\nm . result ()\n0.3\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'categorical_crossentropy' , metrics = [ keras . metrics . CategoricalAccuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'categorical_crossentropy' , metrics = [ keras . metrics . CategoricalAccuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/tanh",
    "content": "DEPRECATED.\ntf . keras . backend . tanh ( x )\ntf . keras . backend . tanh ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/is_interactive_logging_enabled",
    "content": "Check if interactive logging is enabled.\nMain aliases tf.keras.utils.is_interactive_logging_enabled\ntf.keras.utils.is_interactive_logging_enabled\ntf.keras.utils.is_interactive_logging_enabled\ntf . keras . config . is_interactive_logging_enabled ()\ntf . keras . config . is_interactive_logging_enabled ()\nTo switch between writing logs to stdout and absl.logging , you may use keras.config.enable_interactive_logging() and keras.config.disable_interactive_logging() .\nabsl.logging\nkeras.config.enable_interactive_logging()\nkeras.config.disable_interactive_logging()\nReturns Boolean, True if interactive logging is enabled,\nand False otherwise.\nReturns\nTrue\nFalse"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/eigh",
    "content": "Computes the eigenvalues and eigenvectors of a complex Hermitian.\nMain aliases tf.keras.ops.linalg.eigh\ntf.keras.ops.linalg.eigh\ntf.keras.ops.linalg.eigh\ntf . keras . ops . eigh ( x )\ntf . keras . ops . eigh ( x )\nArgs\nArgs\nx Input tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tuple of two tensors: a tensor of shape (..., M) containing\neigenvalues and a tensor of shape (..., M, M) containing eigenvectors.\nReturns\n(..., M)\n(..., M, M)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Regularizer",
    "content": "Regularizer base class.\nMain aliases tf.keras.regularizers.Regularizer Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Regularizer\ntf.keras.regularizers.Regularizer\ntf.keras.regularizers.Regularizer\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Regularizer\ntf.compat.v1.keras.Regularizer\nUsed in the notebooks\nScalable model compression\nRegularizers allow you to apply penalties on layer parameters or layer\nactivity during optimization. These penalties are summed into the loss\nfunction that the network optimizes.\nRegularization penalties are applied on a per-layer basis. The exact API\nwill depend on the layer, but many layers (e.g. Dense , Conv1D , Conv2D and Conv3D ) have a unified API.\nDense\nConv1D\nConv2D\nConv3D\nThese layers expose 3 keyword arguments:\nkernel_regularizer : Regularizer to apply a penalty on the layer's kernel\nkernel_regularizer\nbias_regularizer : Regularizer to apply a penalty on the layer's bias\nbias_regularizer\nactivity_regularizer : Regularizer to apply a penalty on the layer's\noutput\nactivity_regularizer\nAll layers (including custom layers) expose activity_regularizer as a\nsettable property, whether or not it is in the constructor arguments.\nactivity_regularizer\nThe value returned by the activity_regularizer is divided by the input\nbatch size so that the relative weighting between the weight regularizers\nand the activity regularizers does not change with the batch size.\nactivity_regularizer\nYou can access a layer's regularization penalties by calling layer.losses after calling the layer on inputs.\nlayer.losses\nExample\nlayer = Dense ( 5 , input_dim = 5 , kernel_initializer = 'ones' , kernel_regularizer = L1 ( 0.01 ), activity_regularizer = L2 ( 0.01 )) tensor = ops . ones ( shape = ( 5 , 5 )) * 2.0 out = layer ( tensor )\nlayer = Dense (\n5 , input_dim = 5 ,\nkernel_initializer = 'ones' ,\nkernel_regularizer = L1 ( 0.01 ),\nactivity_regularizer = L2 ( 0.01 ))\ntensor = ops . ones ( shape = ( 5 , 5 )) * 2.0\nout = layer ( tensor )\n# The kernel regularization term is 0.25 # The activity regularization term (after dividing by the batch size) # is 5 ops . sum ( layer . losses ) 5.25\n# The kernel regularization term is 0.25\n# The activity regularization term (after dividing by the batch size)\n# is 5\nops . sum ( layer . losses )\n5.25\nAvailable penalties\nL1 ( 0.3 ) # L1 Regularization Penalty L2 ( 0.1 ) # L2 Regularization Penalty L1L2 ( l1 = 0.01 , l2 = 0.01 ) # L1 + L2 penalties\nL1 ( 0.3 ) # L1 Regularization Penalty L2 ( 0.1 ) # L2 Regularization Penalty L1L2 ( l1 = 0.01 , l2 = 0.01 ) # L1 + L2 penalties\nDirectly calling a regularizer\nCompute a regularization loss on a tensor by directly calling a regularizer\nas if it is a one-argument function.\nE.g.\nregularizer = L2 ( 2. ) tensor = ops . ones ( shape = ( 5 , 5 )) regularizer ( tensor ) 50.0\nregularizer = L2 ( 2. )\ntensor = ops . ones ( shape = ( 5 , 5 ))\nregularizer ( tensor )\n50.0\nDeveloping new regularizers\nAny function that takes in a weight matrix and returns a scalar\ntensor can be used as a regularizer, e.g.:\ndef l1_reg ( weight_matrix ): return 0.01 * ops . sum ( ops . absolute ( weight_matrix )) layer = Dense ( 5 , input_dim = 5 , kernel_initializer = 'ones' , kernel_regularizer = l1_reg ) tensor = ops . ones ( shape = ( 5 , 5 )) out = layer ( tensor ) layer . losses 0.25\ndef l1_reg ( weight_matrix ):\nreturn 0.01 * ops . sum ( ops . absolute ( weight_matrix ))\nlayer = Dense ( 5 , input_dim = 5 ,\nkernel_initializer = 'ones' , kernel_regularizer = l1_reg )\ntensor = ops . ones ( shape = ( 5 , 5 ))\nout = layer ( tensor )\nlayer . losses\n0.25\nAlternatively, you can write your custom regularizers in an\nobject-oriented way by extending this regularizer base class, e.g.:\nclass L2Regularizer ( Regularizer ): def __init__ ( self , l2 = 0. ): self . l2 = l2 def __call__ ( self , x ): return self . l2 * ops . sum ( ops . square ( x )) def get_config ( self ): return { 'l2' : float ( self . l2 )} layer = Dense ( 5 , input_dim = 5 , kernel_initializer = 'ones' , kernel_regularizer = L2Regularizer ( l2 = 0.5 ))\nclass L2Regularizer ( Regularizer ):\ndef __init__ ( self , l2 = 0. ):\nself . l2 = l2\ndef __call__ ( self , x ):\nreturn self . l2 * ops . sum ( ops . square ( x ))\ndef get_config ( self ):\nreturn { 'l2' : float ( self . l2 )}\nlayer = Dense (\n5 , input_dim = 5 , kernel_initializer = 'ones' ,\nkernel_regularizer = L2Regularizer ( l2 = 0.5 ))\ntensor = ops . ones ( shape = ( 5 , 5 )) out = layer ( tensor ) layer . losses 12.5\ntensor = ops . ones ( shape = ( 5 , 5 ))\nout = layer ( tensor )\nlayer . losses\n12.5\nA note on serialization and deserialization:\nRegistering the regularizers as serializable is optional if you are just\ntraining and executing models, exporting to and from SavedModels, or saving\nand loading weight checkpoints.\nRegistration is required for saving and\nloading models to HDF5 format, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON. If using this\nfunctionality, you must make sure any python process running your model has\nalso defined and registered your custom regularizer.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a regularizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same regularizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A regularizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the regularizer.\nAn regularizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the regularizer.\nThe same regularizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a regularization penalty from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout",
    "content": "Applies dropout to the input.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Dropout ( rate , noise_shape = None , seed = None , ** kwargs )\ntf . keras . layers . Dropout ( rate , noise_shape = None , seed = None , ** kwargs )\nUsed in the notebooks\nEffective Tensorflow 2\nMigrate checkpoint saving\nMigrate evaluation\nMigrate the fault tolerance mechanism\nMigrate TensorBoard: TensorFlow's visualization toolkit\nOverfit and underfit\nUsing DTensors with Keras\nSimple audio recognition: Recognizing keywords\nDeep Convolutional Generative Adversarial Network\nBasic text classification\nThe Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\nInputs not set to 0 are scaled up by 1 / (1 - rate) such that the sum over\nall inputs is unchanged.\nDropout\nrate\n1 / (1 - rate)\nNote that the Dropout layer only applies when training is set to True in call() , such that no values are dropped during inference.\nWhen using model.fit , training will be appropriately set to True automatically. In other contexts, you can set the argument explicitly\nto True when calling the layer.\nDropout\ntraining\nTrue\ncall()\nmodel.fit\ntraining\nTrue\nTrue\n(This is in contrast to setting trainable=False for a Dropout layer. trainable does not affect the layer's behavior, as Dropout does\nnot have any variables/weights that can be frozen during training.)\ntrainable=False\nDropout\ntrainable\nDropout\nArgs\nArgs\nrate Float between 0 and 1. Fraction of the input units to drop. noise_shape 1D integer tensor representing the shape of the\nbinary dropout mask that will be multiplied with the input.\nFor instance, if your inputs have shape (batch_size, timesteps, features) and\nyou want the dropout mask to be the same for all timesteps,\nyou can use noise_shape=(batch_size, 1, features) . seed A Python integer to use as random seed.\nrate\nnoise_shape\n(batch_size, timesteps, features)\nnoise_shape=(batch_size, 1, features)\nseed\nCall arguments\nCall arguments\ninputs Input tensor (of any rank). training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (doing nothing).\ninputs\ntraining\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/copy",
    "content": "Returns a copy of x .\nx\nMain aliases tf.keras.ops.numpy.copy\ntf.keras.ops.numpy.copy\ntf.keras.ops.numpy.copy\ntf . keras . ops . copy ( x )\ntf . keras . ops . copy ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns A copy of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/set_dtype_policy",
    "content": "Sets the default dtype policy globally.\nMain aliases tf.keras.mixed_precision.set_dtype_policy , tf.keras.mixed_precision.set_global_policy\ntf.keras.mixed_precision.set_dtype_policy , tf.keras.mixed_precision.set_global_policy\ntf.keras.mixed_precision.set_dtype_policy\ntf.keras.mixed_precision.set_global_policy\ntf . keras . config . set_dtype_policy ( policy )\ntf . keras . config . set_dtype_policy ( policy )\nUsed in the notebooks\nMixed precision\nImage classification with Model Garden\nInstance Segmentation with Model Garden\nObject detection with Model Garden\nSemantic Segmentation with Model Garden\nkeras . config . set_dtype_policy ( \"mixed_float16\" )\nkeras . config . set_dtype_policy ( \"mixed_float16\" )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies/QuantizedFloat8DTypePolicy",
    "content": "A dtype policy for a Keras layer.\nInherits From: QuantizedDTypePolicy , DTypePolicy\nQuantizedDTypePolicy\nDTypePolicy\ntf . keras . dtype_policies . QuantizedFloat8DTypePolicy ( name , amax_history_length = 1024 )\ntf . keras . dtype_policies . QuantizedFloat8DTypePolicy ( name , amax_history_length = 1024 )\nA dtype policy determines a layer's computation and variable dtypes. Each\nlayer has a policy. Policies can be passed to the dtype argument of layer\nconstructors, or a global policy can be set with keras.config.set_dtype_policy .\ndtype\nkeras.config.set_dtype_policy\nArgs\nArgs\nname The policy name, which determines the compute and variable dtypes.\nCan be any dtype name, such as \"float32\" or \"float64\" ,\nwhich causes both the compute and variable dtypes\nwill be that dtype.\nCan also be the string \"mixed_float16\" or \"mixed_bfloat16\" ,\nwhich causes the compute dtype to be float16 or bfloat16 and the variable dtype to be float32 .\nname\n\"float32\"\n\"float64\"\n\"mixed_float16\"\n\"mixed_bfloat16\"\nfloat16\nbfloat16\nfloat32\nTypically you only need to interact with dtype policies when using mixed\nprecision, which is the use of float16 or bfloat16 for computations and\nfloat32 for variables. This is why the term mixed_precision appears in the\nAPI name. Mixed precision can be enabled by passing \"mixed_float16\" or \"mixed_bfloat16\" to keras.mixed_precision.set_dtype_policy() .\nmixed_precision\n\"mixed_float16\"\n\"mixed_bfloat16\"\nkeras.mixed_precision.set_dtype_policy()\nkeras . config . set_dtype_policy ( \"mixed_float16\" ) layer1 = keras . layers . Dense ( 10 ) layer1 . dtype_policy # layer1 will automatically use mixed precision < DTypePolicy \"mixed_float16\" > # Can optionally override layer to use float32 # instead of mixed precision. layer2 = keras . layers . Dense ( 10 , dtype = \"float32\" ) layer2 . dtype_policy < DTypePolicy \"float32\" > # Set policy back to initial float32. keras . config . set_dtype_policy ( 'float32' )\nkeras . config . set_dtype_policy ( \"mixed_float16\" )\nlayer1 = keras . layers . Dense ( 10 )\nlayer1 . dtype_policy # layer1 will automatically use mixed precision\n< DTypePolicy \"mixed_float16\" >\n# Can optionally override layer to use float32\n# instead of mixed precision.\nlayer2 = keras . layers . Dense ( 10 , dtype = \"float32\" )\nlayer2 . dtype_policy\n< DTypePolicy \"float32\" >\n# Set policy back to initial float32.\nkeras . config . set_dtype_policy ( 'float32' )\nIn the example above, passing dtype=\"float32\" to the layer is\nequivalent to passing dtype=keras.config.DTypePolicy(\"float32\") .\nIn general, passing a dtype policy name to a layer is equivalent\nto passing the corresponding policy, so it is never necessary\nto explicitly construct a DTypePolicy object.\ndtype=\"float32\"\ndtype=keras.config.DTypePolicy(\"float32\")\nDTypePolicy\nAttributes\nAttributes\namax_history_length The length of the amax history window.\namax_history_length\nThis property is used for scaling factor computation in float8 training. compute_dtype The compute dtype of this policy.\ncompute_dtype\nThis is the dtype layers will do their computations in. Typically layers\noutput tensors with the compute dtype as well.\nNote that even if the compute dtype is float16 or bfloat16, hardware\ndevices may not do individual adds, multiplies, and other fundamental\noperations in float16 or bfloat16, but instead may do some of them in\nfloat32 for numeric stability. The compute dtype is the dtype of the\ninputs and outputs of the ops that the layer executes.\nInternally, many ops will do certain internal calculations in\nfloat32 or some other device-internal intermediate format with higher\nprecision than float16/bfloat16, to increase numeric stability. name Returns the name of this policy. quantization_mode The quantization mode of this policy. variable_dtype The variable dtype of this policy.\nname\nquantization_mode\nvariable_dtype\nThis is the dtype layers will create their variables in, unless a layer\nexplicitly chooses a different dtype. If this is different than DTypePolicy.compute_dtype , Layers will cast variables to\nthe compute dtype to avoid type errors.\nDTypePolicy.compute_dtype\nVariable regularizers are run in the variable dtype, not the compute\ndtype.\nMethods\nconvert_input\nconvert_input\nView source\nconvert_input ( x , autocast , dtype )\nconvert_input ( x , autocast , dtype )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/serialize",
    "content": "Returns the layer configuration as a Python dict.\ntf . keras . layers . serialize ( layer )\ntf . keras . layers . serialize ( layer )\nArgs\nArgs\nlayer A keras.layers.Layer instance to serialize.\nlayer\nkeras.layers.Layer\nReturns Python dict which contains the configuration of the layer.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_bernoulli",
    "content": "DEPRECATED.\ntf . keras . backend . random_bernoulli ( shape , p = 0.0 , dtype = None , seed = None )\ntf . keras . backend . random_bernoulli ( shape , p = 0.0 , dtype = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/normalize",
    "content": "Normalizes x over the specified axis.\nx\nMain aliases tf.keras.ops.nn.normalize\ntf.keras.ops.nn.normalize\ntf.keras.ops.nn.normalize\ntf . keras . ops . normalize ( x , axis =- 1 , order = 2 )\ntf . keras . ops . normalize ( x , axis =- 1 , order = 2 )\nIt is defined as: normalize(x) = x / max(norm(x), epsilon) .\nnormalize(x) = x / max(norm(x), epsilon)\nArgs\nArgs\nx Input tensor. axis The axis or axes along which to perform normalization.\nDefault to -1. order The exponent value in the norm formulation.\nDefaults to 2.\nx\naxis\norder\nReturns The normalized array.\nReturns\nx = keras . ops . convert_to_tensor ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) x_norm = keras . ops . math . normalize ( x ) print ( x_norm ) array ([[ 0.26726124 0.5345225 0.8017837 ] [ 0.45584232 0.5698029 0.68376344 ]], shape = ( 2 , 3 ), dtype = float32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]])\nx_norm = keras . ops . math . normalize ( x )\nprint ( x_norm )\narray ([[ 0.26726124 0.5345225 0.8017837 ]\n[ 0.45584232 0.5698029 0.68376344 ]], shape = ( 2 , 3 ), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta",
    "content": "Optimizer that implements the Adadelta algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Adadelta ( learning_rate = 0.001 , rho = 0.95 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adadelta' , ** kwargs )\ntf . keras . optimizers . Adadelta ( learning_rate = 0.001 , rho = 0.95 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adadelta' , ** kwargs )\nAdadelta optimization is a stochastic gradient descent method that is based\non adaptive learning rate per dimension to address two drawbacks:\nThe continual decay of learning rates throughout training.\nThe need for a manually selected global learning rate.\nAdadelta is a more robust extension of Adagrad that adapts learning rates\nbased on a moving window of gradient updates, instead of accumulating all\npast gradients. This way, Adadelta continues learning even when many updates\nhave been done. Compared to Adagrad, in the original version of Adadelta you\ndon't have to set an initial learning rate. In this version, the initial\nlearning rate can be set, as in most other Keras optimizers.\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . Note that Adadelta tends to benefit from higher initial learning rate values compared\nto other optimizers. To match the exact form in the original paper,\nuse 1.0. rho A floating point value. The decay rate. Defaults to 0.95 . epsilon Small floating point value for maintaining numerical stability. name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nAdadelta\nrho\n0.95\nepsilon\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nZeiler, 2012\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( grad , variable , learning_rate )\nupdate_step ( grad , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ThresholdedReLU",
    "content": "DEPRECATED.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ThresholdedReLU ( theta = 1.0 , ** kwargs )\ntf . keras . layers . ThresholdedReLU ( theta = 1.0 , ** kwargs )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/serialize",
    "content": "tf . keras . quantizers . serialize ( initializer )\ntf . keras . quantizers . serialize ( initializer )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/leaky_relu",
    "content": "Leaky relu activation function.\ntf . keras . activations . leaky_relu ( x , negative_slope = 0.2 )\ntf . keras . activations . leaky_relu ( x , negative_slope = 0.2 )\nArgs\nArgs\nx Input tensor. negative_slope A float that controls the slope\nfor values lower than the threshold.\nx\nnegative_slope\nfloat"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tan",
    "content": "Compute tangent, element-wise.\nMain aliases tf.keras.ops.numpy.tan\ntf.keras.ops.numpy.tan\ntf.keras.ops.numpy.tan\ntf . keras . ops . tan ( x )\ntf . keras . ops . tan ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/mod",
    "content": "Returns the element-wise remainder of division.\nMain aliases tf.keras.ops.numpy.mod\ntf.keras.ops.numpy.mod\ntf.keras.ops.numpy.mod\ntf . keras . ops . mod ( x1 , x2 )\ntf . keras . ops . mod ( x1 , x2 )\nArgs\nArgs\nx1 First tensor. x2 Second tensor.\nx1\nx2\nReturns Output tensor, element-wise remainder of division.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/maximum",
    "content": "Element-wise maximum of x1 and x2 .\nx1\nx2\nMain aliases tf.keras.ops.numpy.maximum\ntf.keras.ops.numpy.maximum\ntf.keras.ops.numpy.maximum\ntf . keras . ops . maximum ( x1 , x2 )\ntf . keras . ops . maximum ( x1 , x2 )\nArgs\nArgs\nx1 First tensor. x2 Second tensor.\nx1\nx2\nReturns Output tensor, element-wise maximum of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/min",
    "content": "Return the minimum of a tensor or minimum along an axis.\nMain aliases tf.keras.ops.numpy.min\ntf.keras.ops.numpy.min\ntf.keras.ops.numpy.min\ntf . keras . ops . min ( x , axis = None , keepdims = False , initial = None )\ntf . keras . ops . min ( x , axis = None , keepdims = False , initial = None )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which to operate. By default, flattened input\nis used. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one. Defaults to False . initial The maximum value of an output element. Defaults to None .\nx\naxis\nkeepdims\nTrue\nFalse\ninitial\nNone\nReturns Minimum of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/map_structure",
    "content": "Maps func through given structures.\nfunc\ntf . keras . tree . map_structure ( func , * structures )\ntf . keras . tree . map_structure ( func , * structures )\nstructure = [[ 1 ], [ 2 ], [ 3 ]] keras . tree . map_structure ( lambda v : v ** 2 , structure ) [[ 1 ], [ 4 ], [ 9 ]] keras . tree . map_structure ( lambda x , y : x * y , structure , structure ) [[ 1 ], [ 4 ], [ 9 ]]\nstructure = [[ 1 ], [ 2 ], [ 3 ]]\nkeras . tree . map_structure ( lambda v : v ** 2 , structure )\n[[ 1 ], [ 4 ], [ 9 ]]\nkeras . tree . map_structure ( lambda x , y : x * y , structure , structure )\n[[ 1 ], [ 4 ], [ 9 ]]\nFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ]) structure = Foo ( a = 1 , b = 2 ) keras . tree . map_structure ( lambda v : v * 2 , structure ) Foo ( a = 2 , b = 4 )\nFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ])\nstructure = Foo ( a = 1 , b = 2 )\nkeras . tree . map_structure ( lambda v : v * 2 , structure )\nFoo ( a = 2 , b = 4 )\nArgs\nArgs\nfunc A callable that accepts as many arguments as there are structures. *structures Arbitrarily nested structures of the same layout.\nfunc\n*structures\nReturns A new structure with the same layout as the given ones.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/moving_average_update",
    "content": "DEPRECATED.\ntf . keras . backend . moving_average_update ( x , value , momentum )\ntf . keras . backend . moving_average_update ( x , value , momentum )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/nan_to_num",
    "content": "Replace NaN with zero and infinity with large finite numbers.\nMain aliases tf.keras.ops.numpy.nan_to_num\ntf.keras.ops.numpy.nan_to_num\ntf.keras.ops.numpy.nan_to_num\ntf . keras . ops . nan_to_num ( x , nan = 0.0 , posinf = None , neginf = None )\ntf . keras . ops . nan_to_num ( x , nan = 0.0 , posinf = None , neginf = None )\nArgs\nArgs\nx Input data. nan Optional float or int. Value to replace NaN entries with. posinf Optional float or int.\nValue to replace positive infinity with. neginf Optional float or int.\nValue to replace negative infinity with.\nx\nnan\nNaN\nposinf\nneginf\nReturns x , with non-finite values replaced.\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/identity",
    "content": "Return the identity tensor.\nMain aliases tf.keras.ops.numpy.identity\ntf.keras.ops.numpy.identity\ntf.keras.ops.numpy.identity\ntf . keras . ops . identity ( n , dtype = None )\ntf . keras . ops . identity ( n , dtype = None )\nThe identity tensor is a square tensor with ones on the main diagonal and\nzeros elsewhere.\nArgs\nArgs\nn Number of rows (and columns) in the n x n output tensor. dtype Data type of the output tensor.\nn\nn x n\ndtype\nReturns The identity tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/get",
    "content": "Retrieves a Keras initializer object via an identifier.\ntf . keras . initializers . get ( identifier )\ntf . keras . initializers . get ( identifier )\nThe identifier may be the string name of a initializers function or class\n(case-sensitively).\nidentifier\nidentifier = 'Ones' keras . initializers . deserialize ( identifier ) < ... keras . initializers . initializers . Ones ... >\nidentifier = 'Ones'\nkeras . initializers . deserialize ( identifier )\n< ... keras . initializers . initializers . Ones ... >\nYou can also specify config of the initializer to this function by passing\ndict containing class_name and config as an identifier. Also note that\nthe class_name must map to a Initializer class.\nconfig\nclass_name\nconfig\nclass_name\nInitializer\ncfg = { 'class_name' : 'Ones' , 'config' : {} } keras . initializers . deserialize ( cfg ) < ... keras . initializers . initializers . Ones ... >\ncfg = { 'class_name' : 'Ones' , 'config' : {} }\nkeras . initializers . deserialize ( cfg )\n< ... keras . initializers . initializers . Ones ... >\nIn the case that the identifier is a class, this method will return a new\ninstance of the class by its constructor.\nidentifier\nArgs\nArgs\nidentifier String or dict that contains the initializer name or\nconfigurations.\nidentifier\nReturns Initializer instance base on the input identifier.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu",
    "content": "Applies the rectified linear unit activation function.\ntf . keras . activations . relu ( x , negative_slope = 0.0 , max_value = None , threshold = 0.0 )\ntf . keras . activations . relu ( x , negative_slope = 0.0 , max_value = None , threshold = 0.0 )\nWith default values, this returns the standard ReLU activation: max(x, 0) , the element-wise maximum of 0 and the input tensor.\nmax(x, 0)\nModifying default parameters allows you to use non-zero thresholds,\nchange the max value of the activation,\nand to use a non-zero multiple of the input for values below the threshold.\nx = [ - 10 , - 5 , 0.0 , 5 , 10 ] keras . activations . relu ( x ) [ 0. , 0. , 0. , 5. , 10. ] keras . activations . relu ( x , negative_slope = 0.5 ) [ - 5. , - 2.5 , 0. , 5. , 10. ] keras . activations . relu ( x , max_value = 5. ) [ 0. , 0. , 0. , 5. , 5. ] keras . activations . relu ( x , threshold = 5. ) [ - 0. , - 0. , 0. , 0. , 10. ]\nx = [ - 10 , - 5 , 0.0 , 5 , 10 ]\nkeras . activations . relu ( x )\n[ 0. , 0. , 0. , 5. , 10. ]\nkeras . activations . relu ( x , negative_slope = 0.5 )\n[ - 5. , - 2.5 , 0. , 5. , 10. ]\nkeras . activations . relu ( x , max_value = 5. )\n[ 0. , 0. , 0. , 5. , 5. ]\nkeras . activations . relu ( x , threshold = 5. )\n[ - 0. , - 0. , 0. , 0. , 10. ]\nArgs\nArgs\nx Input tensor. negative_slope A float that controls the slope\nfor values lower than the threshold. max_value A float that sets the saturation threshold (the largest\nvalue the function will return). threshold A float giving the threshold value of the activation\nfunction below which values will be damped or set to zero.\nx\nnegative_slope\nfloat\nmax_value\nfloat\nthreshold\nfloat\nReturns A tensor with the same shape and dtype as input x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nResNet101V2(...) : Instantiates the ResNet101V2 architecture.\nResNet101V2(...)\nResNet152V2(...) : Instantiates the ResNet152V2 architecture.\nResNet152V2(...)\nResNet50V2(...) : Instantiates the ResNet50V2 architecture.\nResNet50V2(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/top_k",
    "content": "Finds the top-k values and their indices in a tensor.\ntf . keras . ops . top_k ( x , k , sorted = True )\ntf . keras . ops . top_k ( x , k , sorted = True )\nArgs\nArgs\nx Input tensor. k An integer representing the number of top elements to retrieve. sorted A boolean indicating whether to sort the output in\ndescending order. Defaults to True .\nx\nk\nsorted\nTrue\nReturns A tuple containing two tensors. The first tensor contains the\ntop-k values, and the second tensor contains the indices of the\ntop-k values in the input tensor.\nReturns\nx = keras . ops . convert_to_tensor ([ 5 , 2 , 7 , 1 , 9 , 3 ]) values , indices = top_k ( x , k = 3 ) print ( values ) array ([ 9 7 5 ], shape = ( 3 ,), dtype = int32 ) print ( indices ) array ([ 4 2 0 ], shape = ( 3 ,), dtype = int32 )\nx = keras . ops . convert_to_tensor ([ 5 , 2 , 7 , 1 , 9 , 3 ])\nvalues , indices = top_k ( x , k = 3 )\nprint ( values )\narray ([ 9 7 5 ], shape = ( 3 ,), dtype = int32 )\nprint ( indices )\narray ([ 4 2 0 ], shape = ( 3 ,), dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/median",
    "content": "Compute the median along the specified axis.\nMain aliases tf.keras.ops.numpy.median\ntf.keras.ops.numpy.median\ntf.keras.ops.numpy.median\ntf . keras . ops . median ( x , axis = None , keepdims = False )\ntf . keras . ops . median ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which the medians are computed. Defaults to axis=None which is to compute the median(s) along a flattened\nversion of the array. keepdims If this is set to True , the axes which are reduce\nare left in the result as dimensions with size one.\nx\naxis\naxis=None\nkeepdims\nTrue\nReturns The output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy",
    "content": "Computes the sparse categorical crossentropy loss.\nMain aliases tf.keras.metrics.sparse_categorical_crossentropy\ntf.keras.metrics.sparse_categorical_crossentropy\ntf.keras.metrics.sparse_categorical_crossentropy\ntf . keras . losses . sparse_categorical_crossentropy ( y_true , y_pred , from_logits = False , ignore_class = None , axis =- 1 )\ntf . keras . losses . sparse_categorical_crossentropy ( y_true , y_pred , from_logits = False , ignore_class = None , axis =- 1 )\nUsed in the notebooks\nUse TPUs\nUsing DTensors with Keras\nIntroduction to the TensorFlow Models NLP library\nArgs\nArgs\ny_true Ground truth values. y_pred The predicted values. from_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. ignore_class Optional integer. The ID of a class to be ignored during\nloss computation. This is useful, for example, in segmentation\nproblems featuring a \"void\" class (commonly -1 or 255) in\nsegmentation maps. By default ( ignore_class=None ), all classes are\nconsidered. axis Defaults to -1 . The dimension along which the entropy is\ncomputed.\ny_true\ny_pred\nfrom_logits\ny_pred\ny_pred\nignore_class\nignore_class=None\naxis\n-1\nReturns Sparse categorical crossentropy loss value.\nReturns\ny_true = [ 1 , 2 ] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] loss = keras . losses . sparse_categorical_crossentropy ( y_true , y_pred ) assert loss . shape == ( 2 ,) loss array ([ 0.0513 , 2.303 ], dtype = float32 )\ny_true = [ 1 , 2 ]\ny_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]\nloss = keras . losses . sparse_categorical_crossentropy ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\nloss\narray ([ 0.0513 , 2.303 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/enable_unsafe_deserialization",
    "content": "Disables safe mode globally, allowing deserialization of lambdas.\ntf . keras . config . enable_unsafe_deserialization ()\ntf . keras . config . enable_unsafe_deserialization ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Huber",
    "content": "Computes the Huber loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . Huber ( delta = 1.0 , reduction = 'sum_over_batch_size' , name = 'huber_loss' )\ntf . keras . losses . Huber ( delta = 1.0 , reduction = 'sum_over_batch_size' , name = 'huber_loss' )\nUsed in the notebooks\nPlaying CartPole with the Actor-Critic method\nParametrized Quantum Circuits for Reinforcement Learning\nfor x in error : if abs ( x ) < = delta : loss . append ( 0.5 * x ^ 2 ) elif abs ( x ) > delta : loss . append ( delta * abs ( x ) - 0.5 * delta ^ 2 ) loss = mean ( loss , axis =- 1 )\nfor x in error : if abs ( x ) < = delta : loss . append ( 0.5 * x ^ 2 ) elif abs ( x ) > delta : loss . append ( delta * abs ( x ) - 0.5 * delta ^ 2 ) loss = mean ( loss , axis =- 1 )\nSee: Huber loss .\nArgs\nArgs\ndelta A float, the point where the Huber loss function changes from a\nquadratic to linear. reduction Type of reduction to apply to loss. Options are \"sum\" , \"sum_over_batch_size\" or None . Defaults to \"sum_over_batch_size\" . name Optional name for the instance.\ndelta\nreduction\n\"sum\"\n\"sum_over_batch_size\"\nNone\n\"sum_over_batch_size\"\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast",
    "content": "A preprocessing layer which randomly adjusts contrast during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomContrast ( factor , seed = None , ** kwargs )\ntf . keras . layers . RandomContrast ( factor , seed = None , ** kwargs )\nThis layer will randomly adjust the contrast of an image or images\nby a random factor. Contrast is adjusted independently\nfor each channel of each image during training.\nFor each channel, this layer computes the mean of the image pixels in the\nchannel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean .\nx\n(x - mean) * contrast_factor + mean\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nin integer or floating point dtype.\nBy default, the layer will output floats.\n[0., 1.)\n[0, 255]\ntf.data\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format.\n(..., height, width, channels)\n\"channels_last\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format.\n(..., height, width, channels)\n\"channels_last\"\nArgs\nArgs\nfactor a positive float represented as fraction of value, or a tuple of\nsize 2 representing lower and upper bound.\nWhen represented as a single float, lower = upper.\nThe contrast factor will be randomly picked between [1.0 - lower, 1.0 + upper] . For any pixel x in the channel,\nthe output will be (x - mean) * factor + mean where mean is the mean value of the channel. seed Integer. Used to create a random seed.\nfactor\n[1.0 - lower, 1.0 + upper]\n(x - mean) * factor + mean\nmean\nseed\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sparse_categorical_crossentropy",
    "content": "DEPRECATED.\ntf . keras . backend . sparse_categorical_crossentropy ( target , output , from_logits = False , axis =- 1 , ignore_class = None )\ntf . keras . backend . sparse_categorical_crossentropy ( target , output , from_logits = False , axis =- 1 , ignore_class = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/traverse",
    "content": "Traverses the given nested structure, applying the given function.\ntf . keras . tree . traverse ( func , structure , top_down = True )\ntf . keras . tree . traverse ( func , structure , top_down = True )\nThe traversal is depth-first. If top_down is True (default), parents\nare returned before their children (giving the option to avoid traversing\ninto a sub-tree).\ntop_down\nv = [] keras . tree . traverse ( v . append , [( 1 , 2 ), [ 3 ], { \"a\" : 4 }], top_down = True ) [( 1 , 2 ), [ 3 ], { 'a' : 4 }] v [[( 1 , 2 ), [ 3 ], { 'a' : 4 }], ( 1 , 2 ), 1 , 2 , [ 3 ], 3 , { 'a' : 4 }, 4 ]\nv = []\nkeras . tree . traverse ( v . append , [( 1 , 2 ), [ 3 ], { \"a\" : 4 }], top_down = True )\n[( 1 , 2 ), [ 3 ], { 'a' : 4 }]\nv\n[[( 1 , 2 ), [ 3 ], { 'a' : 4 }], ( 1 , 2 ), 1 , 2 , [ 3 ], 3 , { 'a' : 4 }, 4 ]\nv = [] keras . tree . traverse ( v . append , [( 1 , 2 ), [ 3 ], { \"a\" : 4 }], top_down = False ) [( 1 , 2 ), [ 3 ], { 'a' : 4 }] v [ 1 , 2 , ( 1 , 2 ), 3 , [ 3 ], 4 , { 'a' : 4 }, [( 1 , 2 ), [ 3 ], { 'a' : 4 }]]\nv = []\nkeras . tree . traverse ( v . append , [( 1 , 2 ), [ 3 ], { \"a\" : 4 }], top_down = False )\n[( 1 , 2 ), [ 3 ], { 'a' : 4 }]\nv\n[ 1 , 2 , ( 1 , 2 ), 3 , [ 3 ], 4 , { 'a' : 4 }, [( 1 , 2 ), [ 3 ], { 'a' : 4 }]]\nArgs\nArgs\nfunc The function to be applied to each sub-nest of the structure.\nfunc\nWhen traversing top-down:\n    If func(subtree) is None the traversal continues into the\n    sub-tree.\n    If func(subtree) is not None the traversal does not continue\n    into the sub-tree. The sub-tree will be replaced by func(subtree) in the returned structure (to replace the sub-tree with None , use\n    the special value _MAP_TO_NONE ).\nfunc(subtree) is None\nfunc(subtree) is not None\nfunc(subtree)\nNone\n_MAP_TO_NONE\nWhen traversing bottom-up:\n    If func(subtree) is None the traversed sub-tree is returned\n    unaltered.\n    If func(subtree) is not None the sub-tree will be replaced by func(subtree) in the returned structure (to replace the sub-tree\n    with None, use the special value _MAP_TO_NONE ). structure The structure to traverse. top_down If True, parent structures will be visited before their\nchildren.\nfunc(subtree) is None\nfunc(subtree) is not None\nfunc(subtree)\n_MAP_TO_NONE\nstructure\ntop_down\nReturns The structured output from the traversal.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nInceptionV3(...) : Instantiates the Inception v3 architecture.\nInceptionV3(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/repeat_elements",
    "content": "DEPRECATED.\ntf . keras . backend . repeat_elements ( x , rep , axis )\ntf . keras . backend . repeat_elements ( x , rep , axis )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ravel",
    "content": "Return a contiguous flattened tensor.\nMain aliases tf.keras.ops.numpy.ravel\ntf.keras.ops.numpy.ravel\ntf.keras.ops.numpy.ravel\ntf . keras . ops . ravel ( x )\ntf . keras . ops . ravel ( x )\nA 1-D tensor, containing the elements of the input, is returned.\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50",
    "content": "Instantiates the ResNet50 architecture.\nMain aliases tf.keras.applications.resnet.ResNet50 , tf.keras.applications.resnet50.ResNet50\ntf.keras.applications.resnet.ResNet50 , tf.keras.applications.resnet50.ResNet50\ntf.keras.applications.resnet.ResNet50\ntf.keras.applications.resnet50.ResNet50\ntf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet50 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nUsed in the notebooks\nWorking with preprocessing layers\nDeep Residual Learning for Image Recognition (CVPR 2015)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet.preprocess_input\nresnet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/IoU",
    "content": "Computes the Intersection-Over-Union metric for specific target classes.\nInherits From: Metric\nMetric\ntf . keras . metrics . IoU ( num_classes , target_class_ids , name = None , dtype = None , ignore_class = None , sparse_y_true = True , sparse_y_pred = True , axis =- 1 )\ntf . keras . metrics . IoU ( num_classes , target_class_ids , name = None , dtype = None , ignore_class = None , sparse_y_true = True , sparse_y_pred = True , axis =- 1 )\niou = true_positives / ( true_positives + false_positives + false_negatives )\niou = true_positives / ( true_positives + false_positives + false_negatives )\nIntersection-Over-Union is a common evaluation metric for semantic image\nsegmentation.\nTo compute IoUs, the predictions are accumulated in a confusion matrix,\nweighted by sample_weight and the metric is then calculated from it.\nsample_weight\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nNote, this class first computes IoUs for all individual classes, then\nreturns the mean of IoUs for the classes that are specified by target_class_ids . If target_class_ids has only one id value, the IoU of\nthat specific class is returned.\ntarget_class_ids\ntarget_class_ids\nArgs\nArgs\nnum_classes The possible number of labels the prediction task can have. target_class_ids A tuple or list of target class ids for which the\nmetric is returned. To compute IoU for a specific class, a list\n(or tuple) of a single id value should be provided. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. ignore_class Optional integer. The ID of a class to be ignored during\nmetric computation. This is useful, for example, in segmentation\nproblems featuring a \"void\" class (commonly -1 or 255) in\nsegmentation maps. By default ( ignore_class=None ), all classes are\n  considered. sparse_y_true Whether labels are encoded using integers or\ndense floating point vectors. If False , the argmax function\nis used to determine each sample's most likely associated label. sparse_y_pred Whether predictions are encoded using integers or\ndense floating point vectors. If False , the argmax function\nis used to determine each sample's most likely associated label. axis (Optional) -1 is the dimension containing the logits.\nDefaults to -1 .\nnum_classes\ntarget_class_ids\nname\ndtype\nignore_class\nignore_class=None\nsparse_y_true\nFalse\nargmax\nsparse_y_pred\nFalse\nargmax\naxis\n-1\n# cm = [[1, 1], #        [1, 1]] # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1] # iou = true_positives / (sum_row + sum_col - true_positives)) # iou = [0.33, 0.33] m = keras . metrics . IoU ( num_classes = 2 , target_class_ids = [ 0 ]) m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ]) m . result () 0.33333334\n# cm = [[1, 1],\n#        [1, 1]]\n# sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n# iou = true_positives / (sum_row + sum_col - true_positives))\n# iou = [0.33, 0.33]\nm = keras . metrics . IoU ( num_classes = 2 , target_class_ids = [ 0 ])\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ])\nm . result ()\n0.33333334\nm . reset_state () m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ], sample_weight = [ 0.3 , 0.3 , 0.3 , 0.1 ]) # cm = [[0.3, 0.3], #        [0.3, 0.1]] # sum_row = [0.6, 0.4], sum_col = [0.6, 0.4], # true_positives = [0.3, 0.1] # iou = [0.33, 0.14] m . result () 0.33333334\nm . reset_state ()\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ],\nsample_weight = [ 0.3 , 0.3 , 0.3 , 0.1 ])\n# cm = [[0.3, 0.3],\n#        [0.3, 0.1]]\n# sum_row = [0.6, 0.4], sum_col = [0.6, 0.4],\n# true_positives = [0.3, 0.1]\n# iou = [0.33, 0.14]\nm . result ()\n0.33333334\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . IoU ( num_classes = 2 , target_class_ids = [ 0 ])])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . IoU ( num_classes = 2 , target_class_ids = [ 0 ])])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the intersection-over-union via the confusion matrix.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same as y_true ,\nand must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/depthwise_conv2d",
    "content": "DEPRECATED.\ntf . keras . backend . depthwise_conv2d ( x , depthwise_kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )\ntf . keras . backend . depthwise_conv2d ( x , depthwise_kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool1D",
    "content": "Max pooling operation for 1D temporal data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.MaxPooling1D\ntf.keras.layers.MaxPooling1D\ntf.keras.layers.MaxPooling1D\ntf . keras . layers . MaxPool1D ( pool_size = 2 , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . MaxPool1D ( pool_size = 2 , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nUsed in the notebooks\nUsing Counterfactual Logit Pairing with Keras\nWiki Talk Comments Toxicity Prediction\nDownsamples the input representation by taking the maximum value over a\nspatial window of size pool_size . The window is shifted by strides .\npool_size\nstrides\nThe resulting output when using the \"valid\" padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides) .\n\"valid\"\noutput_shape = (input_shape - pool_size + 1) / strides)\nThe resulting output shape when using the \"same\" padding option is: output_shape = input_shape / strides\n\"same\"\noutput_shape = input_shape / strides\nArgs\nArgs\npool_size int, size of the max pooling window. strides int or None. Specifies how much the pooling window moves\nfor each pooling step. If None, it will default to pool_size . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, steps, features) .\ndata_format=\"channels_last\"\n(batch_size, steps, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, steps) .\ndata_format=\"channels_first\"\n(batch_size, features, steps)\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, downsampled_steps, features) .\ndata_format=\"channels_last\"\n(batch_size, downsampled_steps, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, downsampled_steps) .\ndata_format=\"channels_first\"\n(batch_size, features, downsampled_steps)\nstrides=1 and padding=\"valid\" :\nstrides=1\npadding=\"valid\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) max_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 , strides = 1 , padding = \"valid\" ) max_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\nmax_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 ,\nstrides = 1 , padding = \"valid\" )\nmax_pool_1d ( x )\nstrides=2 and padding=\"valid\" :\nstrides=2\npadding=\"valid\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) max_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 , strides = 2 , padding = \"valid\" ) max_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\nmax_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 ,\nstrides = 2 , padding = \"valid\" )\nmax_pool_1d ( x )\nstrides=1 and padding=\"same\" :\nstrides=1\npadding=\"same\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) max_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 , strides = 1 , padding = \"same\" ) max_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\nmax_pool_1d = keras . layers . MaxPooling1D ( pool_size = 2 ,\nstrides = 1 , padding = \"same\" )\nmax_pool_1d ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/tile",
    "content": "DEPRECATED.\ntf . keras . backend . tile ( x , n )\ntf . keras . backend . tile ( x , n )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanAbsoluteError",
    "content": "Computes the mean of absolute difference between labels and predictions.\nInherits From: Loss\nLoss\ntf . keras . losses . MeanAbsoluteError ( reduction = 'sum_over_batch_size' , name = 'mean_absolute_error' )\ntf . keras . losses . MeanAbsoluteError ( reduction = 'sum_over_batch_size' , name = 'mean_absolute_error' )\nloss = mean ( abs ( y_true - y_pred ))\nloss = mean ( abs ( y_true - y_pred ))\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_brightness_shift",
    "content": "Performs a brightness shift.\ntf . keras . preprocessing . image . apply_brightness_shift ( x , brightness , scale = True )\ntf . keras . preprocessing . image . apply_brightness_shift ( x , brightness , scale = True )\nDEPRECATED.\nArgs\nArgs\nx Input tensor. Must be 3D. brightness Float. The new brightness value. scale Whether to rescale the image such that minimum and maximum values\nare 0 and 255 respectively. Default: True.\nx\nbrightness\nscale\nReturns Numpy image tensor.\nReturns\nRaises\nRaises\nImportError if PIL is not available.\nImportError"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal",
    "content": "The Glorot normal initializer, also called Xavier normal initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.glorot_normal\ntf.keras.initializers.glorot_normal\ntf.keras.initializers.glorot_normal\ntf . keras . initializers . GlorotNormal ( seed = None )\ntf . keras . initializers . GlorotNormal ( seed = None )\nUsed in the notebooks\nBuilding Your Own Federated Learning Algorithm\nComposing Learning Algorithms\nDraws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of\ninput units in the weight tensor and fan_out is the number of output units\nin the weight tensor.\nstddev = sqrt(2 / (fan_in + fan_out))\nfan_in\nfan_out\n# Standalone usage: initializer = GlorotNormal () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = GlorotNormal ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = GlorotNormal () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = GlorotNormal ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nGlorot et al., 2010\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nResNet101(...) : Instantiates the ResNet101 architecture.\nResNet101(...)\nResNet152(...) : Instantiates the ResNet152 architecture.\nResNet152(...)\nResNet50(...) : Instantiates the ResNet50 architecture.\nResNet50(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback",
    "content": "Base class used to build new callbacks.\ntf . keras . callbacks . Callback ()\ntf . keras . callbacks . Callback ()\nUsed in the notebooks\nMigrate the fault tolerance mechanism\nMigrate LoggingTensorHook and StopAtStepHook to Keras callbacks\nMigrate early stopping\nMigrate SessionRunHook to Keras callbacks\nDistributed training with Keras\nImage segmentation\nUncertainty-aware Deep Learning with SNGP\nAssess privacy risks with the TensorFlow Privacy Report\nImage captioning with visual attention\nCallbacks can be passed to keras methods such as fit() , evaluate() , and predict() in order to hook into the various stages of the model training,\nevaluation, and inference lifecycle.\nfit()\nevaluate()\npredict()\nTo create a custom callback, subclass keras.callbacks.Callback and\noverride the method associated with the stage of interest.\nkeras.callbacks.Callback\ntraining_finished = False class MyCallback ( Callback ): def on_train_end ( self , logs = None ): global training_finished training_finished = True model = Sequential ([ layers . Dense ( 1 , input_shape = ( 1 ,))]) model . compile ( loss = 'mean_squared_error' ) model . fit ( np . array ([[ 1.0 ]]), np . array ([[ 1.0 ]]), callbacks = [ MyCallback ()]) assert training_finished == True\ntraining_finished = False\nclass MyCallback ( Callback ):\ndef on_train_end ( self , logs = None ):\nglobal training_finished\ntraining_finished = True\nmodel = Sequential ([\nlayers . Dense ( 1 , input_shape = ( 1 ,))])\nmodel . compile ( loss = 'mean_squared_error' )\nmodel . fit ( np . array ([[ 1.0 ]]), np . array ([[ 1.0 ]]),\ncallbacks = [ MyCallback ()])\nassert training_finished == True\nIf you want to use Callback objects in a custom training loop:\nCallback\nYou should pack all your callbacks into a single callbacks.CallbackList so they can all be called together.\ncallbacks.CallbackList\nYou will need to manually call all the on_* methods at the appropriate\nlocations in your loop. Like this:\non_*\ncallbacks = keras . callbacks . CallbackList ([ ... ]) callbacks . append ( ... ) callbacks . on_train_begin ( ... ) for epoch in range ( EPOCHS ): callbacks . on_epoch_begin ( epoch ) for i , data in dataset . enumerate (): callbacks . on_train_batch_begin ( i ) batch_logs = model . train_step ( data ) callbacks . on_train_batch_end ( i , batch_logs ) epoch_logs = ... callbacks . on_epoch_end ( epoch , epoch_logs ) final_logs =... callbacks . on_train_end ( final_logs )\ncallbacks = keras . callbacks . CallbackList ([ ... ]) callbacks . append ( ... ) callbacks . on_train_begin ( ... ) for epoch in range ( EPOCHS ): callbacks . on_epoch_begin ( epoch ) for i , data in dataset . enumerate (): callbacks . on_train_batch_begin ( i ) batch_logs = model . train_step ( data ) callbacks . on_train_batch_end ( i , batch_logs ) epoch_logs = ... callbacks . on_epoch_end ( epoch , epoch_logs ) final_logs =... callbacks . on_train_end ( final_logs )\nThe logs dictionary that callback methods\ntake as argument will contain keys for quantities relevant to\nthe current batch or epoch (see method-specific docstrings).\nlogs\nAttributes\nAttributes\nparams Dict. Training parameters\n(eg. verbosity, batch size, number of epochs...). model Instance of Model .\nReference of the model being trained.\nparams\nmodel\nModel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/diff",
    "content": "Calculate the n-th discrete difference along the given axis.\nMain aliases tf.keras.ops.numpy.diff\ntf.keras.ops.numpy.diff\ntf.keras.ops.numpy.diff\ntf . keras . ops . diff ( a , n = 1 , axis =- 1 )\ntf . keras . ops . diff ( a , n = 1 , axis =- 1 )\nThe first difference is given by out[i] = a[i+1] - a[i] along\nthe given axis, higher differences are calculated by using diff recursively.\nout[i] = a[i+1] - a[i]\ndiff\nArgs\nArgs\na Input tensor. n The number of times values are differenced. Defaults to 1 . axis Axis to compute discrete difference(s) along.\nDefaults to -1 .(last axis).\na\nn\n1\naxis\n-1\nReturns Tensor of diagonals.\nReturns\nfrom keras.src import ops x = ops . convert_to_tensor ([ 1 , 2 , 4 , 7 , 0 ]) ops . diff ( x ) array ([ 1 , 2 , 3 , - 7 ]) ops . diff ( x , n = 2 ) array ([ 1 , 1 , - 10 ])\nfrom keras.src import ops\nx = ops . convert_to_tensor ([ 1 , 2 , 4 , 7 , 0 ])\nops . diff ( x )\narray ([ 1 , 2 , 3 , - 7 ])\nops . diff ( x , n = 2 )\narray ([ 1 , 1 , - 10 ])\nx = ops . convert_to_tensor ([[ 1 , 3 , 6 , 10 ], [ 0 , 5 , 6 , 8 ]]) ops . diff ( x ) array ([[ 2 , 3 , 4 ], [ 5 , 1 , 2 ]]) ops . diff ( x , axis = 0 ) array ([[ - 1 , 2 , 0 , - 2 ]])\nx = ops . convert_to_tensor ([[ 1 , 3 , 6 , 10 ], [ 0 , 5 , 6 , 8 ]])\nops . diff ( x )\narray ([[ 2 , 3 , 4 ],\n[ 5 , 1 , 2 ]])\nops . diff ( x , axis = 0 )\narray ([[ - 1 , 2 , 0 , - 2 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/trace",
    "content": "Return the sum along diagonals of the tensor.\nMain aliases tf.keras.ops.numpy.trace\ntf.keras.ops.numpy.trace\ntf.keras.ops.numpy.trace\ntf . keras . ops . trace ( x , offset = 0 , axis1 = 0 , axis2 = 1 )\ntf . keras . ops . trace ( x , offset = 0 , axis1 = 0 , axis2 = 1 )\nIf x is 2-D, the sum along its diagonal with the given offset is\nreturned, i.e., the sum of elements x[i, i+offset] for all i .\nx\nx[i, i+offset]\ni\nIf a has more than two dimensions, then the axes specified by axis1 and axis2 are used to determine the 2-D sub-arrays whose traces are\nreturned.\naxis1\naxis2\nThe shape of the resulting tensor is the same as that of x with axis1 and axis2 removed.\nx\naxis1\naxis2\nArgs\nArgs\nx Input tensor. offset Offset of the diagonal from the main diagonal. Can be\nboth positive and negative. Defaults to 0 . axis1 Axis to be used as the first axis of the 2-D sub-arrays.\nDefaults to 0 .(first axis). axis2 Axis to be used as the second axis of the 2-D sub-arrays.\nDefaults to 1 (second axis).\nx\noffset\n0\naxis1\n0\naxis2\n1\nReturns If x is 2-D, the sum of the diagonal is returned. If x has\nlarger dimensions, then a tensor of sums along diagonals is\nreturned.\nReturns\nx\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/binary_crossentropy",
    "content": "Computes the binary crossentropy loss.\nMain aliases tf.keras.metrics.binary_crossentropy\ntf.keras.metrics.binary_crossentropy\ntf.keras.metrics.binary_crossentropy\ntf . keras . losses . binary_crossentropy ( y_true , y_pred , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\ntf . keras . losses . binary_crossentropy ( y_true , y_pred , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\nUsed in the notebooks\nWiki Talk Comments Toxicity Prediction\nArgs\nArgs\ny_true Ground truth values. shape = [batch_size, d0, .. dN] . y_pred The predicted values. shape = [batch_size, d0, .. dN] . from_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. label_smoothing Float in [0, 1] . If > 0 then smooth the labels by\nsqueezing them towards 0.5, that is,\nusing 1. - 0.5 * label_smoothing for the target class\nand 0.5 * label_smoothing for the non-target class. axis The axis along which the mean is computed. Defaults to -1 .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\n[0, 1]\n0\n1. - 0.5 * label_smoothing\n0.5 * label_smoothing\naxis\n-1\nReturns Binary crossentropy loss value. shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = [[ 0 , 1 ], [ 0 , 0 ]] y_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]] loss = keras . losses . binary_crossentropy ( y_true , y_pred ) assert loss . shape == ( 2 ,) loss array ([ 0.916 , 0.714 ], dtype = float32 )\ny_true = [[ 0 , 1 ], [ 0 , 0 ]]\ny_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]\nloss = keras . losses . binary_crossentropy ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\nloss\narray ([ 0.916 , 0.714 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ndim",
    "content": "DEPRECATED.\ntf . keras . backend . ndim ( x )\ntf . keras . backend . ndim ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/crop_images",
    "content": "Crop images to a specified height and width .\nimages\nheight\nwidth\ntf . keras . ops . image . crop_images ( images , top_cropping = None , left_cropping = None , target_height = None , target_width = None , bottom_cropping = None , right_cropping = None )\ntf . keras . ops . image . crop_images ( images , top_cropping = None , left_cropping = None , target_height = None , target_width = None , bottom_cropping = None , right_cropping = None )\nArgs\nArgs\nimages 4-D batch of images of shape (batch, height, width, channels) or 3-D single image of shape (height, width, channels) . top_cropping Number of columns to crop from the top. bottom_cropping Number of columns to crop from the bottom. left_cropping Number of columns to crop from the left. right_cropping Number of columns to crop from the right. target_height Height of the output images. target_width Width of the output images.\nimages\n(batch, height, width, channels)\n(height, width, channels)\ntop_cropping\nbottom_cropping\nleft_cropping\nright_cropping\ntarget_height\ntarget_width\nReturns If images were 4D, a 4D float Tensor of shape (batch, target_height, target_width, channels) If images were 3D, a 3D float Tensor of shape (target_height, target_width, channels)\nReturns\nimages\n(batch, target_height, target_width, channels)\nimages\n(target_height, target_width, channels)\nimages = np . reshape ( np . arange ( 1 , 28 , dtype = \"float32\" ), [ 3 , 3 , 3 ]) images [:,:, 0 ] # print the first channel of the images array ([[ 1. , 4. , 7. ], [ 10. , 13. , 16. ], [ 19. , 22. , 25. ]], dtype = float32 ) cropped_images = keras . image . crop_images ( images , 0 , 0 , 2 , 2 ) cropped_images [:,:, 0 ] # print the first channel of the cropped images array ([[ 1. , 4. ], [ 10. , 13. ]], dtype = float32 )\nimages = np . reshape ( np . arange ( 1 , 28 , dtype = \"float32\" ), [ 3 , 3 , 3 ])\nimages [:,:, 0 ] # print the first channel of the images\narray ([[ 1. , 4. , 7. ],\n[ 10. , 13. , 16. ],\n[ 19. , 22. , 25. ]], dtype = float32 )\ncropped_images = keras . image . crop_images ( images , 0 , 0 , 2 , 2 )\ncropped_images [:,:, 0 ] # print the first channel of the cropped images\narray ([[ 1. , 4. ],\n[ 10. , 13. ]], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B2",
    "content": "Instantiates the EfficientNetV2B2 architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2B2\ntf.keras.applications.efficientnet_v2.EfficientNetV2B2\ntf.keras.applications.efficientnet_v2.EfficientNetV2B2\ntf . keras . applications . EfficientNetV2B2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2B2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM1D",
    "content": "1D Convolutional LSTM.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . ConvLSTM1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\ntf . keras . layers . ConvLSTM1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 1 integer, specifying the size of\nthe convolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the\nsame height/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated convolution. activation Activation function to use. By default hyperbolic tangent\nactivation function is applied ( tanh(x) ). recurrent_activation Activation function to use for the recurrent step. use_bias Boolean, whether the layer uses a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. recurrent_initializer Initializer for the recurrent_kernel weights\nmatrix, used for the linear transformation of the recurrent state. bias_initializer Initializer for the bias vector. unit_forget_bias Boolean. If True , add 1 to the bias of\nthe forget gate at initialization.\nUse in combination with bias_initializer=\"zeros\" .\nThis is recommended in Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. bias_regularizer Regularizer function applied to the bias vector. activity_regularizer Regularizer function applied to. kernel_constraint Constraint function applied to the kernel weights\nmatrix. recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. bias_constraint Constraint function applied to the bias vector. dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. seed Random seed for dropout. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state in addition\nto the output. Default: False . go_backwards Boolean (default: False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default False). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default: False ).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences.\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\ntanh(x)\nrecurrent_activation\nuse_bias\nkernel_initializer\nkernel\nrecurrent_initializer\nrecurrent_kernel\nbias_initializer\nunit_forget_bias\nTrue\nbias_initializer=\"zeros\"\nkernel_regularizer\nkernel\nrecurrent_regularizer\nrecurrent_kernel\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nkernel\nrecurrent_constraint\nrecurrent_kernel\nbias_constraint\ndropout\nrecurrent_dropout\nseed\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nTrue\nunroll\nFalse\nTrue\nCall arguments\nCall arguments\ninputs A 4D tensor. initial_state List of initial state tensors to be passed to the first\ncall of the cell. mask Binary tensor of shape (samples, timesteps) indicating whether a\ngiven timestep should be masked. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode.\nThis is only relevant if dropout or recurrent_dropout are set.\ninputs\ninitial_state\nmask\n(samples, timesteps)\ntraining\ndropout\nrecurrent_dropout\nIf data_format=\"channels_first\" :\n4D tensor with shape: (samples, time, channels, rows)\ndata_format=\"channels_first\"\n(samples, time, channels, rows)\nIf data_format=\"channels_last\" :\n4D tensor with shape: (samples, time, rows, channels)\ndata_format=\"channels_last\"\n(samples, time, rows, channels)\nIf return_state : a list of tensors. The first tensor is the output.\nThe remaining tensors are the last states,\neach 3D tensor with shape: (samples, filters, new_rows) if data_format='channels_first' or shape: (samples, new_rows, filters) if data_format='channels_last' . rows values might have changed due to padding.\nreturn_state\n(samples, filters, new_rows)\ndata_format='channels_first'\n(samples, new_rows, filters)\ndata_format='channels_last'\nrows\nIf return_sequences : 4D tensor with shape: (samples, timesteps,\nfilters, new_rows) if data_format='channels_first'\nor shape: (samples, timesteps, new_rows, filters) if data_format='channels_last' .\nreturn_sequences\n(samples, timesteps,\nfilters, new_rows)\n(samples, timesteps, new_rows, filters)\ndata_format='channels_last'\nElse, 3D tensor with shape: (samples, filters, new_rows) if data_format='channels_first' or shape: (samples, new_rows, filters) if data_format='channels_last' .\n(samples, filters, new_rows)\ndata_format='channels_first'\n(samples, new_rows, filters)\ndata_format='channels_last'\nShi et al., 2015 (the current implementation does not include the feedback loop on the\ncells output).\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndata_format\ndata_format\ndilation_rate\ndilation_rate\ndropout\ndropout\nfilters\nfilters\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\nkernel_size\nkernel_size\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. padding\npadding\nrecurrent_activation\nrecurrent_activation\nrecurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nstrides\nstrides\nunit_forget_bias\nunit_forget_bias\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arcsinh",
    "content": "Inverse hyperbolic sine, element-wise.\nMain aliases tf.keras.ops.numpy.arcsinh\ntf.keras.ops.numpy.arcsinh\ntf.keras.ops.numpy.arcsinh\ntf . keras . ops . arcsinh ( x )\ntf . keras . ops . arcsinh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ 1 , - 1 , 0 ]) keras . ops . arcsinh ( x ) array ([ 0.88137364 , - 0.88137364 , 0.0 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 1 , - 1 , 0 ])\nkeras . ops . arcsinh ( x )\narray ([ 0.88137364 , - 0.88137364 , 0.0 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/softmax",
    "content": "Softmax activation function.\nMain aliases tf.keras.ops.nn.softmax\ntf.keras.ops.nn.softmax\ntf.keras.ops.nn.softmax\ntf . keras . ops . softmax ( x , axis =- 1 )\ntf . keras . ops . softmax ( x , axis =- 1 )\nThe elements of the output vector lie within the range (0, 1) , and their\ntotal sum is exactly 1 (excluding the floating point rounding error).\n(0, 1)\nEach vector is processed independently. The axis argument specifies the\naxis along which the function is applied within the input.\naxis\nf(x) = exp(x) / sum(exp(x))\nf(x) = exp(x) / sum(exp(x))\nArgs\nArgs\nx Input tensor. axis Integer, axis along which the softmax is applied.\nx\naxis\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_softmax = keras . ops . softmax ( x ) print ( x_softmax ) array ([ 0.09003057 , 0.24472847 , 0.66524096 ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_softmax = keras . ops . softmax ( x )\nprint ( x_softmax )\narray ([ 0.09003057 , 0.24472847 , 0.66524096 ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Wrapper",
    "content": "Abstract wrapper base class.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Wrapper ( layer , ** kwargs )\ntf . keras . layers . Wrapper ( layer , ** kwargs )\nWrappers take another layer and augment it in various ways.\nDo not use this class as a layer, it is only an abstract base class.\nTwo usable wrappers are the TimeDistributed and Bidirectional layers.\nTimeDistributed\nBidirectional\nArgs\nArgs\nlayer The layer to be wrapped.\nlayer\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2L",
    "content": "Instantiates the EfficientNetV2L architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2L\ntf.keras.applications.efficientnet_v2.EfficientNetV2L\ntf.keras.applications.efficientnet_v2.EfficientNetV2L\ntf . keras . applications . EfficientNetV2L ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2L ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau",
    "content": "Reduce learning rate when a metric has stopped improving.\nInherits From: Callback\nCallback\ntf . keras . callbacks . ReduceLROnPlateau ( monitor = 'val_loss' , factor = 0.1 , patience = 10 , verbose = 0 , mode = 'auto' , min_delta = 0.0001 , cooldown = 0 , min_lr = 0.0 , ** kwargs )\ntf . keras . callbacks . ReduceLROnPlateau ( monitor = 'val_loss' , factor = 0.1 , patience = 10 , verbose = 0 , mode = 'auto' , min_delta = 0.0001 , cooldown = 0 , min_lr = 0.0 , ** kwargs )\nModels often benefit from reducing the learning rate by a factor\nof 2-10 once learning stagnates. This callback monitors a\nquantity and if no improvement is seen for a 'patience' number\nof epochs, the learning rate is reduced.\nreduce_lr = ReduceLROnPlateau ( monitor = 'val_loss' , factor = 0.2 , patience = 5 , min_lr = 0.001 ) model . fit ( x_train , y_train , callbacks = [ reduce_lr ])\nreduce_lr = ReduceLROnPlateau ( monitor = 'val_loss' , factor = 0.2 , patience = 5 , min_lr = 0.001 ) model . fit ( x_train , y_train , callbacks = [ reduce_lr ])\nArgs\nArgs\nmonitor String. Quantity to be monitored. factor Float. Factor by which the learning rate will be reduced. new_lr = lr * factor . patience Integer. Number of epochs with no improvement after which\nlearning rate will be reduced. verbose Integer. 0: quiet, 1: update messages. mode String. One of {'auto', 'min', 'max'} . In 'min' mode,\nthe learning rate will be reduced when the\nquantity monitored has stopped decreasing; in 'max' mode it will\nbe reduced when the quantity monitored has stopped increasing; in 'auto' mode, the direction is automatically inferred from the name\nof the monitored quantity. min_delta Float. Threshold for measuring the new optimum, to only focus\non significant changes. cooldown Integer. Number of epochs to wait before resuming normal\noperation after the learning rate has been reduced. min_lr Float. Lower bound on the learning rate.\nmonitor\nfactor\nnew_lr = lr * factor\npatience\nverbose\nmode\n{'auto', 'min', 'max'}\n'min'\n'max'\n'auto'\nmin_delta\ncooldown\nmin_lr\nAttributes\nAttributes\nmodel\nmodel\nMethods\nin_cooldown\nin_cooldown\nView source\nin_cooldown ()\nin_cooldown ()\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/eye",
    "content": "DEPRECATED.\ntf . keras . backend . eye ( size , dtype = None , name = None )\ntf . keras . backend . eye ( size , dtype = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE",
    "content": "Computes the mean squared error between labels and predictions.\nMain aliases tf.keras.losses.mse , tf.keras.metrics.MSE , tf.keras.metrics.mse\ntf.keras.losses.mse , tf.keras.metrics.MSE , tf.keras.metrics.mse\ntf.keras.losses.mse\ntf.keras.metrics.MSE\ntf.keras.metrics.mse\ntf . keras . losses . MSE ( y_true , y_pred )\ntf . keras . losses . MSE ( y_true , y_pred )\nloss = mean ( square ( y_true - y_pred ), axis =- 1 )\nloss = mean ( square ( y_true - y_pred ), axis =- 1 )\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . mean_squared_error ( y_true , y_pred )\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . mean_squared_error ( y_true , y_pred )\nArgs\nArgs\ny_true Ground truth values with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Mean squared error values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/conjugate",
    "content": "Returns the complex conjugate, element-wise.\nMain aliases tf.keras.ops.numpy.conjugate\ntf.keras.ops.numpy.conjugate\ntf.keras.ops.numpy.conjugate\ntf . keras . ops . conjugate ( x )\ntf . keras . ops . conjugate ( x )\nThe complex conjugate of a complex number is obtained by changing the sign\nof its imaginary part.\nkeras.ops.conj is a shorthand for this function.\nkeras.ops.conj\nArgs\nArgs\nx Input tensor.\nx\nReturns The complex conjugate of each element in x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/custom_gradient",
    "content": "Decorator to define a function with a custom gradient.\ntf . keras . ops . custom_gradient ( f )\ntf . keras . ops . custom_gradient ( f )\nThis decorator allows fine grained control over the gradients of a sequence\nfor operations. This may be useful for multiple reasons, including providing\na more efficient or numerically stable gradient for a sequence of\noperations.\nArgs\nArgs\nf Function f(*args) that returns a tuple (output, grad_fn) , where:\nf\nf(*args)\n(output, grad_fn)\nargs is a sequence of (nested structures of) tensor inputs to\nthe function.\nargs\noutput is a (nested structure of) tensor outputs of applying\noperations in forward_fn to args .\noutput\nforward_fn\nargs\ngrad_fn is a function with the signature grad_fn(*args,\nupstream) which returns a tuple of tensors the same size as\n(flattened) args : the derivatives of tensors in output with\nrespect to the tensors in args . upstream is a tensor or\nsequence of tensors holding the initial value gradients for each\ntensor in output .\ngrad_fn\ngrad_fn(*args,\nupstream)\nargs\noutput\nargs\nupstream\noutput\nReturns A function h(*args) which returns the same value as f(*args)[0] and whose gradient is determined by f(*args)[1] .\nReturns\nh(*args)\nf(*args)[0]\nf(*args)[1]\nBackend-agnostic example.\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( * args , upstream = None ): if upstream is None : ( upstream ,) = args return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( * args , upstream = None ): if upstream is None : ( upstream ,) = args return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad\nNote that the grad function that returns gradient computation\nrequires args as well as an upstream keyword argument, depending\non the backend being set. With the JAX and TensorFlow backends,\nit requires only one argument, whereas it might use the upstream argument in the case of the PyTorch backend.\nargs\nupstream\nupstream\nWhen working with TensorFlow/JAX backend, grad(upstream) is sufficient. With PyTorch, the grad function requires *args as well as upstream , e.g. def grad(*args, upstream) .\nFollow the previous example to use @ops.custom_gradient in\na way that is compatible with all backends.\ngrad(upstream)\ngrad\n*args\nupstream\ndef grad(*args, upstream)\n@ops.custom_gradient\nHere's JAX & TensorFlow-specific example:\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( upstream ): return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( upstream ): return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad\nLastly, here's a PyTorch-specific example,\nusing *args & upstream :\n*args\nupstream\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( * args , upstream ): return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad\n@ops . custom_gradient def log1pexp ( x ): e = ops . exp ( x ) def grad ( * args , upstream ): return ops . multiply ( upstream , 1.0 - 1.0 / ops . add ( 1 , e )) return ops . log ( 1 + e ), grad"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/subtract",
    "content": "Functional interface to the keras.layers.Subtract layer.\nkeras.layers.Subtract\ntf . keras . layers . subtract ( inputs , ** kwargs )\ntf . keras . layers . subtract ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors of size 2, each tensor of\nthe same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the difference of the inputs. It has the same shape\nas the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . subtract ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . subtract ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) subtracted = keras . layers . subtract ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( subtracted ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\nsubtracted = keras . layers . subtract ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( subtracted )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ConvNeXtXLarge",
    "content": "Instantiates the ConvNeXtXLarge architecture.\nMain aliases tf.keras.applications.convnext.ConvNeXtXLarge\ntf.keras.applications.convnext.ConvNeXtXLarge\ntf.keras.applications.convnext.ConvNeXtXLarge\ntf . keras . applications . ConvNeXtXLarge ( model_name = 'convnext_xlarge' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ConvNeXtXLarge ( model_name = 'convnext_xlarge' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nA ConvNet for the 2020s (CVPR 2022)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe base , large , and xlarge models were first pre-trained on the\nImageNet-21k dataset and then fine-tuned on the ImageNet-1k dataset. The\npre-trained parameters of the models were assembled from the official repository . To get a\nsense of how these parameters were converted to Keras compatible parameters,\nplease refer to this repository .\nbase\nlarge\nxlarge\nNormalization\nWhen calling the summary() method after instantiating a ConvNeXt model,\nprefer setting the expand_nested argument summary() to True to better\ninvestigate the instantiated model.\nsummary()\nexpand_nested\nsummary()\nTrue\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet-1k), or the path to the weights\nfile to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/softsign",
    "content": "DEPRECATED.\ntf . keras . backend . softsign ( x )\ntf . keras . backend . softsign ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG19",
    "content": "Instantiates the VGG19 model.\nMain aliases tf.keras.applications.vgg19.VGG19\ntf.keras.applications.vgg19.VGG19\ntf.keras.applications.vgg19.VGG19\ntf . keras . applications . VGG19 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . VGG19 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nUsed in the notebooks\nNeural style transfer\nVery Deep Convolutional Networks for Large-Scale Image Recognition (ICLR 2015)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe default input size for this model is 224x224.\nkeras.applications.vgg19.preprocess_input\nvgg19.preprocess_input\nArgs\nArgs\ninclude_top whether to include the 3 fully-connected\nlayers at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with \"channels_first\" data format).\nIt should have exactly 3 input channels,\nand width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\nchannels_last\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\"\nlayer.  When loading pretrained weights, classifier_activation can\nonly be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping2D",
    "content": "Cropping layer for 2D input (e.g. picture).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Cropping2D ( cropping = (( 0 , 0 ), ( 0 , 0 )), data_format = None , ** kwargs )\ntf . keras . layers . Cropping2D ( cropping = (( 0 , 0 ), ( 0 , 0 )), data_format = None , ** kwargs )\nIt crops along spatial dimensions, i.e. height and width.\ninput_shape = ( 2 , 28 , 28 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) y = keras . layers . Cropping2D ( cropping = (( 2 , 2 ), ( 4 , 4 )))( x ) y . shape ( 2 , 24 , 20 , 3 )\ninput_shape = ( 2 , 28 , 28 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\ny = keras . layers . Cropping2D ( cropping = (( 2 , 2 ), ( 4 , 4 )))( x )\ny . shape\n( 2 , 24 , 20 , 3 )\nArgs\nArgs\ncropping Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\ncropping\nIf int: the same symmetric cropping is applied to height and\nwidth.\nIf tuple of 2 ints: interpreted as two different symmetric\ncropping values for height and width: (symmetric_height_crop, symmetric_width_crop) .\n(symmetric_height_crop, symmetric_width_crop)\nIf tuple of 2 tuples of 2 ints: interpreted as ((top_crop, bottom_crop), (left_crop, right_crop)) . data_format A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, height, width) .\nWhen unspecified, uses image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json (if exists). Defaults to \"channels_last\" .\n((top_crop, bottom_crop), (left_crop, right_crop))\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, height, width, channels)\n\"channels_first\"\n(batch_size, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nInput shape 4D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, height, width, channels)\ndata_format\n\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, height, width)\ndata_format\n\"channels_first\"\n(batch_size, channels, height, width)\nOutput shape 4D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, cropped_height, cropped_width, channels)\ndata_format\n\"channels_last\"\n(batch_size, cropped_height, cropped_width, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, cropped_height, cropped_width)\ndata_format\n\"channels_first\"\n(batch_size, channels, cropped_height, cropped_width)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN",
    "content": "Fully-connected RNN where the output is to be fed back as the new input.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . SimpleRNN ( units , activation = 'tanh' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , seed = None , ** kwargs )\ntf . keras . layers . SimpleRNN ( units , activation = 'tanh' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , seed = None , ** kwargs )\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use.\nDefault: hyperbolic tangent ( tanh ).\nIf you pass None, no activation is applied\n(ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer uses\na bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent\nstate.  Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . activity_regularizer Regularizer function applied to the output of the\nlayer (its \"activation\"). Default: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix.  Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1.\nFraction of the units to drop for the linear transformation\nof the inputs. Default: 0. recurrent_dropout Float between 0 and 1.\nFraction of the units to drop for the linear transformation of the\nrecurrent state. Default: 0. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state\nin addition to the output. Default: False . go_backwards Boolean (default: False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default: False ). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default: False ).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences.\nunits\nactivation\ntanh\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nactivity_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nFalse\nTrue\nunroll\nFalse\nTrue\nCall arguments\nCall arguments\nsequence A 3D tensor, with shape [batch, timesteps, feature] . mask Binary tensor of shape [batch, timesteps] indicating whether\na given timestep should be masked. An individual True entry\nindicates that the corresponding timestep should be utilized,\nwhile a False entry indicates that the corresponding timestep\nshould be ignored. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode.\nThis argument is passed to the cell when calling it.\nThis is only relevant if dropout or recurrent_dropout is used. initial_state List of initial state tensors to be passed to the first\ncall of the cell.\nsequence\n[batch, timesteps, feature]\nmask\n[batch, timesteps]\nTrue\nFalse\ntraining\ndropout\nrecurrent_dropout\ninitial_state\ninputs = np . random . random (( 32 , 10 , 8 )) simple_rnn = keras . layers . SimpleRNN ( 4 ) output = simple_rnn ( inputs ) # The output has shape `(32, 4)`. simple_rnn = keras . layers . SimpleRNN ( 4 , return_sequences = True , return_state = True ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. whole_sequence_output , final_state = simple_rnn ( inputs )\ninputs = np . random . random (( 32 , 10 , 8 )) simple_rnn = keras . layers . SimpleRNN ( 4 ) output = simple_rnn ( inputs ) # The output has shape `(32, 4)`. simple_rnn = keras . layers . SimpleRNN ( 4 , return_sequences = True , return_state = True ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. whole_sequence_output , final_state = simple_rnn ( inputs )\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndropout\ndropout\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. recurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nunits\nunits\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ctc_decode",
    "content": "Decodes the output of a CTC model.\nMain aliases tf.keras.ops.nn.ctc_decode\ntf.keras.ops.nn.ctc_decode\ntf.keras.ops.nn.ctc_decode\ntf . keras . ops . ctc_decode ( inputs , sequence_lengths , strategy = 'greedy' , beam_width = 100 , top_paths = 1 , merge_repeated = True , mask_index = None )\ntf . keras . ops . ctc_decode ( inputs , sequence_lengths , strategy = 'greedy' , beam_width = 100 , top_paths = 1 , merge_repeated = True , mask_index = None )\nArgs\nArgs\ninputs A tensor of shape (batch_size, max_length, num_classes) containing the logits (the output of the model).\nThey should not be normalized via softmax. sequence_lengths A tensor of shape (batch_size,) containing the\nsequence lengths for the batch. strategy A string for the decoding strategy. Supported values are \"greedy\" and \"beam_search\" . beam_width An integer scalar beam width used in beam search.\nDefaults to 100. top_paths An integer scalar, the number of top paths to return.\nDefaults to 1. merge_repeated A boolean scalar, whether to merge repeated\nlabels in the output. Defaults to True . mask_index An integer scalar, the index of the mask character in\nthe vocabulary. Defaults to None .\ninputs\n(batch_size, max_length, num_classes)\nsequence_lengths\n(batch_size,)\nstrategy\n\"greedy\"\n\"beam_search\"\nbeam_width\ntop_paths\nmerge_repeated\nTrue\nmask_index\nNone\nReturns A tuple containing:\nReturns\nThe tensor representing the list of decoded sequences. If strategy=\"greedy\" , the shape is (1, batch_size, max_length) . If strategy=\"beam_seatch\" , the shape is (top_paths, batch_size, max_length) . Note that: -1 indicates the\nblank label.\nstrategy=\"greedy\"\n(1, batch_size, max_length)\nstrategy=\"beam_seatch\"\n(top_paths, batch_size, max_length)\n-1\nIf strategy=\"greedy\" , a tensor of shape (batch_size, 1) representing the negative of the sum of the probability logits for\neach sequence. If strategy=\"beam_seatch\" , a tensor of shape (batch_size, top_paths) representing the log probability for each\nsequence.\nstrategy=\"greedy\"\n(batch_size, 1)\nstrategy=\"beam_seatch\"\n(batch_size, top_paths)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/get_label_names",
    "content": "Returns labels as a list of strings with indices matching training data.\ntf . keras . datasets . reuters . get_label_names ()\ntf . keras . datasets . reuters . get_label_names ()\nReuters Dataset"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/stack",
    "content": "Join a sequence of tensors along a new axis.\nMain aliases tf.keras.ops.numpy.stack\ntf.keras.ops.numpy.stack\ntf.keras.ops.numpy.stack\ntf . keras . ops . stack ( x , axis = 0 )\ntf . keras . ops . stack ( x , axis = 0 )\nThe axis parameter specifies the index of the new axis in the\ndimensions of the result.\naxis\nArgs\nArgs\nx A sequence of tensors. axis Axis along which to stack. Defaults to 0 .\nx\naxis\n0\nReturns The stacked tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ConvNeXtTiny",
    "content": "Instantiates the ConvNeXtTiny architecture.\nMain aliases tf.keras.applications.convnext.ConvNeXtTiny\ntf.keras.applications.convnext.ConvNeXtTiny\ntf.keras.applications.convnext.ConvNeXtTiny\ntf . keras . applications . ConvNeXtTiny ( model_name = 'convnext_tiny' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ConvNeXtTiny ( model_name = 'convnext_tiny' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nA ConvNet for the 2020s (CVPR 2022)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe base , large , and xlarge models were first pre-trained on the\nImageNet-21k dataset and then fine-tuned on the ImageNet-1k dataset. The\npre-trained parameters of the models were assembled from the official repository . To get a\nsense of how these parameters were converted to Keras compatible parameters,\nplease refer to this repository .\nbase\nlarge\nxlarge\nNormalization\nWhen calling the summary() method after instantiating a ConvNeXt model,\nprefer setting the expand_nested argument summary() to True to better\ninvestigate the instantiated model.\nsummary()\nexpand_nested\nsummary()\nTrue\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet-1k), or the path to the weights\nfile to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping1D",
    "content": "Cropping layer for 1D input (e.g. temporal sequence).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Cropping1D ( cropping = ( 1 , 1 ), ** kwargs )\ntf . keras . layers . Cropping1D ( cropping = ( 1 , 1 ), ** kwargs )\nIt crops along the time dimension (axis 1).\ninput_shape = ( 2 , 3 , 2 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) x [[[ 0 1 ] [ 2 3 ] [ 4 5 ]] [[ 6 7 ] [ 8 9 ] [ 10 11 ]]] y = keras . layers . Cropping1D ( cropping = 1 )( x ) y [[[ 2 3 ]] [[ 8 9 ]]]\ninput_shape = ( 2 , 3 , 2 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\nx\n[[[ 0 1 ]\n[ 2 3 ]\n[ 4 5 ]]\n[[ 6 7 ]\n[ 8 9 ]\n[ 10 11 ]]]\ny = keras . layers . Cropping1D ( cropping = 1 )( x )\ny\n[[[ 2 3 ]]\n[[ 8 9 ]]]\nArgs\nArgs\ncropping Int, or tuple of int (length 2), or dictionary.\ncropping\nIf int: how many units should be trimmed off at the beginning and\nend of the cropping dimension (axis 1).\nIf tuple of 2 ints: how many units should be trimmed off at the\nbeginning and end of the cropping dimension\n( (left_crop, right_crop) ).\n(left_crop, right_crop)\nInput shape 3D tensor with shape (batch_size, axis_to_crop, features)\nInput shape\n(batch_size, axis_to_crop, features)\nOutput shape 3D tensor with shape (batch_size, cropped_axis, features)\nOutput shape\n(batch_size, cropped_axis, features)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalCrossentropy",
    "content": "Computes the crossentropy metric between the labels and predictions.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . CategoricalCrossentropy ( name = 'categorical_crossentropy' , dtype = None , from_logits = False , label_smoothing = 0 , axis =- 1 )\ntf . keras . metrics . CategoricalCrossentropy ( name = 'categorical_crossentropy' , dtype = None , from_logits = False , label_smoothing = 0 , axis =- 1 )\nThis is the crossentropy metric class to be used when there are multiple\nlabel classes (2 or more). It assumes that labels are one-hot encoded,\ne.g., when labels values are [2, 0, 1] , then y_true is [[0, 0, 1], [1, 0, 0], [0, 1, 0]] .\n[2, 0, 1]\ny_true\n[[0, 0, 1], [1, 0, 0], [0, 1, 0]]\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. from_logits (Optional) Whether output is expected to be\na logits tensor. By default, we consider that output\nencodes a probability distribution. label_smoothing (Optional) Float in [0, 1] .\nWhen > 0, label values are smoothed, meaning the confidence\non label values are relaxed. e.g. label_smoothing=0.2 means\nthat we will use a value of 0.1 for label\n\"0\" and 0.9 for label \"1\". axis (Optional) Defaults to -1 .\nThe dimension along which entropy is computed.\nname\ndtype\nfrom_logits\nlabel_smoothing\n[0, 1]\nlabel_smoothing=0.2\naxis\n-1\n# EPSILON = 1e-7, y = y_true, y` = y_pred # y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON) # y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]] # xent = -sum(y * log(y'), axis = -1) #      = -((log 0.95), (log 0.1)) #      = [0.051, 2.302] # Reduced xent = (0.051 + 2.302) / 2 m = keras . metrics . CategoricalCrossentropy () m . update_state ([[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]], [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]) m . result () 1.1769392\n# EPSILON = 1e-7, y = y_true, y` = y_pred\n# y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n# y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n# xent = -sum(y * log(y'), axis = -1)\n#      = -((log 0.95), (log 0.1))\n#      = [0.051, 2.302]\n# Reduced xent = (0.051 + 2.302) / 2\nm = keras . metrics . CategoricalCrossentropy ()\nm . update_state ([[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]],\n[[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]])\nm . result ()\n1.1769392\nm . reset_state () m . update_state ([[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]], [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]], sample_weight = np . array ([ 0.3 , 0.7 ])) m . result () 1.6271976\nm . reset_state ()\nm . update_state ([[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]],\n[[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]],\nsample_weight = np . array ([ 0.3 , 0.7 ]))\nm . result ()\n1.6271976\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . CategoricalCrossentropy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . CategoricalCrossentropy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/quantize_and_dequantize",
    "content": "tf . keras . quantizers . quantize_and_dequantize ( inputs , scale , quantized_dtype , compute_dtype )\ntf . keras . quantizers . quantize_and_dequantize ( inputs , scale , quantized_dtype , compute_dtype )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/skipgrams",
    "content": "Generates skipgram word pairs.\ntf . keras . preprocessing . sequence . skipgrams ( sequence , vocabulary_size , window_size = 4 , negative_samples = 1.0 , shuffle = True , categorical = False , sampling_table = None , seed = None )\ntf . keras . preprocessing . sequence . skipgrams ( sequence , vocabulary_size , window_size = 4 , negative_samples = 1.0 , shuffle = True , categorical = False , sampling_table = None , seed = None )\nUsed in the notebooks\nword2vec\nDEPRECATED.\nThis function transforms a sequence of word indexes (list of integers)\ninto tuples of words of the form:\n(word, word in the same window), with label 1 (positive samples).\n(word, random word from the vocabulary), with label 0 (negative samples).\nRead more about Skipgram in this gnomic paper by Mikolov et al.: Efficient Estimation of Word Representations in\nVector Space\nArgs\nArgs\nsequence A word sequence (sentence), encoded as a list\nof word indices (integers). If using a sampling_table ,\nword indices are expected to match the rank\nof the words in a reference dataset (e.g. 10 would encode\nthe 10-th most frequently occurring token).\nNote that index 0 is expected to be a non-word and will be skipped. vocabulary_size Int, maximum possible word index + 1 window_size Int, size of sampling windows (technically half-window).\nThe window of a word w_i will be [i - window_size, i + window_size+1] . negative_samples Float >= 0. 0 for no negative (i.e. random) samples.\n1 for same number as positive samples. shuffle Whether to shuffle the word couples before returning them. categorical bool. if False, labels will be\nintegers (eg. [0, 1, 1 .. ] ),\nif True , labels will be categorical, e.g. [[1,0],[0,1],[0,1] .. ] . sampling_table 1D array of size vocabulary_size where the entry i\nencodes the probability to sample a word of rank i. seed Random seed.\nsequence\nsampling_table\nvocabulary_size\nwindow_size\nw_i\n[i - window_size, i + window_size+1]\nnegative_samples\nshuffle\ncategorical\n[0, 1, 1 .. ]\nTrue\n[[1,0],[0,1],[0,1] .. ]\nsampling_table\nvocabulary_size\nseed\nReturns couples, labels: where couples are int pairs and labels are either 0 or 1.\nReturns\ncouples\nlabels\nNote By convention, index 0 in the vocabulary is\na non-word and will be skipped.\nNote"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/serialize",
    "content": "Serializes metric function or Metric instance.\nMetric\ntf . keras . metrics . serialize ( metric )\ntf . keras . metrics . serialize ( metric )\nArgs\nArgs\nmetric A Keras Metric instance or a metric function.\nmetric\nMetric\nReturns Metric configuration dictionary.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/expand_dims",
    "content": "DEPRECATED.\ntf . keras . backend . expand_dims ( x , axis =- 1 )\ntf . keras . backend . expand_dims ( x , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/california_housing",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the California Housing dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/greater_equal",
    "content": "DEPRECATED.\ntf . keras . backend . greater_equal ( x , y )\ntf . keras . backend . greater_equal ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/conv1d",
    "content": "DEPRECATED.\ntf . keras . backend . conv1d ( x , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\ntf . keras . backend . conv1d ( x , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/select",
    "content": "Return elements from choicelist , based on conditions in condlist .\nchoicelist\ncondlist\nMain aliases tf.keras.ops.numpy.select\ntf.keras.ops.numpy.select\ntf.keras.ops.numpy.select\ntf . keras . ops . select ( condlist , choicelist , default = 0 )\ntf . keras . ops . select ( condlist , choicelist , default = 0 )\nArgs\nArgs\ncondlist List of boolean tensors.\nThe list of conditions which determine from which array\nin choicelist the output elements are taken.\nWhen multiple conditions are satisfied,\nthe first one encountered in condlist is used. choicelist List of tensors.\nThe list of tensors from which the output elements are taken.\nThis list has to be of the same length as condlist . defaults Optional scalar value.\nThe element inserted in the output\nwhen all conditions evaluate to False .\ncondlist\nchoicelist\ncondlist\ndefaults\nFalse\nReturns Tensor where the output at position m is the m -th element\nof the tensor in choicelist where the m -th element of the\ncorresponding tensor in condlist is True .\nReturns\nm\nm\nchoicelist\nm\ncondlist\nTrue\nfrom keras import ops x = ops . arange ( 6 ) condlist = [ x<3 , x>3 ] choicelist = [ x , x ** 2 ] ops . select ( condlist , choicelist , 42 ) # Returns: tensor([0,  1,  2, 42, 16, 25])\nfrom keras import ops x = ops . arange ( 6 ) condlist = [ x<3 , x>3 ] choicelist = [ x , x ** 2 ] ops . select ( condlist , choicelist , 42 ) # Returns: tensor([0,  1,  2, 42, 16, 25])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory",
    "content": "Generates a tf.data.Dataset from text files in a directory.\ntf.data.Dataset\nMain aliases tf.keras.utils.text_dataset_from_directory\ntf.keras.utils.text_dataset_from_directory\ntf.keras.utils.text_dataset_from_directory\ntf . keras . preprocessing . text_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , batch_size = 32 , max_length = None , shuffle = True , seed = None , validation_split = None , subset = None , follow_links = False , verbose = True )\ntf . keras . preprocessing . text_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , batch_size = 32 , max_length = None , shuffle = True , seed = None , validation_split = None , subset = None , follow_links = False , verbose = True )\nUsed in the notebooks\nBasic text classification\nLoad text\nClassify text with BERT\nWarm-start embedding layer matrix\nWord embeddings\nIf your directory structure is:\nmain_directory / ... class_a / ...... a_text_1 . txt ...... a_text_2 . txt ... class_b / ...... b_text_1 . txt ...... b_text_2 . txt\nmain_directory / ... class_a / ...... a_text_1 . txt ...... a_text_2 . txt ... class_b / ...... b_text_1 . txt ...... b_text_2 . txt\nThen calling text_dataset_from_directory(main_directory,\nlabels='inferred') will return a tf.data.Dataset that yields batches of\ntexts from the subdirectories class_a and class_b , together with labels\n0 and 1 (0 corresponding to class_a and 1 corresponding to class_b ).\ntext_dataset_from_directory(main_directory,\nlabels='inferred')\ntf.data.Dataset\nclass_a\nclass_b\nclass_a\nclass_b\nOnly .txt files are supported at this time.\n.txt\nArgs\nArgs\ndirectory Directory where the data is located.\nIf labels is \"inferred\" , it should contain\nsubdirectories, each containing text files for a class.\nOtherwise, the directory structure is ignored. labels Either \"inferred\" (labels are generated from the directory structure), None (no labels),\nor a list/tuple of integer labels of the same size as the number of\ntext files found in the directory. Labels should be sorted according\nto the alphanumeric order of the text file paths\n(obtained via os.walk(directory) in Python). label_mode String describing the encoding of labels . Options are:\ndirectory\nlabels\n\"inferred\"\nlabels\n\"inferred\"\nNone\nos.walk(directory)\nlabel_mode\nlabels\n\"int\" : means that the labels are encoded as integers\n(e.g. for sparse_categorical_crossentropy loss).\n\"int\"\nsparse_categorical_crossentropy\n\"categorical\" means that the labels are\nencoded as a categorical vector\n(e.g. for categorical_crossentropy loss).\n\"categorical\"\ncategorical_crossentropy\n\"binary\" means that the labels (there can be only 2)\nare encoded as float32 scalars with values 0 or 1\n(e.g. for binary_crossentropy ).\n\"binary\"\nfloat32\nbinary_crossentropy\nNone (no labels). class_names Only valid if \"labels\" is \"inferred\" .\nThis is the explicit list of class names\n(must match names of subdirectories). Used to control the order\nof the classes (otherwise alphanumerical order is used). batch_size Size of the batches of data. Defaults to 32.\nIf None , the data will not be batched\n(the dataset will yield individual samples). max_length Maximum size of a text string. Texts longer than this will\nbe truncated to max_length . shuffle Whether to shuffle the data. Defaults to True .\nIf set to False , sorts the data in alphanumeric order. seed Optional random seed for shuffling and transformations. validation_split Optional float between 0 and 1,\nfraction of data to reserve for validation. subset Subset of the data to return.\nOne of \"training\" , \"validation\" or \"both\" .\nOnly used if validation_split is set.\nWhen subset=\"both\" , the utility returns a tuple of two datasets\n(the training and validation datasets respectively). follow_links Whether to visits subdirectories pointed to by symlinks.\nDefaults to False . verbose Whether to display number information on classes and\nnumber of files found. Defaults to True .\nNone\nclass_names\n\"labels\"\n\"inferred\"\nbatch_size\nNone\nmax_length\nmax_length\nshuffle\nTrue\nFalse\nseed\nvalidation_split\nsubset\n\"training\"\n\"validation\"\n\"both\"\nvalidation_split\nsubset=\"both\"\nfollow_links\nFalse\nverbose\nTrue\nReturns\nReturns\nA tf.data.Dataset object.\ntf.data.Dataset\nIf label_mode is None , it yields string tensors of shape (batch_size,) , containing the contents of a batch of text files.\nlabel_mode\nNone\nstring\n(batch_size,)\nOtherwise, it yields a tuple (texts, labels) , where texts has shape (batch_size,) and labels follows the format described\nbelow.\n(texts, labels)\ntexts\n(batch_size,)\nlabels\nRules regarding labels format:\nif label_mode is int , the labels are an int32 tensor of shape (batch_size,) .\nlabel_mode\nint\nint32\n(batch_size,)\nif label_mode is binary , the labels are a float32 tensor of\n1s and 0s of shape (batch_size, 1) .\nlabel_mode\nbinary\nfloat32\n(batch_size, 1)\nif label_mode is categorical , the labels are a float32 tensor\nof shape (batch_size, num_classes) , representing a one-hot\nencoding of the class index.\nlabel_mode\ncategorical\nfloat32\n(batch_size, num_classes)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/array",
    "content": "Create a tensor.\nMain aliases tf.keras.ops.numpy.array\ntf.keras.ops.numpy.array\ntf.keras.ops.numpy.array\ntf . keras . ops . array ( x , dtype = None )\ntf . keras . ops . array ( x , dtype = None )\nArgs\nArgs\nx Input tensor. dtype The desired data-type for the tensor.\nx\ndtype\nReturns A tensor.\nReturns\nkeras . ops . array ([ 1 , 2 , 3 ]) array ([ 1 , 2 , 3 ], dtype = int32 )\nkeras . ops . array ([ 1 , 2 , 3 ])\narray ([ 1 , 2 , 3 ], dtype = int32 )\nkeras . ops . array ([ 1 , 2 , 3 ], dtype = \"float32\" ) array ([ 1. , 2. , 3. ], dtype = float32 )\nkeras . ops . array ([ 1 , 2 , 3 ], dtype = \"float32\" )\narray ([ 1. , 2. , 3. ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cumprod",
    "content": "Return the cumulative product of elements along a given axis.\nMain aliases tf.keras.ops.numpy.cumprod\ntf.keras.ops.numpy.cumprod\ntf.keras.ops.numpy.cumprod\ntf . keras . ops . cumprod ( x , axis = None , dtype = None )\ntf . keras . ops . cumprod ( x , axis = None , dtype = None )\nArgs\nArgs\nx Input tensor. axis Axis along which the cumulative product is computed.\nBy default the input is flattened. dtype dtype of returned tensor. Defaults to x.dtype.\nx\naxis\ndtype\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data",
    "content": "Loads the CIFAR10 dataset.\ntf . keras . datasets . cifar10 . load_data ()\ntf . keras . datasets . cifar10 . load_data ()\nUsed in the notebooks\nWorking with preprocessing layers\nConvolutional Neural Network (CNN)\nThis is a dataset of 50,000 32x32 color training images and 10,000 test\nimages, labeled over 10 categories. See more info at the CIFAR homepage .\nReturns Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train : uint8 NumPy array of grayscale image data with shapes (50000, 32, 32, 3) , containing the training data. Pixel values range\n  from 0 to 255.\nx_train\nuint8\n(50000, 32, 32, 3)\ny_train : uint8 NumPy array of labels (integers in range 0-9)\n  with shape (50000, 1) for the training data.\ny_train\nuint8\n(50000, 1)\nx_test : uint8 NumPy array of grayscale image data with shapes (10000, 32, 32, 3) , containing the test data. Pixel values range\n  from 0 to 255.\nx_test\nuint8\n(10000, 32, 32, 3)\ny_test : uint8 NumPy array of labels (integers in range 0-9)\n  with shape (10000, 1) for the test data.\ny_test\nuint8\n(10000, 1)\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . cifar10 . load_data () assert x_train . shape == ( 50000 , 32 , 32 , 3 ) assert x_test . shape == ( 10000 , 32 , 32 , 3 ) assert y_train . shape == ( 50000 , 1 ) assert y_test . shape == ( 10000 , 1 )\n( x_train , y_train ), ( x_test , y_test ) = keras . datasets . cifar10 . load_data () assert x_train . shape == ( 50000 , 32 , 32 , 3 ) assert x_test . shape == ( 10000 , 32 , 32 , 3 ) assert y_train . shape == ( 50000 , 1 ) assert y_test . shape == ( 10000 , 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nEfficientNetV2B0(...) : Instantiates the EfficientNetV2B0 architecture.\nEfficientNetV2B0(...)\nEfficientNetV2B1(...) : Instantiates the EfficientNetV2B1 architecture.\nEfficientNetV2B1(...)\nEfficientNetV2B2(...) : Instantiates the EfficientNetV2B2 architecture.\nEfficientNetV2B2(...)\nEfficientNetV2B3(...) : Instantiates the EfficientNetV2B3 architecture.\nEfficientNetV2B3(...)\nEfficientNetV2L(...) : Instantiates the EfficientNetV2L architecture.\nEfficientNetV2L(...)\nEfficientNetV2M(...) : Instantiates the EfficientNetV2M architecture.\nEfficientNetV2M(...)\nEfficientNetV2S(...) : Instantiates the EfficientNetV2S architecture.\nEfficientNetV2S(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : A placeholder method for backward compatibility.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies/QuantizedDTypePolicy",
    "content": "A dtype policy for a Keras layer.\nInherits From: DTypePolicy\nDTypePolicy\ntf . keras . dtype_policies . QuantizedDTypePolicy ( name )\ntf . keras . dtype_policies . QuantizedDTypePolicy ( name )\nA dtype policy determines a layer's computation and variable dtypes. Each\nlayer has a policy. Policies can be passed to the dtype argument of layer\nconstructors, or a global policy can be set with keras.config.set_dtype_policy .\ndtype\nkeras.config.set_dtype_policy\nArgs\nArgs\nname The policy name, which determines the compute and variable dtypes.\nCan be any dtype name, such as \"float32\" or \"float64\" ,\nwhich causes both the compute and variable dtypes\nwill be that dtype.\nCan also be the string \"mixed_float16\" or \"mixed_bfloat16\" ,\nwhich causes the compute dtype to be float16 or bfloat16 and the variable dtype to be float32 .\nname\n\"float32\"\n\"float64\"\n\"mixed_float16\"\n\"mixed_bfloat16\"\nfloat16\nbfloat16\nfloat32\nTypically you only need to interact with dtype policies when using mixed\nprecision, which is the use of float16 or bfloat16 for computations and\nfloat32 for variables. This is why the term mixed_precision appears in the\nAPI name. Mixed precision can be enabled by passing \"mixed_float16\" or \"mixed_bfloat16\" to keras.mixed_precision.set_dtype_policy() .\nmixed_precision\n\"mixed_float16\"\n\"mixed_bfloat16\"\nkeras.mixed_precision.set_dtype_policy()\nkeras . config . set_dtype_policy ( \"mixed_float16\" ) layer1 = keras . layers . Dense ( 10 ) layer1 . dtype_policy # layer1 will automatically use mixed precision < DTypePolicy \"mixed_float16\" > # Can optionally override layer to use float32 # instead of mixed precision. layer2 = keras . layers . Dense ( 10 , dtype = \"float32\" ) layer2 . dtype_policy < DTypePolicy \"float32\" > # Set policy back to initial float32. keras . config . set_dtype_policy ( 'float32' )\nkeras . config . set_dtype_policy ( \"mixed_float16\" )\nlayer1 = keras . layers . Dense ( 10 )\nlayer1 . dtype_policy # layer1 will automatically use mixed precision\n< DTypePolicy \"mixed_float16\" >\n# Can optionally override layer to use float32\n# instead of mixed precision.\nlayer2 = keras . layers . Dense ( 10 , dtype = \"float32\" )\nlayer2 . dtype_policy\n< DTypePolicy \"float32\" >\n# Set policy back to initial float32.\nkeras . config . set_dtype_policy ( 'float32' )\nIn the example above, passing dtype=\"float32\" to the layer is\nequivalent to passing dtype=keras.config.DTypePolicy(\"float32\") .\nIn general, passing a dtype policy name to a layer is equivalent\nto passing the corresponding policy, so it is never necessary\nto explicitly construct a DTypePolicy object.\ndtype=\"float32\"\ndtype=keras.config.DTypePolicy(\"float32\")\nDTypePolicy\nAttributes\nAttributes\ncompute_dtype The compute dtype of this policy.\ncompute_dtype\nThis is the dtype layers will do their computations in. Typically layers\noutput tensors with the compute dtype as well.\nNote that even if the compute dtype is float16 or bfloat16, hardware\ndevices may not do individual adds, multiplies, and other fundamental\noperations in float16 or bfloat16, but instead may do some of them in\nfloat32 for numeric stability. The compute dtype is the dtype of the\ninputs and outputs of the ops that the layer executes.\nInternally, many ops will do certain internal calculations in\nfloat32 or some other device-internal intermediate format with higher\nprecision than float16/bfloat16, to increase numeric stability. name Returns the name of this policy. quantization_mode The quantization mode of this policy. variable_dtype The variable dtype of this policy.\nname\nquantization_mode\nvariable_dtype\nThis is the dtype layers will create their variables in, unless a layer\nexplicitly chooses a different dtype. If this is different than DTypePolicy.compute_dtype , Layers will cast variables to\nthe compute dtype to avoid type errors.\nDTypePolicy.compute_dtype\nVariable regularizers are run in the variable dtype, not the compute\ndtype.\nMethods\nconvert_input\nconvert_input\nView source\nconvert_input ( x , autocast , dtype )\nconvert_input ( x , autocast , dtype )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate",
    "content": "Functional interface to the Concatenate layer.\nConcatenate\ntf . keras . layers . concatenate ( inputs , axis =- 1 , ** kwargs )\ntf . keras . layers . concatenate ( inputs , axis =- 1 , ** kwargs )\nUsed in the notebooks\npix2pix: Image-to-image translation with a conditional GAN\nClassify structured data using Keras preprocessing layers\nStreaming structured data from Elasticsearch using Tensorflow-IO\nTensorflow datasets from MongoDB collections\nQuantum Convolutional Neural Network\nArgs\nArgs\ninputs A list of input tensors. axis Concatenation axis. **kwargs Standard layer keyword arguments.\ninputs\naxis\n**kwargs\nReturns A tensor, the concatenation of the inputs alongside axis axis .\nReturns\naxis"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_rotation",
    "content": "DEPRECATED.\ntf . keras . preprocessing . image . random_rotation ( x , rg , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )\ntf . keras . preprocessing . image . random_rotation ( x , rg , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/get_value",
    "content": "DEPRECATED.\ntf . keras . backend . get_value ( x )\ntf . keras . backend . get_value ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/is_keras_tensor",
    "content": "Returns whether x is a Keras tensor.\nx\nMain aliases tf.keras.utils.is_keras_tensor\ntf.keras.utils.is_keras_tensor\ntf.keras.utils.is_keras_tensor\ntf . keras . backend . is_keras_tensor ( x )\ntf . keras . backend . is_keras_tensor ( x )\nA \"Keras tensor\" is a symbolic tensor , such as a tensor\nthat was created via Input() . A \"symbolic tensor\"\ncan be understood as a placeholder -- it does not\ncontain any actual numerical data, only a shape and dtype.\nIt can be used for building Functional models, but it\ncannot be used in actual computations.\nInput()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nabs(...) : DEPRECATED.\nabs(...)\nall(...) : DEPRECATED.\nall(...)\nany(...) : DEPRECATED.\nany(...)\narange(...) : DEPRECATED.\narange(...)\nargmax(...) : DEPRECATED.\nargmax(...)\nargmin(...) : DEPRECATED.\nargmin(...)\nbackend(...) : Publicly accessible method for determining the current backend.\nbackend(...)\nbatch_dot(...) : DEPRECATED.\nbatch_dot(...)\nbatch_flatten(...) : DEPRECATED.\nbatch_flatten(...)\nbatch_get_value(...) : DEPRECATED.\nbatch_get_value(...)\nbatch_normalization(...) : DEPRECATED.\nbatch_normalization(...)\nbatch_set_value(...) : DEPRECATED.\nbatch_set_value(...)\nbias_add(...) : DEPRECATED.\nbias_add(...)\nbinary_crossentropy(...) : DEPRECATED.\nbinary_crossentropy(...)\nbinary_focal_crossentropy(...) : DEPRECATED.\nbinary_focal_crossentropy(...)\ncast(...) : DEPRECATED.\ncast(...)\ncast_to_floatx(...) : DEPRECATED.\ncast_to_floatx(...)\ncategorical_crossentropy(...) : DEPRECATED.\ncategorical_crossentropy(...)\ncategorical_focal_crossentropy(...) : DEPRECATED.\ncategorical_focal_crossentropy(...)\nclear_session(...) : Resets all state generated by Keras.\nclear_session(...)\nclip(...) : DEPRECATED.\nclip(...)\nconcatenate(...) : DEPRECATED.\nconcatenate(...)\nconstant(...) : DEPRECATED.\nconstant(...)\nconv1d(...) : DEPRECATED.\nconv1d(...)\nconv2d(...) : DEPRECATED.\nconv2d(...)\nconv2d_transpose(...) : DEPRECATED.\nconv2d_transpose(...)\nconv3d(...) : DEPRECATED.\nconv3d(...)\ncos(...) : DEPRECATED.\ncos(...)\ncount_params(...) : DEPRECATED.\ncount_params(...)\nctc_batch_cost(...) : DEPRECATED.\nctc_batch_cost(...)\nctc_decode(...) : DEPRECATED.\nctc_decode(...)\nctc_label_dense_to_sparse(...) : DEPRECATED.\nctc_label_dense_to_sparse(...)\ncumprod(...) : DEPRECATED.\ncumprod(...)\ncumsum(...) : DEPRECATED.\ncumsum(...)\ndepthwise_conv2d(...) : DEPRECATED.\ndepthwise_conv2d(...)\ndot(...) : DEPRECATED.\ndot(...)\ndropout(...) : DEPRECATED.\ndropout(...)\ndtype(...) : DEPRECATED.\ndtype(...)\nelu(...) : DEPRECATED.\nelu(...)\nepsilon(...) : Return the value of the fuzz factor used in numeric expressions.\nepsilon(...)\nequal(...) : DEPRECATED.\nequal(...)\neval(...) : DEPRECATED.\neval(...)\nexp(...) : DEPRECATED.\nexp(...)\nexpand_dims(...) : DEPRECATED.\nexpand_dims(...)\neye(...) : DEPRECATED.\neye(...)\nflatten(...) : DEPRECATED.\nflatten(...)\nfloatx(...) : Return the default float type, as a string.\nfloatx(...)\nfoldl(...) : DEPRECATED.\nfoldl(...)\nfoldr(...) : DEPRECATED.\nfoldr(...)\ngather(...) : DEPRECATED.\ngather(...)\nget_uid(...) : Associates a string prefix with an integer counter.\nget_uid(...)\nget_value(...) : DEPRECATED.\nget_value(...)\ngradients(...) : DEPRECATED.\ngradients(...)\ngreater(...) : DEPRECATED.\ngreater(...)\ngreater_equal(...) : DEPRECATED.\ngreater_equal(...)\nhard_sigmoid(...) : DEPRECATED.\nhard_sigmoid(...)\nimage_data_format(...) : Return the default image data format convention.\nimage_data_format(...)\nin_top_k(...) : DEPRECATED.\nin_top_k(...)\nint_shape(...) : DEPRECATED.\nint_shape(...)\nis_float_dtype(...)\nis_float_dtype(...)\nis_int_dtype(...)\nis_int_dtype(...)\nis_keras_tensor(...) : Returns whether x is a Keras tensor.\nis_keras_tensor(...)\nx\nis_sparse(...) : DEPRECATED.\nis_sparse(...)\nl2_normalize(...) : DEPRECATED.\nl2_normalize(...)\nless(...) : DEPRECATED.\nless(...)\nless_equal(...) : DEPRECATED.\nless_equal(...)\nlog(...) : DEPRECATED.\nlog(...)\nmap_fn(...) : DEPRECATED.\nmap_fn(...)\nmax(...) : DEPRECATED.\nmax(...)\nmaximum(...) : DEPRECATED.\nmaximum(...)\nmean(...) : DEPRECATED.\nmean(...)\nmin(...) : DEPRECATED.\nmin(...)\nminimum(...) : DEPRECATED.\nminimum(...)\nmoving_average_update(...) : DEPRECATED.\nmoving_average_update(...)\nname_scope(...) : DEPRECATED.\nname_scope(...)\nndim(...) : DEPRECATED.\nndim(...)\nnot_equal(...) : DEPRECATED.\nnot_equal(...)\none_hot(...) : DEPRECATED.\none_hot(...)\nones(...) : DEPRECATED.\nones(...)\nones_like(...) : DEPRECATED.\nones_like(...)\npermute_dimensions(...) : DEPRECATED.\npermute_dimensions(...)\npool2d(...) : DEPRECATED.\npool2d(...)\npool3d(...) : DEPRECATED.\npool3d(...)\npow(...) : DEPRECATED.\npow(...)\nprod(...) : DEPRECATED.\nprod(...)\nrandom_bernoulli(...) : DEPRECATED.\nrandom_bernoulli(...)\nrandom_normal(...) : DEPRECATED.\nrandom_normal(...)\nrandom_normal_variable(...) : DEPRECATED.\nrandom_normal_variable(...)\nrandom_uniform(...) : DEPRECATED.\nrandom_uniform(...)\nrandom_uniform_variable(...) : DEPRECATED.\nrandom_uniform_variable(...)\nrelu(...) : DEPRECATED.\nrelu(...)\nrepeat(...) : DEPRECATED.\nrepeat(...)\nrepeat_elements(...) : DEPRECATED.\nrepeat_elements(...)\nreshape(...) : DEPRECATED.\nreshape(...)\nresize_images(...) : DEPRECATED.\nresize_images(...)\nresize_volumes(...) : DEPRECATED.\nresize_volumes(...)\nresult_type(...) : Returns the type from applying the Keras type promotion rules.\nresult_type(...)\nreverse(...) : DEPRECATED.\nreverse(...)\nrnn(...) : DEPRECATED.\nrnn(...)\nround(...) : DEPRECATED.\nround(...)\nseparable_conv2d(...) : DEPRECATED.\nseparable_conv2d(...)\nset_epsilon(...) : Set the value of the fuzz factor used in numeric expressions.\nset_epsilon(...)\nset_floatx(...) : Set the default float dtype.\nset_floatx(...)\nset_image_data_format(...) : Set the value of the image data format convention.\nset_image_data_format(...)\nset_value(...) : DEPRECATED.\nset_value(...)\nshape(...) : DEPRECATED.\nshape(...)\nsigmoid(...) : DEPRECATED.\nsigmoid(...)\nsign(...) : DEPRECATED.\nsign(...)\nsin(...) : DEPRECATED.\nsin(...)\nsoftmax(...) : DEPRECATED.\nsoftmax(...)\nsoftplus(...) : DEPRECATED.\nsoftplus(...)\nsoftsign(...) : DEPRECATED.\nsoftsign(...)\nsparse_categorical_crossentropy(...) : DEPRECATED.\nsparse_categorical_crossentropy(...)\nspatial_2d_padding(...) : DEPRECATED.\nspatial_2d_padding(...)\nspatial_3d_padding(...) : DEPRECATED.\nspatial_3d_padding(...)\nsqrt(...) : DEPRECATED.\nsqrt(...)\nsquare(...) : DEPRECATED.\nsquare(...)\nsqueeze(...) : DEPRECATED.\nsqueeze(...)\nstack(...) : DEPRECATED.\nstack(...)\nstandardize_dtype(...)\nstandardize_dtype(...)\nstd(...) : DEPRECATED.\nstd(...)\nstop_gradient(...) : DEPRECATED.\nstop_gradient(...)\nsum(...) : DEPRECATED.\nsum(...)\nswitch(...) : DEPRECATED.\nswitch(...)\ntanh(...) : DEPRECATED.\ntanh(...)\ntemporal_padding(...) : DEPRECATED.\ntemporal_padding(...)\ntile(...) : DEPRECATED.\ntile(...)\nto_dense(...) : DEPRECATED.\nto_dense(...)\ntranspose(...) : DEPRECATED.\ntranspose(...)\ntruncated_normal(...) : DEPRECATED.\ntruncated_normal(...)\nupdate(...) : DEPRECATED.\nupdate(...)\nupdate_add(...) : DEPRECATED.\nupdate_add(...)\nupdate_sub(...) : DEPRECATED.\nupdate_sub(...)\nvar(...) : DEPRECATED.\nvar(...)\nvariable(...) : DEPRECATED.\nvariable(...)\nzeros(...) : DEPRECATED.\nzeros(...)\nzeros_like(...) : DEPRECATED.\nzeros_like(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/convnext/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . convnext . decode_predictions ( preds , top = 5 )\ntf . keras . applications . convnext . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arctan2",
    "content": "Element-wise arc tangent of x1/x2 choosing the quadrant correctly.\nx1/x2\nMain aliases tf.keras.ops.numpy.arctan2\ntf.keras.ops.numpy.arctan2\ntf.keras.ops.numpy.arctan2\ntf . keras . ops . arctan2 ( x1 , x2 )\ntf . keras . ops . arctan2 ( x1 , x2 )\nThe quadrant (i.e., branch) is chosen so that arctan2(x1, x2) is the\nsigned angle in radians between the ray ending at the origin and passing\nthrough the point (1, 0) , and the ray ending at the origin and passing\nthrough the point (x2, x1) . (Note the role reversal: the \"y-coordinate\"\nis the first function parameter, the \"x-coordinate\" is the second.) By IEEE\nconvention, this function is defined for x2 = +/-0 and for either or both\nof x1 and x2 = +/-inf .\narctan2(x1, x2)\n(1, 0)\n(x2, x1)\nx2 = +/-0\nx1\nx2\n= +/-inf\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Tensor of angles in radians, in the range [-pi, pi] .\nReturns\n[-pi, pi]\nConsider four points in different quadrants:\n>>> x = keras . ops . convert_to_tensor ([ - 1 , + 1 , + 1 , - 1 ]) >>> y = keras . ops . convert_to_tensor ([ - 1 , - 1 , + 1 , + 1 ]) >>> keras . ops . arctan2 ( y , x ) * 180 / numpy . pi array ([ - 135. , - 45. , 45. , 135. ], dtype = float32 )\n>>> x = keras . ops . convert_to_tensor ([ - 1 , + 1 , + 1 , - 1 ]) >>> y = keras . ops . convert_to_tensor ([ - 1 , - 1 , + 1 , + 1 ]) >>> keras . ops . arctan2 ( y , x ) * 180 / numpy . pi array ([ - 135. , - 45. , 45. , 135. ], dtype = float32 )\nNote the order of the parameters. arctan2 is defined also when x2=0 and\nat several other points, obtaining values in the range [-pi, pi] :\narctan2\n[-pi, pi]\n>>> keras . ops . arctan2 ( ... keras . ops . array ([ 1. , - 1. ]), ... keras . ops . array ([ 0. , 0. ]), ... ) array ([ 1.5707964 , - 1.5707964 ], dtype = float32 ) >>> keras . ops . arctan2 ( ... keras . ops . array ([ 0. , 0. , numpy . inf ]), ... keras . ops . array ([ + 0. , - 0. , numpy . inf ]), ... ) array ([ 0. , 3.1415925 , 0.7853982 ], dtype = float32 )\n>>> keras . ops . arctan2 ( ... keras . ops . array ([ 1. , - 1. ]), ... keras . ops . array ([ 0. , 0. ]), ... ) array ([ 1.5707964 , - 1.5707964 ], dtype = float32 ) >>> keras . ops . arctan2 ( ... keras . ops . array ([ 0. , 0. , numpy . inf ]), ... keras . ops . array ([ + 0. , - 0. , numpy . inf ]), ... ) array ([ 0. , 3.1415925 , 0.7853982 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/distribute_tensor",
    "content": "Change the layout of a Tensor value in the jit function execution.\ntf . keras . distribution . distribute_tensor ( tensor , layout )\ntf . keras . distribution . distribute_tensor ( tensor , layout )\nArgs\nArgs\ntensor a Tensor to change the layout. layout TensorLayout to be applied on the value.\ntensor\nlayout\nTensorLayout\nReturns a new value with the specified tensor layout.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/permute_dimensions",
    "content": "DEPRECATED.\ntf . keras . backend . permute_dimensions ( x , pattern )\ntf . keras . backend . permute_dimensions ( x , pattern )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator",
    "content": "DEPRECATED.\ntf . keras . preprocessing . image . ImageDataGenerator ( featurewise_center = False , samplewise_center = False , featurewise_std_normalization = False , samplewise_std_normalization = False , zca_whitening = False , zca_epsilon = 1e-06 , rotation_range = 0 , width_shift_range = 0.0 , height_shift_range = 0.0 , brightness_range = None , shear_range = 0.0 , zoom_range = 0.0 , channel_shift_range = 0.0 , fill_mode = 'nearest' , cval = 0.0 , horizontal_flip = False , vertical_flip = False , rescale = None , preprocessing_function = None , data_format = None , validation_split = 0.0 , interpolation_order = 1 , dtype = None )\ntf . keras . preprocessing . image . ImageDataGenerator ( featurewise_center = False , samplewise_center = False , featurewise_std_normalization = False , samplewise_std_normalization = False , zca_whitening = False , zca_epsilon = 1e-06 , rotation_range = 0 , width_shift_range = 0.0 , height_shift_range = 0.0 , brightness_range = None , shear_range = 0.0 , zoom_range = 0.0 , channel_shift_range = 0.0 , fill_mode = 'nearest' , cval = 0.0 , horizontal_flip = False , vertical_flip = False , rescale = None , preprocessing_function = None , data_format = None , validation_split = 0.0 , interpolation_order = 1 , dtype = None )\nUsed in the notebooks\ntf.data: Build TensorFlow input pipelines\nMethods\napply_transform\napply_transform\nView source\napply_transform ( x , transform_parameters )\napply_transform ( x , transform_parameters )\nApplies a transformation to an image according to given parameters.\nArgs\nx 3D tensor, single image. transform_parameters Dictionary with string - parameter pairs\ndescribing the transformation.\nCurrently, the following parameters\nfrom the dictionary are used:\nx\ntransform_parameters\n'theta' : Float. Rotation angle in degrees.\n'theta'\n'tx' : Float. Shift in the x direction.\n'tx'\n'ty' : Float. Shift in the y direction.\n'ty'\n'shear' : Float. Shear angle in degrees.\n'shear'\n'zx' : Float. Zoom in the x direction.\n'zx'\n'zy' : Float. Zoom in the y direction.\n'zy'\n'flip_horizontal' : Boolean. Horizontal flip.\n'flip_horizontal'\n'flip_vertical' : Boolean. Vertical flip.\n'flip_vertical'\n'channel_shift_intensity' : Float. Channel shift intensity.\n'channel_shift_intensity'\n'brightness' : Float. Brightness shift intensity.\n'brightness'\nReturns A transformed version of the input (same shape).\nfit\nfit\nView source\nfit ( x , augment = False , rounds = 1 , seed = None )\nfit ( x , augment = False , rounds = 1 , seed = None )\nFits the data generator to some sample data.\nThis computes the internal data stats related to the\ndata-dependent transformations, based on an array of sample data.\nOnly required if featurewise_center or featurewise_std_normalization or zca_whitening are set to True .\nfeaturewise_center\nfeaturewise_std_normalization\nzca_whitening\nTrue\nWhen rescale is set to a value, rescaling is applied to\nsample data before computing the internal data stats.\nrescale\nArgs\nx Sample data. Should have rank 4.\nIn case of grayscale data,\nthe channels axis should have value 1, in case\nof RGB data, it should have value 3, and in case\nof RGBA data, it should have value 4. augment Boolean (default: False).\nWhether to fit on randomly augmented samples. rounds Int (default: 1).\nIf using data augmentation ( augment=True ),\nthis is how many augmentation passes over the data to use. seed Int (default: None). Random seed.\nx\naugment\nrounds\naugment=True\nseed\nflow\nflow\nView source\nflow ( x , y = None , batch_size = 32 , shuffle = True , sample_weight = None , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , ignore_class_split = False , subset = None )\nflow ( x , y = None , batch_size = 32 , shuffle = True , sample_weight = None , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , ignore_class_split = False , subset = None )\nflow_from_dataframe\nflow_from_dataframe\nView source\nflow_from_dataframe ( dataframe , directory = None , x_col = 'filename' , y_col = 'class' , weight_col = None , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , subset = None , interpolation = 'nearest' , validate_filenames = True , ** kwargs )\nflow_from_dataframe ( dataframe , directory = None , x_col = 'filename' , y_col = 'class' , weight_col = None , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , subset = None , interpolation = 'nearest' , validate_filenames = True , ** kwargs )\nflow_from_directory\nflow_from_directory\nView source\nflow_from_directory ( directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , follow_links = False , subset = None , interpolation = 'nearest' , keep_aspect_ratio = False )\nflow_from_directory ( directory , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , follow_links = False , subset = None , interpolation = 'nearest' , keep_aspect_ratio = False )\nget_random_transform\nget_random_transform\nView source\nget_random_transform ( img_shape , seed = None )\nget_random_transform ( img_shape , seed = None )\nGenerates random parameters for a transformation.\nArgs\nimg_shape Tuple of integers.\nShape of the image that is transformed. seed Random seed.\nimg_shape\nseed\nReturns A dictionary containing randomly chosen parameters describing the\ntransformation.\nrandom_transform\nrandom_transform\nView source\nrandom_transform ( x , seed = None )\nrandom_transform ( x , seed = None )\nApplies a random transformation to an image.\nArgs\nx 3D tensor, single image. seed Random seed.\nx\nseed\nReturns A randomly transformed version of the input (same shape).\nstandardize\nstandardize\nView source\nstandardize ( x )\nstandardize ( x )\nApplies the normalization configuration in-place to a batch of inputs.\nx is changed in-place since the function is mainly used internally\nto standardize images and feed them to your network. If a copy of x would be created instead it would have a significant performance cost.\nIf you want to apply this method without changing the input in-place\nyou can call the method creating a copy before:\nx\nx\nstandardize(np.copy(x))\nArgs\nx Batch of inputs to be normalized.\nx\nReturns The inputs, normalized."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/divide_no_nan",
    "content": "Safe element-wise division which returns 0 where the denominator is 0.\nMain aliases tf.keras.ops.numpy.divide_no_nan\ntf.keras.ops.numpy.divide_no_nan\ntf.keras.ops.numpy.divide_no_nan\ntf . keras . ops . divide_no_nan ( x1 , x2 )\ntf . keras . ops . divide_no_nan ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns The quotient x1/x2 , element-wise, with zero where x2 is zero.\nReturns\nx1/x2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout3D",
    "content": "Spatial 3D version of Dropout.\nInherits From: Dropout , Layer , Operation\nDropout\nLayer\nOperation\ntf . keras . layers . SpatialDropout3D ( rate , data_format = None , seed = None , name = None , dtype = None )\ntf . keras . layers . SpatialDropout3D ( rate , data_format = None , seed = None , name = None , dtype = None )\nThis version performs the same function as Dropout, however, it drops\nentire 3D feature maps instead of individual elements. If adjacent voxels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout3D will help promote independence\nbetween feature maps and should be used instead.\nArgs\nArgs\nrate Float between 0 and 1. Fraction of the input units to drop. data_format \"channels_first\" or \"channels_last\" .\nIn \"channels_first\" mode, the channels dimension (the depth)\nis at index 1, in \"channels_last\" mode is it at index 4.\nIt defaults to the image_data_format value found in your\nKeras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" .\nrate\ndata_format\n\"channels_first\"\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nCall arguments\nCall arguments\ninputs A 5D tensor. training Python boolean indicating whether the layer\nshould behave in training mode (applying dropout)\nor in inference mode (pass-through).\ninputs\ntraining\nInput shape 5D tensor with shape: (samples, channels, dim1, dim2, dim3) if\n    data_format='channels_first'\nor 5D tensor with shape: (samples, dim1, dim2, dim3, channels) if\n    data_format='channels_last'.\nInput shape\n(samples, channels, dim1, dim2, dim3)\n(samples, dim1, dim2, dim3, channels)\nOutput shape: Same as input.\nTompson et al., 2014\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/selu",
    "content": "Scaled Exponential Linear Unit (SELU) activation function.\nMain aliases tf.keras.ops.nn.selu\ntf.keras.ops.nn.selu\ntf.keras.ops.nn.selu\ntf . keras . ops . selu ( x )\ntf . keras . ops . selu ( x )\nf(x) =  scale * alpha * (exp(x) - 1.) for x < 0 , f(x) = scale * x for x >= 0 .\nf(x) =  scale * alpha * (exp(x) - 1.) for x < 0\nf(x) = scale * x for x >= 0\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_selu = keras . ops . selu ( x ) print ( x_selu ) array ([ - 1.11133055 , 0. , 1.05070098 ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_selu = keras . ops . selu ( x )\nprint ( x_selu )\narray ([ - 1.11133055 , 0. , 1.05070098 ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/pad_images",
    "content": "Pad images with zeros to the specified height and width .\nimages\nheight\nwidth\ntf . keras . ops . image . pad_images ( images , top_padding = None , left_padding = None , target_height = None , target_width = None , bottom_padding = None , right_padding = None )\ntf . keras . ops . image . pad_images ( images , top_padding = None , left_padding = None , target_height = None , target_width = None , bottom_padding = None , right_padding = None )\nArgs\nArgs\nimages 4D Tensor of shape (batch, height, width, channels) or 3D\nTensor of shape (height, width, channels) . top_padding Number of rows of zeros to add on top. bottom_padding Number of rows of zeros to add at the bottom. left_padding Number of columns of zeros to add on the left. right_padding Number of columns of zeros to add on the right. target_height Height of output images. target_width Width of output images.\nimages\n(batch, height, width, channels)\n(height, width, channels)\ntop_padding\nbottom_padding\nleft_padding\nright_padding\ntarget_height\ntarget_width\nReturns If images were 4D, a 4D float Tensor of shape (batch, target_height, target_width, channels) If images were 3D, a 3D float Tensor of shape (target_height, target_width, channels)\nReturns\nimages\n(batch, target_height, target_width, channels)\nimages\n(target_height, target_width, channels)\nimages = np . random . random (( 15 , 25 , 3 )) padded_images = keras . ops . image . pad_images ( images , 2 , 3 , target_height = 20 , target_width = 30 ) padded_images . shape ( 20 , 30 , 3 )\nimages = np . random . random (( 15 , 25 , 3 ))\npadded_images = keras . ops . image . pad_images (\nimages , 2 , 3 , target_height = 20 , target_width = 30\n)\npadded_images . shape\n( 20 , 30 , 3 )\nbatch_images = np . random . random (( 2 , 15 , 25 , 3 )) padded_batch = keras . ops . image . pad_images ( batch_images , 2 , 3 , target_height = 20 , target_width = 30 ) padded_batch . shape ( 2 , 20 , 30 , 3 )\nbatch_images = np . random . random (( 2 , 15 , 25 , 3 ))\npadded_batch = keras . ops . image . pad_images (\nbatch_images , 2 , 3 , target_height = 20 , target_width = 30\n)\npadded_batch . shape\n( 2 , 20 , 30 , 3 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/erfinv",
    "content": "Computes the inverse error function of x , element-wise.\nx\ntf . keras . ops . erfinv ( x )\ntf . keras . ops . erfinv ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same dtype as x .\nReturns\nx\nx = np . array ([ - 0.5 , - 0.2 , - 0.1 , 0.0 , 0.3 ]) keras . ops . erfinv ( x ) array ([ - 0.47694 , - 0.17914 , - 0.08886 , 0. , 0.27246 ], dtype = float32 )\nx = np . array ([ - 0.5 , - 0.2 , - 0.1 , 0.0 , 0.3 ])\nkeras . ops . erfinv ( x )\narray ([ - 0.47694 , - 0.17914 , - 0.08886 , 0. , 0.27246 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/vectorized_map",
    "content": "Parallel map of function on axis 0 of tensor(s) elements .\nfunction\nelements\ntf . keras . ops . vectorized_map ( function , elements )\ntf . keras . ops . vectorized_map ( function , elements )\nSchematically, vectorized_map implements the following,\nin the case of a single tensor input elements :\nvectorized_map\nelements\ndef vectorized_map ( function , elements ) outputs = [] for e in elements : outputs . append ( function ( e )) return stack ( outputs )\ndef vectorized_map ( function , elements ) outputs = [] for e in elements : outputs . append ( function ( e )) return stack ( outputs )\nIn the case of an iterable of tensors elements ,\nit implements the following:\nelements\ndef vectorized_map ( function , elements ) batch_size = elements [ 0 ] . shape [ 0 ] outputs = [] for index in range ( batch_size ): outputs . append ( function ([ e [ index ] for e in elements ])) return np . stack ( outputs )\ndef vectorized_map ( function , elements ) batch_size = elements [ 0 ] . shape [ 0 ] outputs = [] for index in range ( batch_size ): outputs . append ( function ([ e [ index ] for e in elements ])) return np . stack ( outputs )\nIn this case, function is expected to take as input\na single list of tensor arguments.\nfunction"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNet",
    "content": "Instantiates the MobileNet architecture.\nMain aliases tf.keras.applications.mobilenet.MobileNet\ntf.keras.applications.mobilenet.MobileNet\ntf.keras.applications.mobilenet.MobileNet\ntf . keras . applications . MobileNet ( input_shape = None , alpha = 1.0 , depth_multiplier = 1 , dropout = 0.001 , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . MobileNet ( input_shape = None , alpha = 1.0 , depth_multiplier = 1 , dropout = 0.001 , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nUsed in the notebooks\nUsing the SavedModel format\nMobileNets: Efficient Convolutional Neural Networks\nfor Mobile Vision Applications\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.mobilenet.preprocess_input\nmobilenet.preprocess_input\nArgs\nArgs\ninput_shape Optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format).\nIt should have exactly 3 inputs channels, and width and\nheight should be no smaller than 32. E.g. (200, 200, 3) would\nbe one valid value. Defaults to None . input_shape will be ignored if the input_tensor is provided. alpha Controls the width of the network. This is known as the width\nmultiplier in the MobileNet paper.\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\nNone\ninput_shape\ninput_tensor\nalpha\nIf alpha < 1.0 , proportionally decreases the number\nof filters in each layer.\nalpha < 1.0\nIf alpha > 1.0 , proportionally increases the number\nof filters in each layer.\nalpha > 1.0\nIf alpha == 1 , default number of filters from the paper\nare used at each layer. Defaults to 1.0 . depth_multiplier Depth multiplier for depthwise convolution.\nThis is called the resolution multiplier in the MobileNet paper.\nDefaults to 1.0 . dropout Dropout rate. Defaults to 0.001 . include_top Boolean, whether to include the fully-connected layer\nat the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights file\nto be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_tensor is useful\nfor sharing inputs between multiple different networks.\nDefaults to None . pooling Optional pooling mode for feature extraction when include_top is False .\nalpha == 1\n1.0\ndepth_multiplier\n1.0\ndropout\n0.001\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_tensor\nNone\npooling\ninclude_top\nFalse\nNone (default) means that the output of the model will be\nthe 4D tensor output of the last convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes Optional number of classes to classify images into,\nonly to be specified if include_top is True , and if\nno weights argument is specified. Defaults to 1000 . classifier_activation A str or callable. The activation function\nto use on the \"top\" layer. Ignored unless include_top=True .\nSet classifier_activation=None to return the logits of the \"top\"\nlayer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D",
    "content": "2D depthwise convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . DepthwiseConv2D ( kernel_size , strides = ( 1 , 1 ), padding = 'valid' , depth_multiplier = 1 , data_format = None , dilation_rate = ( 1 , 1 ), activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . DepthwiseConv2D ( kernel_size , strides = ( 1 , 1 ), padding = 'valid' , depth_multiplier = 1 , data_format = None , dilation_rate = ( 1 , 1 ), activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , bias_constraint = None , ** kwargs )\nUsed in the notebooks\nPruning for on-device inference w/ XNNPACK\nDepthwise convolution is a type of convolution in which each input channel\nis convolved with a different kernel (called a depthwise kernel). You can\nunderstand depthwise convolution as the first step in a depthwise separable\nconvolution.\nIt is implemented via the following steps:\nSplit the input into individual channels.\nConvolve each channel with an individual depthwise kernel with depth_multiplier output channels.\ndepth_multiplier\nConcatenate the convolved outputs along the channels axis.\nUnlike a regular 2D convolution, depthwise convolution does not mix\ninformation across different input channels.\nThe depth_multiplier argument determines how many filters are applied to\none input channel. As such, it controls the amount of output channels that\nare generated per input channel in the depthwise step.\ndepth_multiplier\nArgs\nArgs\nkernel_size int or tuple/list of 2 integer, specifying the size of the\ndepthwise convolution window. strides int or tuple/list of 2 integer, specifying the stride length\nof the depthwise convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. depth_multiplier The number of depthwise convolution output channels\nfor each input channel. The total number of depthwise convolution\noutput channels will be equal to input_channel * depth_multiplier . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file\nat ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 2 integers, specifying the dilation\nrate to use for dilated convolution. activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. depthwise_initializer Initializer for the convolution kernel.\nIf None , the default initializer ( \"glorot_uniform\" )\nwill be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. depthwise_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. depthwise_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndepth_multiplier\ninput_channel * depth_multiplier\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\nNone\nuse_bias\nTrue\ndepthwise_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\ndepthwise_regularizer\nbias_regularizer\nactivity_regularizer\ndepthwise_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, height, width, channels)\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, channels, height, width)\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, new_height, new_width, channels * depth_multiplier)\ndata_format=\"channels_last\"\n(batch_size, new_height, new_width, channels * depth_multiplier)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, channels * depth_multiplier, new_height, new_width)\ndata_format=\"channels_first\"\n(batch_size, channels * depth_multiplier, new_height, new_width)\nReturns A 4D tensor representing activation(depthwise_conv2d(inputs, kernel) + bias) .\nReturns\nactivation(depthwise_conv2d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nx = np . random . rand ( 4 , 10 , 10 , 12 ) y = keras . layers . DepthwiseConv2D ( 3 , 3 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 8 , 8 , 36 )\nx = np . random . rand ( 4 , 10 , 10 , 12 )\ny = keras . layers . DepthwiseConv2D ( 3 , 3 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 8 , 8 , 36 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryIoU",
    "content": "Computes the Intersection-Over-Union metric for class 0 and/or 1.\nInherits From: IoU , Metric\nIoU\nMetric\ntf . keras . metrics . BinaryIoU ( target_class_ids = ( 0 , 1 ), threshold = 0.5 , name = None , dtype = None )\ntf . keras . metrics . BinaryIoU ( target_class_ids = ( 0 , 1 ), threshold = 0.5 , name = None , dtype = None )\niou = true_positives / ( true_positives + false_positives + false_negatives )\niou = true_positives / ( true_positives + false_positives + false_negatives )\nIntersection-Over-Union is a common evaluation metric for semantic image\nsegmentation.\nTo compute IoUs, the predictions are accumulated in a confusion matrix,\nweighted by sample_weight and the metric is then calculated from it.\nsample_weight\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nThis class can be used to compute IoUs for a binary classification task\nwhere the predictions are provided as logits. First a threshold is applied\nto the predicted values such that those that are below the threshold are\nconverted to class 0 and those that are above the threshold are converted\nto class 1.\nthreshold\nthreshold\nthreshold\nIoUs for classes 0 and 1 are then computed, the mean of IoUs for the classes\nthat are specified by target_class_ids is returned.\ntarget_class_ids\nthreshold=0\nIoU\nArgs\nArgs\ntarget_class_ids A tuple or list of target class ids for which the\nmetric is returned. Options are [0] , [1] , or [0, 1] . With [0] (or [1] ), the IoU metric for class 0 (or class 1,\nrespectively) is returned. With [0, 1] , the mean of IoUs for the\ntwo classes is returned. threshold A threshold that applies to the prediction logits to convert\nthem to either predicted class 0 if the logit is below threshold or predicted class 1 if the logit is above threshold . name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\ntarget_class_ids\n[0]\n[1]\n[0, 1]\n[0]\n[1]\n[0, 1]\nthreshold\nthreshold\nthreshold\nname\ndtype\nm = keras . metrics . BinaryIoU ( target_class_ids = [ 0 , 1 ], threshold = 0.3 ) m . update_state ([ 0 , 1 , 0 , 1 ], [ 0.1 , 0.2 , 0.4 , 0.7 ]) m . result () 0.33333334\nm = keras . metrics . BinaryIoU ( target_class_ids = [ 0 , 1 ], threshold = 0.3 )\nm . update_state ([ 0 , 1 , 0 , 1 ], [ 0.1 , 0.2 , 0.4 , 0.7 ])\nm . result ()\n0.33333334\nm . reset_state () m . update_state ([ 0 , 1 , 0 , 1 ], [ 0.1 , 0.2 , 0.4 , 0.7 ], sample_weight = [ 0.2 , 0.3 , 0.4 , 0.1 ]) # cm = [[0.2, 0.4], #        [0.3, 0.1]] # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], # true_positives = [0.2, 0.1] # iou = [0.222, 0.125] m . result () 0.17361112\nm . reset_state ()\nm . update_state ([ 0 , 1 , 0 , 1 ], [ 0.1 , 0.2 , 0.4 , 0.7 ],\nsample_weight = [ 0.2 , 0.3 , 0.4 , 0.1 ])\n# cm = [[0.2, 0.4],\n#        [0.3, 0.1]]\n# sum_row = [0.6, 0.4], sum_col = [0.5, 0.5],\n# true_positives = [0.2, 0.1]\n# iou = [0.222, 0.125]\nm . result ()\n0.17361112\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . BinaryIoU ( target_class_ids = [ 0 ], threshold = 0.5 )] )\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . BinaryIoU ( target_class_ids = [ 0 ], threshold = 0.5 )] )\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the intersection-over-union via the confusion matrix.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the confusion matrix statistics.\nBefore the confusion matrix is updated, the predicted values are\nthresholded to be:\n    0 for values that are smaller than the threshold 1 for values that are larger or equal to the threshold\nthreshold\nthreshold\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same as y_true ,\nand must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionResNetV2",
    "content": "Instantiates the Inception-ResNet v2 architecture.\nMain aliases tf.keras.applications.inception_resnet_v2.InceptionResNetV2\ntf.keras.applications.inception_resnet_v2.InceptionResNetV2\ntf.keras.applications.inception_resnet_v2.InceptionResNetV2\ntf . keras . applications . InceptionResNetV2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . InceptionResNetV2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nInception-v4, Inception-ResNet and the Impact of\nResidual Connections on Learning (AAAI 2017)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.inception_resnet_v2.preprocess_input\ninception_resnet_v2.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (299, 299, 3) (with 'channels_last' data format)\nor (3, 299, 299) (with 'channels_first' data format).\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 75.\nE.g. (150, 150, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(299, 299, 3)\n'channels_last'\n(3, 299, 299)\n'channels_first'\n(150, 150, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional block.\nNone\n'avg' means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\n'avg'\n'max' means that global max pooling will be applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True ,\nand if no weights argument is specified. classifier_activation A str or callable.\nThe activation function to use on the \"top\" layer.\nIgnored unless include_top=True .\nSet classifier_activation=None to return the logits\nof the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\n'max'\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nboston_housing module: DO NOT EDIT.\nboston_housing\ncalifornia_housing module: DO NOT EDIT.\ncalifornia_housing\ncifar10 module: DO NOT EDIT.\ncifar10\ncifar100 module: DO NOT EDIT.\ncifar100\nfashion_mnist module: DO NOT EDIT.\nfashion_mnist\nimdb module: DO NOT EDIT.\nimdb\nmnist module: DO NOT EDIT.\nmnist\nreuters module: DO NOT EDIT.\nreuters"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/variable",
    "content": "DEPRECATED.\ntf . keras . backend . variable ( value , dtype = None , name = None , constraint = None )\ntf . keras . backend . variable ( value , dtype = None , name = None , constraint = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Multiply",
    "content": "Performs elementwise multiplication.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Multiply ( ** kwargs )\ntf . keras . layers . Multiply ( ** kwargs )\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Multiply ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Multiply ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `y = keras.layers.multiply([x1, x2])` y = keras . layers . Multiply ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `y = keras.layers.multiply([x1, x2])`\ny = keras . layers . Multiply ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense",
    "content": "Just your regular densely-connected NN layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , lora_rank = None , ** kwargs )\ntf . keras . layers . Dense ( units , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , lora_rank = None , ** kwargs )\nUsed in the notebooks\nAdvanced automatic differentiation\nDebug a TensorFlow 2 migrated training pipeline\nEffective Tensorflow 2\nMigration examples: Canned Estimators\nMigrate early stopping\nOverfit and underfit\nTime series forecasting\nLoad a pandas DataFrame\nUsing DTensors with Keras\nIntro to Autoencoders\nDense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function\npassed as the activation argument, kernel is a weights matrix\ncreated by the layer, and bias is a bias vector created by the layer\n(only applicable if use_bias is True ).\nDense\noutput = activation(dot(input, kernel) + bias)\nactivation\nactivation\nkernel\nbias\nuse_bias\nTrue\nDense\ninputs\nkernel\ninputs\nkernel\ntf.tensordot\n(batch_size, d0, d1)\nkernel\n(d1, units)\nkernel\ninput\n(1, 1, d1)\nbatch_size * d0\n(batch_size, d0, units)\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use.\nIf you don't specify anything, no activation is applied\n(ie. \"linear\" activation: a(x) = x ). use_bias Boolean, whether the layer uses a bias vector. kernel_initializer Initializer for the kernel weights matrix. bias_initializer Initializer for the bias vector. kernel_regularizer Regularizer function applied to\nthe kernel weights matrix. bias_regularizer Regularizer function applied to the bias vector. activity_regularizer Regularizer function applied to\nthe output of the layer (its \"activation\"). kernel_constraint Constraint function applied to\nthe kernel weights matrix. bias_constraint Constraint function applied to the bias vector. lora_rank Optional integer. If set, the layer's forward pass\nwill implement LoRA (Low-Rank Adaptation)\nwith the provided rank. LoRA sets the layer's kernel\nto non-trainable and replaces it with a delta over the\noriginal kernel, obtained via multiplying two lower-rank\ntrainable matrices. This can be useful to reduce the\ncomputation cost of fine-tuning large dense layers.\nYou can also enable LoRA on an existing Dense layer by calling layer.enable_lora(rank) .\nunits\nactivation\na(x) = x\nuse_bias\nkernel_initializer\nkernel\nbias_initializer\nkernel_regularizer\nkernel\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nkernel\nbias_constraint\nlora_rank\nDense\nlayer.enable_lora(rank)\nInput shape N-D tensor with shape: (batch_size, ..., input_dim) .\nThe most common situation would be\na 2D input with shape (batch_size, input_dim) .\nInput shape\n(batch_size, ..., input_dim)\n(batch_size, input_dim)\nOutput shape N-D tensor with shape: (batch_size, ..., units) .\nFor instance, for a 2D input with shape (batch_size, input_dim) ,\nthe output would have shape (batch_size, units) .\nOutput shape\n(batch_size, ..., units)\n(batch_size, input_dim)\n(batch_size, units)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel\nkernel\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nquantized_build\nquantized_build\nView source\nquantized_build ( input_shape , mode )\nquantized_build ( input_shape , mode )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nClass Variables\nClass Variables\nQUANTIZATION_MODE_ERROR_TEMPLATE (\"Invalid quantization mode. Expected one of ('int8', 'float8'). Received: \"\n 'quantization_mode={mode}')\n(\"Invalid quantization mode. Expected one of ('int8', 'float8'). Received: \"\n 'quantization_mode={mode}')"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4",
    "content": "Instantiates the EfficientNetB4 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB4\ntf.keras.applications.efficientnet.EfficientNetB4\ntf.keras.applications.efficientnet.EfficientNetB4\ntf . keras . applications . EfficientNetB4 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB4 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/hard_sigmoid",
    "content": "DEPRECATED.\ntf . keras . backend . hard_sigmoid ( x )\ntf . keras . backend . hard_sigmoid ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/SwapEMAWeights",
    "content": "Swaps model weights and EMA weights before and after evaluation.\nInherits From: Callback\nCallback\ntf . keras . callbacks . SwapEMAWeights ( swap_on_epoch = False )\ntf . keras . callbacks . SwapEMAWeights ( swap_on_epoch = False )\nThis callbacks replaces the model's weight values with the values of\nthe optimizer's EMA weights (the exponential moving average of the past\nmodel weights values, implementing \"Polyak averaging\") before model\nevaluation, and restores the previous weights after evaluation.\nThe SwapEMAWeights callback is to be used in conjunction with\nan optimizer that sets use_ema=True .\nSwapEMAWeights\nuse_ema=True\nNote that the weights are swapped in-place in order to save memory.\nThe behavior is undefined if you modify the EMA weights\nor model weights in other callbacks.\n# Remember to set `use_ema=True` in the optimizer optimizer = SGD ( use_ema = True ) model . compile ( optimizer = optimizer , loss =... , metrics =... ) # Metrics will be computed with EMA weights model . fit ( X_train , Y_train , callbacks = [ SwapEMAWeights ()]) # If you want to save model checkpoint with EMA weights, you can set # `swap_on_epoch=True` and place ModelCheckpoint after SwapEMAWeights. model . fit ( X_train , Y_train , callbacks = [ SwapEMAWeights ( swap_on_epoch = True ), ModelCheckpoint ( ... )] )\n# Remember to set `use_ema=True` in the optimizer optimizer = SGD ( use_ema = True ) model . compile ( optimizer = optimizer , loss =... , metrics =... ) # Metrics will be computed with EMA weights model . fit ( X_train , Y_train , callbacks = [ SwapEMAWeights ()]) # If you want to save model checkpoint with EMA weights, you can set # `swap_on_epoch=True` and place ModelCheckpoint after SwapEMAWeights. model . fit ( X_train , Y_train , callbacks = [ SwapEMAWeights ( swap_on_epoch = True ), ModelCheckpoint ( ... )] )\nArgs\nArgs\nswap_on_epoch whether to perform swapping at on_epoch_begin() and on_epoch_end() . This is useful if you want to use\nEMA weights for other callbacks such as ModelCheckpoint .\nDefaults to False .\nswap_on_epoch\non_epoch_begin()\non_epoch_end()\nModelCheckpoint\nFalse\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalHinge",
    "content": "Computes the categorical hinge loss between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . CategoricalHinge ( reduction = 'sum_over_batch_size' , name = 'categorical_hinge' )\ntf . keras . losses . CategoricalHinge ( reduction = 'sum_over_batch_size' , name = 'categorical_hinge' )\nloss = maximum ( neg - pos + 1 , 0 )\nloss = maximum ( neg - pos + 1 , 0 )\nwhere neg=maximum((1-y_true)*y_pred) and pos=sum(y_true*y_pred)\nneg=maximum((1-y_true)*y_pred)\npos=sum(y_true*y_pred)\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/elu",
    "content": "DEPRECATED.\ntf . keras . backend . elu ( x , alpha = 1.0 )\ntf . keras . backend . elu ( x , alpha = 1.0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/int_shape",
    "content": "DEPRECATED.\ntf . keras . backend . int_shape ( x )\ntf . keras . backend . int_shape ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SpecificityAtSensitivity",
    "content": "Computes best specificity where sensitivity is >= specified value.\nInherits From: Metric\nMetric\ntf . keras . metrics . SpecificityAtSensitivity ( sensitivity , num_thresholds = 200 , class_id = None , name = None , dtype = None )\ntf . keras . metrics . SpecificityAtSensitivity ( sensitivity , num_thresholds = 200 , class_id = None , name = None , dtype = None )\nSensitivity measures the proportion of actual positives that are correctly\nidentified as such (tp / (tp + fn)) . Specificity measures the proportion of actual negatives that are correctly\nidentified as such (tn / (tn + fp)) .\nSensitivity\n(tp / (tp + fn))\nSpecificity\n(tn / (tn + fp))\nThis metric creates four local variables, true_positives , true_negatives , false_positives and false_negatives that are used to\ncompute the specificity at the given sensitivity. The threshold for the\ngiven sensitivity value is computed and used to evaluate the corresponding\nspecificity.\ntrue_positives\ntrue_negatives\nfalse_positives\nfalse_negatives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf class_id is specified, we calculate precision by considering only the\nentries in the batch for which class_id is above the threshold\npredictions, and computing the fraction of them for which class_id is\nindeed a correct label.\nclass_id\nclass_id\nclass_id\nFor additional information about specificity and sensitivity, see the following .\nArgs\nArgs\nsensitivity A scalar value in range [0, 1] . num_thresholds (Optional) Defaults to 200. The number of thresholds to\nuse for matching the given sensitivity. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nsensitivity\n[0, 1]\nnum_thresholds\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . SpecificityAtSensitivity ( 0.5 ) m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ]) m . result () 0.66666667\nm = keras . metrics . SpecificityAtSensitivity ( 0.5 )\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ])\nm . result ()\n0.66666667\nm . reset_state () m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ], sample_weight = [ 1 , 1 , 2 , 2 , 2 ]) m . result () 0.5\nm . reset_state ()\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ],\nsample_weight = [ 1 , 1 , 2 , 2 , 2 ])\nm . result ()\n0.5\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . SpecificityAtSensitivity ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . SpecificityAtSensitivity ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/vstack",
    "content": "Stack tensors in sequence vertically (row wise).\nMain aliases tf.keras.ops.numpy.vstack\ntf.keras.ops.numpy.vstack\ntf.keras.ops.numpy.vstack\ntf . keras . ops . vstack ( xs )\ntf . keras . ops . vstack ( xs )\nArgs\nArgs\nxs Sequence of tensors.\nxs\nReturns Tensor formed by stacking the given tensors.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/mean",
    "content": "Compute the arithmetic mean along the specified axes.\nMain aliases tf.keras.ops.numpy.mean\ntf.keras.ops.numpy.mean\ntf.keras.ops.numpy.mean\ntf . keras . ops . mean ( x , axis = None , keepdims = False )\ntf . keras . ops . mean ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which the means are computed. The default\nis to compute the mean of the flattened tensor. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one.\nx\naxis\nkeepdims\nTrue\nReturns Output tensor containing the mean values.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/separable_conv",
    "content": "General N-D separable convolution.\nMain aliases tf.keras.ops.nn.separable_conv\ntf.keras.ops.nn.separable_conv\ntf.keras.ops.nn.separable_conv\ntf . keras . ops . separable_conv ( inputs , depthwise_kernel , pointwise_kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\ntf . keras . ops . separable_conv ( inputs , depthwise_kernel , pointwise_kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\nThis ops supports 1D and 2D separable convolution. separable_conv is\na depthwise conv followed by a pointwise conv.\nseparable_conv\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . depthwise_kernel Tensor of rank N+2. depthwise_kernel has shape\n[kernel_spatial_shape, num_input_channels, num_channels_multiplier], num_input_channels should match the number of channels in inputs . pointwise_kernel Tensor of rank N+2. pointwise_kernel has shape (*ones_like(kernel_spatial_shape),\nnum_input_channels * num_channels_multiplier, num_output_channels) . strides int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the strides of the convolution along each spatial\ndimension. If strides is int, then every spatial dimension shares\nthe same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) . dilation_rate int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the dilation rate to use for dilated convolution. If dilation_rate is int, then every spatial dimension shares\nthe same dilation_rate .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\ndepthwise_kernel\ndepthwise_kernel\nnum_input_channels\ninputs\npointwise_kernel\npointwise_kernel\n(*ones_like(kernel_spatial_shape),\nnum_input_channels * num_channels_multiplier, num_output_channels)\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\ndilation_rate\nlen(inputs_spatial_shape)\ndilation_rate\ndilation_rate\nReturns A tensor of rank N+2, the result of the depthwise conv operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanAbsolutePercentageError",
    "content": "Computes the mean absolute percentage error between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . MeanAbsolutePercentageError ( reduction = 'sum_over_batch_size' , name = 'mean_absolute_percentage_error' )\ntf . keras . losses . MeanAbsolutePercentageError ( reduction = 'sum_over_batch_size' , name = 'mean_absolute_percentage_error' )\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ))\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ))\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3/preprocess_input",
    "content": "A placeholder method for backward compatibility.\ntf . keras . applications . mobilenet_v3 . preprocess_input ( x , data_format = None )\ntf . keras . applications . mobilenet_v3 . preprocess_input ( x , data_format = None )\nThe preprocessing logic has been included in the mobilenet_v3 model\nimplementation. Users are no longer required to call this method to\nnormalize the input data. This method does nothing and only kept as a\nplaceholder to align the API surface between old and new version of model.\nArgs\nArgs\nx A floating point numpy.array or a tensor. data_format Optional data format of the image tensor/array. None means the global setting keras.config.image_data_format() is used\n(unless you changed it, it uses \"channels_last\" ).\nDefaults to None .\nx\nnumpy.array\ndata_format\nNone\nkeras.config.image_data_format()\n\"channels_last\"\nNone\nReturns Unchanged numpy.array or tensor.\nReturns\nnumpy.array"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/expand_dims",
    "content": "Expand the shape of a tensor.\nMain aliases tf.keras.ops.numpy.expand_dims\ntf.keras.ops.numpy.expand_dims\ntf.keras.ops.numpy.expand_dims\ntf . keras . ops . expand_dims ( x , axis )\ntf . keras . ops . expand_dims ( x , axis )\nInsert a new axis at the axis position in the expanded tensor shape.\naxis\nArgs\nArgs\nx Input tensor. axis Position in the expanded axes where the new axis\n(or axes) is placed.\nx\naxis\nReturns Output tensor with the number of dimensions increased.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/reshape",
    "content": "Gives a new shape to a tensor without changing its data.\nMain aliases tf.keras.ops.numpy.reshape\ntf.keras.ops.numpy.reshape\ntf.keras.ops.numpy.reshape\ntf . keras . ops . reshape ( x , newshape )\ntf . keras . ops . reshape ( x , newshape )\nArgs\nArgs\nx Input tensor. newshape The new shape should be compatible with the original shape.\nOne shape dimension can be -1 in which case the value is\ninferred from the length of the array and remaining dimensions.\nx\nnewshape\nReturns The reshaped tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass DataParallel : Distribution for data parallelism.\nclass DataParallel\nclass DeviceMesh : A cluster of computation devices for distributed computation.\nclass DeviceMesh\nclass LayoutMap : A dict-like object that maps string to TensorLayout instances.\nclass LayoutMap\nTensorLayout\nclass ModelParallel : Distribution that shards model variables.\nclass ModelParallel\nclass TensorLayout : A layout to apply to a tensor.\nclass TensorLayout\nFunctions\ndistribute_tensor(...) : Change the layout of a Tensor value in the jit function execution.\ndistribute_tensor(...)\ndistribution(...) : Retrieve the current distribution from global context.\ndistribution(...)\ninitialize(...) : Initialize the distribution system for multi-host/process setting.\ninitialize(...)\nlist_devices(...) : Return all the available devices based on the device type.\nlist_devices(...)\nset_distribution(...) : Set the distribution as the global distribution setting.\nset_distribution(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy",
    "content": "Computes the categorical crossentropy loss.\nMain aliases tf.keras.metrics.categorical_crossentropy\ntf.keras.metrics.categorical_crossentropy\ntf.keras.metrics.categorical_crossentropy\ntf . keras . losses . categorical_crossentropy ( y_true , y_pred , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\ntf . keras . losses . categorical_crossentropy ( y_true , y_pred , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\nArgs\nArgs\ny_true Tensor of one-hot true targets. y_pred Tensor of predicted targets. from_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. label_smoothing Float in [0, 1]. If > 0 then smooth the labels. For\nexample, if 0.1 , use 0.1 / num_classes for non-target labels\nand 0.9 + 0.1 / num_classes for target labels. axis Defaults to -1 . The dimension along which the entropy is\ncomputed.\ny_true\ny_pred\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\n0\n0.1\n0.1 / num_classes\n0.9 + 0.1 / num_classes\naxis\n-1\nReturns Categorical crossentropy loss value.\nReturns\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] loss = keras . losses . categorical_crossentropy ( y_true , y_pred ) assert loss . shape == ( 2 ,) loss array ([ 0.0513 , 2.303 ], dtype = float32 )\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]\ny_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]\nloss = keras . losses . categorical_crossentropy ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\nloss\narray ([ 0.0513 , 2.303 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B1",
    "content": "Instantiates the EfficientNetV2B1 architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2B1\ntf.keras.applications.efficientnet_v2.EfficientNetV2B1\ntf.keras.applications.efficientnet_v2.EfficientNetV2B1\ntf . keras . applications . EfficientNetV2B1 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2B1 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/mean",
    "content": "DEPRECATED.\ntf . keras . backend . mean ( x , axis = None , keepdims = False )\ntf . keras . backend . mean ( x , axis = None , keepdims = False )\nUsed in the notebooks\nQuantum Convolutional Neural Network"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping",
    "content": "Stop training when a monitored metric has stopped improving.\nInherits From: Callback\nCallback\ntf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , min_delta = 0 , patience = 0 , verbose = 0 , mode = 'auto' , baseline = None , restore_best_weights = False , start_from_epoch = 0 )\ntf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , min_delta = 0 , patience = 0 , verbose = 0 , mode = 'auto' , baseline = None , restore_best_weights = False , start_from_epoch = 0 )\nUsed in the notebooks\nMigrate early stopping\nGenerate music with an RNN\nSimple audio recognition: Recognizing keywords\nTransfer learning with YAMNet for environmental sound classification\nIntroduction to the Keras Tuner\nOverfit and underfit\nAssuming the goal of a training is to minimize the loss. With this, the\nmetric to be monitored would be 'loss' , and mode would be 'min' . A model.fit() training loop will check at end of every epoch whether\nthe loss is no longer decreasing, considering the min_delta and patience if applicable. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.\n'loss'\n'min'\nmodel.fit()\nmin_delta\npatience\nmodel.stop_training\nThe quantity to be monitored needs to be available in logs dict.\nTo make it so, pass the loss or metrics at model.compile() .\nlogs\nmodel.compile()\nArgs\nArgs\nmonitor Quantity to be monitored. Defaults to \"val_loss\" . min_delta Minimum change in the monitored quantity to qualify as an\nimprovement, i.e. an absolute change of less than min_delta, will\ncount as no improvement. Defaults to 0 . patience Number of epochs with no improvement after which training will\nbe stopped. Defaults to 0 . verbose Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays\nmessages when the callback takes an action. Defaults to 0 . mode One of {\"auto\", \"min\", \"max\"} . In min mode, training will stop\nwhen the quantity monitored has stopped decreasing; in \"max\" mode\nit will stop when the quantity monitored has stopped increasing; in \"auto\" mode, the direction is automatically inferred from the name\nof the monitored quantity. Defaults to \"auto\" . baseline Baseline value for the monitored quantity. If not None ,\ntraining will stop if the model doesn't show improvement over the\nbaseline. Defaults to None . restore_best_weights Whether to restore model weights from the epoch\nwith the best value of the monitored quantity. If False , the model\nweights obtained at the last step of training are used. An epoch\nwill be restored regardless of the performance relative to the baseline . If no epoch improves on baseline , training will run\nfor patience epochs and restore weights from the best epoch in\nthat set. Defaults to False . start_from_epoch Number of epochs to wait before starting to monitor\nimprovement. This allows for a warm-up period in which no\nimprovement is expected and thus training will not be stopped.\nDefaults to 0 .\nmonitor\n\"val_loss\"\nmin_delta\n0\npatience\n0\nverbose\n0\nmode\n{\"auto\", \"min\", \"max\"}\nmin\n\"max\"\n\"auto\"\n\"auto\"\nbaseline\nNone\nNone\nrestore_best_weights\nFalse\nbaseline\nbaseline\npatience\nFalse\nstart_from_epoch\n0\ncallback = keras . callbacks . EarlyStopping ( monitor = 'loss' , patience = 3 ) # This callback will stop the training when there is no improvement in # the loss for three consecutive epochs. model = keras . models . Sequential ([ keras . layers . Dense ( 10 )]) model . compile ( keras . optimizers . SGD (), loss = 'mse' ) history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 0 ) len ( history . history [ 'loss' ]) # Only 4 epochs are run. 4\ncallback = keras . callbacks . EarlyStopping ( monitor = 'loss' ,\npatience = 3 )\n# This callback will stop the training when there is no improvement in\n# the loss for three consecutive epochs.\nmodel = keras . models . Sequential ([ keras . layers . Dense ( 10 )])\nmodel . compile ( keras . optimizers . SGD (), loss = 'mse' )\nhistory = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ),\nepochs = 10 , batch_size = 1 , callbacks = [ callback ],\nverbose = 0 )\nlen ( history . history [ 'loss' ]) # Only 4 epochs are run.\n4\nAttributes\nAttributes\nmodel\nmodel\nMethods\nget_monitor_value\nget_monitor_value\nView source\nget_monitor_value ( logs )\nget_monitor_value ( logs )\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError",
    "content": "Computes the mean of squares of errors between labels and predictions.\nInherits From: Loss\nLoss\ntf . keras . losses . MeanSquaredError ( reduction = 'sum_over_batch_size' , name = 'mean_squared_error' )\ntf . keras . losses . MeanSquaredError ( reduction = 'sum_over_batch_size' , name = 'mean_squared_error' )\nUsed in the notebooks\nTime series forecasting\nIntro to Autoencoders\nLoad CSV data\nHello, many worlds\nRecommending movies: ranking\nloss = mean ( square ( y_true - y_pred ))\nloss = mean ( square ( y_true - y_pred ))\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/equal",
    "content": "Returns (x1 == x2) element-wise.\n(x1 == x2)\nMain aliases tf.keras.ops.numpy.equal\ntf.keras.ops.numpy.equal\ntf.keras.ops.numpy.equal\ntf . keras . ops . equal ( x1 , x2 )\ntf . keras . ops . equal ( x1 , x2 )\nArgs\nArgs\nx1 Tensor to compare. x2 Tensor to compare.\nx1\nx2\nReturns Output tensor, element-wise comparison of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_custom_objects",
    "content": "Retrieves a live reference to the global dictionary of custom objects.\ntf . keras . utils . get_custom_objects ()\ntf . keras . utils . get_custom_objects ()\nCustom objects set using custom_object_scope() are not added to the\nglobal dictionary of custom objects, and will not appear in the returned\ndictionary.\ncustom_object_scope()\nget_custom_objects () . clear () get_custom_objects ()[ 'MyObject' ] = MyObject\nget_custom_objects () . clear () get_custom_objects ()[ 'MyObject' ] = MyObject\nReturns Global dictionary mapping registered class names to classes.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten",
    "content": "Flattens the input. Does not affect the batch size.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Flatten ( data_format = None , ** kwargs )\ntf . keras . layers . Flatten ( data_format = None , ** kwargs )\nUsed in the notebooks\nEffective Tensorflow 2\nMigrate early stopping\nUse TF1.x models in TF2 workflows\ntf.data: Build TensorFlow input pipelines\nMigrate checkpoint saving\nImage classification\nScalable model compression\nSimple audio recognition: Recognizing keywords\nCustom training with tf.distribute.Strategy\nUsing DTensors with Keras\n(batch,)\n(batch, 1)\nArgs\nArgs\ndata_format A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, ..., channels) while \"channels_first\" corresponds to\ninputs with shape (batch, channels, ...) .\nWhen unspecified, uses image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json (if exists). Defaults to \"channels_last\" .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, ..., channels)\n\"channels_first\"\n(batch, channels, ...)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nx = keras . Input ( shape = ( 10 , 64 )) y = keras . layers . Flatten ()( x ) y . shape ( None , 640 )\nx = keras . Input ( shape = ( 10 , 64 ))\ny = keras . layers . Flatten ()( x )\ny . shape\n( None , 640 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu6",
    "content": "Relu6 activation function.\ntf . keras . activations . relu6 ( x )\ntf . keras . activations . relu6 ( x )\nIt's the ReLU function, but truncated to a maximum value of 6.\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SquaredHinge",
    "content": "Computes the hinge metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . SquaredHinge ( name = 'squared_hinge' , dtype = None )\ntf . keras . metrics . SquaredHinge ( name = 'squared_hinge' , dtype = None )\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\ny_true\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . SquaredHinge () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]) m . result () 1.86 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]], sample_weight = [ 1 , 0 ]) m . result () 1.46\nm = keras . metrics . SquaredHinge ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]])\nm . result ()\n1.86\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n1.46\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/binary_focal_crossentropy",
    "content": "Computes the binary focal crossentropy loss.\nMain aliases tf.keras.metrics.binary_focal_crossentropy\ntf.keras.metrics.binary_focal_crossentropy\ntf.keras.metrics.binary_focal_crossentropy\ntf . keras . losses . binary_focal_crossentropy ( y_true , y_pred , apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\ntf . keras . losses . binary_focal_crossentropy ( y_true , y_pred , apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 )\nAccording to Lin et al., 2018 , it\nhelps to apply a focal factor to down-weight easy examples and focus more on\nhard examples. By default, the focal tensor is computed as follows:\nfocal_factor = (1 - output) ** gamma for class 1 focal_factor = output ** gamma for class 0\nwhere gamma is a focusing parameter. When gamma = 0, there is no focal\neffect on the binary crossentropy loss.\nfocal_factor = (1 - output) ** gamma\nfocal_factor = output ** gamma\ngamma\ngamma\nIf apply_class_balancing == True , this function also takes into account a\nweight balancing factor for the binary classes 0 and 1 as follows:\napply_class_balancing == True\nweight = alpha for class 1 ( target == 1 ) weight = 1 - alpha for class 0\nwhere alpha is a float in the range of [0, 1] .\nweight = alpha\ntarget == 1\nweight = 1 - alpha\nalpha\n[0, 1]\nArgs\nArgs\ny_true Ground truth values, of shape (batch_size, d0, .. dN) . y_pred The predicted values, of shape (batch_size, d0, .. dN) . apply_class_balancing A bool, whether to apply weight balancing on the\nbinary classes 0 and 1. alpha A weight balancing factor for class 1, default is 0.25 as\nmentioned in the reference. The weight for class 0 is 1.0 - alpha . gamma A focusing parameter, default is 2.0 as mentioned in the\nreference. from_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. label_smoothing Float in [0, 1] . If > 0 then smooth the labels by\nsqueezing them towards 0.5, that is,\nusing 1. - 0.5 * label_smoothing for the target class\nand 0.5 * label_smoothing for the non-target class. axis The axis along which the mean is computed. Defaults to -1 .\ny_true\n(batch_size, d0, .. dN)\ny_pred\n(batch_size, d0, .. dN)\napply_class_balancing\nalpha\n0.25\n1.0 - alpha\ngamma\n2.0\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\n[0, 1]\n0\n1. - 0.5 * label_smoothing\n0.5 * label_smoothing\naxis\n-1\nReturns Binary focal crossentropy loss value\nwith shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = [[ 0 , 1 ], [ 0 , 0 ]] y_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]] loss = keras . losses . binary_focal_crossentropy ( y_true , y_pred , gamma = 2 ) assert loss . shape == ( 2 ,) loss array ([ 0.330 , 0.206 ], dtype = float32 )\ny_true = [[ 0 , 1 ], [ 0 , 0 ]]\ny_pred = [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]\nloss = keras . losses . binary_focal_crossentropy (\ny_true , y_pred , gamma = 2 )\nassert loss . shape == ( 2 ,)\nloss\narray ([ 0.330 , 0.206 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/serialize",
    "content": "Returns the optimizer configuration as a Python dict.\ntf . keras . optimizers . serialize ( optimizer )\ntf . keras . optimizers . serialize ( optimizer )\nArgs\nArgs\noptimizer An Optimizer instance to serialize.\noptimizer\nOptimizer\nReturns Python dict which contains the configuration of the optimizer.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/depthwise_conv",
    "content": "General N-D depthwise convolution.\nMain aliases tf.keras.ops.nn.depthwise_conv\ntf.keras.ops.nn.depthwise_conv\ntf.keras.ops.nn.depthwise_conv\ntf . keras . ops . depthwise_conv ( inputs , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\ntf . keras . ops . depthwise_conv ( inputs , kernel , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 )\nThis ops supports 1D and 2D depthwise convolution.\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . kernel Tensor of rank N+2. kernel has shape\n[kernel_spatial_shape, num_input_channels, num_channels_multiplier], num_input_channels should match the number of channels in inputs . strides int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the strides of the convolution along each spatial\ndimension. If strides is int, then every spatial dimension shares\nthe same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) . dilation_rate int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the dilation rate to use for dilated convolution. If dilation_rate is int, then every spatial dimension shares\nthe same dilation_rate .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\nkernel\nkernel\nnum_input_channels\ninputs\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\ndilation_rate\nlen(inputs_spatial_shape)\ndilation_rate\ndilation_rate\nReturns A tensor of rank N+2, the result of the depthwise conv operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential",
    "content": "Sequential groups a linear stack of layers into a Model .\nSequential\nModel\nInherits From: Model , Layer , Operation\nModel\nLayer\nOperation\nMain aliases tf.keras.models.Sequential Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Sequential\ntf.keras.models.Sequential\ntf.keras.models.Sequential\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Sequential\ntf.compat.v1.keras.Sequential\ntf . keras . Sequential ( layers = None , trainable = True , name = None )\ntf . keras . Sequential ( layers = None , trainable = True , name = None )\nUsed in the notebooks\nDistributed training with TensorFlow\nEffective Tensorflow 2\nExtension types\nMigration examples: Canned Estimators\nMigrate early stopping\nTime series forecasting\nOverfit and underfit\nIntro to Autoencoders\nLoad text\nData augmentation\nmodel = keras . Sequential () model . add ( keras . Input ( shape = ( 16 ,))) model . add ( keras . layers . Dense ( 8 )) # Note that you can also omit the initial `Input`. # In that case the model doesn't have any weights until the first call # to a training/evaluation method (since it isn't yet built): model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 4 )) # model.weights not created yet # Whereas if you specify an `Input`, the model gets built # continuously as you are adding layers: model = keras . Sequential () model . add ( keras . Input ( shape = ( 16 ,))) model . add ( keras . layers . Dense ( 8 )) len ( model . weights ) # Returns \"2\" # When using the delayed-build pattern (no input shape specified), you can # choose to manually build your model by calling # `build(batch_input_shape)`: model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 4 )) model . build (( None , 16 )) len ( model . weights ) # Returns \"4\" # Note that when using the delayed-build pattern (no input shape specified), # the model gets built the first time you call `fit`, `eval`, or `predict`, # or the first time you call the model on some input data. model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 1 )) model . compile ( optimizer = 'sgd' , loss = 'mse' ) # This builds the model for the first time: model . fit ( x , y , batch_size = 32 , epochs = 10 )\nmodel = keras . Sequential () model . add ( keras . Input ( shape = ( 16 ,))) model . add ( keras . layers . Dense ( 8 )) # Note that you can also omit the initial `Input`. # In that case the model doesn't have any weights until the first call # to a training/evaluation method (since it isn't yet built): model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 4 )) # model.weights not created yet # Whereas if you specify an `Input`, the model gets built # continuously as you are adding layers: model = keras . Sequential () model . add ( keras . Input ( shape = ( 16 ,))) model . add ( keras . layers . Dense ( 8 )) len ( model . weights ) # Returns \"2\" # When using the delayed-build pattern (no input shape specified), you can # choose to manually build your model by calling # `build(batch_input_shape)`: model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 4 )) model . build (( None , 16 )) len ( model . weights ) # Returns \"4\" # Note that when using the delayed-build pattern (no input shape specified), # the model gets built the first time you call `fit`, `eval`, or `predict`, # or the first time you call the model on some input data. model = keras . Sequential () model . add ( keras . layers . Dense ( 8 )) model . add ( keras . layers . Dense ( 1 )) model . compile ( optimizer = 'sgd' , loss = 'mse' ) # This builds the model for the first time: model . fit ( x , y , batch_size = 32 , epochs = 10 )\nAttributes\nAttributes\ncompiled_metrics\ncompiled_metrics\ndistribute_reduction_method\ndistribute_reduction_method\ndistribute_strategy\ndistribute_strategy\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. input_shape\ninput_shape\ninputs\ninputs\njit_compile\njit_compile\nlayers\nlayers\nmetrics_names\nmetrics_names\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output_shape\noutput_shape\noutputs\noutputs\nrun_eagerly\nrun_eagerly\nMethods\nadd\nadd\nView source\nadd ( layer , rebuild = True )\nadd ( layer , rebuild = True )\nAdds a layer instance on top of the layer stack.\nArgs\nlayer layer instance.\nlayer\ncompile\ncompile\nView source\ncompile ( optimizer = 'rmsprop' , loss = None , loss_weights = None , metrics = None , weighted_metrics = None , run_eagerly = False , steps_per_execution = 1 , jit_compile = 'auto' , auto_scale_loss = True )\ncompile ( optimizer = 'rmsprop' , loss = None , loss_weights = None , metrics = None , weighted_metrics = None , run_eagerly = False , steps_per_execution = 1 , jit_compile = 'auto' , auto_scale_loss = True )\nConfigures the model for training.\nmodel . compile ( optimizer = keras . optimizers . Adam ( learning_rate = 1e-3 ), loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . BinaryAccuracy (), keras . metrics . FalseNegatives (), ], )\nmodel . compile ( optimizer = keras . optimizers . Adam ( learning_rate = 1e-3 ), loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . BinaryAccuracy (), keras . metrics . FalseNegatives (), ], )\nArgs\noptimizer String (name of optimizer) or optimizer instance. See keras.optimizers . loss Loss function. May be a string (name of loss function), or\na keras.losses.Loss instance. See keras.losses . A\nloss function is any callable with the signature loss = fn(y_true, y_pred) , where y_true are the ground truth\nvalues, and y_pred are the model's predictions. y_true should have shape (batch_size, d0, .. dN) (except in the case of sparse loss functions such as\nsparse categorical crossentropy which expects integer arrays of\nshape (batch_size, d0, .. dN-1) ). y_pred should have shape (batch_size, d0, .. dN) .\nThe loss function should return a float tensor. loss_weights Optional list or dictionary specifying scalar\ncoefficients (Python floats) to weight the loss contributions of\ndifferent model outputs. The loss value that will be minimized\nby the model will then be the weighted sum of all individual\nlosses, weighted by the loss_weights coefficients.  If a list,\nit is expected to have a 1:1 mapping to the model's outputs. If\na dict, it is expected to map output names (strings) to scalar\ncoefficients. metrics List of metrics to be evaluated by the model during\ntraining and testing. Each of this can be a string (name of a\nbuilt-in function), function or a keras.metrics.Metric instance. See keras.metrics . Typically you will use metrics=['accuracy'] . A function is any callable with the\nsignature result = fn(y_true, _pred) . To specify different\nmetrics for different outputs of a multi-output model, you could\nalso pass a dictionary, such as metrics={'a':'accuracy', 'b':['accuracy', 'mse']} .\nYou can also pass a list to specify a metric or a list of\nmetrics for each output, such as metrics=[['accuracy'], ['accuracy', 'mse']] or metrics=['accuracy', ['accuracy', 'mse']] . When you pass\nthe strings 'accuracy' or 'acc', we convert this to one of keras.metrics.BinaryAccuracy , keras.metrics.CategoricalAccuracy , keras.metrics.SparseCategoricalAccuracy based on the\nshapes of the targets and of the model output. A similar\nconversion is done for the strings \"crossentropy\" and \"ce\" as well.\nThe metrics passed here are evaluated without sample weighting;\nif you would like sample weighting to apply, you can specify\nyour metrics via the weighted_metrics argument instead. weighted_metrics List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing. run_eagerly Bool. If True , this model's forward pass\nwill never be compiled. It is recommended to leave this\nas False when training (for best performance),\nand to set it to True when debugging. steps_per_execution Int. The number of batches to run\nduring each a single compiled function call. Running multiple\nbatches inside a single compiled function call can\ngreatly improve performance on TPUs or small models with a large\nPython overhead. At most, one full epoch will be run each\nexecution. If a number larger than the size of the epoch is\npassed, the execution will be truncated to the size of the\nepoch. Note that if steps_per_execution is set to N , Callback.on_batch_begin and Callback.on_batch_end methods\nwill only be called every N batches (i.e. before/after\neach compiled function execution).\nNot supported with the PyTorch backend. jit_compile Bool or \"auto\" . Whether to use XLA compilation when\ncompiling a model. For jax and tensorflow backends, jit_compile=\"auto\" enables XLA compilation if the model\nsupports it, and disabled otherwise.\nFor torch backend, \"auto\" will default to eager\nexecution and jit_compile=True will run with torch.compile with the \"inductor\" backend. auto_scale_loss Bool. If True and the model dtype policy is \"mixed_float16\" , the passed optimizer will be automatically\nwrapped in a LossScaleOptimizer , which will dynamically\nscale the loss to prevent underflow.\noptimizer\nkeras.optimizers\nloss\nkeras.losses.Loss\nkeras.losses\nloss = fn(y_true, y_pred)\ny_true\ny_pred\ny_true\n(batch_size, d0, .. dN)\n(batch_size, d0, .. dN-1)\ny_pred\n(batch_size, d0, .. dN)\nloss_weights\nloss_weights\nmetrics\nkeras.metrics.Metric\nkeras.metrics\nmetrics=['accuracy']\nresult = fn(y_true, _pred)\nmetrics={'a':'accuracy', 'b':['accuracy', 'mse']}\nmetrics=[['accuracy'], ['accuracy', 'mse']]\nmetrics=['accuracy', ['accuracy', 'mse']]\nkeras.metrics.BinaryAccuracy\nkeras.metrics.CategoricalAccuracy\nkeras.metrics.SparseCategoricalAccuracy\n\"crossentropy\"\n\"ce\"\nweighted_metrics\nweighted_metrics\nsample_weight\nclass_weight\nrun_eagerly\nTrue\nFalse\nTrue\nsteps_per_execution\nsteps_per_execution\nN\nCallback.on_batch_begin\nCallback.on_batch_end\nN\njit_compile\n\"auto\"\njax\ntensorflow\njit_compile=\"auto\"\ntorch\n\"auto\"\njit_compile=True\ntorch.compile\n\"inductor\"\nauto_scale_loss\nTrue\n\"mixed_float16\"\nLossScaleOptimizer\ncompile_from_config\ncompile_from_config\nView source\ncompile_from_config ( config )\ncompile_from_config ( config )\nCompiles the model with the information given in config.\nThis method uses the information in the config (optimizer, loss,\nmetrics, etc.) to compile the model.\nArgs\nconfig Dict containing information for compiling the model.\nconfig\ncompiled_loss\ncompiled_loss\nView source\ncompiled_loss ( y , y_pred , sample_weight = None , regularization_losses = None )\ncompiled_loss ( y , y_pred , sample_weight = None , regularization_losses = None )\ncompute_loss\ncompute_loss\nView source\ncompute_loss ( x = None , y = None , y_pred = None , sample_weight = None )\ncompute_loss ( x = None , y = None , y_pred = None , sample_weight = None )\nCompute the total loss, validate it, and return it.\nSubclasses can optionally override this method to provide custom loss\ncomputation logic.\nclass MyModel ( Model ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . loss_tracker = metrics . Mean ( name = 'loss' ) def compute_loss ( self , x , y , y_pred , sample_weight ): loss = ops . means (( y_pred - y ) ** 2 ) loss += ops . sum ( self . losses ) self . loss_tracker . update_state ( loss ) return loss def reset_metrics ( self ): self . loss_tracker . reset_state () @property def metrics ( self ): return [ self . loss_tracker ] inputs = layers . Input ( shape = ( 10 ,), name = 'my_input' ) outputs = layers . Dense ( 10 )( inputs ) model = MyModel ( inputs , outputs ) model . add_loss ( ops . sum ( outputs )) optimizer = SGD () model . compile ( optimizer , loss = 'mse' , steps_per_execution = 10 ) dataset = ... model . fit ( dataset , epochs = 2 , steps_per_epoch = 10 ) print ( f \"Custom loss: { model . loss_tracker . result () } \" )\nclass MyModel ( Model ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . loss_tracker = metrics . Mean ( name = 'loss' ) def compute_loss ( self , x , y , y_pred , sample_weight ): loss = ops . means (( y_pred - y ) ** 2 ) loss += ops . sum ( self . losses ) self . loss_tracker . update_state ( loss ) return loss def reset_metrics ( self ): self . loss_tracker . reset_state () @property def metrics ( self ): return [ self . loss_tracker ] inputs = layers . Input ( shape = ( 10 ,), name = 'my_input' ) outputs = layers . Dense ( 10 )( inputs ) model = MyModel ( inputs , outputs ) model . add_loss ( ops . sum ( outputs )) optimizer = SGD () model . compile ( optimizer , loss = 'mse' , steps_per_execution = 10 ) dataset = ... model . fit ( dataset , epochs = 2 , steps_per_epoch = 10 ) print ( f \"Custom loss: { model . loss_tracker . result () } \" )\nArgs\nx Input data. y Target data. y_pred Predictions returned by the model (output of model(x) ) sample_weight Sample weights for weighting the loss function.\nx\ny\ny_pred\nmodel(x)\nsample_weight\nReturns The total loss as a scalar tensor, or None if no loss results\n(which is the case when called by Model.test_step ).\nNone\nModel.test_step\ncompute_metrics\ncompute_metrics\nView source\ncompute_metrics ( x , y , y_pred , sample_weight = None )\ncompute_metrics ( x , y , y_pred , sample_weight = None )\nUpdate metric states and collect all metrics to be returned.\nSubclasses can optionally override this method to provide custom metric\nupdating and collection logic.\nclass MyModel ( Sequential ): def compute_metrics ( self , x , y , y_pred , sample_weight ): # This super call updates `self.compiled_metrics` and returns # results for all metrics listed in `self.metrics`. metric_results = super () . compute_metrics ( x , y , y_pred , sample_weight ) # Note that `self.custom_metric` is not listed # in `self.metrics`. self . custom_metric . update_state ( x , y , y_pred , sample_weight ) metric_results [ 'metric_name' ] = self . custom_metric . result () return metric_results\nclass MyModel ( Sequential ): def compute_metrics ( self , x , y , y_pred , sample_weight ): # This super call updates `self.compiled_metrics` and returns # results for all metrics listed in `self.metrics`. metric_results = super () . compute_metrics ( x , y , y_pred , sample_weight ) # Note that `self.custom_metric` is not listed # in `self.metrics`. self . custom_metric . update_state ( x , y , y_pred , sample_weight ) metric_results [ 'metric_name' ] = self . custom_metric . result () return metric_results\nArgs\nx Input data. y Target data. y_pred Predictions returned by the model output of model.call(x) . sample_weight Sample weights for weighting the loss function.\nx\ny\ny_pred\nmodel.call(x)\nsample_weight\nReturns A dict containing values that will be passed to keras.callbacks.CallbackList.on_train_batch_end() . Typically,\nthe values of the metrics listed in self.metrics are returned. Example {'loss': 0.2, 'accuracy': 0.7} .\ndict\nkeras.callbacks.CallbackList.on_train_batch_end()\nself.metrics\nExample\n{'loss': 0.2, 'accuracy': 0.7}\nevaluate\nevaluate\nView source\nevaluate ( x = None , y = None , batch_size = None , verbose = 'auto' , sample_weight = None , steps = None , callbacks = None , return_dict = False , ** kwargs )\nevaluate ( x = None , y = None , batch_size = None , verbose = 'auto' , sample_weight = None , steps = None , callbacks = None , return_dict = False , ** kwargs )\nReturns the loss value & metrics values for the model in test mode.\nComputation is done in batches (see the batch_size arg.)\nbatch_size\nArgs\nx Input data. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.\nA tf.data.Dataset . Should return a tuple\nof either (inputs, targets) or (inputs, targets, sample_weights) .\ntf.data.Dataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nA generator or keras.utils.PyDataset returning (inputs, targets) or (inputs, targets, sample_weights) . y Target data. Like the input data x , it could be either NumPy\narray(s) or backend-native tensor(s).\nIf x is a tf.data.Dataset or keras.utils.PyDataset instance, y should not be specified\n(since targets will be obtained from the iterator/dataset). batch_size Integer or None . Number of samples per batch of\ncomputation. If unspecified, batch_size will default to 32. Do\nnot specify the batch_size if your data is in the form of a\ndataset, generators, or keras.utils.PyDataset instances\n(since they generate batches). verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = single line. \"auto\" becomes 1 for most cases.\nNote that the progress bar is not\nparticularly useful when logged to a file, so verbose=2 is\nrecommended when not running interactively\n(e.g. in a production environment). Defaults to \"auto\" . sample_weight Optional NumPy array of weights for the test samples,\nused for weighting the loss function. You can either pass a flat\n(1D) NumPy array with the same length as the input samples\n(1:1 mapping between weights and samples), or in the case of\ntemporal data, you can pass a 2D array with shape (samples,\nsequence_length) , to apply a different weight to every\ntimestep of every sample. This argument is not supported when x is a dataset, instead pass sample weights as the third\nelement of x . steps Integer or None . Total number of steps (batches of samples)\nbefore declaring the evaluation round finished. Ignored with the\ndefault value of None . If x is a tf.data.Dataset and steps is None , evaluation will run until the dataset\nis exhausted. callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during evaluation. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric.\nIf False , they are returned as a list.\nkeras.utils.PyDataset\n(inputs, targets)\n(inputs, targets, sample_weights)\ny\nx\nx\ntf.data.Dataset\nkeras.utils.PyDataset\ny\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nverbose\n\"auto\"\n\"auto\"\nverbose=2\n\"auto\"\nsample_weight\n(samples,\nsequence_length)\nx\nx\nsteps\nNone\nNone\nx\ntf.data.Dataset\nsteps\nNone\ncallbacks\nkeras.callbacks.Callback\nreturn_dict\nTrue\nFalse\nReturns Scalar test loss (if the model has a single output and no metrics)\nor list of scalars (if the model has multiple outputs\nand/or metrics). The attribute model.metrics_names will give you\nthe display labels for the scalar outputs.\nmodel.metrics_names\nexport\nexport\nView source\nexport ( filepath , format = 'tf_saved_model' )\nexport ( filepath , format = 'tf_saved_model' )\nCreate a TF SavedModel artifact for inference.\nThis method lets you export a model to a lightweight SavedModel artifact\nthat contains the model's forward pass only (its call() method)\nand can be served via e.g. TF-Serving. The forward pass is registered\nunder the name serve() (see example below).\ncall()\nserve()\nThe original code of the model (including any custom layers you may\nhave used) is no longer necessary to reload the artifact -- it is\nentirely standalone.\nArgs\nfilepath str or pathlib.Path object. Path where to save\nthe artifact.\nfilepath\nstr\npathlib.Path\n# Create the artifact model . export ( \"path/to/location\" ) # Later, in a different process / environment... reloaded_artifact = tf . saved_model . load ( \"path/to/location\" ) predictions = reloaded_artifact . serve ( input_data )\n# Create the artifact model . export ( \"path/to/location\" ) # Later, in a different process / environment... reloaded_artifact = tf . saved_model . load ( \"path/to/location\" ) predictions = reloaded_artifact . serve ( input_data )\nIf you would like to customize your serving endpoints, you can\nuse the lower-level keras.export.ExportArchive class. The export() method relies on ExportArchive internally.\nkeras.export.ExportArchive\nexport()\nExportArchive\nfit\nfit\nView source\nfit ( x = None , y = None , batch_size = None , epochs = 1 , verbose = 'auto' , callbacks = None , validation_split = 0.0 , validation_data = None , shuffle = True , class_weight = None , sample_weight = None , initial_epoch = 0 , steps_per_epoch = None , validation_steps = None , validation_batch_size = None , validation_freq = 1 )\nfit ( x = None , y = None , batch_size = None , epochs = 1 , verbose = 'auto' , callbacks = None , validation_split = 0.0 , validation_data = None , shuffle = True , class_weight = None , sample_weight = None , initial_epoch = 0 , steps_per_epoch = None , validation_steps = None , validation_batch_size = None , validation_freq = 1 )\nTrains the model for a fixed number of epochs (dataset iterations).\nArgs\nx Input data. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.\nA tf.data.Dataset . Should return a tuple\nof either (inputs, targets) or (inputs, targets, sample_weights) .\ntf.data.Dataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nA keras.utils.PyDataset returning (inputs,\ntargets) or (inputs, targets, sample_weights) . y Target data. Like the input data x ,\nit could be either NumPy array(s) or backend-native tensor(s).\nIf x is a dataset, generator,\nor keras.utils.PyDataset instance, y should\nnot be specified (since targets will be obtained from x ). batch_size Integer or None .\nNumber of samples per gradient update.\nIf unspecified, batch_size will default to 32.\nDo not specify the batch_size if your data is in the\nform of datasets, generators, or keras.utils.PyDataset instances (since they generate batches). epochs Integer. Number of epochs to train the model.\nAn epoch is an iteration over the entire x and y data provided\n(unless the steps_per_epoch flag is set to\nsomething other than None).\nNote that in conjunction with initial_epoch , epochs is to be understood as \"final epoch\".\nThe model is not trained for a number of iterations\ngiven by epochs , but merely until the epoch\nof index epochs is reached. verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = one line per epoch.\n\"auto\" becomes 1 for most cases.\nNote that the progress bar is not\nparticularly useful when logged to a file,\nso verbose=2 is recommended when not running interactively\n(e.g., in a production environment). Defaults to \"auto\" . callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during training.\nSee keras.callbacks . Note keras.callbacks.ProgbarLogger and keras.callbacks.History callbacks are created\nautomatically and need not be passed to model.fit() . keras.callbacks.ProgbarLogger is created\nor not based on the verbose argument in model.fit() . validation_split Float between 0 and 1.\nFraction of the training data to be used as validation data.\nThe model will set apart this fraction of the training data,\nwill not train on it, and will evaluate\nthe loss and any model metrics\non this data at the end of each epoch.\nThe validation data is selected from the last samples\nin the x and y data provided, before shuffling. This\nargument is not supported when x is a dataset, generator or keras.utils.PyDataset instance.\nIf both validation_data and validation_split are provided, validation_data will override validation_split . validation_data Data on which to evaluate\nthe loss and any model metrics at the end of each epoch.\nThe model will not be trained on this data. Thus, note the fact\nthat the validation loss of data provided using validation_split or validation_data is not affected by\nregularization layers like noise and dropout. validation_data will override validation_split .\nIt could be:\nkeras.utils.PyDataset\n(inputs,\ntargets)\n(inputs, targets, sample_weights)\ny\nx\nx\nkeras.utils.PyDataset\ny\nx\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nepochs\nx\ny\nsteps_per_epoch\ninitial_epoch\nepochs\nepochs\nepochs\nverbose\n\"auto\"\nverbose=2\n\"auto\"\ncallbacks\nkeras.callbacks.Callback\nkeras.callbacks\nkeras.callbacks.ProgbarLogger\nkeras.callbacks.History\nmodel.fit()\nkeras.callbacks.ProgbarLogger\nverbose\nmodel.fit()\nvalidation_split\nx\ny\nx\nkeras.utils.PyDataset\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_data\nvalidation_split\nA tuple (x_val, y_val) of NumPy arrays or tensors.\n(x_val, y_val)\nA tuple (x_val, y_val, val_sample_weights) of NumPy\narrays.\n(x_val, y_val, val_sample_weights)\nA tf.data.Dataset .\ntf.data.Dataset\nA Python generator or keras.utils.PyDataset returning (inputs, targets) or (inputs, targets, sample_weights) . shuffle Boolean, whether to shuffle the training data\nbefore each epoch. This argument is\nignored when x is a generator or a tf.data.Dataset . class_weight Optional dictionary mapping class indices (integers)\nto a weight (float) value, used for weighting the loss function\n(during training only).\nThis can be useful to tell the model to\n\"pay more attention\" to samples from\nan under-represented class. When class_weight is specified\nand targets have a rank of 2 or greater, either y must be\none-hot encoded, or an explicit final dimension of 1 must\nbe included for sparse class labels. sample_weight Optional NumPy array of weights for\nthe training samples, used for weighting the loss function\n(during training only). You can either pass a flat (1D)\nNumPy array with the same length as the input samples\n(1:1 mapping between weights and samples),\nor in the case of temporal data,\nyou can pass a 2D array with shape (samples, sequence_length) ,\nto apply a different weight to every timestep of every sample.\nThis argument is not supported when x is a dataset, generator,\nor keras.utils.PyDataset instance, instead provide the\nsample_weights as the third element of x .\nNote that sample weighting does not apply to metrics specified\nvia the metrics argument in compile() . To apply sample\nweighting to your metrics, you can specify them via the weighted_metrics in compile() instead. initial_epoch Integer.\nEpoch at which to start training\n(useful for resuming a previous training run). steps_per_epoch Integer or None .\nTotal number of steps (batches of samples)\nbefore declaring one epoch finished and starting the\nnext epoch. When training with input tensors such as\nbackend-native tensors, the default None is equal to\nthe number of samples in your dataset divided by\nthe batch size, or 1 if that cannot be determined. If x is a tf.data.Dataset , and steps_per_epoch is None , the epoch will run until the input dataset is\nexhausted.  When passing an infinitely repeating dataset, you\nmust specify the steps_per_epoch argument. If steps_per_epoch=-1 the training will run indefinitely with an\ninfinitely repeating dataset. validation_steps Only relevant if validation_data is provided.\nTotal number of steps (batches of\nsamples) to draw before stopping when performing validation\nat the end of every epoch. If validation_steps is None ,\nvalidation will run until the validation_data dataset is\nexhausted. In the case of an infinitely repeated dataset, it\nwill run into an infinite loop. If validation_steps is\nspecified and only part of the dataset will be consumed, the\nevaluation will start from the beginning of the dataset at each\nepoch. This ensures that the same validation samples are used\nevery time. validation_batch_size Integer or None .\nNumber of samples per validation batch.\nIf unspecified, will default to batch_size .\nDo not specify the validation_batch_size if your data is in\nthe form of datasets or keras.utils.PyDataset instances (since they generate batches). validation_freq Only relevant if validation data is provided.\nSpecifies how many training epochs to run\nbefore a new validation run is performed,\ne.g. validation_freq=2 runs validation every 2 epochs.\nkeras.utils.PyDataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nshuffle\nx\ntf.data.Dataset\nclass_weight\nclass_weight\ny\n1\nsample_weight\n(samples, sequence_length)\nx\nkeras.utils.PyDataset\nx\nmetrics\ncompile()\nweighted_metrics\ncompile()\ninitial_epoch\nsteps_per_epoch\nNone\nNone\nx\ntf.data.Dataset\nsteps_per_epoch\nNone\nsteps_per_epoch\nsteps_per_epoch=-1\nvalidation_steps\nvalidation_data\nvalidation_steps\nNone\nvalidation_data\nvalidation_steps\nvalidation_batch_size\nNone\nbatch_size\nvalidation_batch_size\nkeras.utils.PyDataset\nvalidation_freq\nvalidation_freq=2\nUnpacking behavior for iterator-like inputs:\n    A common pattern is to pass an iterator like object such as a tf.data.Dataset or a keras.utils.PyDataset to fit() ,\n    which will in fact yield not only features ( x )\n    but optionally targets ( y ) and sample weights ( sample_weight ).\n    Keras requires that the output of such iterator-likes be\n    unambiguous. The iterator should return a tuple\n    of length 1, 2, or 3, where the optional second and third elements\n    will be used for y and sample_weight respectively.\n    Any other type provided will be wrapped in\n    a length-one tuple, effectively treating everything as x . When\n    yielding dicts, they should still adhere to the top-level tuple\n    structure,\n    e.g. ({\"x0\": x0, \"x1\": x1}, y) . Keras will not attempt to separate\n    features, targets, and weights from the keys of a single dict.\n    A notable unsupported data type is the namedtuple . The reason is\n    that it behaves like both an ordered datatype (tuple) and a mapping\n    datatype (dict). So given a namedtuple of the form: namedtuple(\"example_tuple\", [\"y\", \"x\"]) it is ambiguous whether to reverse the order of the elements when\n    interpreting the value. Even worse is a tuple of the form: namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"]) where it is unclear if the tuple was intended to be unpacked\n    into x , y , and sample_weight or passed through\n    as a single element to x .\ntf.data.Dataset\nkeras.utils.PyDataset\nfit()\nx\ny\nsample_weight\ny\nsample_weight\nx\n({\"x0\": x0, \"x1\": x1}, y)\nnamedtuple\nnamedtuple(\"example_tuple\", [\"y\", \"x\"])\nnamedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])\nx\ny\nsample_weight\nx\nReturns A History object. Its History.history attribute is\na record of training loss values and metrics values\nat successive epochs, as well as validation loss values\nand validation metrics values (if applicable).\nHistory\nHistory.history\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_compile_config\nget_compile_config\nView source\nget_compile_config ()\nget_compile_config ()\nReturns a serialized config with information for compiling the model.\nThis method returns a config dictionary containing all the information\n(optimizer, loss, metrics, etc.) with which the model was compiled.\nReturns A dict containing information for compiling the model.\nget_layer\nget_layer\nView source\nget_layer ( name = None , index = None )\nget_layer ( name = None , index = None )\nRetrieves a layer based on either its name (unique) or index.\nIf name and index are both provided, index will take precedence.\nIndices are based on order of horizontal graph traversal (bottom-up).\nname\nindex\nindex\nArgs\nname String, name of layer. index Integer, index of layer.\nname\nindex\nReturns A layer instance.\nget_metrics_result\nget_metrics_result\nView source\nget_metrics_result ()\nget_metrics_result ()\nReturns the model's metrics values as a dict.\nIf any of the metric result is a dict (containing multiple metrics),\neach of them gets added to the top level returned dict of this method.\nReturns A dict containing values of the metrics listed in self.metrics . Example {'loss': 0.2, 'accuracy': 0.7} .\ndict\nself.metrics\nExample\n{'loss': 0.2, 'accuracy': 0.7}\nload_weights\nload_weights\nView source\nload_weights ( filepath , skip_mismatch = False , ** kwargs )\nload_weights ( filepath , skip_mismatch = False , ** kwargs )\nLoad weights from a file saved via save_weights() .\nsave_weights()\nWeights are loaded based on the network's\ntopology. This means the architecture should be the same as when the\nweights were saved. Note that layers that don't have weights are not\ntaken into account in the topological ordering, so adding or removing\nlayers is fine as long as they don't have weights.\nPartial weight loading\nIf you have modified your model, for instance by adding a new layer\n(with weights) or by changing the shape of the weights of a layer,\nyou can choose to ignore errors and continue loading\nby setting skip_mismatch=True . In this case any layer with\nmismatching weights will be skipped. A warning will be displayed\nfor each skipped layer.\nskip_mismatch=True\nArgs\nfilepath String, path to the weights file to load.\nIt can either be a .weights.h5 file\nor a legacy .h5 weights file. skip_mismatch Boolean, whether to skip loading of layers where\nthere is a mismatch in the number of weights, or a mismatch in\nthe shape of the weights.\nfilepath\n.weights.h5\n.h5\nskip_mismatch\nloss\nloss\nView source\nloss ( y , y_pred , sample_weight = None )\nloss ( y , y_pred , sample_weight = None )\nmake_predict_function\nmake_predict_function\nView source\nmake_predict_function ( force = False )\nmake_predict_function ( force = False )\nmake_test_function\nmake_test_function\nView source\nmake_test_function ( force = False )\nmake_test_function ( force = False )\nmake_train_function\nmake_train_function\nView source\nmake_train_function ( force = False )\nmake_train_function ( force = False )\npop\npop\nView source\npop ( rebuild = True )\npop ( rebuild = True )\nRemoves the last layer in the model.\npredict\npredict\nView source\npredict ( x , batch_size = None , verbose = 'auto' , steps = None , callbacks = None )\npredict ( x , batch_size = None , verbose = 'auto' , steps = None , callbacks = None )\nGenerates output predictions for the input samples.\nComputation is done in batches. This method is designed for batch\nprocessing of large numbers of inputs. It is not intended for use inside\nof loops that iterate over your data and process small numbers of inputs\nat a time.\nFor small numbers of inputs that fit in one batch,\ndirectly use __call__() for faster execution, e.g., model(x) , or model(x, training=False) if you have layers such as BatchNormalization that behave differently during\ninference.\n__call__()\nmodel(x)\nmodel(x, training=False)\nBatchNormalization\nModel\npredict()\n__call__()\nArgs\nx Input samples. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA tf.data.Dataset .\ntf.data.Dataset\nA keras.utils.PyDataset instance. batch_size Integer or None .\nNumber of samples per batch.\nIf unspecified, batch_size will default to 32.\nDo not specify the batch_size if your data is in the\nform of dataset, generators, or keras.utils.PyDataset instances (since they generate batches). verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = single line. \"auto\" becomes 1 for most cases. Note that the progress bar\nis not particularly useful when logged to a file,\nso verbose=2 is recommended when not running interactively\n(e.g. in a production environment). Defaults to \"auto\" . steps Total number of steps (batches of samples)\nbefore declaring the prediction round finished.\nIgnored with the default value of None .\nIf x is a tf.data.Dataset and steps is None , predict() will run until the input dataset is exhausted. callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during prediction.\nkeras.utils.PyDataset\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nverbose\n\"auto\"\n\"auto\"\nverbose=2\n\"auto\"\nsteps\nNone\nx\ntf.data.Dataset\nsteps\nNone\npredict()\ncallbacks\nkeras.callbacks.Callback\nReturns NumPy array(s) of predictions.\npredict_on_batch\npredict_on_batch\nView source\npredict_on_batch ( x )\npredict_on_batch ( x )\nReturns predictions for a single batch of samples.\nArgs\nx Input data. It must be array-like.\nx\nReturns NumPy array(s) of predictions.\npredict_step\npredict_step\nView source\npredict_step ( data )\npredict_step ( data )\nreset_metrics\nreset_metrics\nView source\nreset_metrics ()\nreset_metrics ()\nsave\nsave\nView source\nsave ( filepath , overwrite = True , ** kwargs )\nsave ( filepath , overwrite = True , ** kwargs )\nSaves a model as a .keras file.\n.keras\nArgs\nfilepath str or pathlib.Path object. Path where to save\nthe model. Must end in .keras . overwrite Whether we should overwrite any existing model at\nthe target location, or instead ask the user via\nan interactive prompt. save_format The save_format argument is deprecated in Keras 3.\nFormat to use, as a string. Only the \"keras\" format is\nsupported at this time.\nfilepath\nstr\npathlib.Path\n.keras\noverwrite\nsave_format\nsave_format\n\"keras\"\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nNote that model.save() is an alias for keras.saving.save_model() .\nmodel.save()\nkeras.saving.save_model()\nThe saved .keras file contains:\n.keras\nThe model's configuration (architecture)\nThe model's weights\nThe model's optimizer's state (if any)\nThus models can be reinstantiated in the exact same state.\nsave_weights\nsave_weights\nView source\nsave_weights ( filepath , overwrite = True )\nsave_weights ( filepath , overwrite = True )\nSaves all layer weights to a .weights.h5 file.\n.weights.h5\nArgs\nfilepath str or pathlib.Path object.\nPath where to save the model. Must end in .weights.h5 . overwrite Whether we should overwrite any existing model\nat the target location, or instead ask the user\nvia an interactive prompt.\nfilepath\nstr\npathlib.Path\n.weights.h5\noverwrite\nstateless_compute_loss\nstateless_compute_loss\nView source\nstateless_compute_loss ( trainable_variables , non_trainable_variables , metrics_variables , x = None , y = None , y_pred = None , sample_weight = None )\nstateless_compute_loss ( trainable_variables , non_trainable_variables , metrics_variables , x = None , y = None , y_pred = None , sample_weight = None )\nsummary\nsummary\nView source\nsummary ( line_length = None , positions = None , print_fn = None , expand_nested = False , show_trainable = False , layer_range = None )\nsummary ( line_length = None , positions = None , print_fn = None , expand_nested = False , show_trainable = False , layer_range = None )\nPrints a string summary of the network.\nArgs\nline_length Total length of printed lines\n(e.g. set this to adapt the display to different\nterminal window sizes). positions Relative or absolute positions of log elements\nin each line. If not provided, becomes [0.3, 0.6, 0.70, 1.] . Defaults to None . print_fn Print function to use. By default, prints to stdout .\nIf stdout doesn't work in your environment, change to print .\nIt will be called on each line of the summary.\nYou can set it to a custom function\nin order to capture the string summary. expand_nested Whether to expand the nested models.\nDefaults to False . show_trainable Whether to show if a layer is trainable.\nDefaults to False . layer_range a list or tuple of 2 strings,\nwhich is the starting layer name and ending layer name\n(both inclusive) indicating the range of layers to be printed\nin summary. It also accepts regex patterns instead of exact\nname. In such case, start predicate will be the first element\nit matches to layer_range[0] and the end predicate will be\nthe last element it matches to layer_range[1] .\nBy default None which considers all layers of model.\nline_length\npositions\n[0.3, 0.6, 0.70, 1.]\nNone\nprint_fn\nstdout\nstdout\nprint\nexpand_nested\nFalse\nshow_trainable\nFalse\nlayer_range\nlayer_range[0]\nlayer_range[1]\nNone\nRaises\nValueError if summary() is called before the model is built.\nValueError\nsummary()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\ntest_on_batch\ntest_on_batch\nView source\ntest_on_batch ( x , y = None , sample_weight = None , return_dict = False )\ntest_on_batch ( x , y = None , sample_weight = None , return_dict = False )\nTest the model on a single batch of samples.\nArgs\nx Input data. Must be array-like. y Target data. Must be array-like. sample_weight Optional array of the same length as x, containing\nweights to apply to the model's loss for each sample.\nIn the case of temporal data, you can pass a 2D array\nwith shape (samples, sequence_length) , to apply a different\nweight to every timestep of every sample. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric. If False ,\nthey are returned as a list.\nx\ny\nsample_weight\n(samples, sequence_length)\nreturn_dict\nTrue\nFalse\nReturns A scalar loss value (when no metrics and return_dict=False ),\na list of loss and metric values\n(if there are metrics and return_dict=False ), or a dict of\nmetric and loss values (if return_dict=True ).\nreturn_dict=False\nreturn_dict=False\nreturn_dict=True\ntest_step\ntest_step\nView source\ntest_step ( data )\ntest_step ( data )\nto_json\nto_json\nView source\nto_json ( ** kwargs )\nto_json ( ** kwargs )\nReturns a JSON string containing the network configuration.\nTo load a network from a JSON save file, use keras.models.model_from_json(json_string, custom_objects={...}) .\nkeras.models.model_from_json(json_string, custom_objects={...})\nArgs\n**kwargs Additional keyword arguments to be passed to json.dumps() .\n**kwargs\njson.dumps()\nReturns A JSON string.\ntrain_on_batch\ntrain_on_batch\nView source\ntrain_on_batch ( x , y = None , sample_weight = None , class_weight = None , return_dict = False )\ntrain_on_batch ( x , y = None , sample_weight = None , class_weight = None , return_dict = False )\nRuns a single gradient update on a single batch of data.\nArgs\nx Input data. Must be array-like. y Target data. Must be array-like. sample_weight Optional array of the same length as x, containing\nweights to apply to the model's loss for each sample.\nIn the case of temporal data, you can pass a 2D array\nwith shape (samples, sequence_length) , to apply a different\nweight to every timestep of every sample. class_weight Optional dictionary mapping class indices (integers)\nto a weight (float) to apply to the model's loss for the samples\nfrom this class during training. This can be useful to tell the\nmodel to \"pay more attention\" to samples from an\nunder-represented class. When class_weight is specified\nand targets have a rank of 2 or greater, either y must\nbe one-hot encoded, or an explicit final dimension of 1\nmust be included for sparse class labels. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric. If False ,\nthey are returned as a list.\nx\ny\nsample_weight\n(samples, sequence_length)\nclass_weight\nclass_weight\ny\nreturn_dict\nTrue\nFalse\nReturns A scalar loss value (when no metrics and return_dict=False ),\na list of loss and metric values\n(if there are metrics and return_dict=False ), or a dict of\nmetric and loss values (if return_dict=True ).\nreturn_dict=False\nreturn_dict=False\nreturn_dict=True\ntrain_step\ntrain_step\nView source\ntrain_step ( data )\ntrain_step ( data )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D",
    "content": "Max pooling operation for 2D spatial data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.MaxPooling2D\ntf.keras.layers.MaxPooling2D\ntf.keras.layers.MaxPooling2D\ntf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . MaxPool2D ( pool_size = ( 2 , 2 ), strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nUsed in the notebooks\nEffective Tensorflow 2\nSparse weights using structural pruning\nImage classification\nData augmentation\nLoad and preprocess images\nCustom training with tf.distribute.Strategy\nConvolutional Neural Network (CNN)\nDownsamples the input along its spatial dimensions (height and width)\nby taking the maximum value over an input window\n(of size defined by pool_size ) for each channel of the input.\nThe window is shifted by strides along each dimension.\npool_size\nstrides\nThe resulting output when using the \"valid\" padding option has a spatial\nshape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape >= pool_size )\n\"valid\"\noutput_shape = math.floor((input_shape - pool_size) / strides) + 1\ninput_shape >= pool_size\nThe resulting output shape when using the \"same\" padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1\n\"same\"\noutput_shape = math.floor((input_shape - 1) / strides) + 1\nArgs\nArgs\npool_size int or tuple of 2 integers, factors by which to downscale\n(dim1, dim2). If only one integer is specified, the same\nwindow length will be used for all dimensions. strides int or tuple of 2 integers, or None. Strides values. If None,\nit will default to pool_size . If only one int is specified, the\nsame stride size will be used for all dimensions. padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, height, width, channels) .\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, height, width) .\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, pooled_height, pooled_width, channels) .\ndata_format=\"channels_last\"\n(batch_size, pooled_height, pooled_width, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, pooled_height, pooled_width) .\ndata_format=\"channels_first\"\n(batch_size, channels, pooled_height, pooled_width)\nstrides=(1, 1) and padding=\"valid\" :\nstrides=(1, 1)\npadding=\"valid\"\nx = np . array ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) x = np . reshape ( x , [ 1 , 3 , 3 , 1 ]) max_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = \"valid\" ) max_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. ],\n[ 4. , 5. , 6. ],\n[ 7. , 8. , 9. ]])\nx = np . reshape ( x , [ 1 , 3 , 3 , 1 ])\nmax_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 1 , 1 ), padding = \"valid\" )\nmax_pool_2d ( x )\nstrides=(2, 2) and padding=\"valid\" :\nstrides=(2, 2)\npadding=\"valid\"\nx = np . array ([[ 1. , 2. , 3. , 4. ], [ 5. , 6. , 7. , 8. ], [ 9. , 10. , 11. , 12. ]]) x = np . reshape ( x , [ 1 , 3 , 4 , 1 ]) max_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"valid\" ) max_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. , 4. ],\n[ 5. , 6. , 7. , 8. ],\n[ 9. , 10. , 11. , 12. ]])\nx = np . reshape ( x , [ 1 , 3 , 4 , 1 ])\nmax_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 2 , 2 ), padding = \"valid\" )\nmax_pool_2d ( x )\nstride=(1, 1) and padding=\"same\" :\nstride=(1, 1)\npadding=\"same\"\nx = np . array ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) x = np . reshape ( x , [ 1 , 3 , 3 , 1 ]) max_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = \"same\" ) max_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. ],\n[ 4. , 5. , 6. ],\n[ 7. , 8. , 9. ]])\nx = np . reshape ( x , [ 1 , 3 , 3 , 1 ])\nmax_pool_2d = keras . layers . MaxPooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 1 , 1 ), padding = \"same\" )\nmax_pool_2d ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/legacy/saving/deserialize_keras_object",
    "content": "Turns the serialized form of a Keras object back into an actual object.\nMain aliases tf.keras.utils.legacy.deserialize_keras_object\ntf.keras.utils.legacy.deserialize_keras_object\ntf.keras.utils.legacy.deserialize_keras_object\ntf . keras . legacy . saving . deserialize_keras_object ( identifier , module_objects = None , custom_objects = None , printable_module_name = 'object' )\ntf . keras . legacy . saving . deserialize_keras_object ( identifier , module_objects = None , custom_objects = None , printable_module_name = 'object' )\nThis function is for mid-level library implementers rather than end users.\nImportantly, this utility requires you to provide the dict of module_objects to use for looking up the object config; this is not\npopulated by default. If you need a deserialization utility that has\npreexisting knowledge of built-in Keras objects, use e.g. keras.layers.deserialize(config) , keras.metrics.deserialize(config) ,\netc.\nmodule_objects\nkeras.layers.deserialize(config)\nkeras.metrics.deserialize(config)\nCalling deserialize_keras_object while underneath the SharedObjectLoadingScope context manager will cause any already-seen\nshared objects to be returned as-is rather than creating a new object.\ndeserialize_keras_object\nSharedObjectLoadingScope\nArgs\nArgs\nidentifier the serialized form of the object. module_objects A dictionary of built-in objects to look the name up in.\nGenerally, module_objects is provided by midlevel library\nimplementers. custom_objects A dictionary of custom objects to look the name up in.\nGenerally, custom_objects is provided by the end user. printable_module_name A human-readable string representing the type of\nthe object. Printed in case of exception.\nidentifier\nmodule_objects\nmodule_objects\ncustom_objects\ncustom_objects\nprintable_module_name\nReturns The deserialized object.\nReturns\nA mid-level library implementer might want to implement a utility for\nretrieving an object from its config, as such:\ndef deserialize ( config , custom_objects = None ): return deserialize_keras_object ( identifier , module_objects = globals (), custom_objects = custom_objects , name = \"MyObjectType\" , )\ndef deserialize ( config , custom_objects = None ): return deserialize_keras_object ( identifier , module_objects = globals (), custom_objects = custom_objects , name = \"MyObjectType\" , )\nThis is how e.g. keras.layers.deserialize() is implemented.\nkeras.layers.deserialize()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/square",
    "content": "DEPRECATED.\ntf . keras . backend . square ( x )\ntf . keras . backend . square ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/conj",
    "content": "Shorthand for keras.ops.conjugate .\nkeras.ops.conjugate\nMain aliases tf.keras.ops.numpy.conj\ntf.keras.ops.numpy.conj\ntf.keras.ops.numpy.conj\ntf . keras . ops . conj ( x )\ntf . keras . ops . conj ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy",
    "content": "DEPRECATED.\ntf . keras . backend . categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )\ntf . keras . backend . categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/gradients",
    "content": "DEPRECATED.\ntf . keras . backend . gradients ( loss , variables )\ntf . keras . backend . gradients ( loss , variables )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/NonNeg",
    "content": "Constrains the weights to be non-negative.\nInherits From: Constraint\nConstraint\nMain aliases tf.keras.constraints.non_neg\ntf.keras.constraints.non_neg\ntf.keras.constraints.non_neg\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a weight constraint from a configuration dictionary.\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns A keras.constraints.Constraint instance.\nkeras.constraints.Constraint\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns a Python dict of the object config.\nA constraint config is a Python dictionary (JSON-serializable) that can\nbe used to reinstantiate the same object.\nReturns Python dict containing the configuration of the constraint object.\n__call__\n__call__\nView source\n__call__ ( w )\n__call__ ( w )\nApplies the constraint to the input weight variable.\nBy default, the inputs weight variable is not modified.\nUsers should override this method to implement their own projection\nfunction.\nArgs\nw Input weight variable.\nw\nReturns Projected variable (by default, returns unmodified inputs)."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_get_value",
    "content": "DEPRECATED.\ntf . keras . backend . batch_get_value ( tensors )\ntf . keras . backend . batch_get_value ( tensors )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/cast_to_floatx",
    "content": "DEPRECATED.\ntf . keras . backend . cast_to_floatx ( x )\ntf . keras . backend . cast_to_floatx ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/less",
    "content": "DEPRECATED.\ntf . keras . backend . less ( x , y )\ntf . keras . backend . less ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN",
    "content": "Base class for recurrent layers.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RNN ( cell , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , zero_output_for_mask = False , ** kwargs )\ntf . keras . layers . RNN ( cell , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , zero_output_for_mask = False , ** kwargs )\nUsed in the notebooks\nTime series forecasting\nArgs\nArgs\ncell A RNN cell instance or a list of RNN cell instances.\nA RNN cell is a class that has:\ncell\nA call(input_at_t, states_at_t) method, returning (output_at_t, states_at_t_plus_1) . The call method of the\ncell can also take the optional argument constants , see\nsection \"Note on passing external constants\" below.\ncall(input_at_t, states_at_t)\n(output_at_t, states_at_t_plus_1)\nconstants\nA state_size attribute. This can be a single integer\n(single state) in which case it is the size of the recurrent\nstate. This can also be a list/tuple of integers\n(one size per state).\nstate_size\nA output_size attribute, a single integer.\noutput_size\nA get_initial_state(batch_size=None) method that creates a tensor meant to be fed to call() as the\ninitial state, if the user didn't specify any initial state\nvia other means. The returned initial state should have\nshape (batch_size, cell.state_size) .\nThe cell might choose to create a tensor full of zeros,\nor other values based on the cell's implementation. inputs is the input tensor to the RNN layer, with shape (batch_size, timesteps, features) .\nIf this method is not implemented\nby the cell, the RNN layer will create a zero filled tensor\nwith shape (batch_size, cell.state_size) .\nIn the case that cell is a list of RNN cell instances, the cells\nwill be stacked on top of each other in the RNN, resulting in an\nefficient stacked RNN. return_sequences Boolean (default False ). Whether to return the last\noutput in the output sequence, or the full sequence. return_state Boolean (default False ).\nWhether to return the last state in addition to the output. go_backwards Boolean (default False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default False ). If True, the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default False ).\nIf True, the network will be unrolled, else a symbolic loop will be\nused. Unrolling can speed-up a RNN, although it tends to be more\nmemory-intensive. Unrolling is only suitable for short sequences. zero_output_for_mask Boolean (default False ).\nWhether the output should use zeros for the masked timesteps.\nNote that this field is only used when return_sequences is True and mask is provided.\nIt can useful if you want to reuse the raw output sequence of\nthe RNN without interference from the masked timesteps, e.g.,\nmerging bidirectional RNNs.\nget_initial_state(batch_size=None)\ncall()\n(batch_size, cell.state_size)\ninputs\n(batch_size, timesteps, features)\n(batch_size, cell.state_size)\ncell\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nFalse\ni\ni\nunroll\nFalse\nzero_output_for_mask\nFalse\nreturn_sequences\nTrue\nmask\nCall arguments\nCall arguments\ninputs Input tensor. initial_state List of initial state tensors to be passed to the first\ncall of the cell. mask Binary tensor of shape [batch_size, timesteps] indicating whether a given timestep should be masked.\nAn individual True entry indicates that the corresponding\ntimestep should be utilized, while a False entry indicates\nthat the corresponding timestep should be ignored. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. This argument is passed\nto the cell when calling it.\nThis is for use with cells that use dropout.\ninputs\ninitial_state\nmask\n[batch_size, timesteps]\nTrue\nFalse\ntraining\nInput shape 3-D tensor with shape (batch_size, timesteps, features) .\nInput shape\n(batch_size, timesteps, features)\nIf return_state : a list of tensors. The first tensor is\nthe output. The remaining tensors are the last states,\neach with shape (batch_size, state_size) , where state_size could\nbe a high dimension tensor shape.\nreturn_state\n(batch_size, state_size)\nstate_size\nIf return_sequences : 3D tensor with shape (batch_size, timesteps, output_size) .\nreturn_sequences\n(batch_size, timesteps, output_size)\nThis layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse a keras.layers.Embedding layer with the mask_zero parameter\nset to True .\nkeras.layers.Embedding\nmask_zero\nTrue\nNote on using statefulness in RNNs:\nYou can set RNN layers to be 'stateful', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch. This assumes a one-to-one mapping\nbetween samples in different successive batches.\nTo enable statefulness:\nSpecify stateful=True in the layer constructor.\nstateful=True\nSpecify a fixed batch size for your model, by passing\nIf sequential model: batch_input_shape=(...) to the first layer in your model.\nElse for functional model with 1 or more Input layers: batch_shape=(...) to all the first layers in your model.\nThis is the expected shape of your inputs including the batch size .\nIt should be a tuple of integers, e.g. (32, 10, 100) .\nbatch_input_shape=(...)\nbatch_shape=(...)\n(32, 10, 100)\nSpecify shuffle=False when calling fit() .\nshuffle=False\nfit()\nTo reset the states of your model, call .reset_states() on either\na specific layer, or on your entire model.\n.reset_states()\nNote on specifying the initial state of RNNs:\nYou can specify the initial state of RNN layers symbolically by\ncalling them with the keyword argument initial_state . The value of initial_state should be a tensor or list of tensors representing\nthe initial state of the RNN layer.\ninitial_state\ninitial_state\nYou can specify the initial state of RNN layers numerically by\ncalling reset_states with the keyword argument states . The value of states should be a numpy array or list of numpy arrays representing\nthe initial state of the RNN layer.\nreset_states\nstates\nstates\nfrom keras.src.layers import RNN from keras.src import ops # First, let's define a RNN Cell, as a layer subclass. class MinimalRNNCell ( keras . layers . Layer ): def __init__ ( self , units , ** kwargs ): super () . __init__ ( ** kwargs ) self . units = units self . state_size = units def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = 'uniform' , name = 'kernel' ) self . recurrent_kernel = self . add_weight ( shape = ( self . units , self . units ), initializer = 'uniform' , name = 'recurrent_kernel' ) self . built = True def call ( self , inputs , states ): prev_output = states [ 0 ] h = ops . matmul ( inputs , self . kernel ) output = h + ops . matmul ( prev_output , self . recurrent_kernel ) return output , [ output ] # Let's use this cell in a RNN layer: cell = MinimalRNNCell ( 32 ) x = keras . Input (( None , 5 )) layer = RNN ( cell ) y = layer ( x ) # Here's how to use the cell to build a stacked RNN: cells = [ MinimalRNNCell ( 32 ), MinimalRNNCell ( 64 )] x = keras . Input (( None , 5 )) layer = RNN ( cells ) y = layer ( x )\nfrom keras.src.layers import RNN from keras.src import ops # First, let's define a RNN Cell, as a layer subclass. class MinimalRNNCell ( keras . layers . Layer ): def __init__ ( self , units , ** kwargs ): super () . __init__ ( ** kwargs ) self . units = units self . state_size = units def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = 'uniform' , name = 'kernel' ) self . recurrent_kernel = self . add_weight ( shape = ( self . units , self . units ), initializer = 'uniform' , name = 'recurrent_kernel' ) self . built = True def call ( self , inputs , states ): prev_output = states [ 0 ] h = ops . matmul ( inputs , self . kernel ) output = h + ops . matmul ( prev_output , self . recurrent_kernel ) return output , [ output ] # Let's use this cell in a RNN layer: cell = MinimalRNNCell ( 32 ) x = keras . Input (( None , 5 )) layer = RNN ( cell ) y = layer ( x ) # Here's how to use the cell to build a stacked RNN: cells = [ MinimalRNNCell ( 32 ), MinimalRNNCell ( 64 )] x = keras . Input (( None , 5 )) layer = RNN ( cells ) y = layer ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/dropout",
    "content": "tf . keras . random . dropout ( inputs , rate , noise_shape = None , seed = None )\ntf . keras . random . dropout ( inputs , rate , noise_shape = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/zeros",
    "content": "DEPRECATED.\ntf . keras . backend . zeros ( shape , dtype = None , name = None )\ntf . keras . backend . zeros ( shape , dtype = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed",
    "content": "This wrapper allows to apply a layer to every temporal slice of an input.\nInherits From: Wrapper , Layer , Operation\nWrapper\nLayer\nOperation\ntf . keras . layers . TimeDistributed ( layer , ** kwargs )\ntf . keras . layers . TimeDistributed ( layer , ** kwargs )\nUsed in the notebooks\nLoad video data\nEvery input should be at least 3D, and the dimension of index one of the\nfirst input will be considered to be the temporal dimension.\nConsider a batch of 32 video samples, where each sample is a 128x128 RGB\nimage with channels_last data format, across 10 timesteps.\nThe batch input shape is (32, 10, 128, 128, 3) .\nchannels_last\n(32, 10, 128, 128, 3)\nYou can then use TimeDistributed to apply the same Conv2D layer to each\nof the 10 timesteps, independently:\nTimeDistributed\nConv2D\ninputs = layers . Input ( shape = ( 10 , 128 , 128 , 3 ), batch_size = 32 ) conv_2d_layer = layers . Conv2D ( 64 , ( 3 , 3 )) outputs = layers . TimeDistributed ( conv_2d_layer )( inputs ) outputs . shape ( 32 , 10 , 126 , 126 , 64 )\ninputs = layers . Input ( shape = ( 10 , 128 , 128 , 3 ), batch_size = 32 )\nconv_2d_layer = layers . Conv2D ( 64 , ( 3 , 3 ))\noutputs = layers . TimeDistributed ( conv_2d_layer )( inputs )\noutputs . shape\n( 32 , 10 , 126 , 126 , 64 )\nBecause TimeDistributed applies the same instance of Conv2D to each of\nthe timestamps, the same set of weights are used at each timestamp.\nTimeDistributed\nConv2D\nArgs\nArgs\nlayer a keras.layers.Layer instance.\nlayer\nkeras.layers.Layer\nCall arguments\nCall arguments\ninputs Input tensor of shape (batch, time, ...) or nested tensors,\nand each of which has shape (batch, time, ...). training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. This argument is passed to the\nwrapped layer (only if the layer supports this argument). mask Binary tensor of shape (samples, timesteps) indicating whether\na given timestep should be masked. This argument is passed to the\nwrapped layer (only if the layer supports this argument).\ninputs\ntraining\nmask\n(samples, timesteps)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl",
    "content": "Optimizer that implements the FTRL algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Ftrl ( learning_rate = 0.001 , learning_rate_power =- 0.5 , initial_accumulator_value = 0.1 , l1_regularization_strength = 0.0 , l2_regularization_strength = 0.0 , l2_shrinkage_regularization_strength = 0.0 , beta = 0.0 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'ftrl' , ** kwargs )\ntf . keras . optimizers . Ftrl ( learning_rate = 0.001 , learning_rate_power =- 0.5 , initial_accumulator_value = 0.1 , l1_regularization_strength = 0.0 , l2_regularization_strength = 0.0 , l2_shrinkage_regularization_strength = 0.0 , beta = 0.0 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'ftrl' , ** kwargs )\n\"Follow The Regularized Leader\" (FTRL) is an optimization algorithm\ndeveloped at Google for click-through rate prediction in the early 2010s. It\nis most suitable for shallow models with large and sparse feature spaces.\nThe algorithm is described by McMahan et al., 2013 .\nThe Keras version has support for both online L2 regularization\n(the L2 regularization described in the paper\nabove) and shrinkage-type L2 regularization\n(which is the addition of an L2 penalty to the loss function).\nn = 0 sigma = 0 z = 0\nn = 0 sigma = 0 z = 0\nUpdate rule for one variable w :\nw\nprev_n = n n = n + g ** 2 sigma = ( n ** - lr_power - prev_n ** - lr_power ) / lr z = z + g - sigma * w if abs ( z ) < lambda_1 : w = 0 else : w = ( sgn ( z ) * lambda_1 - z ) / (( beta + sqrt ( n )) / alpha + lambda_2 )\nprev_n = n n = n + g ** 2 sigma = ( n ** - lr_power - prev_n ** - lr_power ) / lr z = z + g - sigma * w if abs ( z ) < lambda_1 : w = 0 else : w = ( sgn ( z ) * lambda_1 - z ) / (( beta + sqrt ( n )) / alpha + lambda_2 )\nlr is the learning rate\nlr\ng is the gradient for the variable\ng\nlambda_1 is the L1 regularization strength\nlambda_1\nlambda_2 is the L2 regularization strength\nlambda_2\nlr_power is the power to scale n.\nlr_power\nCheck the documentation for the l2_shrinkage_regularization_strength parameter for more details when shrinkage is enabled, in which case gradient\nis replaced with a gradient with shrinkage.\nl2_shrinkage_regularization_strength\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . learning_rate_power A float value, must be less or equal to zero.\nControls how the learning rate decreases during training. Use zero\nfor a fixed learning rate. initial_accumulator_value The starting value for accumulators. Only\nzero or positive values are allowed. l1_regularization_strength A float value, must be greater than or equal\nto zero. Defaults to 0.0 . l2_regularization_strength A float value, must be greater than or equal\nto zero. Defaults to 0.0 . l2_shrinkage_regularization_strength A float value, must be greater\nthan or equal to zero. This differs from L2 above in that the L2\nabove is a stabilization penalty, whereas this L2 shrinkage is a\nmagnitude penalty. When input is sparse shrinkage will only happen\non the active weights. beta A float value, representing the beta value from the paper.\nDefaults to 0.0 . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nlearning_rate_power\ninitial_accumulator_value\nl1_regularization_strength\n0.0\nl2_regularization_strength\n0.0\nl2_shrinkage_regularization_strength\nbeta\n0.0\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nArgs\nvar_list list of model variables to build Ftrl variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet121",
    "content": "Instantiates the Densenet121 architecture.\nMain aliases tf.keras.applications.densenet.DenseNet121\ntf.keras.applications.densenet.DenseNet121\ntf.keras.applications.densenet.DenseNet121\ntf . keras . applications . DenseNet121 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . DenseNet121 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nDensely Connected Convolutional Networks (CVPR 2017)\nOptionally loads weights pre-trained on ImageNet.\nNote that the data format convention used by the model is\nthe one specified in your Keras config at ~/.keras/keras.json .\n~/.keras/keras.json\nkeras.applications.densenet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) (with 'channels_last' data format)\nor (3, 224, 224) (with 'channels_first' data format).\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\n(224, 224, 3)\n'channels_last'\n(3, 224, 224)\n'channels_first'\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable.\nThe activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits\nof the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Keras model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/EinsumDense",
    "content": "A layer that uses einsum as the backing computation.\neinsum\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . EinsumDense ( equation , output_shape , activation = None , bias_axes = None , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , kernel_constraint = None , bias_constraint = None , lora_rank = None , ** kwargs )\ntf . keras . layers . EinsumDense ( equation , output_shape , activation = None , bias_axes = None , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , kernel_constraint = None , bias_constraint = None , lora_rank = None , ** kwargs )\nThis layer can perform einsum calculations of arbitrary dimensionality.\nArgs\nArgs\nequation An equation describing the einsum to perform.\nThis equation must be a valid einsum string of the form ab,bc->ac , ...ab,bc->...ac , or ab...,bc->ac... where 'ab', 'bc', and 'ac' can be any valid einsum\naxis expression sequence. output_shape The expected shape of the output tensor\n(excluding the batch dimension and any dimensions\nrepresented by ellipses). You can specify None for any dimension\nthat is unknown or can be inferred from the input shape. activation Activation function to use. If you don't specify anything,\nno activation is applied\n(that is, a \"linear\" activation: a(x) = x ). bias_axes A string containing the output dimension(s)\nto apply a bias to. Each character in the bias_axes string\nshould correspond to a character in the output portion\nof the equation string. kernel_initializer Initializer for the kernel weights matrix. bias_initializer Initializer for the bias vector. kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. bias_regularizer Regularizer function applied to the bias vector. kernel_constraint Constraint function applied to the kernel weights\nmatrix. bias_constraint Constraint function applied to the bias vector. lora_rank Optional integer. If set, the layer's forward pass\nwill implement LoRA (Low-Rank Adaptation)\nwith the provided rank. LoRA sets the layer's kernel\nto non-trainable and replaces it with a delta over the\noriginal kernel, obtained via multiplying two lower-rank\ntrainable matrices\n(the factorization happens on the last dimension).\nThis can be useful to reduce the\ncomputation cost of fine-tuning large dense layers.\nYou can also enable LoRA on an existing EinsumDense layer by calling layer.enable_lora(rank) . **kwargs Base layer keyword arguments, such as name and dtype .\nequation\nab,bc->ac\n...ab,bc->...ac\nab...,bc->ac...\noutput_shape\nNone\nactivation\na(x) = x\nbias_axes\nbias_axes\nequation\nkernel_initializer\nkernel\nbias_initializer\nkernel_regularizer\nkernel\nbias_regularizer\nkernel_constraint\nkernel\nbias_constraint\nlora_rank\nEinsumDense\nlayer.enable_lora(rank)\n**kwargs\nname\ndtype\nBiased dense layer with einsums\nThis example shows how to instantiate a standard Keras dense layer using\neinsum operations. This example is equivalent to keras.layers.Dense(64, use_bias=True) .\nkeras.layers.Dense(64, use_bias=True)\nlayer = keras . layers . EinsumDense ( \"ab,bc->ac\" , output_shape = 64 , bias_axes = \"c\" ) input_tensor = keras . Input ( shape = [ 32 ]) output_tensor = layer ( input_tensor ) output_tensor . shape ( None , 64 )\nlayer = keras . layers . EinsumDense ( \"ab,bc->ac\" ,\noutput_shape = 64 ,\nbias_axes = \"c\" )\ninput_tensor = keras . Input ( shape = [ 32 ])\noutput_tensor = layer ( input_tensor )\noutput_tensor . shape\n( None , 64 )\nApplying a dense layer to a sequence\nThis example shows how to instantiate a layer that applies the same dense\noperation to every element in a sequence. Here, the output_shape has two\nvalues (since there are two non-batch dimensions in the output); the first\ndimension in the output_shape is None , because the sequence dimension b has an unknown shape.\noutput_shape\noutput_shape\nNone\nb\nlayer = keras . layers . EinsumDense ( \"abc,cd->abd\" , output_shape = ( None , 64 ), bias_axes = \"d\" ) input_tensor = keras . Input ( shape = [ 32 , 128 ]) output_tensor = layer ( input_tensor ) output_tensor . shape ( None , 32 , 64 )\nlayer = keras . layers . EinsumDense ( \"abc,cd->abd\" ,\noutput_shape = ( None , 64 ),\nbias_axes = \"d\" )\ninput_tensor = keras . Input ( shape = [ 32 , 128 ])\noutput_tensor = layer ( input_tensor )\noutput_tensor . shape\n( None , 32 , 64 )\nApplying a dense layer to a sequence using ellipses\nThis example shows how to instantiate a layer that applies the same dense\noperation to every element in a sequence, but uses the ellipsis notation\ninstead of specifying the batch and sequence dimensions.\nBecause we are using ellipsis notation and have specified only one axis, the output_shape arg is a single value. When instantiated in this way, the\nlayer can handle any number of sequence dimensions - including the case\nwhere no sequence dimension exists.\noutput_shape\nlayer = keras . layers . EinsumDense ( \"...x,xy->...y\" , output_shape = 64 , bias_axes = \"y\" ) input_tensor = keras . Input ( shape = [ 32 , 128 ]) output_tensor = layer ( input_tensor ) output_tensor . shape ( None , 32 , 64 )\nlayer = keras . layers . EinsumDense ( \"...x,xy->...y\" ,\noutput_shape = 64 ,\nbias_axes = \"y\" )\ninput_tensor = keras . Input ( shape = [ 32 , 128 ])\noutput_tensor = layer ( input_tensor )\noutput_tensor . shape\n( None , 32 , 64 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel\nkernel\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nquantized_build\nquantized_build\nView source\nquantized_build ( input_shape , mode )\nquantized_build ( input_shape , mode )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nClass Variables\nClass Variables\nQUANTIZATION_MODE_ERROR_TEMPLATE (\"Invalid quantization mode. Expected one of ('int8', 'float8'). Received: \"\n 'quantization_mode={mode}')\n(\"Invalid quantization mode. Expected one of ('int8', 'float8'). Received: \"\n 'quantization_mode={mode}')"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/get",
    "content": "Retrieve a Keras regularizer object via an identifier.\ntf . keras . regularizers . get ( identifier )\ntf . keras . regularizers . get ( identifier )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . efficientnet_v2 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . efficientnet_v2 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot",
    "content": "Computes element-wise dot product of two tensors.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Dot ( axes , normalize = False , ** kwargs )\ntf . keras . layers . Dot ( axes , normalize = False , ** kwargs )\nUsed in the notebooks\nFederated Reconstruction for Matrix Factorization\nIt takes a list of inputs of size 2, and the axes\ncorresponding to each input along with the dot product\nis to be performed.\nLet's say x and y are the two input tensors with shapes (2, 3, 5) and (2, 10, 3) . The batch dimension should be\nof same size for both the inputs, and axes should correspond\nto the dimensions that have the same size in the corresponding\ninputs. e.g. with axes=(1, 2) , the dot product of x , and y will result in a tensor with shape (2, 5, 10)\nx\ny\n(2, 3, 5)\n(2, 10, 3)\naxes\naxes=(1, 2)\nx\ny\n(2, 5, 10)\nx = np . arange ( 10 ) . reshape ( 1 , 5 , 2 ) y = np . arange ( 10 , 20 ) . reshape ( 1 , 2 , 5 ) keras . layers . Dot ( axes = ( 1 , 2 ))([ x , y ])\nx = np . arange ( 10 ) . reshape ( 1 , 5 , 2 )\ny = np . arange ( 10 , 20 ) . reshape ( 1 , 2 , 5 )\nkeras . layers . Dot ( axes = ( 1 , 2 ))([ x , y ])\nUsage in a Keras model:\nx1 = keras . layers . Dense ( 8 )( np . arange ( 10 ) . reshape ( 5 , 2 )) x2 = keras . layers . Dense ( 8 )( np . arange ( 10 , 20 ) . reshape ( 5 , 2 )) y = keras . layers . Dot ( axes = 1 )([ x1 , x2 ])\nx1 = keras . layers . Dense ( 8 )( np . arange ( 10 ) . reshape ( 5 , 2 ))\nx2 = keras . layers . Dense ( 8 )( np . arange ( 10 , 20 ) . reshape ( 5 , 2 ))\ny = keras . layers . Dot ( axes = 1 )([ x1 , x2 ])\nArgs\nArgs\naxes Integer or tuple of integers, axis or axes along which to\ntake the dot product. If a tuple, should be two integers\ncorresponding to the desired axis from the first input and the\ndesired axis from the second input, respectively. Note that the\nsize of the two selected axes must match. normalize Whether to L2-normalize samples along the dot product axis\nbefore taking the dot product. If set to True , then\nthe output of the dot product is the cosine proximity\nbetween the two samples. **kwargs Standard layer keyword arguments.\naxes\nnormalize\nTrue\n**kwargs\nReturns A tensor, the dot product of the samples from the inputs.\nReturns\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/smart_resize",
    "content": "Resize images to a target size without aspect ratio distortion.\ntf . keras . preprocessing . image . smart_resize ( x , size , interpolation = 'bilinear' , data_format = 'channels_last' , backend_module = None )\ntf . keras . preprocessing . image . smart_resize ( x , size , interpolation = 'bilinear' , data_format = 'channels_last' , backend_module = None )\nImage datasets typically yield images that have each a different\nsize. However, these images need to be batched before they can be\nprocessed by Keras layers. To be batched, images need to share the same\nheight and width.\nYou could simply do, in TF (or JAX equivalent):\nsize = ( 200 , 200 ) ds = ds . map ( lambda img : resize ( img , size ))\nsize = ( 200 , 200 ) ds = ds . map ( lambda img : resize ( img , size ))\nHowever, if you do this, you distort the aspect ratio of your images, since\nin general they do not all have the same aspect ratio as size . This is\nfine in many cases, but not always (e.g. for image generation models\nthis can be a problem).\nsize\nNote that passing the argument preserve_aspect_ratio=True to resize will preserve the aspect ratio, but at the cost of no longer respecting the\nprovided target size.\npreserve_aspect_ratio=True\nresize\nsize = ( 200 , 200 ) ds = ds . map ( lambda img : smart_resize ( img , size ))\nsize = ( 200 , 200 ) ds = ds . map ( lambda img : smart_resize ( img , size ))\nYour output images will actually be (200, 200) , and will not be distorted.\nInstead, the parts of the image that do not fit within the target size\nget cropped out.\n(200, 200)\nThe resizing process is:\nTake the largest centered crop of the image that has the same aspect\nratio as the target size. For instance, if size=(200, 200) and the input\nimage has size (340, 500) , we take a crop of (340, 340) centered along\nthe width.\nsize=(200, 200)\n(340, 500)\n(340, 340)\nResize the cropped image to the target size. In the example above,\nwe resize the (340, 340) crop to (200, 200) .\n(340, 340)\n(200, 200)\nArgs\nArgs\nx Input image or batch of images (as a tensor or NumPy array).\nMust be in format (height, width, channels) or (batch_size, height, width, channels) . size Tuple of (height, width) integer. Target size. interpolation String, interpolation to use for resizing.\nDefaults to 'bilinear' .\nSupports bilinear , nearest , bicubic , lanczos3 , lanczos5 . data_format \"channels_last\" or \"channels_first\" . backend_module Backend module to use (if different from the default\nbackend).\nx\n(height, width, channels)\n(batch_size, height, width, channels)\nsize\n(height, width)\ninterpolation\n'bilinear'\nbilinear\nnearest\nbicubic\nlanczos3\nlanczos5\ndata_format\n\"channels_last\"\n\"channels_first\"\nbackend_module\nReturns Array with shape (size[0], size[1], channels) .\nIf the input image was a NumPy array, the output is a NumPy array,\nand if it was a backend-native tensor,\nthe output is a backend-native tensor.\nReturns\n(size[0], size[1], channels)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/OrthogonalRegularizer",
    "content": "Regularizer that encourages input vectors to be orthogonal to each other.\nInherits From: Regularizer\nRegularizer\nMain aliases tf.keras.regularizers.orthogonal_regularizer\ntf.keras.regularizers.orthogonal_regularizer\ntf.keras.regularizers.orthogonal_regularizer\ntf . keras . regularizers . OrthogonalRegularizer ( factor = 0.01 , mode = 'rows' )\ntf . keras . regularizers . OrthogonalRegularizer ( factor = 0.01 , mode = 'rows' )\nIt can be applied to either the rows of a matrix ( mode=\"rows\" ) or its\ncolumns ( mode=\"columns\" ). When applied to a Dense kernel of shape (input_dim, units) , rows mode will seek to make the feature vectors\n(i.e. the basis of the output space) orthogonal to each other.\nmode=\"rows\"\nmode=\"columns\"\nDense\n(input_dim, units)\nArguments\nArguments\nfactor Float. The regularization factor. The regularization penalty\nwill be proportional to factor times the mean of the dot products\nbetween the L2-normalized rows (if mode=\"rows\" , or columns if mode=\"columns\" ) of the inputs, excluding the product of each\nrow/column with itself.  Defaults to 0.01 . mode String, one of {\"rows\", \"columns\"} . Defaults to \"rows\" . In\nrows mode, the regularization effect seeks to make the rows of the\ninput orthogonal to each other. In columns mode, it seeks to make\nthe columns of the input orthogonal to each other.\nfactor\nfactor\nmode=\"rows\"\nmode=\"columns\"\n0.01\nmode\n{\"rows\", \"columns\"}\n\"rows\"\nregularizer = OrthogonalRegularizer ( factor = 0.01 ) layer = Dense ( units = 4 , kernel_regularizer = regularizer )\nregularizer = OrthogonalRegularizer ( factor = 0.01 )\nlayer = Dense ( units = 4 , kernel_regularizer = regularizer )\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a regularizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same regularizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A regularizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the regularizer.\nAn regularizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the regularizer.\nThe same regularizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( inputs )\n__call__ ( inputs )\nCompute a regularization penalty from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool3D",
    "content": "Global max pooling operation for 3D data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalMaxPooling3D\ntf.keras.layers.GlobalMaxPooling3D\ntf.keras.layers.GlobalMaxPooling3D\ntf . keras . layers . GlobalMaxPool3D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalMaxPool3D ( data_format = None , keepdims = False , ** kwargs )\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\nspatial dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nIf data_format='channels_last' :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format='channels_last'\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format='channels_first' :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format='channels_first'\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf keepdims=False :\n2D tensor with shape (batch_size, channels) .\nkeepdims=False\n(batch_size, channels)\nIf keepdims=True : If data_format=\"channels_last\" :\n5D tensor with shape (batch_size, 1, 1, 1, channels) If data_format=\"channels_first\" :\n5D tensor with shape (batch_size, channels, 1, 1, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n5D tensor with shape (batch_size, 1, 1, 1, channels)\ndata_format=\"channels_last\"\n(batch_size, 1, 1, 1, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape (batch_size, channels, 1, 1, 1)\ndata_format=\"channels_first\"\n(batch_size, channels, 1, 1, 1)\nx = np . random . rand ( 2 , 4 , 5 , 4 , 3 ) y = keras . layers . GlobalMaxPooling3D ()( x ) y . shape ( 2 , 3 )\nx = np . random . rand ( 2 , 4 , 5 , 4 , 3 )\ny = keras . layers . GlobalMaxPooling3D ()( x )\ny . shape\n( 2 , 3 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/reciprocal",
    "content": "Return the reciprocal of the argument, element-wise.\nMain aliases tf.keras.ops.numpy.reciprocal\ntf.keras.ops.numpy.reciprocal\ntf.keras.ops.numpy.reciprocal\ntf . keras . ops . reciprocal ( x )\ntf . keras . ops . reciprocal ( x )\nCalculates 1/x .\n1/x\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise reciprocal of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass BackupAndRestore : Callback to back up and restore the training state.\nclass BackupAndRestore\nclass CSVLogger : Callback that streams epoch results to a CSV file.\nclass CSVLogger\nclass Callback : Base class used to build new callbacks.\nclass Callback\nclass CallbackList : Container abstracting a list of callbacks.\nclass CallbackList\nclass EarlyStopping : Stop training when a monitored metric has stopped improving.\nclass EarlyStopping\nclass History : Callback that records events into a History object.\nclass History\nHistory\nclass LambdaCallback : Callback for creating simple, custom callbacks on-the-fly.\nclass LambdaCallback\nclass LearningRateScheduler : Learning rate scheduler.\nclass LearningRateScheduler\nclass ModelCheckpoint : Callback to save the Keras model or model weights at some frequency.\nclass ModelCheckpoint\nclass ProgbarLogger : Callback that prints metrics to stdout.\nclass ProgbarLogger\nclass ReduceLROnPlateau : Reduce learning rate when a metric has stopped improving.\nclass ReduceLROnPlateau\nclass RemoteMonitor : Callback used to stream events to a server.\nclass RemoteMonitor\nclass SwapEMAWeights : Swaps model weights and EMA weights before and after evaluation.\nclass SwapEMAWeights\nclass TensorBoard : Enable visualizations for TensorBoard.\nclass TensorBoard\nclass TerminateOnNaN : Callback that terminates training when a NaN loss is encountered.\nclass TerminateOnNaN"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arccos",
    "content": "Trigonometric inverse cosine, element-wise.\nMain aliases tf.keras.ops.numpy.arccos\ntf.keras.ops.numpy.arccos\ntf.keras.ops.numpy.arccos\ntf . keras . ops . arccos ( x )\ntf . keras . ops . arccos ( x )\nThe inverse of cos so that, if y = cos(x) , then x = arccos(y) .\ncos\ny = cos(x)\nx = arccos(y)\nArgs\nArgs\nx Input tensor.\nx\nReturns Tensor of the angle of the ray intersecting the unit circle at the given\nx-coordinate in radians [0, pi] .\nReturns\n[0, pi]\nx = keras . ops . convert_to_tensor ([ 1 , - 1 ]) keras . ops . arccos ( x ) array ([ 0.0 , 3.1415927 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 1 , - 1 ])\nkeras . ops . arccos ( x )\narray ([ 0.0 , 3.1415927 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/append",
    "content": "Append tensor x2 to the end of tensor x1 .\nx2\nx1\nMain aliases tf.keras.ops.numpy.append\ntf.keras.ops.numpy.append\ntf.keras.ops.numpy.append\ntf . keras . ops . append ( x1 , x2 , axis = None )\ntf . keras . ops . append ( x1 , x2 , axis = None )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor. axis Axis along which tensor x2 is appended to tensor x1 .\nIf None , both tensors are flattened before use.\nx1\nx2\naxis\nx2\nx1\nNone\nReturns A tensor with the values of x2 appended to x1 .\nReturns\nx2\nx1\nx1 = keras . ops . convert_to_tensor ([ 1 , 2 , 3 ]) x2 = keras . ops . convert_to_tensor ([[ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) keras . ops . append ( x1 , x2 ) array ([ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ], dtype = int32 )\nx1 = keras . ops . convert_to_tensor ([ 1 , 2 , 3 ])\nx2 = keras . ops . convert_to_tensor ([[ 4 , 5 , 6 ], [ 7 , 8 , 9 ]])\nkeras . ops . append ( x1 , x2 )\narray ([ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ], dtype = int32 )\nWhen axis is specified, x1 and x2 must have compatible shapes.\naxis\nx1\nx2\n>>> x1 = keras . ops . convert_to_tensor ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> x2 = keras . ops . convert_to_tensor ([[ 7 , 8 , 9 ]]) >>> keras . ops . append ( x1 , x2 , axis = 0 ) array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]], dtype = int32 ) >>> x3 = keras . ops . convert_to_tensor ([ 7 , 8 , 9 ]) >>> keras . ops . append ( x1 , x3 , axis = 0 ) Traceback ( most recent call last ): ... TypeError : Cannot concatenate arrays with different numbers of dimensions : got ( 2 , 3 ), ( 3 ,) .\n>>> x1 = keras . ops . convert_to_tensor ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]]) >>> x2 = keras . ops . convert_to_tensor ([[ 7 , 8 , 9 ]]) >>> keras . ops . append ( x1 , x2 , axis = 0 ) array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]], dtype = int32 ) >>> x3 = keras . ops . convert_to_tensor ([ 7 , 8 , 9 ]) >>> keras . ops . append ( x1 , x3 , axis = 0 ) Traceback ( most recent call last ): ... TypeError : Cannot concatenate arrays with different numbers of dimensions : got ( 2 , 3 ), ( 3 ,) ."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupQueryAttention",
    "content": "Grouped Query Attention layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . GroupQueryAttention ( head_dim , num_query_heads , num_key_value_heads , dropout = 0.0 , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . GroupQueryAttention ( head_dim , num_query_heads , num_key_value_heads , dropout = 0.0 , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nThis is an implementation of grouped-query attention introduced by Ainslie et al., 2023 . Here num_key_value_heads denotes number of groups, setting num_key_value_heads to 1 is equivalent to multi-query attention, and\nwhen num_key_value_heads is equal to num_query_heads it is equivalent\nto multi-head attention.\nnum_key_value_heads\nnum_key_value_heads\nnum_key_value_heads\nnum_query_heads\nThis layer first projects query , key , and value tensors. Then, key and value are repeated to match the number of heads of query .\nquery\nkey\nvalue\nkey\nvalue\nquery\nThen, the query is scaled and dot-producted with key tensors. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities and concatenated back to a single\ntensor.\nquery\nkey\nArgs\nArgs\nhead_dim Size of each attention head. num_query_heads Number of query attention heads. num_key_value_heads Number of key and value attention heads. dropout Dropout probability. use_bias Boolean, whether the dense layers use bias vectors/matrices. kernel_initializer Initializer for dense layer kernels. bias_initializer Initializer for dense layer biases. kernel_regularizer Regularizer for dense layer kernels. bias_regularizer Regularizer for dense layer biases. activity_regularizer Regularizer for dense layer activity. kernel_constraint Constraint for dense layer kernels. bias_constraint Constraint for dense layer kernels.\nhead_dim\nnum_query_heads\nnum_key_value_heads\ndropout\nuse_bias\nkernel_initializer\nbias_initializer\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nbias_constraint\nCall arguments\nCall arguments\nquery Query tensor of shape (batch_dim, target_seq_len, feature_dim) ,\nwhere batch_dim is batch size, target_seq_len is the length of\ntarget sequence, and feature_dim is dimension of feature. value Value tensor of shape (batch_dim, source_seq_len, feature_dim) ,\nwhere batch_dim is batch size, source_seq_len is the length of\nsource sequence, and feature_dim is dimension of feature. key Optional key tensor of shape (batch_dim, source_seq_len, feature_dim) . If not given, will use value for both key and value , which is most common case. attention_mask A boolean mask of shape (batch_dim, target_seq_len, source_seq_len) , that prevents\nattention to certain positions. The boolean mask specifies which\nquery elements can attend to which key elements, where 1 indicates\nattention and 0 indicates no attention. Broadcasting can happen for\nthe missing batch dimensions and the head dimension. return_attention_scores A boolean to indicate whether the output\nshould be (attention_output, attention_scores) if True , or attention_output if False . Defaults to False . training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (no dropout).\nWill go with either using the training mode of the parent\nlayer/model or False (inference) if there is no parent layer. use_causal_mask A boolean to indicate whether to apply a causal mask to\nprevent tokens from attending to future tokens (e.g., used in a\ndecoder Transformer).\nquery\n(batch_dim, target_seq_len, feature_dim)\nbatch_dim\ntarget_seq_len\nfeature_dim\nvalue\n(batch_dim, source_seq_len, feature_dim)\nbatch_dim\nsource_seq_len\nfeature_dim\nkey\n(batch_dim, source_seq_len, feature_dim)\nvalue\nkey\nvalue\nattention_mask\n(batch_dim, target_seq_len, source_seq_len)\nreturn_attention_scores\n(attention_output, attention_scores)\nTrue\nattention_output\nFalse\nFalse\ntraining\nFalse\nuse_causal_mask\nReturns\nReturns\nattention_output Result of the computation, of shape (batch_dim, target_seq_len, feature_dim) , where target_seq_len is for target sequence length and feature_dim is the query input\nlast dim. attention_scores (Optional) attention coefficients of shape (batch_dim, num_query_heads, target_seq_len, source_seq_len) .\nattention_output\n(batch_dim, target_seq_len, feature_dim)\ntarget_seq_len\nfeature_dim\nattention_scores\n(batch_dim, num_query_heads, target_seq_len, source_seq_len)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Zeros",
    "content": "Initializer that generates tensors initialized to 0.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.zeros\ntf.keras.initializers.zeros\ntf.keras.initializers.zeros\nUsed in the notebooks\nScalable model compression\n# Standalone usage: initializer = Zeros () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = Zeros ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = Zeros () layer = Dense ( units = 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = Zeros ()\nlayer = Dense ( units = 3 , kernel_initializer = initializer )\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor. Only numeric or boolean dtypes\nare supported. If not specified, keras.backend.floatx() is used, which default to float32 unless you configured it\notherwise (via keras.backend.set_floatx(float_dtype) ).\nshape\ndtype\nkeras.backend.floatx()\nfloat32\nkeras.backend.set_floatx(float_dtype)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ConvNeXtBase",
    "content": "Instantiates the ConvNeXtBase architecture.\nMain aliases tf.keras.applications.convnext.ConvNeXtBase\ntf.keras.applications.convnext.ConvNeXtBase\ntf.keras.applications.convnext.ConvNeXtBase\ntf . keras . applications . ConvNeXtBase ( model_name = 'convnext_base' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ConvNeXtBase ( model_name = 'convnext_base' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nA ConvNet for the 2020s (CVPR 2022)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe base , large , and xlarge models were first pre-trained on the\nImageNet-21k dataset and then fine-tuned on the ImageNet-1k dataset. The\npre-trained parameters of the models were assembled from the official repository . To get a\nsense of how these parameters were converted to Keras compatible parameters,\nplease refer to this repository .\nbase\nlarge\nxlarge\nNormalization\nWhen calling the summary() method after instantiating a ConvNeXt model,\nprefer setting the expand_nested argument summary() to True to better\ninvestigate the instantiated model.\nsummary()\nexpand_nested\nsummary()\nTrue\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet-1k), or the path to the weights\nfile to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/add",
    "content": "Functional interface to the keras.layers.Add layer.\nkeras.layers.Add\ntf . keras . layers . add ( inputs , ** kwargs )\ntf . keras . layers . add ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors with the same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the sum of the inputs. It has the same shape as the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . add ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . add ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) added = keras . layers . add ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( added ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\nadded = keras . layers . add ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( added )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/KLDivergence",
    "content": "Computes Kullback-Leibler divergence metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . KLDivergence ( name = 'kl_divergence' , dtype = None )\ntf . keras . metrics . KLDivergence ( name = 'kl_divergence' , dtype = None )\nmetric = y_true * log ( y_true / y_pred )\nmetric = y_true * log ( y_true / y_pred )\ny_true and y_pred are expected to be probability\ndistributions, with values between 0 and 1. They will get\nclipped to the [0, 1] range.\ny_true\ny_pred\n[0, 1]\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . KLDivergence () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]) m . result () 0.45814306\nm = keras . metrics . KLDivergence ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]])\nm . result ()\n0.45814306\nm . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]], sample_weight = [ 1 , 0 ]) m . result () 0.9162892\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.9162892\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . KLDivergence ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . KLDivergence ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet169",
    "content": "Instantiates the Densenet169 architecture.\nMain aliases tf.keras.applications.densenet.DenseNet169\ntf.keras.applications.densenet.DenseNet169\ntf.keras.applications.densenet.DenseNet169\ntf . keras . applications . DenseNet169 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . DenseNet169 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nDensely Connected Convolutional Networks (CVPR 2017)\nOptionally loads weights pre-trained on ImageNet.\nNote that the data format convention used by the model is\nthe one specified in your Keras config at ~/.keras/keras.json .\n~/.keras/keras.json\nkeras.applications.densenet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) (with 'channels_last' data format)\nor (3, 224, 224) (with 'channels_first' data format).\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\n(224, 224, 3)\n'channels_last'\n(3, 224, 224)\n'channels_first'\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable.\nThe activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits\nof the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Keras model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/softplus",
    "content": "Softplus activation function.\ntf . keras . activations . softplus ( x )\ntf . keras . activations . softplus ( x )\nIt is defined as: softplus(x) = log(exp(x) + 1) .\nsoftplus(x) = log(exp(x) + 1)\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall",
    "content": "Computes the recall of the predictions with respect to the labels.\nInherits From: Metric\nMetric\ntf . keras . metrics . Recall ( thresholds = None , top_k = None , class_id = None , name = None , dtype = None )\ntf . keras . metrics . Recall ( thresholds = None , top_k = None , class_id = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nClient-efficient large-model federated learning via `federated_select` and sparse aggregation\nThis metric creates two local variables, true_positives and false_negatives , that are used to compute the recall. This value is\nultimately returned as recall , an idempotent operation that simply divides true_positives by the sum of true_positives and false_negatives .\ntrue_positives\nfalse_negatives\nrecall\ntrue_positives\ntrue_positives\nfalse_negatives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf top_k is set, recall will be computed as how often on average a class\namong the labels of a batch entry is in the top-k predictions.\ntop_k\nIf class_id is specified, we calculate recall by considering only the\nentries in the batch for which class_id is in the label, and computing the\nfraction of them for which class_id is above the threshold and/or in the\ntop-k predictions.\nclass_id\nclass_id\nclass_id\nArgs\nArgs\nthresholds (Optional) A float value, or a Python list/tuple of float\nthreshold values in [0, 1] . A threshold is compared with\nprediction values to determine the truth value of predictions (i.e.,\nabove the threshold is True , below is False ). If used with a\nloss function that sets from_logits=True (i.e. no sigmoid\napplied to predictions), thresholds should be set to 0.\nOne metric value is generated for each threshold value.\nIf neither thresholds nor top_k are set,\nthe default is to calculate recall with thresholds=0.5 . top_k (Optional) Unset by default. An int value specifying the top-k\npredictions to consider when calculating recall. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nthresholds\ntop_k\nthresholds=0.5\ntop_k\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . Recall () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ]) m . result () 0.6666667\nm = keras . metrics . Recall ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ])\nm . result ()\n0.6666667\nm . reset_state () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Recall ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Recall ()])\nUsage with a loss with from_logits=True :\nfrom_logits=True\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . Recall ( thresholds = 0 )])\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . Recall ( thresholds = 0 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates true positive and false negative statistics.\nArgs\ny_true The ground truth values, with the same dimensions as y_pred . Will be cast to bool . y_pred The predicted values. Each element must be in the range [0, 1] . sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nbool\ny_pred\n[0, 1]\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/convnext",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nConvNeXtBase(...) : Instantiates the ConvNeXtBase architecture.\nConvNeXtBase(...)\nConvNeXtLarge(...) : Instantiates the ConvNeXtLarge architecture.\nConvNeXtLarge(...)\nConvNeXtSmall(...) : Instantiates the ConvNeXtSmall architecture.\nConvNeXtSmall(...)\nConvNeXtTiny(...) : Instantiates the ConvNeXtTiny architecture.\nConvNeXtTiny(...)\nConvNeXtXLarge(...) : Instantiates the ConvNeXtXLarge architecture.\nConvNeXtXLarge(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : A placeholder method for backward compatibility.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/round",
    "content": "DEPRECATED.\ntf . keras . backend . round ( x )\ntf . keras . backend . round ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/average",
    "content": "Compute the weighted average along the specified axis.\nMain aliases tf.keras.ops.numpy.average\ntf.keras.ops.numpy.average\ntf.keras.ops.numpy.average\ntf . keras . ops . average ( x , axis = None , weights = None )\ntf . keras . ops . average ( x , axis = None , weights = None )\nArgs\nArgs\nx Input tensor. axis Integer along which to average x . The default, axis=None ,\nwill average over all of the elements of the input tensor. If axis\nis negative it counts from the last to the first axis. weights Tensor of wieghts associated with the values in x . Each\nvalue in x contributes to the average according to its\nassociated weight. The weights array can either be 1-D (in which\ncase its length must be the size of a along the given axis) or of\nthe same shape as x . If weights=None (default), then all data\nin x are assumed to have a weight equal to one.\nx\naxis\nx\naxis=None\nweights\nx\nx\nx\nweights=None\nx\nThe 1-D calculation is: avg = sum(a * weights) / sum(weights) .\nThe only constraint on weights is that sum(weights) must not be 0.\navg = sum(a * weights) / sum(weights)\nsum(weights)\nReturns Return the average along the specified axis.\nReturns\ndata = keras . ops . arange ( 1 , 5 ) data array ([ 1 , 2 , 3 , 4 ], dtype = int32 ) keras . ops . average ( data ) array ( 2.5 , dtype = float32 ) keras . ops . average ( keras . ops . arange ( 1 , 11 ), weights = keras . ops . arange ( 10 , 0 , - 1 ) ) array ( 4. , dtype = float32 )\ndata = keras . ops . arange ( 1 , 5 )\ndata\narray ([ 1 , 2 , 3 , 4 ], dtype = int32 )\nkeras . ops . average ( data )\narray ( 2.5 , dtype = float32 )\nkeras . ops . average (\nkeras . ops . arange ( 1 , 11 ),\nweights = keras . ops . arange ( 10 , 0 , - 1 )\n)\narray ( 4. , dtype = float32 )\ndata = keras . ops . arange ( 6 ) . reshape (( 3 , 2 )) data array ([[ 0 , 1 ], [ 2 , 3 ], [ 4 , 5 ]], dtype = int32 ) keras . ops . average ( data , axis = 1 , weights = keras . ops . array ([ 1. / 4 , 3. / 4 ]) ) array ([ 0.75 , 2.75 , 4.75 ], dtype = float32 ) keras . ops . average ( data , weights = keras . ops . array ([ 1. / 4 , 3. / 4 ]) ) Traceback ( most recent call last ): ValueError : Axis must be specified when shapes of a and weights differ .\ndata = keras . ops . arange ( 6 ) . reshape (( 3 , 2 ))\ndata\narray ([[ 0 , 1 ],\n[ 2 , 3 ],\n[ 4 , 5 ]], dtype = int32 )\nkeras . ops . average (\ndata ,\naxis = 1 ,\nweights = keras . ops . array ([ 1. / 4 , 3. / 4 ])\n)\narray ([ 0.75 , 2.75 , 4.75 ], dtype = float32 )\nkeras . ops . average (\ndata ,\nweights = keras . ops . array ([ 1. / 4 , 3. / 4 ])\n)\nTraceback ( most recent call last ):\nValueError : Axis must be specified when shapes of a and weights differ ."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell",
    "content": "Cell class for the GRU layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . GRUCell ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , reset_after = True , seed = None , ** kwargs )\ntf . keras . layers . GRUCell ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , reset_after = True , seed = None , ** kwargs )\nThis class processes one step within the whole time sequence input, whereas keras.layer.GRU processes the whole sequence.\nkeras.layer.GRU\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use. Default: hyperbolic tangent\n( tanh ). If you pass None, no activation is applied\n(ie. \"linear\" activation: a(x) = x ). recurrent_activation Activation function to use for the recurrent step.\nDefault: sigmoid ( sigmoid ). If you pass None , no activation is\napplied (ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer\nshould use a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation\nof the recurrent state. Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. Default: 0. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. Default: 0. reset_after GRU convention (whether to apply reset gate after or\nbefore matrix multiplication). False = \"before\",\nTrue = \"after\" (default and cuDNN compatible). seed Random seed for dropout.\nunits\nactivation\ntanh\na(x) = x\nrecurrent_activation\nsigmoid\nNone\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nreset_after\nseed\nCall arguments\nCall arguments\ninputs A 2D tensor, with shape (batch, features) . states A 2D tensor with shape (batch, units) , which is the state\nfrom the previous time step. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. Only relevant when dropout or recurrent_dropout is used.\ninputs\n(batch, features)\nstates\n(batch, units)\ntraining\ndropout\nrecurrent_dropout\ninputs = np . random . random (( 32 , 10 , 8 )) rnn = keras . layers . RNN ( keras . layers . GRUCell ( 4 )) output = rnn ( inputs ) output . shape ( 32 , 4 ) rnn = keras . layers . RNN ( keras . layers . GRUCell ( 4 ), return_sequences = True , return_state = True ) whole_sequence_output , final_state = rnn ( inputs ) whole_sequence_output . shape ( 32 , 10 , 4 ) final_state . shape ( 32 , 4 )\ninputs = np . random . random (( 32 , 10 , 8 ))\nrnn = keras . layers . RNN ( keras . layers . GRUCell ( 4 ))\noutput = rnn ( inputs )\noutput . shape\n( 32 , 4 )\nrnn = keras . layers . RNN (\nkeras . layers . GRUCell ( 4 ),\nreturn_sequences = True ,\nreturn_state = True )\nwhole_sequence_output , final_state = rnn ( inputs )\nwhole_sequence_output . shape\n( 32 , 10 , 4 )\nfinal_state . shape\n( 32 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_dropout_mask\nget_dropout_mask\nView source\nget_dropout_mask ( step_input )\nget_dropout_mask ( step_input )\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size = None )\nget_initial_state ( batch_size = None )\nget_recurrent_dropout_mask\nget_recurrent_dropout_mask\nView source\nget_recurrent_dropout_mask ( step_input )\nget_recurrent_dropout_mask ( step_input )\nreset_dropout_mask\nreset_dropout_mask\nView source\nreset_dropout_mask ()\nreset_dropout_mask ()\nReset the cached dropout mask if any.\nThe RNN layer invokes this in the call() method\nso that the cached mask is cleared after calling cell.call() . The\nmask should be cached across all timestep within the same batch, but\nshouldn't be cached between batches.\ncall()\ncell.call()\nreset_recurrent_dropout_mask\nreset_recurrent_dropout_mask\nView source\nreset_recurrent_dropout_mask ()\nreset_recurrent_dropout_mask ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cast",
    "content": "Cast a tensor to the desired dtype.\ntf . keras . ops . cast ( x , dtype )\ntf . keras . ops . cast ( x , dtype )\nArgs\nArgs\nx A tensor or variable. dtype The target type.\nx\ndtype\nReturns A tensor of the specified dtype .\nReturns\ndtype\nx = keras . ops . arange ( 4 ) x = keras . ops . cast ( x , dtype = \"float16\" )\nx = keras . ops . arange ( 4 )\nx = keras . ops . cast ( x , dtype = \"float16\" )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/take",
    "content": "Take elements from a tensor along an axis.\nMain aliases tf.keras.ops.numpy.take\ntf.keras.ops.numpy.take\ntf.keras.ops.numpy.take\ntf . keras . ops . take ( x , indices , axis = None )\ntf . keras . ops . take ( x , indices , axis = None )\nArgs\nArgs\nx Source tensor. indices The indices of the values to extract. axis The axis over which to select values. By default, the\nflattened input tensor is used.\nx\nindices\naxis\nReturns The corresponding tensor of values.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Optimizer",
    "content": "A class for Tensorflow specific optimizer logic.\nMain aliases tf.keras.optimizers.Optimizer Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Optimizer\ntf.keras.optimizers.Optimizer\ntf.keras.optimizers.Optimizer\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Optimizer\ntf.compat.v1.keras.Optimizer\ntf . keras . Optimizer ( * args , ** kwargs )\ntf . keras . Optimizer ( * args , ** kwargs )\nThe major behavior change for this class is for tf.distribute.\nIt will override methods from base Keras core Optimizer,\nwhich provide distribute specific functionality, e.g. variable\ncreation, loss reduction, etc.\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( variables )\nbuild ( variables )\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/ctc",
    "content": "CTC (Connectionist Temporal Classification) loss.\ntf . keras . losses . ctc ( y_true , y_pred )\ntf . keras . losses . ctc ( y_true , y_pred )\nArgs\nArgs\ny_true A tensor of shape (batch_size, max_length) containing\nthe true labels in integer format. 0 always represents\nthe blank/mask index and should not be used for classes. y_pred A tensor of shape (batch_size, max_length, num_classes) containing logits (the output of your model).\nThey should not be normalized via softmax.\ny_true\n(batch_size, max_length)\n0\ny_pred\n(batch_size, max_length, num_classes)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ConvNeXtLarge",
    "content": "Instantiates the ConvNeXtLarge architecture.\nMain aliases tf.keras.applications.convnext.ConvNeXtLarge\ntf.keras.applications.convnext.ConvNeXtLarge\ntf.keras.applications.convnext.ConvNeXtLarge\ntf . keras . applications . ConvNeXtLarge ( model_name = 'convnext_large' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ConvNeXtLarge ( model_name = 'convnext_large' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nA ConvNet for the 2020s (CVPR 2022)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe base , large , and xlarge models were first pre-trained on the\nImageNet-21k dataset and then fine-tuned on the ImageNet-1k dataset. The\npre-trained parameters of the models were assembled from the official repository . To get a\nsense of how these parameters were converted to Keras compatible parameters,\nplease refer to this repository .\nbase\nlarge\nxlarge\nNormalization\nWhen calling the summary() method after instantiating a ConvNeXt model,\nprefer setting the expand_nested argument summary() to True to better\ninvestigate the instantiated model.\nsummary()\nexpand_nested\nsummary()\nTrue\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet-1k), or the path to the weights\nfile to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding3D",
    "content": "Zero-padding layer for 3D data (spatial or spatio-temporal).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ZeroPadding3D ( padding = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None , ** kwargs )\ntf . keras . layers . ZeroPadding3D ( padding = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None , ** kwargs )\ninput_shape = ( 1 , 1 , 2 , 2 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) y = keras . layers . ZeroPadding3D ( padding = 2 )( x ) y . shape ( 1 , 5 , 6 , 6 , 3 )\ninput_shape = ( 1 , 1 , 2 , 2 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\ny = keras . layers . ZeroPadding3D ( padding = 2 )( x )\ny . shape\n( 1 , 5 , 6 , 6 , 3 )\nArgs\nArgs\npadding Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\npadding\nIf int: the same symmetric padding is applied to depth, height,\nand width.\nIf tuple of 3 ints: interpreted as three different symmetric\npadding values for depth, height, and width: (symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad) .\n(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)\nIf tuple of 3 tuples of 2 ints: interpreted as ((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\nright_dim2_pad), (left_dim3_pad, right_dim3_pad)) . data_format A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nWhen unspecified, uses image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json (if exists). Defaults to \"channels_last\" .\n((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\nright_dim2_pad), (left_dim3_pad, right_dim3_pad))\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nInput shape 5D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, first_axis_to_pad, second_axis_to_pad,\nthird_axis_to_pad, depth)\ndata_format\n\"channels_last\"\n(batch_size, first_axis_to_pad, second_axis_to_pad,\nthird_axis_to_pad, depth)\nIf data_format is \"channels_first\" : (batch_size, depth, first_axis_to_pad, second_axis_to_pad,\nthird_axis_to_pad)\ndata_format\n\"channels_first\"\n(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\nthird_axis_to_pad)\nOutput shape 5D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, first_padded_axis, second_padded_axis,\nthird_axis_to_pad, depth)\ndata_format\n\"channels_last\"\n(batch_size, first_padded_axis, second_padded_axis,\nthird_axis_to_pad, depth)\nIf data_format is \"channels_first\" : (batch_size, depth, first_padded_axis, second_padded_axis,\nthird_axis_to_pad)\ndata_format\n\"channels_first\"\n(batch_size, depth, first_padded_axis, second_padded_axis,\nthird_axis_to_pad)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the MNIST dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . xception . preprocess_input ( x , data_format = None )\ntf . keras . applications . xception . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B0",
    "content": "Instantiates the EfficientNetV2B0 architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2B0\ntf.keras.applications.efficientnet_v2.EfficientNetV2B0\ntf.keras.applications.efficientnet_v2.EfficientNetV2B0\ntf . keras . applications . EfficientNetV2B0 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2B0 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy",
    "content": "Computes the crossentropy loss between the labels and predictions.\nInherits From: Loss\nLoss\ntf . keras . losses . CategoricalCrossentropy ( from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'categorical_crossentropy' )\ntf . keras . losses . CategoricalCrossentropy ( from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'categorical_crossentropy' )\nUsed in the notebooks\nEffective Tensorflow 2\nDebug a TensorFlow 2 migrated training pipeline\nAdversarial example using FGSM\nRetraining an Image Classifier\nImplement Differential Privacy with TensorFlow Privacy\nAssess privacy risks with the TensorFlow Privacy Report\nOn-Device Training with TensorFlow Lite\nUse this crossentropy loss function when there are two or more label\nclasses. We expect labels to be provided in a one_hot representation. If\nyou want to provide labels as integers, please use SparseCategoricalCrossentropy loss. There should be num_classes floating\npoint values per feature, i.e., the shape of both y_pred and y_true are [batch_size, num_classes] .\none_hot\nSparseCategoricalCrossentropy\nnum_classes\ny_pred\ny_true\n[batch_size, num_classes]\nArgs\nArgs\nfrom_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. label_smoothing Float in [0, 1]. When > 0, label values are smoothed,\nmeaning the confidence on label values are relaxed. For example, if 0.1 , use 0.1 / num_classes for non-target labels and 0.9 + 0.1 / num_classes for target labels. axis The axis along which to compute crossentropy (the features\naxis). Defaults to -1 . reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\n0.1\n0.1 / num_classes\n0.9 + 0.1 / num_classes\naxis\n-1\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # Using 'auto'/'sum_over_batch_size' reduction type. cce = keras . losses . CategoricalCrossentropy () cce ( y_true , y_pred ) 1.177\ny_true = [[ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]\ny_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]\n# Using 'auto'/'sum_over_batch_size' reduction type.\ncce = keras . losses . CategoricalCrossentropy ()\ncce ( y_true , y_pred )\n1.177\n# Calling with 'sample_weight'. cce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ])) 0.814\n# Calling with 'sample_weight'.\ncce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ]))\n0.814\n# Using 'sum' reduction type. cce = keras . losses . CategoricalCrossentropy ( reduction = \"sum\" ) cce ( y_true , y_pred ) 2.354\n# Using 'sum' reduction type.\ncce = keras . losses . CategoricalCrossentropy (\nreduction = \"sum\" )\ncce ( y_true , y_pred )\n2.354\n# Using 'none' reduction type. cce = keras . losses . CategoricalCrossentropy ( reduction = None ) cce ( y_true , y_pred ) array ([ 0.0513 , 2.303 ], dtype = float32 )\n# Using 'none' reduction type.\ncce = keras . losses . CategoricalCrossentropy (\nreduction = None )\ncce ( y_true , y_pred )\narray ([ 0.0513 , 2.303 ], dtype = float32 )\nUsage with the compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = keras . losses . CategoricalCrossentropy ())\nmodel . compile ( optimizer = 'sgd' , loss = keras . losses . CategoricalCrossentropy ())\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . mobilenet_v2 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . mobilenet_v2 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/legacy/saving/serialize_keras_object",
    "content": "Serialize a Keras object into a JSON-compatible representation.\nMain aliases tf.keras.utils.legacy.serialize_keras_object\ntf.keras.utils.legacy.serialize_keras_object\ntf.keras.utils.legacy.serialize_keras_object\ntf . keras . legacy . saving . serialize_keras_object ( instance )\ntf . keras . legacy . saving . serialize_keras_object ( instance )\nCalls to serialize_keras_object while underneath the SharedObjectSavingScope context manager will cause any objects re-used\nacross multiple layers to be saved with a special shared object ID. This\nallows the network to be re-created properly during deserialization.\nserialize_keras_object\nSharedObjectSavingScope\nArgs\nArgs\ninstance The object to serialize.\ninstance\nReturns A dict-like, JSON-compatible representation of the object's config.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cumsum",
    "content": "Returns the cumulative sum of elements along a given axis.\nMain aliases tf.keras.ops.numpy.cumsum\ntf.keras.ops.numpy.cumsum\ntf.keras.ops.numpy.cumsum\ntf . keras . ops . cumsum ( x , axis = None , dtype = None )\ntf . keras . ops . cumsum ( x , axis = None , dtype = None )\nArgs\nArgs\nx Input tensor. axis Axis along which the cumulative sum is computed.\nBy default the input is flattened. dtype dtype of returned tensor. Defaults to x.dtype.\nx\naxis\ndtype\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/average",
    "content": "Functional interface to the keras.layers.Average layer.\nkeras.layers.Average\ntf . keras . layers . average ( inputs , ** kwargs )\ntf . keras . layers . average ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors , all of the same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the element-wise product of the inputs with the same\nshape as the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . average ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . average ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) y = keras . layers . average ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\ny = keras . layers . average ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D",
    "content": "2D separable convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.SeparableConvolution2D\ntf.keras.layers.SeparableConvolution2D\ntf.keras.layers.SeparableConvolution2D\ntf . keras . layers . SeparableConv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), depth_multiplier = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , pointwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , pointwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , pointwise_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . SeparableConv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), depth_multiplier = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , pointwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , pointwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , pointwise_constraint = None , bias_constraint = None , ** kwargs )\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf use_bias is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\nuse_bias\nArgs\nArgs\nfilters int, the dimensionality of the output space (i.e. the number\nof filters in the pointwise convolution). kernel_size int or tuple/list of 2 integers, specifying the size of the\ndepthwise convolution window. strides int or tuple/list of 2 integers, specifying the stride length\nof the depthwise convolution. If only one int is specified, the same\nstride size will be used for all dimensions. strides > 1 is\nincompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file\nat ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 2 integers, specifying the dilation\nrate to use for dilated convolution. If only one int is specified,\nthe same dilation rate will be used for all dimensions. depth_multiplier The number of depthwise convolution output channels\nfor each input channel. The total number of depthwise convolution\noutput channels will be equal to input_channel * depth_multiplier . activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. depthwise_initializer An initializer for the depthwise convolution\nkernel. If None, then the default initializer ( \"glorot_uniform\" )\nwill be used. pointwise_initializer An initializer for the pointwise convolution\nkernel. If None, then the default initializer ( \"glorot_uniform\" )\nwill be used. bias_initializer An initializer for the bias vector. If None, the\ndefault initializer ('\"zeros\"') will be used. depthwise_regularizer Optional regularizer for the depthwise\nconvolution kernel. pointwise_regularizer Optional regularizer for the pointwise\nconvolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. depthwise_constraint Optional projection function to be applied to the\ndepthwise kernel after being updated by an Optimizer (e.g. used\nfor norm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). pointwise_constraint Optional projection function to be applied to the\npointwise kernel after being updated by an Optimizer . bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\ndepth_multiplier\ninput_channel * depth_multiplier\nactivation\nNone\nuse_bias\nTrue\ndepthwise_initializer\n\"glorot_uniform\"\npointwise_initializer\n\"glorot_uniform\"\nbias_initializer\ndepthwise_regularizer\npointwise_regularizer\nbias_regularizer\nactivity_regularizer\ndepthwise_constraint\nOptimizer\npointwise_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, height, width, channels)\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, channels, height, width)\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, new_height, new_width, filters)\ndata_format=\"channels_last\"\n(batch_size, new_height, new_width, filters)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, filters, new_height, new_width)\ndata_format=\"channels_first\"\n(batch_size, filters, new_height, new_width)\nReturns A 4D tensor representing activation(separable_conv2d(inputs, kernel) + bias) .\nReturns\nactivation(separable_conv2d(inputs, kernel) + bias)\nx = np . random . rand ( 4 , 10 , 10 , 12 ) y = keras . layers . SeparableConv2D ( 3 , 4 , 3 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 4 , 4 , 4 )\nx = np . random . rand ( 4 , 10 , 10 , 12 )\ny = keras . layers . SeparableConv2D ( 3 , 4 , 3 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 4 , 4 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/max_pool",
    "content": "Max pooling operation.\nMain aliases tf.keras.ops.nn.max_pool\ntf.keras.ops.nn.max_pool\ntf.keras.ops.nn.max_pool\ntf . keras . ops . max_pool ( inputs , pool_size , strides = None , padding = 'valid' , data_format = None )\ntf . keras . ops . max_pool ( inputs , pool_size , strides = None , padding = 'valid' , data_format = None )\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . Pooling happens over the spatial\ndimensions only. pool_size int or tuple/list of integers of size len(inputs_spatial_shape) , specifying the size of the pooling\nwindow for each spatial dimension of the input tensor. If pool_size is int, then every spatial dimension shares the same pool_size . strides int or tuple/list of integers of size len(inputs_spatial_shape) . The stride of the sliding window for\neach spatial dimension of the input tensor. If strides is int,\nthen every spatial dimension shares the same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\npool_size\nlen(inputs_spatial_shape)\npool_size\npool_size\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\nReturns A tensor of rank N+2, the result of the max pooling operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed",
    "content": "Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).\ntf . keras . utils . set_random_seed ( seed )\ntf . keras . utils . set_random_seed ( seed )\nUsed in the notebooks\nUse TF1.x models in TF2 workflows\nUsing DTensors with Keras\nYou can use this utility to make almost any Keras program fully\ndeterministic. Some limitations apply in cases where network communications\nare involved (e.g. parameter server distribution), which creates additional\nsources of randomness, or when certain non-deterministic cuDNN ops are\ninvolved.\nCalling this utility is equivalent to the following:\nimport random random . seed ( seed ) import numpy as np np . random . seed ( seed ) import tensorflow as tf # Only if TF is installed tf . random . set_seed ( seed ) import torch # Only if the backend is 'torch' torch . manual_seed ( seed )\nimport random random . seed ( seed ) import numpy as np np . random . seed ( seed ) import tensorflow as tf # Only if TF is installed tf . random . set_seed ( seed ) import torch # Only if the backend is 'torch' torch . manual_seed ( seed )\nNote that the TensorFlow seed is set even if you're not using TensorFlow\nas your backend framework, since many workflows leverage tf.data pipelines (which feature random shuffling). Likewise many workflows\nmight leverage NumPy APIs.\ntf.data\nArguments\nArguments\nseed Integer, the random seed to use.\nseed"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/spatial_2d_padding",
    "content": "DEPRECATED.\ntf . keras . backend . spatial_2d_padding ( x , padding = (( 1 , 1 ), ( 1 , 1 )), data_format = None )\ntf . keras . backend . spatial_2d_padding ( x , padding = (( 1 , 1 ), ( 1 , 1 )), data_format = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/get_word_index",
    "content": "Retrieves a dict mapping words to their index in the IMDB dataset.\ntf . keras . datasets . imdb . get_word_index ( path = 'imdb_word_index.json' )\ntf . keras . datasets . imdb . get_word_index ( path = 'imdb_word_index.json' )\nArgs\nArgs\npath where to cache the data (relative to ~/.keras/dataset ).\npath\n~/.keras/dataset\nReturns The word index dictionary. Keys are word strings, values are their\nindex.\nReturns\n# Use the default parameters to keras.datasets.imdb.load_data start_char = 1 oov_char = 2 index_from = 3 # Retrieve the training sequences. ( x_train , _ ), _ = keras . datasets . imdb . load_data ( start_char = start_char , oov_char = oov_char , index_from = index_from ) # Retrieve the word index file mapping words to indices word_index = keras . datasets . imdb . get_word_index () # Reverse the word index to obtain a dict mapping indices to words # And add `index_from` to indices to sync with `x_train` inverted_word_index = dict ( ( i + index_from , word ) for ( word , i ) in word_index . items () ) # Update `inverted_word_index` to include `start_char` and `oov_char` inverted_word_index [ start_char ] = \"[START]\" inverted_word_index [ oov_char ] = \"[OOV]\" # Decode the first sequence in the dataset decoded_sequence = \" \" . join ( inverted_word_index [ i ] for i in x_train [ 0 ])\n# Use the default parameters to keras.datasets.imdb.load_data start_char = 1 oov_char = 2 index_from = 3 # Retrieve the training sequences. ( x_train , _ ), _ = keras . datasets . imdb . load_data ( start_char = start_char , oov_char = oov_char , index_from = index_from ) # Retrieve the word index file mapping words to indices word_index = keras . datasets . imdb . get_word_index () # Reverse the word index to obtain a dict mapping indices to words # And add `index_from` to indices to sync with `x_train` inverted_word_index = dict ( ( i + index_from , word ) for ( word , i ) in word_index . items () ) # Update `inverted_word_index` to include `start_char` and `oov_char` inverted_word_index [ start_char ] = \"[START]\" inverted_word_index [ oov_char ] = \"[OOV]\" # Decode the first sequence in the dataset decoded_sequence = \" \" . join ( inverted_word_index [ i ] for i in x_train [ 0 ])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/concatenate",
    "content": "DEPRECATED.\ntf . keras . backend . concatenate ( tensors , axis =- 1 )\ntf . keras . backend . concatenate ( tensors , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/truncated_normal",
    "content": "DEPRECATED.\ntf . keras . backend . truncated_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\ntf . keras . backend . truncated_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization",
    "content": "Layer normalization layer (Ba et al., 2016).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . LayerNormalization ( axis =- 1 , epsilon = 0.001 , center = True , scale = True , rms_scaling = False , beta_initializer = 'zeros' , gamma_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , ** kwargs )\ntf . keras . layers . LayerNormalization ( axis =- 1 , epsilon = 0.001 , center = True , scale = True , rms_scaling = False , beta_initializer = 'zeros' , gamma_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , ** kwargs )\nUsed in the notebooks\nImage captioning with visual attention\nNeural machine translation with a Transformer and Keras\nNeural machine translation with attention\nNormalize the activations of the previous layer for each given example in a\nbatch independently, rather than across a batch like Batch Normalization.\ni.e. applies a transformation that maintains the mean activation within each\nexample close to 0 and the activation standard deviation close to 1.\nIf scale or center are enabled, the layer will scale the normalized\noutputs by broadcasting them with a trainable variable gamma , and center\nthe outputs by broadcasting with a trainable variable beta . gamma will\ndefault to a ones tensor and beta will default to a zeros tensor, so that\ncentering and scaling are no-ops before training has begun.\nscale\ncenter\ngamma\nbeta\ngamma\nbeta\nSo, with scaling and centering enabled the normalization equations\nare as follows:\nLet the intermediate activations for a mini-batch to be the inputs .\ninputs\nFor each sample x_i in inputs with k features, we compute the mean and\nvariance of the sample:\nx_i\ninputs\nk\nmean_i = sum ( x_i [ j ] for j in range ( k )) / k var_i = sum (( x_i [ j ] - mean_i ) ** 2 for j in range ( k )) / k\nmean_i = sum ( x_i [ j ] for j in range ( k )) / k var_i = sum (( x_i [ j ] - mean_i ) ** 2 for j in range ( k )) / k\nand then compute a normalized x_i_normalized , including a small factor epsilon for numerical stability.\nx_i_normalized\nepsilon\nx_i_normalized = ( x_i - mean_i ) / sqrt ( var_i + epsilon )\nx_i_normalized = ( x_i - mean_i ) / sqrt ( var_i + epsilon )\nAnd finally x_i_normalized is linearly transformed by gamma and beta ,\nwhich are learned parameters:\nx_i_normalized\ngamma\nbeta\noutput_i = x_i_normalized * gamma + beta\noutput_i = x_i_normalized * gamma + beta\ngamma and beta will span the axes of inputs specified in axis , and\nthis part of the inputs' shape must be fully defined.\ngamma\nbeta\ninputs\naxis\nlayer = keras . layers . LayerNormalization ( axis = [ 1 , 2 , 3 ]) layer . build ([ 5 , 20 , 30 , 40 ]) print ( layer . beta . shape ) ( 20 , 30 , 40 ) print ( layer . gamma . shape ) ( 20 , 30 , 40 )\nlayer = keras . layers . LayerNormalization ( axis = [ 1 , 2 , 3 ])\nlayer . build ([ 5 , 20 , 30 , 40 ])\nprint ( layer . beta . shape )\n( 20 , 30 , 40 )\nprint ( layer . gamma . shape )\n( 20 , 30 , 40 )\nNote that other implementations of layer normalization may choose to define gamma and beta over a separate set of axes from the axes being\nnormalized across. For example, Group Normalization\n( Wu et al. 2018 ) with group size of 1\ncorresponds to a Layer Normalization that normalizes across height, width,\nand channel and has gamma and beta span only the channel dimension.\nSo, this Layer Normalization implementation will not match a Group\nNormalization layer with group size set to 1.\ngamma\nbeta\ngamma\nbeta\nArgs\nArgs\naxis Integer or List/Tuple. The axis or axes to normalize across.\nTypically, this is the features axis/axes. The left-out axes are\ntypically the batch axis/axes. -1 is the last dimension in the\ninput. Defaults to -1 . epsilon Small float added to variance to avoid dividing by zero.\nDefaults to 1e-3. center If True, add offset of beta to normalized tensor. If False, beta is ignored. Defaults to True . scale If True, multiply by gamma . If False, gamma is not used.\nWhen the next layer is linear (also e.g. nn.relu ), this can be\ndisabled since the scaling will be done by the next layer.\nDefaults to True . rms_scaling If True, center and scale are ignored, and the\ninputs are scaled by gamma and the inverse square root\nof the square of all inputs. This is an approximate and faster\napproach that avoids ever computing the mean of the input. beta_initializer Initializer for the beta weight. Defaults to zeros. gamma_initializer Initializer for the gamma weight. Defaults to ones. beta_regularizer Optional regularizer for the beta weight.\nNone by default. gamma_regularizer Optional regularizer for the gamma weight.\nNone by default. beta_constraint Optional constraint for the beta weight.\nNone by default. gamma_constraint Optional constraint for the gamma weight.\nNone by default. **kwargs Base layer keyword arguments (e.g. name and dtype ).\naxis\n-1\n-1\nepsilon\ncenter\nbeta\nbeta\nTrue\nscale\ngamma\ngamma\nnn.relu\nTrue\nrms_scaling\ncenter\nscale\ngamma\nbeta_initializer\ngamma_initializer\nbeta_regularizer\ngamma_regularizer\nbeta_constraint\ngamma_constraint\n**kwargs\nname\ndtype\nLei Ba et al., 2016 .\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/FBetaScore",
    "content": "Computes F-Beta score.\nInherits From: Metric\nMetric\ntf . keras . metrics . FBetaScore ( average = None , beta = 1.0 , threshold = None , name = 'fbeta_score' , dtype = None )\ntf . keras . metrics . FBetaScore ( average = None , beta = 1.0 , threshold = None , name = 'fbeta_score' , dtype = None )\nb2 = beta ** 2 f_beta_score = ( 1 + b2 ) * ( precision * recall ) / ( precision * b2 + recall )\nb2 = beta ** 2 f_beta_score = ( 1 + b2 ) * ( precision * recall ) / ( precision * b2 + recall )\nThis is the weighted harmonic mean of precision and recall.\nIts output range is [0, 1] . It works for both multi-class\nand multi-label classification.\n[0, 1]\nArgs\nArgs\naverage Type of averaging to be performed across per-class results\nin the multi-class case.\nAcceptable values are None , \"micro\" , \"macro\" and \"weighted\" . Defaults to None .\nIf None , no averaging is performed and result() will return\nthe score for each class.\nIf \"micro\" , compute metrics globally by counting the total\ntrue positives, false negatives and false positives.\nIf \"macro\" , compute metrics for each label,\nand return their unweighted mean.\nThis does not take label imbalance into account.\nIf \"weighted\" , compute metrics for each label,\nand return their average weighted by support\n(the number of true instances for each label).\nThis alters \"macro\" to account for label imbalance.\nIt can result in an score that is not between precision and recall. beta Determines the weight of given to recall\nin the harmonic mean between precision and recall (see pseudocode\nequation above). Defaults to 1 . threshold Elements of y_pred greater than threshold are\nconverted to be 1, and the rest 0. If threshold is None , the argmax of y_pred is converted to 1, and the rest to 0. name Optional. String name of the metric instance. dtype Optional. Data type of the metric result.\naverage\nNone\n\"micro\"\n\"macro\"\n\"weighted\"\nNone\nNone\nresult()\n\"micro\"\n\"macro\"\n\"weighted\"\n\"macro\"\nbeta\n1\nthreshold\ny_pred\nthreshold\nthreshold\nNone\ny_pred\nname\ndtype\nReturns F-Beta Score: float.\nReturns\nmetric = keras . metrics . FBetaScore ( beta = 2.0 , threshold = 0.5 ) y_true = np . array ([[ 1 , 1 , 1 ], [ 1 , 0 , 0 ], [ 1 , 1 , 0 ]], np . int32 ) y_pred = np . array ([[ 0.2 , 0.6 , 0.7 ], [ 0.2 , 0.6 , 0.6 ], [ 0.6 , 0.8 , 0.0 ]], np . float32 ) metric . update_state ( y_true , y_pred ) result = metric . result () result [ 0.3846154 , 0.90909094 , 0.8333334 ]\nmetric = keras . metrics . FBetaScore ( beta = 2.0 , threshold = 0.5 )\ny_true = np . array ([[ 1 , 1 , 1 ],\n[ 1 , 0 , 0 ],\n[ 1 , 1 , 0 ]], np . int32 )\ny_pred = np . array ([[ 0.2 , 0.6 , 0.7 ],\n[ 0.2 , 0.6 , 0.6 ],\n[ 0.6 , 0.8 , 0.0 ]], np . float32 )\nmetric . update_state ( y_true , y_pred )\nresult = metric . result ()\nresult\n[ 0.3846154 , 0.90909094 , 0.8333334 ]\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/is_tensor",
    "content": "Check whether the given object is a tensor.\ntf . keras . ops . is_tensor ( x )\ntf . keras . ops . is_tensor ( x )\nFalse\nArgs\nArgs\nx A variable.\nx\nReturns True if x is a tensor, otherwise False .\nReturns\nTrue\nx\nFalse"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/fft",
    "content": "Computes the Fast Fourier Transform along last axis of input.\ntf . keras . ops . fft ( x )\ntf . keras . ops . fft ( x )\nArgs\nArgs\nx Tuple of the real and imaginary parts of the input tensor. Both\ntensors in the tuple should be of floating type.\nx\nReturns A tuple containing two tensors - the real and imaginary parts of the\noutput tensor.\nReturns\nx = ( keras . ops . convert_to_tensor ([ 1. , 2. ]), keras . ops . convert_to_tensor ([ 0. , 1. ]), ) fft ( x ) ( array ([ 3. , - 1. ], dtype = float32 ), array ([ 1. , - 1. ], dtype = float32 ))\nx = (\nkeras . ops . convert_to_tensor ([ 1. , 2. ]),\nkeras . ops . convert_to_tensor ([ 0. , 1. ]),\n)\nfft ( x )\n( array ([ 3. , - 1. ], dtype = float32 ), array ([ 1. , - 1. ], dtype = float32 ))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . mobilenet_v3 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . mobilenet_v3 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup",
    "content": "A preprocessing layer that maps strings to (possibly encoded) indices.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . StringLookup ( max_tokens = None , num_oov_indices = 1 , mask_token = None , oov_token = '[UNK]' , vocabulary = None , idf_weights = None , invert = False , output_mode = 'int' , pad_to_max_tokens = False , sparse = False , encoding = 'utf-8' , name = None , ** kwargs )\ntf . keras . layers . StringLookup ( max_tokens = None , num_oov_indices = 1 , mask_token = None , oov_token = '[UNK]' , vocabulary = None , idf_weights = None , invert = False , output_mode = 'int' , pad_to_max_tokens = False , sparse = False , encoding = 'utf-8' , name = None , ** kwargs )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nWorking with preprocessing layers\nParameter server training with ParameterServerStrategy\nLoad a pandas DataFrame\nDistributed Input\nLoad CSV data\nClassify structured data using Keras preprocessing layers\nThis layer translates a set of arbitrary strings into integer output via a\ntable-based vocabulary lookup. This layer will perform no splitting or\ntransformation of input strings. For a layer than can split and tokenize\nnatural language, see the keras.layers.TextVectorization layer.\nkeras.layers.TextVectorization\nThe vocabulary for the layer must be either supplied on construction or\nlearned via adapt() . During adapt() , the layer will analyze a data set,\ndetermine the frequency of individual strings tokens, and create a\nvocabulary from them. If the vocabulary is capped in size, the most frequent\ntokens will be used to create the vocabulary and all others will be treated\nas out-of-vocabulary (OOV).\nadapt()\nadapt()\nThere are two possible output modes for the layer.\nWhen output_mode is \"int\" ,\ninput strings are converted to their index in the vocabulary (an integer).\nWhen output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" , input strings\nare encoded into an array where each dimension corresponds to an element in\nthe vocabulary.\noutput_mode\n\"int\"\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nThe vocabulary can optionally contain a mask token as well as an OOV token\n(which can optionally occupy multiple indices in the vocabulary, as set\nby num_oov_indices ).\nThe position of these tokens in the vocabulary is fixed. When output_mode is \"int\" , the vocabulary will begin with the mask token (if set), followed\nby OOV indices, followed by the rest of the vocabulary. When output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" the vocabulary will begin with\nOOV indices and instances of the mask token will be dropped.\nnum_oov_indices\noutput_mode\n\"int\"\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\ntf.data\nArgs\nArgs\nmax_tokens Maximum size of the vocabulary for this layer. This should\nonly be specified when adapting the vocabulary or when setting pad_to_max_tokens=True . If None, there is no cap on the size of\nthe vocabulary. Note that this size includes the OOV\nand mask tokens. Defaults to None . num_oov_indices The number of out-of-vocabulary tokens to use.\nIf this value is more than 1, OOV inputs are modulated to\ndetermine their OOV value.\nIf this value is 0, OOV inputs will cause an error when calling\nthe layer. Defaults to 1 . mask_token A token that represents masked inputs. When output_mode is \"int\" , the token is included in vocabulary and mapped to index 0.\nIn other output modes, the token will not appear\nin the vocabulary and instances of the mask token\nin the input will be dropped. If set to None ,\nno mask term will be added. Defaults to None . oov_token Only used when invert is True. The token to return for OOV\nindices. Defaults to \"[UNK]\" . vocabulary Optional. Either an array of integers or a string path to a\ntext file. If passing an array, can pass a tuple, list,\n1D NumPy array, or 1D tensor containing the integer vocbulary terms.\nIf passing a file path, the file should contain one line per term\nin the vocabulary. If this argument is set,\nthere is no need to adapt() the layer. vocabulary_dtype The dtype of the vocabulary terms, for example \"int64\" or \"int32\" . Defaults to \"int64\" . idf_weights Only valid when output_mode is \"tf_idf\" .\nA tuple, list, 1D NumPy array, or 1D tensor or the same length\nas the vocabulary, containing the floating point inverse document\nfrequency weights, which will be multiplied by per sample term\ncounts for the final TF-IDF weight.\nIf the vocabulary argument is set, and output_mode is \"tf_idf\" , this argument must be supplied. invert Only valid when output_mode is \"int\" .\nIf True , this layer will map indices to vocabulary items\ninstead of mapping vocabulary items to indices.\nDefaults to False . output_mode Specification for the output of the layer. Values can be \"int\" , \"one_hot\" , \"multi_hot\" , \"count\" , or \"tf_idf\" configuring the layer as follows:\nmax_tokens\npad_to_max_tokens=True\nNone\nnum_oov_indices\n1\nmask_token\noutput_mode\n\"int\"\nNone\nNone\noov_token\ninvert\n\"[UNK]\"\nvocabulary\nadapt()\nvocabulary_dtype\n\"int64\"\n\"int32\"\n\"int64\"\nidf_weights\noutput_mode\n\"tf_idf\"\nvocabulary\noutput_mode\n\"tf_idf\"\ninvert\noutput_mode\n\"int\"\nTrue\nFalse\noutput_mode\n\"int\"\n\"one_hot\"\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\n\"int\" : Return the vocabulary indices of the input tokens.\n\"int\"\n\"one_hot\" : Encodes each individual element in the input into an\narray the same size as the vocabulary,\ncontaining a 1 at the element index. If the last dimension\nis size 1, will encode on that dimension.\nIf the last dimension is not size 1, will append a new\ndimension for the encoded output.\n\"one_hot\"\n\"multi_hot\" : Encodes each sample in the input into a single\narray the same size as the vocabulary,\ncontaining a 1 for each vocabulary term present in the sample.\nTreats the last dimension as the sample dimension,\nif input shape is (..., sample_length) ,\noutput shape will be (..., num_tokens) .\n\"multi_hot\"\n(..., sample_length)\n(..., num_tokens)\n\"count\" : As \"multi_hot\" , but the int array contains\na count of the number of times the token at that index\nappeared in the sample.\n\"count\"\n\"multi_hot\"\n\"tf_idf\" : As \"multi_hot\" , but the TF-IDF algorithm is\napplied to find the value in each token slot.\nFor \"int\" output, any shape of input and output is supported.\nFor all other output modes, currently only output up to rank 2\nis supported. Defaults to \"int\" . pad_to_max_tokens Only applicable when output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" . If True , the output will have\nits feature axis padded to max_tokens even if the number\nof unique tokens in the vocabulary is less than max_tokens ,\nresulting in a tensor of shape (batch_size, max_tokens) regardless of vocabulary size. Defaults to False . sparse Boolean. Only applicable to \"multi_hot\" , \"count\" , and \"tf_idf\" output modes. Only supported with TensorFlow\nbackend. If True , returns a SparseTensor instead of a dense Tensor . Defaults to False . encoding Optional. The text encoding to use to interpret the input\nstrings. Defaults to \"utf-8\" .\n\"tf_idf\"\n\"multi_hot\"\n\"int\"\n\"int\"\npad_to_max_tokens\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nmax_tokens\nmax_tokens\n(batch_size, max_tokens)\nFalse\nsparse\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nSparseTensor\nTensor\nFalse\nencoding\n\"utf-8\"\nCreating a lookup layer with a known vocabulary\nThis example creates a lookup layer with a pre-existing vocabulary.\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]] layer = StringLookup ( vocabulary = vocab ) layer ( data ) array ([[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]])\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]]\nlayer = StringLookup ( vocabulary = vocab )\nlayer ( data )\narray ([[ 1 , 3 , 4 ],\n[ 4 , 0 , 2 ]])\nCreating a lookup layer with an adapted vocabulary\nThis example creates a lookup layer and generates the vocabulary by\nanalyzing the dataset.\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]] layer = StringLookup () layer . adapt ( data ) layer . get_vocabulary () [ '[UNK]' , 'd' , 'z' , 'c' , 'b' , 'a' ]\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]]\nlayer = StringLookup ()\nlayer . adapt ( data )\nlayer . get_vocabulary ()\n[ '[UNK]' , 'd' , 'z' , 'c' , 'b' , 'a' ]\nNote that the OOV token \"[UNK]\" has been added to the vocabulary.\nThe remaining tokens are sorted by frequency\n( \"d\" , which has 2 occurrences, is first) then by inverse sort order.\n\"[UNK]\"\n\"d\"\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]] layer = StringLookup () layer . adapt ( data ) layer ( data ) array ([[ 5 , 3 , 1 ], [ 1 , 2 , 4 ]])\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]]\nlayer = StringLookup ()\nlayer . adapt ( data )\nlayer ( data )\narray ([[ 5 , 3 , 1 ],\n[ 1 , 2 , 4 ]])\nLookups with multiple OOV indices\nThis example demonstrates how to use a lookup layer with multiple OOV\nindices.  When a layer is created with more than one OOV index, any OOV\nvalues are hashed into the number of OOV buckets, distributing OOV values in\na deterministic fashion across the set.\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ \"a\" , \"c\" , \"d\" ], [ \"m\" , \"z\" , \"b\" ]] layer = StringLookup ( vocabulary = vocab , num_oov_indices = 2 ) layer ( data ) array ([[ 2 , 4 , 5 ], [ 0 , 1 , 3 ]])\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"m\" , \"z\" , \"b\" ]]\nlayer = StringLookup ( vocabulary = vocab , num_oov_indices = 2 )\nlayer ( data )\narray ([[ 2 , 4 , 5 ],\n[ 0 , 1 , 3 ]])\nNote that the output for OOV value 'm' is 0, while the output for OOV value \"z\" is 1. The in-vocab terms have their output index increased by 1 from\nearlier examples (a maps to 2, etc) in order to make space for the extra OOV\nvalue.\n\"z\"\nOne-hot output\nConfigure the layer with output_mode='one_hot' . Note that the first num_oov_indices dimensions in the ont_hot encoding represent OOV values.\noutput_mode='one_hot'\nnum_oov_indices\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [ \"a\" , \"b\" , \"c\" , \"d\" , \"z\" ] layer = StringLookup ( vocabulary = vocab , output_mode = 'one_hot' ) layer ( data ) array ([[ 0. , 1. , 0. , 0. , 0. ], [ 0. , 0. , 1. , 0. , 0. ], [ 0. , 0. , 0. , 1. , 0. ], [ 0. , 0. , 0. , 0. , 1. ], [ 1. , 0. , 0. , 0. , 0. ]], dtype = float32 )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [ \"a\" , \"b\" , \"c\" , \"d\" , \"z\" ]\nlayer = StringLookup ( vocabulary = vocab , output_mode = 'one_hot' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 0. , 0. ],\n[ 0. , 0. , 1. , 0. , 0. ],\n[ 0. , 0. , 0. , 1. , 0. ],\n[ 0. , 0. , 0. , 0. , 1. ],\n[ 1. , 0. , 0. , 0. , 0. ]], dtype = float32 )\nMulti-hot output\nConfigure the layer with output_mode='multi_hot' . Note that the first num_oov_indices dimensions in the multi_hot encoding represent OOV values.\noutput_mode='multi_hot'\nnum_oov_indices\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]] layer = StringLookup ( vocabulary = vocab , output_mode = 'multi_hot' ) layer ( data ) array ([[ 0. , 1. , 0. , 1. , 1. ], [ 1. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]]\nlayer = StringLookup ( vocabulary = vocab , output_mode = 'multi_hot' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 1. , 1. ],\n[ 1. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nToken count output\nConfigure the layer with output_mode='count' . As with multi_hot output,\nthe first num_oov_indices dimensions in the output represent OOV values.\noutput_mode='count'\nnum_oov_indices\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]] layer = StringLookup ( vocabulary = vocab , output_mode = 'count' ) layer ( data ) array ([[ 0. , 1. , 0. , 1. , 2. ], [ 2. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]]\nlayer = StringLookup ( vocabulary = vocab , output_mode = 'count' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 1. , 2. ],\n[ 2. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nTF-IDF output\nConfigure the layer with output_mode=\"tf_idf\" . As with multi_hot output,\nthe first num_oov_indices dimensions in the output represent OOV values.\noutput_mode=\"tf_idf\"\nnum_oov_indices\nEach token bin will output token_count * idf_weight , where the idf weights\nare the inverse document frequency weights per token. These should be\nprovided along with the vocabulary. Note that the idf_weight for OOV\nvalues will default to the average of all idf weights passed in.\ntoken_count * idf_weight\nidf_weight\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] idf_weights = [ 0.25 , 0.75 , 0.6 , 0.4 ] data = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]] layer = StringLookup ( output_mode = \"tf_idf\" ) layer . set_vocabulary ( vocab , idf_weights = idf_weights ) layer ( data ) array ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ], [ 1.0 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\nidf_weights = [ 0.25 , 0.75 , 0.6 , 0.4 ]\ndata = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]]\nlayer = StringLookup ( output_mode = \"tf_idf\" )\nlayer . set_vocabulary ( vocab , idf_weights = idf_weights )\nlayer ( data )\narray ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ],\n[ 1.0 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nTo specify the idf weights for oov values, you will need to pass the entire\nvocabulary including the leading oov token.\nvocab = [ \"[UNK]\" , \"a\" , \"b\" , \"c\" , \"d\" ] idf_weights = [ 0.9 , 0.25 , 0.75 , 0.6 , 0.4 ] data = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]] layer = StringLookup ( output_mode = \"tf_idf\" ) layer . set_vocabulary ( vocab , idf_weights = idf_weights ) layer ( data ) array ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ], [ 1.8 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nvocab = [ \"[UNK]\" , \"a\" , \"b\" , \"c\" , \"d\" ]\nidf_weights = [ 0.9 , 0.25 , 0.75 , 0.6 , 0.4 ]\ndata = [[ \"a\" , \"c\" , \"d\" , \"d\" ], [ \"d\" , \"z\" , \"b\" , \"z\" ]]\nlayer = StringLookup ( output_mode = \"tf_idf\" )\nlayer . set_vocabulary ( vocab , idf_weights = idf_weights )\nlayer ( data )\narray ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ],\n[ 1.8 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nWhen adapting the layer in \"tf_idf\" mode, each input sample will be\nconsidered a document, and IDF weight per token will be calculated as log(1 + num_documents / (1 + token_document_count)) .\n\"tf_idf\"\nlog(1 + num_documents / (1 + token_document_count))\nInverse lookup\nThis example demonstrates how to map indices to strings using this layer.\n(You can also use adapt() with inverse=True , but for simplicity we'll\npass the vocab in this example.)\nadapt()\ninverse=True\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]] layer = StringLookup ( vocabulary = vocab , invert = True ) layer ( data ) array ([[ b 'a' , b 'c' , b 'd' ], [ b 'd' , b '[UNK]' , b 'b' ]], dtype = object )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]]\nlayer = StringLookup ( vocabulary = vocab , invert = True )\nlayer ( data )\narray ([[ b 'a' , b 'c' , b 'd' ],\n[ b 'd' , b '[UNK]' , b 'b' ]], dtype = object )\nNote that the first index correspond to the oov token by default.\nForward and inverse lookup pairs\nThis example demonstrates how to use the vocabulary of a standard lookup\nlayer to create an inverse lookup layer.\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ] data = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]] layer = StringLookup ( vocabulary = vocab ) i_layer = StringLookup ( vocabulary = vocab , invert = True ) int_data = layer ( data ) i_layer ( int_data ) array ([[ b 'a' , b 'c' , b 'd' ], [ b 'd' , b '[UNK]' , b 'b' ]], dtype = object )\nvocab = [ \"a\" , \"b\" , \"c\" , \"d\" ]\ndata = [[ \"a\" , \"c\" , \"d\" ], [ \"d\" , \"z\" , \"b\" ]]\nlayer = StringLookup ( vocabulary = vocab )\ni_layer = StringLookup ( vocabulary = vocab , invert = True )\nint_data = layer ( data )\ni_layer ( int_data )\narray ([[ b 'a' , b 'c' , b 'd' ],\n[ b 'd' , b '[UNK]' , b 'b' ]], dtype = object )\nIn this example, the input value \"z\" resulted in an output of \"[UNK]\" ,\nsince 1000 was not in the vocabulary - it got represented as an OOV, and all\nOOV values are returned as \"[UNK]\" in the inverse layer. Also, note that\nfor the inverse to work, you must have already set the forward layer\nvocabulary either directly or via adapt() before calling get_vocabulary() .\n\"z\"\n\"[UNK]\"\n\"[UNK]\"\nadapt()\nget_vocabulary()\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( data , steps = None )\nadapt ( data , steps = None )\nComputes a vocabulary of integer terms from tokens in a dataset.\nCalling adapt() on a StringLookup layer is an alternative to passing\nin a precomputed vocabulary on construction via the vocabulary argument. A StringLookup layer should always be either adapted over a\ndataset or supplied with a vocabulary.\nadapt()\nStringLookup\nvocabulary\nStringLookup\nDuring adapt() , the layer will build a vocabulary of all string tokens\nseen in the dataset, sorted by occurrence count, with ties broken by\nsort order of the tokens (high to low). At the end of adapt() , if max_tokens is set, the vocabulary will be truncated to max_tokens size. For example, adapting a layer with max_tokens=1000 will compute\nthe 1000 most frequent tokens occurring in the input dataset. If output_mode='tf-idf' , adapt() will also learn the document\nfrequencies of each token in the input dataset.\nadapt()\nadapt()\nmax_tokens\nmax_tokens\nmax_tokens=1000\noutput_mode='tf-idf'\nadapt()\nArguments\ndata The data to train on. It can be passed either as a\nbatched tf.data.Dataset , as a list of strings,\nor as a NumPy array. steps Integer or None .\nTotal number of steps (batches of samples) to process.\nIf data is a tf.data.Dataset , and steps is None , adapt() will run until the input dataset is exhausted.\nWhen passing an infinitely\nrepeating dataset, you must specify the steps argument. This\nargument is not supported with array inputs or list inputs.\ndata\ntf.data.Dataset\nsteps\nNone\ndata\ntf.data.Dataset\nsteps\nNone\nadapt()\nsteps\nfinalize_state\nfinalize_state\nView source\nfinalize_state ()\nfinalize_state ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_vocabulary\nget_vocabulary\nView source\nget_vocabulary ( include_special_tokens = True )\nget_vocabulary ( include_special_tokens = True )\nReturns the current vocabulary of the layer.\nArgs\ninclude_special_tokens If True , the returned vocabulary\nwill include mask and OOV tokens,\nand a term's index in the vocabulary\nwill equal the term's index when calling the layer.\nIf False , the returned vocabulary will not include\nany mask or OOV tokens.\ninclude_special_tokens\nTrue\nFalse\nload_assets\nload_assets\nView source\nload_assets ( dir_path )\nload_assets ( dir_path )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nsave_assets\nsave_assets\nView source\nsave_assets ( dir_path )\nsave_assets ( dir_path )\nset_vocabulary\nset_vocabulary\nView source\nset_vocabulary ( vocabulary , idf_weights = None )\nset_vocabulary ( vocabulary , idf_weights = None )\nSets vocabulary (and optionally document frequency) for this layer.\nThis method sets the vocabulary and idf weights for this layer directly,\ninstead of analyzing a dataset through adapt . It should be used\nwhenever the vocab (and optionally document frequency) information is\nalready known.  If vocabulary data is already present in the layer, this\nmethod will replace it.\nadapt\nArgs\nvocabulary Either an array or a string path to a text file.\nIf passing an array, can pass a tuple, list,\n1D numpy array, or 1D tensor containing the vocbulary terms.\nIf passing a file path, the file should contain one line\nper term in the vocabulary. idf_weights A tuple, list, 1D numpy array, or 1D tensor\nof inverse document frequency weights with equal\nlength to vocabulary. Must be set if output_mode is \"tf_idf\" . Should not be set otherwise.\nvocabulary\nidf_weights\noutput_mode\n\"tf_idf\"\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( data )\nupdate_state ( data )\nvocabulary_size\nvocabulary_size\nView source\nvocabulary_size ()\nvocabulary_size ()\nGets the current size of the layer's vocabulary.\nReturns The integer size of the vocabulary, including optional mask and oov\nindices."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_batch_cost",
    "content": "DEPRECATED.\ntf . keras . backend . ctc_batch_cost ( y_true , y_pred , input_length , label_length )\ntf . keras . backend . ctc_batch_cost ( y_true , y_pred , input_length , label_length )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data",
    "content": "Loads the Boston Housing dataset.\ntf . keras . datasets . boston_housing . load_data ( path = 'boston_housing.npz' , test_split = 0.2 , seed = 113 )\ntf . keras . datasets . boston_housing . load_data ( path = 'boston_housing.npz' , test_split = 0.2 , seed = 113 )\nThis is a dataset taken from the StatLib library which is maintained at\nCarnegie Mellon University.\nSamples contain 13 attributes of houses at different locations around the\nBoston suburbs in the late 1970s. Targets are the median values of\nthe houses at a location (in k$).\nThe attributes themselves are defined in the StatLib website .\nArgs\nArgs\npath path where to cache the dataset locally\n(relative to ~/.keras/datasets ). test_split fraction of the data to reserve as test set. seed Random seed for shuffling the data\nbefore computing the test split.\npath\n~/.keras/datasets\ntest_split\nseed\nReturns Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train, x_test : NumPy arrays with shape (num_samples, 13) containing either the training samples (for x_train),\n    or test samples (for y_train).\n(num_samples, 13)\ny_train, y_test : NumPy arrays of shape (num_samples,) containing the\n    target scalars. The targets are float scalars typically between 10 and\n    50 that represent the home prices in k$.\n(num_samples,)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/fft2",
    "content": "Computes the 2D Fast Fourier Transform along the last two axes of input.\ntf . keras . ops . fft2 ( x )\ntf . keras . ops . fft2 ( x )\nArgs\nArgs\nx Tuple of the real and imaginary parts of the input tensor. Both\ntensors in the tuple should be of floating type.\nx\nReturns A tuple containing two tensors - the real and imaginary parts of the\noutput.\nReturns\nx = ( keras . ops . convert_to_tensor ([[ 1. , 2. ], [ 2. , 1. ]]), keras . ops . convert_to_tensor ([[ 0. , 1. ], [ 1. , 0. ]]), ) fft2 ( x ) ( array ([[ 6. , 0. ], [ 0. , - 2. ]], dtype = float32 ), array ([[ 2. , 0. ], [ 0. , - 2. ]], dtype = float32 ))\nx = (\nkeras . ops . convert_to_tensor ([[ 1. , 2. ], [ 2. , 1. ]]),\nkeras . ops . convert_to_tensor ([[ 0. , 1. ], [ 1. , 0. ]]),\n)\nfft2 ( x )\n( array ([[ 6. , 0. ],\n[ 0. , - 2. ]], dtype = float32 ), array ([[ 2. , 0. ],\n[ 0. , - 2. ]], dtype = float32 ))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/argmin",
    "content": "Returns the indices of the minium values along an axis.\nMain aliases tf.keras.ops.numpy.argmin\ntf.keras.ops.numpy.argmin\ntf.keras.ops.numpy.argmin\ntf . keras . ops . argmin ( x , axis = None , keepdims = False )\ntf . keras . ops . argmin ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis By default, the index is into the flattened tensor, otherwise\nalong the specified axis. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one. Defaults to False .\nx\naxis\nkeepdims\nTrue\nFalse\nReturns Tensor of indices. It has the same shape as x , with the dimension\nalong axis removed.\nReturns\nx\naxis\nx = keras . ops . arange ( 6 ) . reshape ( 2 , 3 ) + 10 x array ([[ 10 , 11 , 12 ], [ 13 , 14 , 15 ]], dtype = int32 ) keras . ops . argmin ( x ) array ( 0 , dtype = int32 ) keras . ops . argmin ( x , axis = 0 ) array ([ 0 , 0 , 0 ], dtype = int32 ) keras . ops . argmin ( x , axis = 1 ) array ([ 0 , 0 ], dtype = int32 )\nx = keras . ops . arange ( 6 ) . reshape ( 2 , 3 ) + 10\nx\narray ([[ 10 , 11 , 12 ],\n[ 13 , 14 , 15 ]], dtype = int32 )\nkeras . ops . argmin ( x )\narray ( 0 , dtype = int32 )\nkeras . ops . argmin ( x , axis = 0 )\narray ([ 0 , 0 , 0 ], dtype = int32 )\nkeras . ops . argmin ( x , axis = 1 )\narray ([ 0 , 0 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/stop_gradient",
    "content": "Stops gradient computation.\ntf . keras . ops . stop_gradient ( variable )\ntf . keras . ops . stop_gradient ( variable )\nArgs\nArgs\nvariable A tensor variable for which the gradient\ncomputation is to be disabled.\nvariable\nReturns The variable with gradient computation disabled.\nReturns\nvar = keras . backend . convert_to_tensor ( [ 1. , 2. , 3. ], dtype = \"float32\" ) var = keras . ops . stop_gradient ( var )\nvar = keras . backend . convert_to_tensor (\n[ 1. , 2. , 3. ],\ndtype = \"float32\"\n)\nvar = keras . ops . stop_gradient ( var )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/LecunUniform",
    "content": "Lecun uniform initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.lecun_uniform\ntf.keras.initializers.lecun_uniform\ntf.keras.initializers.lecun_uniform\ntf . keras . initializers . LecunUniform ( seed = None )\ntf . keras . initializers . LecunUniform ( seed = None )\nDraws samples from a uniform distribution within [-limit, limit] , where limit = sqrt(3 / fan_in) ( fan_in is the number of input units in the\nweight tensor).\n[-limit, limit]\nlimit = sqrt(3 / fan_in)\nfan_in\n# Standalone usage: initializer = LecunUniform () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = LecunUniform ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = LecunUniform () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = LecunUniform ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nKlambauer et al., 2017\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization",
    "content": "A preprocessing layer which buckets continuous features by ranges.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Discretization ( bin_boundaries = None , num_bins = None , epsilon = 0.01 , output_mode = 'int' , sparse = False , dtype = None , name = None )\ntf . keras . layers . Discretization ( bin_boundaries = None , num_bins = None , epsilon = 0.01 , output_mode = 'int' , sparse = False , dtype = None , name = None )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nUsing side features: feature preprocessing\nTaking advantage of context features\nBuilding deep retrieval models\nThis layer will place each element of its input data into one of several\ncontiguous ranges and output an integer index indicating which range each\nelement was placed in.\ntf.data\nInput shape Any array of dimension 2 or higher.\nInput shape\nOutput shape Same as input shape.\nOutput shape\nArguments\nArguments\nbin_boundaries A list of bin boundaries.\nThe leftmost and rightmost bins\nwill always extend to -inf and inf ,\nso bin_boundaries=[0., 1., 2.] generates bins (-inf, 0.) , [0., 1.) , [1., 2.) ,\nand [2., +inf) .\nIf this option is set, adapt() should not be called. num_bins The integer number of bins to compute.\nIf this option is set, adapt() should be called to learn the bin boundaries. epsilon Error tolerance, typically a small fraction\nclose to zero (e.g. 0.01). Higher values of epsilon increase\nthe quantile approximation, and hence result in more\nunequal buckets, but could improve performance\nand resource consumption. output_mode Specification for the output of the layer.\nValues can be \"int\" , \"one_hot\" , \"multi_hot\" , or \"count\" configuring the layer as follows:\nbin_boundaries\n-inf\ninf\nbin_boundaries=[0., 1., 2.]\n(-inf, 0.)\n[0., 1.)\n[1., 2.)\n[2., +inf)\nadapt()\nnum_bins\nadapt()\nepsilon\noutput_mode\n\"int\"\n\"one_hot\"\n\"multi_hot\"\n\"count\"\n\"int\" : Return the discretized bin indices directly.\n\"int\"\n\"one_hot\" : Encodes each individual element in the\ninput into an array the same size as num_bins ,\ncontaining a 1 at the input's bin\nindex. If the last dimension is size 1, will encode on that\ndimension.  If the last dimension is not size 1,\nwill append a new dimension for the encoded output.\n\"one_hot\"\nnum_bins\n\"multi_hot\" : Encodes each sample in the input into a\nsingle array the same size as num_bins ,\ncontaining a 1 for each bin index\nindex present in the sample.\nTreats the last dimension as the sample\ndimension, if input shape is (..., sample_length) ,\noutput shape will be (..., num_tokens) .\n\"multi_hot\"\nnum_bins\n(..., sample_length)\n(..., num_tokens)\n\"count\" : As \"multi_hot\" , but the int array contains\na count of the number of times the bin index appeared\nin the sample.\nDefaults to \"int\" . sparse Boolean. Only applicable to \"one_hot\" , \"multi_hot\" ,\nand \"count\" output modes. Only supported with TensorFlow\nbackend. If True , returns a SparseTensor instead of\na dense Tensor . Defaults to False .\n\"count\"\n\"multi_hot\"\n\"int\"\nsparse\n\"one_hot\"\n\"multi_hot\"\n\"count\"\nTrue\nSparseTensor\nTensor\nFalse\nDiscretize float values based on provided buckets.\n>>> input = np . array ([[ - 1.5 , 1.0 , 3.4 , .5 ], [ 0.0 , 3.0 , 1.3 , 0.0 ]]) >>> layer = Discretization ( bin_boundaries = [ 0. , 1. , 2. ]) >>> layer ( input ) array ([[ 0 , 2 , 3 , 1 ], [ 1 , 3 , 2 , 1 ]])\n>>> input = np . array ([[ - 1.5 , 1.0 , 3.4 , .5 ], [ 0.0 , 3.0 , 1.3 , 0.0 ]]) >>> layer = Discretization ( bin_boundaries = [ 0. , 1. , 2. ]) >>> layer ( input ) array ([[ 0 , 2 , 3 , 1 ], [ 1 , 3 , 2 , 1 ]])\nDiscretize float values based on a number of buckets to compute.\n>>> input = np . array ([[ - 1.5 , 1.0 , 3.4 , .5 ], [ 0.0 , 3.0 , 1.3 , 0.0 ]]) >>> layer = Discretization ( num_bins = 4 , epsilon = 0.01 ) >>> layer . adapt ( input ) >>> layer ( input ) array ([[ 0 , 2 , 3 , 2 ], [ 1 , 3 , 3 , 1 ]])\n>>> input = np . array ([[ - 1.5 , 1.0 , 3.4 , .5 ], [ 0.0 , 3.0 , 1.3 , 0.0 ]]) >>> layer = Discretization ( num_bins = 4 , epsilon = 0.01 ) >>> layer . adapt ( input ) >>> layer ( input ) array ([[ 0 , 2 , 3 , 2 ], [ 1 , 3 , 3 , 1 ]])\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( data , steps = None )\nadapt ( data , steps = None )\nComputes bin boundaries from quantiles in a input dataset.\nCalling adapt() on a Discretization layer is an alternative to\npassing in a bin_boundaries argument during construction. A Discretization layer should always be either adapted over a dataset or\npassed bin_boundaries .\nadapt()\nDiscretization\nbin_boundaries\nDiscretization\nbin_boundaries\nDuring adapt() , the layer will estimate the quantile boundaries of the\ninput dataset. The number of quantiles can be controlled via the num_bins argument, and the error tolerance for quantile boundaries can\nbe controlled via the epsilon argument.\nadapt()\nnum_bins\nepsilon\nArguments\ndata The data to train on. It can be passed either as a\nbatched tf.data.Dataset ,\nor as a NumPy array. steps Integer or None .\nTotal number of steps (batches of samples) to process.\nIf data is a tf.data.Dataset , and steps is None , adapt() will run until the input dataset is exhausted.\nWhen passing an infinitely\nrepeating dataset, you must specify the steps argument. This\nargument is not supported with array inputs or list inputs.\ndata\ntf.data.Dataset\nsteps\nNone\ndata\ntf.data.Dataset\nsteps\nNone\nadapt()\nsteps\nfinalize_state\nfinalize_state\nView source\nfinalize_state ()\nfinalize_state ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( data )\nupdate_state ( data )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sign",
    "content": "Returns a tensor with the signs of the elements of x .\nx\nMain aliases tf.keras.ops.numpy.sign\ntf.keras.ops.numpy.sign\ntf.keras.ops.numpy.sign\ntf . keras . ops . sign ( x )\ntf . keras . ops . sign ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/TruncatedNormal",
    "content": "Initializer that generates a truncated normal distribution.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.truncated_normal\ntf.keras.initializers.truncated_normal\ntf.keras.initializers.truncated_normal\ntf . keras . initializers . TruncatedNormal ( mean = 0.0 , stddev = 0.05 , seed = None )\ntf . keras . initializers . TruncatedNormal ( mean = 0.0 , stddev = 0.05 , seed = None )\nUsed in the notebooks\nCustomizing a Transformer Encoder\nFine-tuning a BERT model\nThe values generated are similar to values from a RandomNormal initializer, except that values more\nthan two standard deviations from the mean are\ndiscarded and re-drawn.\nRandomNormal\n# Standalone usage: initializer = TruncatedNormal ( mean = 0. , stddev = 1. ) values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = TruncatedNormal ( mean = 0. , stddev = 1. )\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = TruncatedNormal ( mean = 0. , stddev = 1. ) layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = TruncatedNormal ( mean = 0. , stddev = 1. )\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nmean A python scalar or a scalar keras tensor. Mean of the random\nvalues to generate. stddev A python scalar or a scalar keras tensor. Standard deviation of\nthe random values to generate. seed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nmean\nstddev\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/compute_float8_amax_history",
    "content": "tf . keras . quantizers . compute_float8_amax_history ( x , amax_history )\ntf . keras . quantizers . compute_float8_amax_history ( x , amax_history )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping3D",
    "content": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Cropping3D ( cropping = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None , ** kwargs )\ntf . keras . layers . Cropping3D ( cropping = (( 1 , 1 ), ( 1 , 1 ), ( 1 , 1 )), data_format = None , ** kwargs )\ninput_shape = ( 2 , 28 , 28 , 10 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) y = keras . layers . Cropping3D ( cropping = ( 2 , 4 , 2 ))( x ) y . shape ( 2 , 24 , 20 , 6 , 3 )\ninput_shape = ( 2 , 28 , 28 , 10 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\ny = keras . layers . Cropping3D ( cropping = ( 2 , 4 , 2 ))( x )\ny . shape\n( 2 , 24 , 20 , 6 , 3 )\nArgs\nArgs\ncropping Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\ncropping\nIf int: the same symmetric cropping is applied to depth, height,\nand width.\nIf tuple of 3 ints: interpreted as three different symmetric\ncropping values for depth, height, and width: (symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop) .\n(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)\nIf tuple of 3 tuples of 2 ints: interpreted as ((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\nright_dim2_crop), (left_dim3_crop, right_dim3_crop)) . data_format A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nWhen unspecified, uses image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json (if exists). Defaults to \"channels_last\" .\n((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\nright_dim2_crop), (left_dim3_crop, right_dim3_crop))\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nInput shape 5D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, first_axis_to_crop, second_axis_to_crop,\nthird_axis_to_crop, channels)\ndata_format\n\"channels_last\"\n(batch_size, first_axis_to_crop, second_axis_to_crop,\nthird_axis_to_crop, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, first_axis_to_crop, second_axis_to_crop,\nthird_axis_to_crop)\ndata_format\n\"channels_first\"\n(batch_size, channels, first_axis_to_crop, second_axis_to_crop,\nthird_axis_to_crop)\nOutput shape 5D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, first_cropped_axis, second_cropped_axis,\nthird_cropped_axis, channels)\ndata_format\n\"channels_last\"\n(batch_size, first_cropped_axis, second_cropped_axis,\nthird_cropped_axis, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, first_cropped_axis, second_cropped_axis,\nthird_cropped_axis)\ndata_format\n\"channels_first\"\n(batch_size, channels, first_cropped_axis, second_cropped_axis,\nthird_cropped_axis)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_flatten",
    "content": "DEPRECATED.\ntf . keras . backend . batch_flatten ( x )\ntf . keras . backend . batch_flatten ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/resize_volumes",
    "content": "DEPRECATED.\ntf . keras . backend . resize_volumes ( x , depth_factor , height_factor , width_factor , data_format )\ntf . keras . backend . resize_volumes ( x , depth_factor , height_factor , width_factor , data_format )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SensitivityAtSpecificity",
    "content": "Computes best sensitivity where specificity is >= specified value.\nInherits From: Metric\nMetric\ntf . keras . metrics . SensitivityAtSpecificity ( specificity , num_thresholds = 200 , class_id = None , name = None , dtype = None )\ntf . keras . metrics . SensitivityAtSpecificity ( specificity , num_thresholds = 200 , class_id = None , name = None , dtype = None )\nSensitivity measures the proportion of actual positives that are correctly\nidentified as such (tp / (tp + fn)) . Specificity measures the proportion of actual negatives that are correctly\nidentified as such (tn / (tn + fp)) .\nSensitivity\n(tp / (tp + fn))\nSpecificity\n(tn / (tn + fp))\nThis metric creates four local variables, true_positives , true_negatives , false_positives and false_negatives that are used to\ncompute the sensitivity at the given specificity. The threshold for the\ngiven specificity value is computed and used to evaluate the corresponding\nsensitivity.\ntrue_positives\ntrue_negatives\nfalse_positives\nfalse_negatives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf class_id is specified, we calculate precision by considering only the\nentries in the batch for which class_id is above the threshold\npredictions, and computing the fraction of them for which class_id is\nindeed a correct label.\nclass_id\nclass_id\nclass_id\nFor additional information about specificity and sensitivity, see the following .\nArgs\nArgs\nspecificity A scalar value in range [0, 1] . num_thresholds (Optional) Defaults to 200. The number of thresholds to\nuse for matching the given specificity. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nspecificity\n[0, 1]\nnum_thresholds\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . SensitivityAtSpecificity ( 0.5 ) m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ]) m . result () 0.5\nm = keras . metrics . SensitivityAtSpecificity ( 0.5 )\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ])\nm . result ()\n0.5\nm . reset_state () m . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ], sample_weight = [ 1 , 1 , 2 , 2 , 1 ]) m . result () 0.333333\nm . reset_state ()\nm . update_state ([ 0 , 0 , 0 , 1 , 1 ], [ 0 , 0.3 , 0.8 , 0.3 , 0.8 ],\nsample_weight = [ 1 , 1 , 2 , 2 , 1 ])\nm . result ()\n0.333333\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . SensitivityAtSpecificity ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . SensitivityAtSpecificity ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/stop_gradient",
    "content": "DEPRECATED.\ntf . keras . backend . stop_gradient ( variables )\ntf . keras . backend . stop_gradient ( variables )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nXception(...) : Instantiates the Xception architecture.\nXception(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sum",
    "content": "DEPRECATED.\ntf . keras . backend . sum ( x , axis = None , keepdims = False )\ntf . keras . backend . sum ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sin",
    "content": "DEPRECATED.\ntf . keras . backend . sin ( x )\ntf . keras . backend . sin ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/eye",
    "content": "Return a 2-D tensor with ones on the diagonal and zeros elsewhere.\nMain aliases tf.keras.ops.numpy.eye\ntf.keras.ops.numpy.eye\ntf.keras.ops.numpy.eye\ntf . keras . ops . eye ( N , M = None , k = 0 , dtype = None )\ntf . keras . ops . eye ( N , M = None , k = 0 , dtype = None )\nArgs\nArgs\nN Number of rows in the output. M Number of columns in the output. If None , defaults to N . k Index of the diagonal: 0 (the default) refers to the main\ndiagonal, a positive value refers to an upper diagonal,\nand a negative value to a lower diagonal. dtype Data type of the returned tensor.\nN\nM\nNone\nN\nk\ndtype\nReturns Tensor with ones on the k-th diagonal and zeros elsewhere.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/shape",
    "content": "DEPRECATED.\ntf . keras . backend . shape ( x )\ntf . keras . backend . shape ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/randint",
    "content": "Draw random integers from a uniform distribution.\ntf . keras . random . randint ( shape , minval , maxval , dtype = 'int32' , seed = None )\ntf . keras . random . randint ( shape , minval , maxval , dtype = 'int32' , seed = None )\nThe generated values follow a uniform distribution in the range [minval, maxval) . The lower bound minval is included in the range,\nwhile the upper bound maxval is excluded.\n[minval, maxval)\nminval\nmaxval\ndtype must be an integer type.\ndtype\nArgs\nArgs\nshape The shape of the random values to generate. minval Float, defaults to 0. Lower bound of the range of\nrandom values to generate (inclusive). maxval Float, defaults to 1. Upper bound of the range of\nrandom values to generate (exclusive). dtype Optional dtype of the tensor. Only integer types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ) seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nminval\nmaxval\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Large",
    "content": "Instantiates the MobileNetV3Large architecture.\ntf . keras . applications . MobileNetV3Large ( input_shape = None , alpha = 1.0 , minimalistic = False , include_top = True , weights = 'imagenet' , input_tensor = None , classes = 1000 , pooling = None , dropout_rate = 0.2 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . MobileNetV3Large ( input_shape = None , alpha = 1.0 , minimalistic = False , include_top = True , weights = 'imagenet' , input_tensor = None , classes = 1000 , pooling = None , dropout_rate = 0.2 , classifier_activation = 'softmax' , include_preprocessing = True )\nUsed in the notebooks\nTensorFlow Lite Model Analyzer\nSearching for MobileNetV3 (ICCV 2019)\nThe following table describes the performance of MobileNets v3:\nMACs stands for Multiply Adds\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.mobilenet_v3.preprocess_input\n[0-255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninput_shape Optional shape tuple, to be specified if you would\nlike to use a model with an input image resolution that is not (224, 224, 3) .\nIt should have exactly 3 inputs channels.\nYou can also omit this option if you would like\nto infer input_shape from an input_tensor.\nIf you choose to include both input_tensor and input_shape then\ninput_shape will be used if they match, if the shapes\ndo not match then we will throw an error.\nE.g. (160, 160, 3) would be one valid value. alpha controls the width of the network. This is known as the\ndepth multiplier in the MobileNetV3 paper, but the name is kept for\nconsistency with MobileNetV1 in Keras.\ninput_shape\n(224, 224, 3)\n(160, 160, 3)\nalpha\nIf alpha < 1.0 , proportionally decreases the number\nof filters in each layer.\nalpha < 1.0\nIf alpha > 1.0 , proportionally increases the number\nof filters in each layer.\nalpha > 1.0\nIf alpha == 1 , default number of filters from the paper\nare used at each layer. minimalistic In addition to large and small models this module also\ncontains so-called minimalistic models, these models have the same\nper-layer dimensions characteristic as MobilenetV3 however, they don't\nutilize any of the advanced blocks (squeeze-and-excite units,\nhard-swish, and 5x5 convolutions).\nWhile these models are less efficient on CPU, they\nare much more performant on GPU/DSP. include_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights String, one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. pooling String, optional pooling mode for feature extraction\nwhen include_top is False .\nalpha == 1\nminimalistic\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\npooling\ninclude_top\nFalse\nNone means that the output of the model\nwill be the 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a\n2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Integer, optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. dropout_rate fraction of the input units to drop on the last layer. classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" . include_preprocessing Boolean, whether to include the preprocessing\nlayer ( Rescaling ) at the bottom of the network. Defaults to True .\nmax\nclasses\ninclude_top\nTrue\nweights\ndropout_rate\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\ninclude_preprocessing\nRescaling\nTrue\nCall arguments\nCall arguments\ninputs A floating point numpy.array or backend-native tensor,\n4D with 3 color channels, with values in the range [0, 255] if include_preprocessing is True and in the range [-1, 1] otherwise.\ninputs\nnumpy.array\n[0, 255]\ninclude_preprocessing\nTrue\n[-1, 1]\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/arange",
    "content": "DEPRECATED.\ntf . keras . backend . arange ( start , stop = None , step = 1 , dtype = 'int32' )\ntf . keras . backend . arange ( start , stop = None , step = 1 , dtype = 'int32' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TerminateOnNaN",
    "content": "Callback that terminates training when a NaN loss is encountered.\nInherits From: Callback\nCallback\ntf . keras . callbacks . TerminateOnNaN ()\ntf . keras . callbacks . TerminateOnNaN ()\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logsumexp",
    "content": "Computes the logarithm of sum of exponentials of elements in a tensor.\ntf . keras . ops . logsumexp ( x , axis = None , keepdims = False )\ntf . keras . ops . logsumexp ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis An integer or a tuple of integers specifying the axis/axes\nalong which to compute the sum. If None , the sum is computed\nover all elements. Defaults to None . keepdims A boolean indicating whether to keep the dimensions of\nthe input tensor when computing the sum. Defaults to False .\nx\naxis\nNone\nNone\nkeepdims\nFalse\nReturns A tensor containing the logarithm of the sum of exponentials of\nelements in x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ 1. , 2. , 3. ]) logsumexp ( x ) 3.407606\nx = keras . ops . convert_to_tensor ([ 1. , 2. , 3. ])\nlogsumexp ( x )\n3.407606"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ConvNeXtSmall",
    "content": "Instantiates the ConvNeXtSmall architecture.\nMain aliases tf.keras.applications.convnext.ConvNeXtSmall\ntf.keras.applications.convnext.ConvNeXtSmall\ntf.keras.applications.convnext.ConvNeXtSmall\ntf . keras . applications . ConvNeXtSmall ( model_name = 'convnext_small' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ConvNeXtSmall ( model_name = 'convnext_small' , include_top = True , include_preprocessing = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nA ConvNet for the 2020s (CVPR 2022)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe base , large , and xlarge models were first pre-trained on the\nImageNet-21k dataset and then fine-tuned on the ImageNet-1k dataset. The\npre-trained parameters of the models were assembled from the official repository . To get a\nsense of how these parameters were converted to Keras compatible parameters,\nplease refer to this repository .\nbase\nlarge\nxlarge\nNormalization\nWhen calling the summary() method after instantiating a ConvNeXt model,\nprefer setting the expand_nested argument summary() to True to better\ninvestigate the instantiated model.\nsummary()\nexpand_nested\nsummary()\nTrue\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet-1k), or the path to the weights\nfile to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the last convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/xception/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . xception . decode_predictions ( preds , top = 5 )\ntf . keras . applications . xception . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint",
    "content": "Callback to save the Keras model or model weights at some frequency.\nInherits From: Callback\nCallback\ntf . keras . callbacks . ModelCheckpoint ( filepath , monitor = 'val_loss' , verbose = 0 , save_best_only = False , save_weights_only = False , mode = 'auto' , save_freq = 'epoch' , initial_value_threshold = None )\ntf . keras . callbacks . ModelCheckpoint ( filepath , monitor = 'val_loss' , verbose = 0 , save_best_only = False , save_weights_only = False , mode = 'auto' , save_freq = 'epoch' , initial_value_threshold = None )\nUsed in the notebooks\nMigrate checkpoint saving\nMigrate evaluation\nMulti-GPU and distributed training\nSave and load models\nGenerate music with an RNN\nDistributed training with Keras\nParameter server training with ParameterServerStrategy\nHuman Pose Classification with MoveNet and TensorFlow Lite\nModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some\ninterval, so the model or weights can be loaded later to continue the\ntraining from the state saved.\nModelCheckpoint\nmodel.fit()\nA few options this callback provides include:\nWhether to only keep the model that has achieved the \"best performance\" so\nfar, or whether to save the model at the end of every epoch regardless of\nperformance.\nDefinition of \"best\"; which quantity to monitor and whether it should be\nmaximized or minimized.\nThe frequency it should save at. Currently, the callback supports saving\nat the end of every epoch, or after a fixed number of training batches.\nWhether only weights are saved, or the whole model is saved.\nmodel . compile ( loss =... , optimizer =... , metrics = [ 'accuracy' ]) EPOCHS = 10 checkpoint_filepath = '/tmp/ckpt/checkpoint.model.keras' model_checkpoint_callback = keras . callbacks . ModelCheckpoint ( filepath = checkpoint_filepath , monitor = 'val_accuracy' , mode = 'max' , save_best_only = True ) # Model is saved at the end of every epoch, if it's the best seen so far. model . fit ( epochs = EPOCHS , callbacks = [ model_checkpoint_callback ]) # The model (that are considered the best) can be loaded as - keras . models . load_model ( checkpoint_filepath ) # Alternatively, one could checkpoint just the model weights as - checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5' model_checkpoint_callback = keras . callbacks . ModelCheckpoint ( filepath = checkpoint_filepath , save_weights_only = True , monitor = 'val_accuracy' , mode = 'max' , save_best_only = True ) # Model weights are saved at the end of every epoch, if it's the best seen # so far. model . fit ( epochs = EPOCHS , callbacks = [ model_checkpoint_callback ]) # The model weights (that are considered the best) can be loaded as - model . load_weights ( checkpoint_filepath )\nmodel . compile ( loss =... , optimizer =... , metrics = [ 'accuracy' ]) EPOCHS = 10 checkpoint_filepath = '/tmp/ckpt/checkpoint.model.keras' model_checkpoint_callback = keras . callbacks . ModelCheckpoint ( filepath = checkpoint_filepath , monitor = 'val_accuracy' , mode = 'max' , save_best_only = True ) # Model is saved at the end of every epoch, if it's the best seen so far. model . fit ( epochs = EPOCHS , callbacks = [ model_checkpoint_callback ]) # The model (that are considered the best) can be loaded as - keras . models . load_model ( checkpoint_filepath ) # Alternatively, one could checkpoint just the model weights as - checkpoint_filepath = '/tmp/ckpt/checkpoint.weights.h5' model_checkpoint_callback = keras . callbacks . ModelCheckpoint ( filepath = checkpoint_filepath , save_weights_only = True , monitor = 'val_accuracy' , mode = 'max' , save_best_only = True ) # Model weights are saved at the end of every epoch, if it's the best seen # so far. model . fit ( epochs = EPOCHS , callbacks = [ model_checkpoint_callback ]) # The model weights (that are considered the best) can be loaded as - model . load_weights ( checkpoint_filepath )\nArgs\nArgs\nfilepath string or PathLike , path to save the model file. filepath can contain named formatting options,\nwhich will be filled the value of epoch and keys in logs (passed in on_epoch_end ).\nThe filepath name needs to end with \".weights.h5\" when save_weights_only=True or should end with \".keras\" when\ncheckpoint saving the whole model (default).\nFor example:\nif filepath is \"{epoch:02d}-{val_loss:.2f}.keras\" , then the\nmodel checkpoints will be saved with the epoch number and the\nvalidation loss in the filename. The directory of the filepath\nshould not be reused by any other callbacks to avoid conflicts. monitor The metric name to monitor. Typically the metrics are set by\nthe Model.compile method. Note:\nfilepath\nPathLike\nfilepath\nepoch\nlogs\non_epoch_end\nfilepath\n\".weights.h5\"\nsave_weights_only=True\n\".keras\"\nfilepath\n\"{epoch:02d}-{val_loss:.2f}.keras\"\nmonitor\nModel.compile\nPrefix the name with \"val_\" to monitor validation metrics.\n\"val_\"\nUse \"loss\" or \"val_loss\" to monitor the model's total loss.\n\"loss\"\n\"val_loss\"\nIf you specify metrics as strings, like \"accuracy\" , pass the\nsame string (with or without the \"val_\" prefix).\n\"accuracy\"\n\"val_\"\nIf you pass metrics.Metric objects, monitor should be set to metric.name\nmetrics.Metric\nmonitor\nmetric.name\nIf you're not sure about the metric names you can check the\ncontents of the history.history dictionary returned by history = model.fit()\nhistory.history\nhistory = model.fit()\nMulti-output models set additional prefixes on the metric names. verbose Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1\ndisplays messages when the callback takes an action. save_best_only if save_best_only=True , it only saves when the model\nis considered the \"best\" and the latest best model according to the\nquantity monitored will not be overwritten. If filepath doesn't\ncontain formatting options like {epoch} then filepath will be\noverwritten by each new better model. mode one of { \"auto\" , \"min\" , \"max\" }. If save_best_only=True , the\ndecision to overwrite the current save file is made based on either\nthe maximization or the minimization of the monitored quantity.\nFor val_acc , this should be \"max\" , for val_loss this should be \"min\" , etc. In \"auto\" mode, the mode is set to \"max\" if the\nquantities monitored are \"acc\" or start with \"fmeasure\" and are\nset to \"min\" for the rest of the quantities. save_weights_only if True , then only the model's weights will be\nsaved ( model.save_weights(filepath) ), else the full model is\nsaved ( model.save(filepath) ). save_freq \"epoch\" or integer. When using \"epoch\" , the callback\nsaves the model after each epoch. When using integer, the callback\nsaves the model at end of this many batches. If the Model is\ncompiled with steps_per_execution=N , then the saving criteria will\nbe checked every Nth batch. Note that if the saving isn't aligned to\nepochs, the monitored metric may potentially be less reliable (it\ncould reflect as little as 1 batch, since the metrics get reset\nevery epoch). Defaults to \"epoch\" . initial_value_threshold Floating point initial \"best\" value of the\nmetric to be monitored. Only applies if save_best_value=True . Only\noverwrites the model weights already saved if the performance of\ncurrent model is better than this value.\nverbose\nsave_best_only\nsave_best_only=True\nfilepath\n{epoch}\nfilepath\nmode\n\"auto\"\n\"min\"\n\"max\"\nsave_best_only=True\nval_acc\n\"max\"\nval_loss\n\"min\"\n\"auto\"\n\"max\"\n\"acc\"\n\"fmeasure\"\n\"min\"\nsave_weights_only\nTrue\nmodel.save_weights(filepath)\nmodel.save(filepath)\nsave_freq\n\"epoch\"\n\"epoch\"\nModel\nsteps_per_execution=N\n\"epoch\"\ninitial_value_threshold\nsave_best_value=True\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/resize",
    "content": "Resize images to size using the specified interpolation method.\ntf . keras . ops . image . resize ( image , size , interpolation = 'bilinear' , antialias = False , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , fill_mode = 'constant' , fill_value = 0.0 , data_format = 'channels_last' )\ntf . keras . ops . image . resize ( image , size , interpolation = 'bilinear' , antialias = False , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , fill_mode = 'constant' , fill_value = 0.0 , data_format = 'channels_last' )\nArgs\nArgs\nimage Input image or batch of images. Must be 3D or 4D. size Size of output image in (height, width) format. interpolation Interpolation method. Available methods are \"nearest\" , \"bilinear\" , and \"bicubic\" . Defaults to \"bilinear\" . antialias Whether to use an antialiasing filter when downsampling an\nimage. Defaults to False . crop_to_aspect_ratio If True , resize the images without aspect\nratio distortion. When the original aspect ratio differs\nfrom the target aspect ratio, the output image will be\ncropped so as to return the\nlargest possible window in the image (of size (height, width) )\nthat matches the target aspect ratio. By default\n( crop_to_aspect_ratio=False ), aspect ratio may not be preserved. pad_to_aspect_ratio If True , pad the images without aspect\nratio distortion. When the original aspect ratio differs\nfrom the target aspect ratio, the output image will be\nevenly padded on the short side. fill_mode When using pad_to_aspect_ratio=True , padded areas\nare filled according to the given mode. Only \"constant\" is\nsupported at this time\n(fill with constant value, equal to fill_value ). fill_value Float. Padding value to use when pad_to_aspect_ratio=True . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, weight) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\nimage\nsize\n(height, width)\ninterpolation\n\"nearest\"\n\"bilinear\"\n\"bicubic\"\n\"bilinear\"\nantialias\nFalse\ncrop_to_aspect_ratio\nTrue\n(height, width)\ncrop_to_aspect_ratio=False\npad_to_aspect_ratio\nTrue\nfill_mode\npad_to_aspect_ratio=True\n\"constant\"\nfill_value\nfill_value\npad_to_aspect_ratio=True\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, weight)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nReturns Resized image or batch of images.\nReturns\nx = np . random . random (( 2 , 4 , 4 , 3 )) # batch of 2 RGB images y = keras . ops . image . resize ( x , ( 2 , 2 )) y . shape ( 2 , 2 , 2 , 3 )\nx = np . random . random (( 2 , 4 , 4 , 3 )) # batch of 2 RGB images\ny = keras . ops . image . resize ( x , ( 2 , 2 ))\ny . shape\n( 2 , 2 , 2 , 3 )\nx = np . random . random (( 4 , 4 , 3 )) # single RGB image y = keras . ops . image . resize ( x , ( 2 , 2 )) y . shape ( 2 , 2 , 3 )\nx = np . random . random (( 4 , 4 , 3 )) # single RGB image\ny = keras . ops . image . resize ( x , ( 2 , 2 ))\ny . shape\n( 2 , 2 , 3 )\nx = np . random . random (( 2 , 3 , 4 , 4 )) # batch of 2 RGB images y = keras . ops . image . resize ( x , ( 2 , 2 ), data_format = \"channels_first\" ) y . shape ( 2 , 3 , 2 , 2 )\nx = np . random . random (( 2 , 3 , 4 , 4 )) # batch of 2 RGB images\ny = keras . ops . image . resize ( x , ( 2 , 2 ),\ndata_format = \"channels_first\" )\ny . shape\n( 2 , 3 , 2 , 2 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nconvnext module: DO NOT EDIT.\nconvnext\ndensenet module: DO NOT EDIT.\ndensenet\nefficientnet module: DO NOT EDIT.\nefficientnet\nefficientnet_v2 module: DO NOT EDIT.\nefficientnet_v2\nimagenet_utils module: DO NOT EDIT.\nimagenet_utils\ninception_resnet_v2 module: DO NOT EDIT.\ninception_resnet_v2\ninception_v3 module: DO NOT EDIT.\ninception_v3\nmobilenet module: DO NOT EDIT.\nmobilenet\nmobilenet_v2 module: DO NOT EDIT.\nmobilenet_v2\nmobilenet_v3 module: DO NOT EDIT.\nmobilenet_v3\nnasnet module: DO NOT EDIT.\nnasnet\nresnet module: DO NOT EDIT.\nresnet\nresnet50 module: DO NOT EDIT.\nresnet50\nresnet_v2 module: DO NOT EDIT.\nresnet_v2\nvgg16 module: DO NOT EDIT.\nvgg16\nvgg19 module: DO NOT EDIT.\nvgg19\nxception module: DO NOT EDIT.\nxception\nFunctions\nConvNeXtBase(...) : Instantiates the ConvNeXtBase architecture.\nConvNeXtBase(...)\nConvNeXtLarge(...) : Instantiates the ConvNeXtLarge architecture.\nConvNeXtLarge(...)\nConvNeXtSmall(...) : Instantiates the ConvNeXtSmall architecture.\nConvNeXtSmall(...)\nConvNeXtTiny(...) : Instantiates the ConvNeXtTiny architecture.\nConvNeXtTiny(...)\nConvNeXtXLarge(...) : Instantiates the ConvNeXtXLarge architecture.\nConvNeXtXLarge(...)\nDenseNet121(...) : Instantiates the Densenet121 architecture.\nDenseNet121(...)\nDenseNet169(...) : Instantiates the Densenet169 architecture.\nDenseNet169(...)\nDenseNet201(...) : Instantiates the Densenet201 architecture.\nDenseNet201(...)\nEfficientNetB0(...) : Instantiates the EfficientNetB0 architecture.\nEfficientNetB0(...)\nEfficientNetB1(...) : Instantiates the EfficientNetB1 architecture.\nEfficientNetB1(...)\nEfficientNetB2(...) : Instantiates the EfficientNetB2 architecture.\nEfficientNetB2(...)\nEfficientNetB3(...) : Instantiates the EfficientNetB3 architecture.\nEfficientNetB3(...)\nEfficientNetB4(...) : Instantiates the EfficientNetB4 architecture.\nEfficientNetB4(...)\nEfficientNetB5(...) : Instantiates the EfficientNetB5 architecture.\nEfficientNetB5(...)\nEfficientNetB6(...) : Instantiates the EfficientNetB6 architecture.\nEfficientNetB6(...)\nEfficientNetB7(...) : Instantiates the EfficientNetB7 architecture.\nEfficientNetB7(...)\nEfficientNetV2B0(...) : Instantiates the EfficientNetV2B0 architecture.\nEfficientNetV2B0(...)\nEfficientNetV2B1(...) : Instantiates the EfficientNetV2B1 architecture.\nEfficientNetV2B1(...)\nEfficientNetV2B2(...) : Instantiates the EfficientNetV2B2 architecture.\nEfficientNetV2B2(...)\nEfficientNetV2B3(...) : Instantiates the EfficientNetV2B3 architecture.\nEfficientNetV2B3(...)\nEfficientNetV2L(...) : Instantiates the EfficientNetV2L architecture.\nEfficientNetV2L(...)\nEfficientNetV2M(...) : Instantiates the EfficientNetV2M architecture.\nEfficientNetV2M(...)\nEfficientNetV2S(...) : Instantiates the EfficientNetV2S architecture.\nEfficientNetV2S(...)\nInceptionResNetV2(...) : Instantiates the Inception-ResNet v2 architecture.\nInceptionResNetV2(...)\nInceptionV3(...) : Instantiates the Inception v3 architecture.\nInceptionV3(...)\nMobileNet(...) : Instantiates the MobileNet architecture.\nMobileNet(...)\nMobileNetV2(...) : Instantiates the MobileNetV2 architecture.\nMobileNetV2(...)\nMobileNetV3Large(...) : Instantiates the MobileNetV3Large architecture.\nMobileNetV3Large(...)\nMobileNetV3Small(...) : Instantiates the MobileNetV3Small architecture.\nMobileNetV3Small(...)\nNASNetLarge(...) : Instantiates a NASNet model in ImageNet mode.\nNASNetLarge(...)\nNASNetMobile(...) : Instantiates a Mobile NASNet model in ImageNet mode.\nNASNetMobile(...)\nResNet101(...) : Instantiates the ResNet101 architecture.\nResNet101(...)\nResNet101V2(...) : Instantiates the ResNet101V2 architecture.\nResNet101V2(...)\nResNet152(...) : Instantiates the ResNet152 architecture.\nResNet152(...)\nResNet152V2(...) : Instantiates the ResNet152V2 architecture.\nResNet152V2(...)\nResNet50(...) : Instantiates the ResNet50 architecture.\nResNet50(...)\nResNet50V2(...) : Instantiates the ResNet50V2 architecture.\nResNet50V2(...)\nVGG16(...) : Instantiates the VGG16 model.\nVGG16(...)\nVGG19(...) : Instantiates the VGG19 model.\nVGG19(...)\nXception(...) : Instantiates the Xception architecture.\nXception(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Constant : Initializer that generates tensors with constant values.\nclass Constant\nclass GlorotNormal : The Glorot normal initializer, also called Xavier normal initializer.\nclass GlorotNormal\nclass GlorotUniform : The Glorot uniform initializer, also called Xavier uniform initializer.\nclass GlorotUniform\nclass HeNormal : He normal initializer.\nclass HeNormal\nclass HeUniform : He uniform variance scaling initializer.\nclass HeUniform\nclass Identity : Initializer that generates the identity matrix.\nclass Identity\nclass IdentityInitializer : Initializer that generates the identity matrix.\nclass IdentityInitializer\nclass Initializer : Initializer base class: all Keras initializers inherit from this class.\nclass Initializer\nclass LecunNormal : Lecun normal initializer.\nclass LecunNormal\nclass LecunUniform : Lecun uniform initializer.\nclass LecunUniform\nclass Ones : Initializer that generates tensors initialized to 1.\nclass Ones\nclass Orthogonal : Initializer that generates an orthogonal matrix.\nclass Orthogonal\nclass OrthogonalInitializer : Initializer that generates an orthogonal matrix.\nclass OrthogonalInitializer\nclass RandomNormal : Random normal initializer.\nclass RandomNormal\nclass RandomUniform : Random uniform initializer.\nclass RandomUniform\nclass TruncatedNormal : Initializer that generates a truncated normal distribution.\nclass TruncatedNormal\nclass VarianceScaling : Initializer that adapts its scale to the shape of its input tensors.\nclass VarianceScaling\nclass Zeros : Initializer that generates tensors initialized to 0.\nclass Zeros\nclass constant : Initializer that generates tensors with constant values.\nclass constant\nclass glorot_normal : The Glorot normal initializer, also called Xavier normal initializer.\nclass glorot_normal\nclass glorot_uniform : The Glorot uniform initializer, also called Xavier uniform initializer.\nclass glorot_uniform\nclass he_normal : He normal initializer.\nclass he_normal\nclass he_uniform : He uniform variance scaling initializer.\nclass he_uniform\nclass identity : Initializer that generates the identity matrix.\nclass identity\nclass lecun_normal : Lecun normal initializer.\nclass lecun_normal\nclass lecun_uniform : Lecun uniform initializer.\nclass lecun_uniform\nclass ones : Initializer that generates tensors initialized to 1.\nclass ones\nclass orthogonal : Initializer that generates an orthogonal matrix.\nclass orthogonal\nclass random_normal : Random normal initializer.\nclass random_normal\nclass random_uniform : Random uniform initializer.\nclass random_uniform\nclass truncated_normal : Initializer that generates a truncated normal distribution.\nclass truncated_normal\nclass variance_scaling : Initializer that adapts its scale to the shape of its input tensors.\nclass variance_scaling\nclass zeros : Initializer that generates tensors initialized to 0.\nclass zeros\nFunctions\ndeserialize(...) : Returns a Keras initializer object via its configuration.\ndeserialize(...)\nget(...) : Retrieves a Keras initializer object via an identifier.\nget(...)\nserialize(...) : Returns the initializer configuration as a Python dict.\nserialize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling1D",
    "content": "Average pooling for temporal data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.AvgPool1D\ntf.keras.layers.AvgPool1D\ntf.keras.layers.AvgPool1D\ntf . keras . layers . AveragePooling1D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . AveragePooling1D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nDownsamples the input representation by taking the average value over the\nwindow defined by pool_size . The window is shifted by strides .  The\nresulting output when using \"valid\" padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides)\npool_size\nstrides\noutput_shape = (input_shape - pool_size + 1) / strides)\nThe resulting output shape when using the \"same\" padding option is: output_shape = input_shape / strides\noutput_shape = input_shape / strides\nArgs\nArgs\npool_size int, size of the max pooling window. strides int or None. Specifies how much the pooling window moves\nfor each pooling step. If None, it will default to pool_size . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, steps, features) .\ndata_format=\"channels_last\"\n(batch_size, steps, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, steps) .\ndata_format=\"channels_first\"\n(batch_size, features, steps)\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, downsampled_steps, features) .\ndata_format=\"channels_last\"\n(batch_size, downsampled_steps, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, downsampled_steps) .\ndata_format=\"channels_first\"\n(batch_size, features, downsampled_steps)\nstrides=1 and padding=\"valid\" :\nstrides=1\npadding=\"valid\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) avg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 , strides = 1 , padding = \"valid\" ) avg_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\navg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 ,\nstrides = 1 , padding = \"valid\" )\navg_pool_1d ( x )\nstrides=2 and padding=\"valid\" :\nstrides=2\npadding=\"valid\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) avg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 , strides = 2 , padding = \"valid\" ) avg_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\navg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 ,\nstrides = 2 , padding = \"valid\" )\navg_pool_1d ( x )\nstrides=1 and padding=\"same\" :\nstrides=1\npadding=\"same\"\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ]) x = np . reshape ( x , [ 1 , 5 , 1 ]) avg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 , strides = 1 , padding = \"same\" ) avg_pool_1d ( x )\nx = np . array ([ 1. , 2. , 3. , 4. , 5. ])\nx = np . reshape ( x , [ 1 , 5 , 1 ])\navg_pool_1d = keras . layers . AveragePooling1D ( pool_size = 2 ,\nstrides = 1 , padding = \"same\" )\navg_pool_1d ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/empty",
    "content": "Return a tensor of given shape and type filled with uninitialized data.\nMain aliases tf.keras.ops.numpy.empty\ntf.keras.ops.numpy.empty\ntf.keras.ops.numpy.empty\ntf . keras . ops . empty ( shape , dtype = None )\ntf . keras . ops . empty ( shape , dtype = None )\nArgs\nArgs\nshape Shape of the empty tensor. dtype Desired data type of the empty tensor.\nshape\ndtype\nReturns The empty tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell",
    "content": "Cell class for SimpleRNN.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . SimpleRNNCell ( units , activation = 'tanh' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , ** kwargs )\ntf . keras . layers . SimpleRNNCell ( units , activation = 'tanh' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , ** kwargs )\nThis class processes one step within the whole time sequence input, whereas keras.layer.SimpleRNN processes the whole sequence.\nkeras.layer.SimpleRNN\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use.\nDefault: hyperbolic tangent ( tanh ).\nIf you pass None , no activation is applied\n(ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer\nshould use a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation\nof the recurrent state. Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. Default: 0. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. Default: 0. seed Random seed for dropout.\nunits\nactivation\ntanh\nNone\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nseed\nCall arguments\nCall arguments\nsequence A 2D tensor, with shape (batch, features) . states A 2D tensor with shape (batch, units) , which is the state\nfrom the previous time step. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. Only relevant when dropout or recurrent_dropout is used.\nsequence\n(batch, features)\nstates\n(batch, units)\ntraining\ndropout\nrecurrent_dropout\ninputs = np . random . random ([ 32 , 10 , 8 ]) . astype ( np . float32 ) rnn = keras . layers . RNN ( keras . layers . SimpleRNNCell ( 4 )) output = rnn ( inputs ) # The output has shape `(32, 4)`. rnn = keras . layers . RNN ( keras . layers . SimpleRNNCell ( 4 ), return_sequences = True , return_state = True ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. whole_sequence_output , final_state = rnn ( inputs )\ninputs = np . random . random ([ 32 , 10 , 8 ]) . astype ( np . float32 ) rnn = keras . layers . RNN ( keras . layers . SimpleRNNCell ( 4 )) output = rnn ( inputs ) # The output has shape `(32, 4)`. rnn = keras . layers . RNN ( keras . layers . SimpleRNNCell ( 4 ), return_sequences = True , return_state = True ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. whole_sequence_output , final_state = rnn ( inputs )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_dropout_mask\nget_dropout_mask\nView source\nget_dropout_mask ( step_input )\nget_dropout_mask ( step_input )\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size = None )\nget_initial_state ( batch_size = None )\nget_recurrent_dropout_mask\nget_recurrent_dropout_mask\nView source\nget_recurrent_dropout_mask ( step_input )\nget_recurrent_dropout_mask ( step_input )\nreset_dropout_mask\nreset_dropout_mask\nView source\nreset_dropout_mask ()\nreset_dropout_mask ()\nReset the cached dropout mask if any.\nThe RNN layer invokes this in the call() method\nso that the cached mask is cleared after calling cell.call() . The\nmask should be cached across all timestep within the same batch, but\nshouldn't be cached between batches.\ncall()\ncell.call()\nreset_recurrent_dropout_mask\nreset_recurrent_dropout_mask\nView source\nreset_recurrent_dropout_mask ()\nreset_recurrent_dropout_mask ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention",
    "content": "Additive attention layer, a.k.a. Bahdanau-style attention.\nInherits From: Attention , Layer , Operation\nAttention\nLayer\nOperation\ntf . keras . layers . AdditiveAttention ( use_scale = True , dropout = 0.0 , ** kwargs )\ntf . keras . layers . AdditiveAttention ( use_scale = True , dropout = 0.0 , ** kwargs )\nInputs are a list with 2 or 3 elements:\nA query tensor of shape (batch_size, Tq, dim) .\nquery\n(batch_size, Tq, dim)\nA value tensor of shape (batch_size, Tv, dim) .\nvalue\n(batch_size, Tv, dim)\nA optional key tensor of shape (batch_size, Tv, dim) . If none\nsupplied, value will be used as key .\nkey\n(batch_size, Tv, dim)\nvalue\nkey\nThe calculation follows the steps:\nCalculate attention scores using query and key with shape (batch_size, Tq, Tv) as a non-linear sum scores = reduce_sum(tanh(query + key), axis=-1) .\nquery\nkey\n(batch_size, Tq, Tv)\nscores = reduce_sum(tanh(query + key), axis=-1)\nUse scores to calculate a softmax distribution with shape (batch_size, Tq, Tv) .\n(batch_size, Tq, Tv)\nUse the softmax distribution to create a linear combination of value with shape (batch_size, Tq, dim) .\nvalue\n(batch_size, Tq, dim)\nArgs\nArgs\nuse_scale If True , will create a scalar variable to scale the\nattention scores. dropout Float between 0 and 1. Fraction of the units to drop for the\nattention scores. Defaults to 0.0 .\nuse_scale\nTrue\ndropout\n0.0\nCall Args\nCall Args\ninputs List of the following tensors:\ninputs\nquery : Query tensor of shape (batch_size, Tq, dim) .\nquery\n(batch_size, Tq, dim)\nvalue : Value tensor of shape (batch_size, Tv, dim) .\nvalue\n(batch_size, Tv, dim)\nkey : Optional key tensor of shape (batch_size, Tv, dim) . If\nnot given, will use value for both key and value , which is\nthe most common case. mask List of the following tensors:\nkey\n(batch_size, Tv, dim)\nvalue\nkey\nvalue\nmask\nquery_mask : A boolean mask tensor of shape (batch_size, Tq) .\nIf given, the output will be zero at the positions where mask==False .\nquery_mask\n(batch_size, Tq)\nmask==False\nvalue_mask : A boolean mask tensor of shape (batch_size, Tv) .\nIf given, will apply the mask such that values at positions\n where mask==False do not contribute to the result. return_attention_scores bool, it True , returns the attention scores\n(after masking and softmax) as an additional output argument. training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (no dropout). use_causal_mask Boolean. Set to True for decoder self-attention. Adds\na mask such that position i cannot attend to positions j > i .\nThis prevents the flow of information from the future towards the\npast. Defaults to False .\nvalue_mask\n(batch_size, Tv)\nmask==False\nreturn_attention_scores\nTrue\ntraining\nuse_causal_mask\nTrue\ni\nj > i\nFalse\nOutput Attention outputs of shape (batch_size, Tq, dim) .\n(Optional) Attention scores after masking and softmax with shape (batch_size, Tq, Tv) .\nOutput\n(batch_size, Tq, dim)\n(batch_size, Tq, Tv)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/digitize",
    "content": "Returns the indices of the bins to which each value in x belongs.\nx\nMain aliases tf.keras.ops.numpy.digitize\ntf.keras.ops.numpy.digitize\ntf.keras.ops.numpy.digitize\ntf . keras . ops . digitize ( x , bins )\ntf . keras . ops . digitize ( x , bins )\nArgs\nArgs\nx Input array to be binned. bins Array of bins. It has to be one-dimensional and monotonically\nincreasing.\nx\nbins\nReturns Output array of indices, of same shape as x .\nReturns\nx\nx = np . array ([ 0.0 , 1.0 , 3.0 , 1.6 ]) bins = np . array ([ 0.0 , 3.0 , 4.5 , 7.0 ]) keras . ops . digitize ( x , bins ) array ([ 1 , 1 , 2 , 1 ])\nx = np . array ([ 0.0 , 1.0 , 3.0 , 1.6 ])\nbins = np . array ([ 0.0 , 3.0 , 4.5 , 7.0 ])\nkeras . ops . digitize ( x , bins )\narray ([ 1 , 1 , 2 , 1 ])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Operation",
    "content": "Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Operation\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Operation\ntf.compat.v1.keras.Operation\ntf . keras . Operation ( dtype = None , name = None )\ntf . keras . Operation ( dtype = None , name = None )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\ncall\ncall\nView source\ncall ( * args , ** kwargs )\ncall ( * args , ** kwargs )\ncompute_output_spec\ncompute_output_spec\nView source\ncompute_output_spec ( * args , ** kwargs )\ncompute_output_spec ( * args , ** kwargs )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the object.\nAn object config is a Python dictionary (serializable)\ncontaining the information needed to re-instantiate it.\nquantized_call\nquantized_call\nView source\nquantized_call ( * args , ** kwargs )\nquantized_call ( * args , ** kwargs )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/switch",
    "content": "DEPRECATED.\ntf . keras . backend . switch ( condition , then_expression , else_expression )\ntf . keras . backend . switch ( condition , then_expression , else_expression )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout1D",
    "content": "Spatial 1D version of Dropout.\nInherits From: Dropout , Layer , Operation\nDropout\nLayer\nOperation\ntf . keras . layers . SpatialDropout1D ( rate , seed = None , name = None , dtype = None )\ntf . keras . layers . SpatialDropout1D ( rate , seed = None , name = None , dtype = None )\nThis layer performs the same function as Dropout, however, it drops\nentire 1D feature maps instead of individual elements. If adjacent frames\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout1D will help promote independence\nbetween feature maps and should be used instead.\nSpatialDropout1D\nArgs\nArgs\nrate Float between 0 and 1. Fraction of the input units to drop.\nrate\nCall arguments\nCall arguments\ninputs A 3D tensor. training Python boolean indicating whether the layer\nshould behave in training mode (applying dropout)\nor in inference mode (pass-through).\ninputs\ntraining\nInput shape 3D tensor with shape: (samples, timesteps, channels)\nInput shape\n(samples, timesteps, channels)\nOutput shape: Same as input.\nTompson et al., 2014\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/CustomObjectScope",
    "content": "Exposes custom classes/functions to Keras deserialization internals.\nMain aliases tf.keras.utils.custom_object_scope\ntf.keras.utils.custom_object_scope\ntf.keras.utils.custom_object_scope\ntf . keras . utils . CustomObjectScope ( custom_objects )\ntf . keras . utils . CustomObjectScope ( custom_objects )\nUnder a scope with custom_object_scope(objects_dict) , Keras methods such\nas keras.models.load_model() or keras.models.model_from_config() will be able to deserialize any\ncustom object referenced by a saved config (e.g. a custom layer or metric).\nwith custom_object_scope(objects_dict)\nkeras.models.load_model()\nkeras.models.model_from_config()\nConsider a custom regularizer my_regularizer :\nmy_regularizer\nlayer = Dense ( 3 , kernel_regularizer = my_regularizer ) # Config contains a reference to `my_regularizer` config = layer . get_config () ... # Later: with custom_object_scope ({ 'my_regularizer' : my_regularizer }): layer = Dense . from_config ( config )\nlayer = Dense ( 3 , kernel_regularizer = my_regularizer ) # Config contains a reference to `my_regularizer` config = layer . get_config () ... # Later: with custom_object_scope ({ 'my_regularizer' : my_regularizer }): layer = Dense . from_config ( config )\nArgs\nArgs\ncustom_objects Dictionary of {str: object} pairs,\nwhere the str key is the object name.\ncustom_objects\n{str: object}\nstr\nMethods\n__enter__\n__enter__\nView source\n__enter__ ()\n__enter__ ()\n__exit__\n__exit__\nView source\n__exit__ ( * args , ** kwargs )\n__exit__ ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/minimum",
    "content": "DEPRECATED.\ntf . keras . backend . minimum ( x , y )\ntf . keras . backend . minimum ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logical_not",
    "content": "Computes the element-wise NOT of the given input tensor.\nMain aliases tf.keras.ops.numpy.logical_not\ntf.keras.ops.numpy.logical_not\ntf.keras.ops.numpy.logical_not\ntf . keras . ops . logical_not ( x )\ntf . keras . ops . logical_not ( x )\nZeros are treated as False and non-zeros are treated as True .\nFalse\nTrue\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise logical NOT of the input.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay",
    "content": "A LearningRateSchedule that uses a piecewise constant decay schedule.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values , name = 'PiecewiseConstant' )\ntf . keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values , name = 'PiecewiseConstant' )\nThe function returns a 1-arg callable to compute the piecewise constant\nwhen passed the current optimizer step. This can be useful for changing the\nlearning rate value across different invocations of optimizer functions.\nExample: use a learning rate that's 1.0 for the first 100001 steps, 0.5\n    for the next 10000 steps, and 0.1 for any additional steps.\nstep = ops . array ( 0 ) boundaries = [ 100000 , 110000 ] values = [ 1.0 , 0.5 , 0.1 ] learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) # Later, whenever we perform an optimization step, we pass in the step. learning_rate = learning_rate_fn ( step )\nstep = ops . array ( 0 ) boundaries = [ 100000 , 110000 ] values = [ 1.0 , 0.5 , 0.1 ] learning_rate_fn = keras . optimizers . schedules . PiecewiseConstantDecay ( boundaries , values ) # Later, whenever we perform an optimization step, we pass in the step. learning_rate = learning_rate_fn ( step )\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate. The learning rate schedule is also serializable and\ndeserializable using keras.optimizers.schedules.serialize and keras.optimizers.schedules.deserialize .\nkeras.optimizers.Optimizer\nkeras.optimizers.schedules.serialize\nkeras.optimizers.schedules.deserialize\nArgs\nArgs\nboundaries A list of Python numbers with strictly increasing\nentries, and with all elements having the same type as the\noptimizer step. values A list of Python numbers that specifies the values for the\nintervals defined by boundaries . It should have one more\nelement than boundaries , and all elements should have the same\ntype. name A string. Optional name of the operation. Defaults to \"PiecewiseConstant\" .\nboundaries\nvalues\nboundaries\nboundaries\nname\n\"PiecewiseConstant\"\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as the boundary tensors.\nReturns\nThe output of the 1-arg function that takes the step is values[0] when step <= boundaries[0] , values[1] when step > boundaries[0] and step <= boundaries[1] ,\n..., and values[-1] when step > boundaries[-1] .\nstep\nvalues[0]\nstep <= boundaries[0]\nvalues[1]\nstep > boundaries[0]\nstep <= boundaries[1]\nvalues[-1]\nstep > boundaries[-1]\nRaises\nRaises\nValueError if the number of elements in the boundaries and values lists do not match.\nValueError\nboundaries\nvalues\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data",
    "content": "Loads the IMDB dataset .\ntf . keras . datasets . imdb . load_data ( path = 'imdb.npz' , num_words = None , skip_top = 0 , maxlen = None , seed = 113 , start_char = 1 , oov_char = 2 , index_from = 3 , ** kwargs )\ntf . keras . datasets . imdb . load_data ( path = 'imdb.npz' , num_words = None , skip_top = 0 , maxlen = None , seed = 113 , start_char = 1 , oov_char = 2 , index_from = 3 , ** kwargs )\nThis is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment\n(positive/negative). Reviews have been preprocessed, and each review is\nencoded as a list of word indexes (integers).\nFor convenience, words are indexed by overall frequency in the dataset,\nso that for instance the integer \"3\" encodes the 3rd most frequent word in\nthe data. This allows for quick filtering operations such as:\n\"only consider the top 10,000 most\ncommon words, but eliminate the top 20 most common words\".\nAs a convention, \"0\" does not stand for a specific word, but instead is used\nto encode the pad token.\nArgs\nArgs\npath where to cache the data (relative to ~/.keras/dataset ). num_words integer or None. Words are\nranked by how often they occur (in the training set) and only\nthe num_words most frequent words are kept. Any less frequent word\nwill appear as oov_char value in the sequence data. If None,\nall words are kept. Defaults to None . skip_top skip the top N most frequently occurring words\n(which may not be informative). These words will appear as oov_char value in the dataset. When 0, no words are\nskipped. Defaults to 0 . maxlen int or None. Maximum sequence length.\nAny longer sequence will be truncated. None, means no truncation.\nDefaults to None . seed int. Seed for reproducible data shuffling. start_char int. The start of a sequence will be marked with this\ncharacter. 0 is usually the padding character. Defaults to 1 . oov_char int. The out-of-vocabulary character.\nWords that were cut out because of the num_words or skip_top limits will be replaced with this character. index_from int. Index actual words with this index and higher.\npath\n~/.keras/dataset\nnum_words\nnum_words\noov_char\nNone\nskip_top\noov_char\n0\nmaxlen\nNone\nseed\nstart_char\n1\noov_char\nnum_words\nskip_top\nindex_from\nReturns Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train , x_test : lists of sequences, which are lists of indexes\n  (integers). If the num_words argument was specific, the maximum\n  possible index value is num_words - 1 . If the maxlen argument was\n  specified, the largest possible sequence length is maxlen .\nx_train\nx_test\nnum_words - 1\nmaxlen\nmaxlen\ny_train , y_test : lists of integer labels (1 or 0).\ny_train\ny_test\nnum_words"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/convnext/preprocess_input",
    "content": "A placeholder method for backward compatibility.\ntf . keras . applications . convnext . preprocess_input ( x , data_format = None )\ntf . keras . applications . convnext . preprocess_input ( x , data_format = None )\nThe preprocessing logic has been included in the convnext model\nimplementation. Users are no longer required to call this method to\nnormalize the input data. This method does nothing and only kept as a\nplaceholder to align the API surface between old and new version of model.\nArgs\nArgs\nx A floating point numpy.array or a tensor. data_format Optional data format of the image tensor/array. Defaults to\nNone, in which case the global setting keras.backend.image_data_format() is used\n(unless you changed it, it defaults to \"channels_last\" ).{mode}\nx\nnumpy.array\ndata_format\nkeras.backend.image_data_format()\n\"channels_last\"\nReturns Unchanged numpy.array or tensor.\nReturns\nnumpy.array"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpectralNormalization",
    "content": "Performs spectral normalization on the weights of a target layer.\nInherits From: Wrapper , Layer , Operation\nWrapper\nLayer\nOperation\ntf . keras . layers . SpectralNormalization ( layer , power_iterations = 1 , ** kwargs )\ntf . keras . layers . SpectralNormalization ( layer , power_iterations = 1 , ** kwargs )\nThis wrapper controls the Lipschitz constant of the weights of a layer by\nconstraining their spectral norm, which can stabilize the training of GANs.\nArgs\nArgs\nlayer A keras.layers.Layer instance that\nhas either a kernel (e.g. Conv2D , Dense ...)\nor an embeddings attribute ( Embedding layer). power_iterations int, the number of iterations during normalization. **kwargs Base wrapper keyword arguments.\nlayer\nkeras.layers.Layer\nkernel\nConv2D\nDense\nembeddings\nEmbedding\npower_iterations\n**kwargs\nWrap keras.layers.Conv2D :\nkeras.layers.Conv2D\n>>> x = np . random . rand ( 1 , 10 , 10 , 1 ) >>> conv2d = SpectralNormalization ( keras . layers . Conv2D ( 2 , 2 )) >>> y = conv2d ( x ) >>> y . shape ( 1 , 9 , 9 , 2 )\n>>> x = np . random . rand ( 1 , 10 , 10 , 1 ) >>> conv2d = SpectralNormalization ( keras . layers . Conv2D ( 2 , 2 )) >>> y = conv2d ( x ) >>> y . shape ( 1 , 9 , 9 , 2 )\nWrap keras.layers.Dense :\nkeras.layers.Dense\n>>> x = np . random . rand ( 1 , 10 , 10 , 1 ) >>> dense = SpectralNormalization ( keras . layers . Dense ( 10 )) >>> y = dense ( x ) >>> y . shape ( 1 , 10 , 10 , 10 )\n>>> x = np . random . rand ( 1 , 10 , 10 , 1 ) >>> dense = SpectralNormalization ( keras . layers . Dense ( 10 )) >>> y = dense ( x ) >>> y . shape ( 1 , 10 , 10 , 10 )\nSpectral Normalization for GAN .\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nnormalized_weights\nnormalized_weights\nView source\nnormalized_weights ()\nnormalized_weights ()\nGenerate spectral normalized weights.\nThis method returns the updated value for self.kernel with the\nspectral normalized value, so that the layer is ready for call() .\nself.kernel\ncall()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/bincount",
    "content": "Count the number of occurrences of each value in a tensor of integers.\nMain aliases tf.keras.ops.numpy.bincount\ntf.keras.ops.numpy.bincount\ntf.keras.ops.numpy.bincount\ntf . keras . ops . bincount ( x , weights = None , minlength = 0 , sparse = False )\ntf . keras . ops . bincount ( x , weights = None , minlength = 0 , sparse = False )\nArgs\nArgs\nx Input tensor.\nIt must be of dimension 1, and it must only contain non-negative\ninteger(s). weights Weight tensor.\nIt must have the same length as x . The default value is None .\nIf specified, x is weighted by it, i.e. if n = x[i] , out[n] += weight[i] instead of the default behavior out[n] += 1 . minlength An integer.\nThe default value is 0. If specified, there will be at least\nthis number of bins in the output tensor. If greater than max(x) + 1 , each value of the output at an index higher than max(x) is set to 0. sparse Whether to return a sparse tensor; for backends that support\nsparse tensors.\nx\nweights\nx\nNone\nx\nn = x[i]\nout[n] += weight[i]\nout[n] += 1\nminlength\nmax(x) + 1\nmax(x)\nsparse\nReturns 1D tensor where each element gives the number of occurrence(s) of its\nindex value in x. Its length is the maximum between max(x) + 1 and\nminlength.\nReturns\nmax(x) + 1\nx = keras . ops . array ([ 1 , 2 , 2 , 3 ], dtype = \"uint8\" ) keras . ops . bincount ( x ) array ([ 0 , 1 , 2 , 1 ], dtype = int32 ) weights = x / 2 weights array ([ 0.5 , 1. , 1. , 1.5 ], dtype = float64 ) keras . ops . bincount ( x , weights = weights ) array ([ 0. , 0.5 , 2. , 1.5 ], dtype = float64 ) minlength = ( keras . ops . max ( x ) . numpy () + 1 ) + 2 # 6 keras . ops . bincount ( x , minlength = minlength ) array ([ 0 , 1 , 2 , 1 , 0 , 0 ], dtype = int32 )\nx = keras . ops . array ([ 1 , 2 , 2 , 3 ], dtype = \"uint8\" )\nkeras . ops . bincount ( x )\narray ([ 0 , 1 , 2 , 1 ], dtype = int32 )\nweights = x / 2\nweights\narray ([ 0.5 , 1. , 1. , 1.5 ], dtype = float64 )\nkeras . ops . bincount ( x , weights = weights )\narray ([ 0. , 0.5 , 2. , 1.5 ], dtype = float64 )\nminlength = ( keras . ops . max ( x ) . numpy () + 1 ) + 2 # 6\nkeras . ops . bincount ( x , minlength = minlength )\narray ([ 0 , 1 , 2 , 1 , 0 , 0 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/squeeze",
    "content": "Remove axes of length one from x .\nx\nMain aliases tf.keras.ops.numpy.squeeze\ntf.keras.ops.numpy.squeeze\ntf.keras.ops.numpy.squeeze\ntf . keras . ops . squeeze ( x , axis = None )\ntf . keras . ops . squeeze ( x , axis = None )\nArgs\nArgs\nx Input tensor. axis Select a subset of the entries of length one in the shape.\nx\naxis\nReturns The input tensor with all or a subset of the dimensions of\nlength 1 removed.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/stft",
    "content": "Short-Time Fourier Transform along the last axis of the input.\ntf . keras . ops . stft ( x , sequence_length , sequence_stride , fft_length , window = 'hann' , center = True )\ntf . keras . ops . stft ( x , sequence_length , sequence_stride , fft_length , window = 'hann' , center = True )\nThe STFT computes the Fourier transform of short overlapping windows of the\ninput. This giving frequency components of the signal as they change over\ntime.\nArgs\nArgs\nx Input tensor. sequence_length An integer representing the sequence length. sequence_stride An integer representing the sequence hop size. fft_length An integer representing the size of the FFT to apply. If not\nspecified, uses the smallest power of 2 enclosing sequence_length . window A string, a tensor of the window or None . If window is a\nstring, available values are \"hann\" and \"hamming\" . If window is a tensor, it will be used directly as the window and its length\nmust be sequence_length . If window is None , no windowing is\nused. Defaults to \"hann\" . center Whether to pad x on both sides so that the t-th sequence is\ncentered at time t * sequence_stride . Otherwise, the t-th sequence\nbegins at time t * sequence_stride . Defaults to True .\nx\nsequence_length\nsequence_stride\nfft_length\nsequence_length\nwindow\nNone\nwindow\n\"hann\"\n\"hamming\"\nwindow\nsequence_length\nwindow\nNone\n\"hann\"\ncenter\nx\nt * sequence_stride\nt * sequence_stride\nTrue\nReturns A tuple containing two tensors - the real and imaginary parts of the\nSTFT output.\nReturns\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ]) stft ( x , 3 , 2 , 3 ) ( array ([[ 0.75 , - 0.375 ], [ 3.75 , - 1.875 ], [ 5.25 , - 2.625 ]]), array ([[ 0.0 , 0.64951905 ], [ 0.0 , 0.64951905 ], [ 0.0 , - 0.64951905 ]]))\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nstft ( x , 3 , 2 , 3 )\n( array ([[ 0.75 , - 0.375 ],\n[ 3.75 , - 1.875 ],\n[ 5.25 , - 2.625 ]]), array ([[ 0.0 , 0.64951905 ],\n[ 0.0 , 0.64951905 ],\n[ 0.0 , - 0.64951905 ]]))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomNormal",
    "content": "Random normal initializer.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.random_normal\ntf.keras.initializers.random_normal\ntf.keras.initializers.random_normal\ntf . keras . initializers . RandomNormal ( mean = 0.0 , stddev = 0.05 , seed = None )\ntf . keras . initializers . RandomNormal ( mean = 0.0 , stddev = 0.05 , seed = None )\nDraws samples from a normal distribution for given parameters.\n# Standalone usage: initializer = RandomNormal ( mean = 0.0 , stddev = 1.0 ) values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = RandomNormal ( mean = 0.0 , stddev = 1.0 )\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = RandomNormal ( mean = 0.0 , stddev = 1.0 ) layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = RandomNormal ( mean = 0.0 , stddev = 1.0 )\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nmean A python scalar or a scalar keras tensor. Mean of the random\nvalues to generate. stddev A python scalar or a scalar keras tensor. Standard deviation of\nthe random values to generate. seed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nmean\nstddev\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/argmax",
    "content": "DEPRECATED.\ntf . keras . backend . argmax ( x , axis =- 1 )\ntf . keras . backend . argmax ( x , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_uniform",
    "content": "DEPRECATED.\ntf . keras . backend . random_uniform ( shape , minval = 0.0 , maxval = 1.0 , dtype = None , seed = None )\ntf . keras . backend . random_uniform ( shape , minval = 0.0 , maxval = 1.0 , dtype = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/minimum",
    "content": "Functional interface to the keras.layers.Minimum layer.\nkeras.layers.Minimum\ntf . keras . layers . minimum ( inputs , ** kwargs )\ntf . keras . layers . minimum ( inputs , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors , all of the same shape. **kwargs Standard layer keyword arguments.\ninputs\n**kwargs\nReturns A tensor as the elementwise product of the inputs with the same\nshape as the inputs.\nReturns\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . minimum ([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . minimum ([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) y = keras . layers . minimum ([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\ny = keras . layers . minimum ([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule",
    "content": "The learning rate schedule base class.\nUsed in the notebooks\nNeural machine translation with a Transformer and Keras\nYou can use a learning rate schedule to modulate how the learning rate\nof your optimizer changes over time.\nSeveral built-in learning rate schedules are available, such as keras.optimizers.schedules.ExponentialDecay or keras.optimizers.schedules.PiecewiseConstantDecay :\nkeras.optimizers.schedules.ExponentialDecay\nkeras.optimizers.schedules.PiecewiseConstantDecay\nlr_schedule = keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate = 1e-2 , decay_steps = 10000 , decay_rate = 0.9 ) optimizer = keras . optimizers . SGD ( learning_rate = lr_schedule )\nlr_schedule = keras . optimizers . schedules . ExponentialDecay ( initial_learning_rate = 1e-2 , decay_steps = 10000 , decay_rate = 0.9 ) optimizer = keras . optimizers . SGD ( learning_rate = lr_schedule )\nA LearningRateSchedule instance can be passed in as the learning_rate argument of any optimizer.\nLearningRateSchedule\nlearning_rate\nTo implement your own schedule object, you should implement the __call__ method, which takes a step argument (scalar integer tensor, the\ncurrent training step count).\nLike for any other Keras object, you can also optionally\nmake your object serializable by implementing the get_config and from_config methods.\n__call__\nstep\nget_config\nfrom_config\nclass MyLRSchedule ( keras . optimizers . schedules . LearningRateSchedule ): def __init__ ( self , initial_learning_rate ): self . initial_learning_rate = initial_learning_rate def __call__ ( self , step ): return self . initial_learning_rate / ( step + 1 ) optimizer = keras . optimizers . SGD ( learning_rate = MyLRSchedule ( 0.1 ))\nclass MyLRSchedule ( keras . optimizers . schedules . LearningRateSchedule ): def __init__ ( self , initial_learning_rate ): self . initial_learning_rate = initial_learning_rate def __call__ ( self , step ): return self . initial_learning_rate / ( step + 1 ) optimizer = keras . optimizers . SGD ( learning_rate = MyLRSchedule ( 0.1 ))\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/gamma",
    "content": "Draw random samples from the Gamma distribution.\ntf . keras . random . gamma ( shape , alpha , dtype = None , seed = None )\ntf . keras . random . gamma ( shape , alpha , dtype = None , seed = None )\nArgs\nArgs\nshape The shape of the random values to generate. alpha Float, the parameter of the distribution. dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ). seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nalpha\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/repeat",
    "content": "Repeat each element of a tensor after themselves.\nMain aliases tf.keras.ops.numpy.repeat\ntf.keras.ops.numpy.repeat\ntf.keras.ops.numpy.repeat\ntf . keras . ops . repeat ( x , repeats , axis = None )\ntf . keras . ops . repeat ( x , repeats , axis = None )\nArgs\nArgs\nx Input tensor. repeats The number of repetitions for each element. axis The axis along which to repeat values. By default, use\nthe flattened input array, and return a flat output array.\nx\nrepeats\naxis\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/DTypePolicy",
    "content": "A dtype policy for a Keras layer.\nMain aliases tf.keras.dtype_policies.DTypePolicy , tf.keras.mixed_precision.DTypePolicy , tf.keras.mixed_precision.Policy Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.DTypePolicy\ntf.keras.dtype_policies.DTypePolicy , tf.keras.mixed_precision.DTypePolicy , tf.keras.mixed_precision.Policy\ntf.keras.dtype_policies.DTypePolicy\ntf.keras.mixed_precision.DTypePolicy\ntf.keras.mixed_precision.Policy\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.DTypePolicy\ntf.compat.v1.keras.DTypePolicy\ntf . keras . DTypePolicy ( name )\ntf . keras . DTypePolicy ( name )\nUsed in the notebooks\nMixed precision\nA dtype policy determines a layer's computation and variable dtypes. Each\nlayer has a policy. Policies can be passed to the dtype argument of layer\nconstructors, or a global policy can be set with keras.config.set_dtype_policy .\ndtype\nkeras.config.set_dtype_policy\nArgs\nArgs\nname The policy name, which determines the compute and variable dtypes.\nCan be any dtype name, such as \"float32\" or \"float64\" ,\nwhich causes both the compute and variable dtypes\nwill be that dtype.\nCan also be the string \"mixed_float16\" or \"mixed_bfloat16\" ,\nwhich causes the compute dtype to be float16 or bfloat16 and the variable dtype to be float32 .\nname\n\"float32\"\n\"float64\"\n\"mixed_float16\"\n\"mixed_bfloat16\"\nfloat16\nbfloat16\nfloat32\nTypically you only need to interact with dtype policies when using mixed\nprecision, which is the use of float16 or bfloat16 for computations and\nfloat32 for variables. This is why the term mixed_precision appears in the\nAPI name. Mixed precision can be enabled by passing \"mixed_float16\" or \"mixed_bfloat16\" to keras.mixed_precision.set_dtype_policy() .\nmixed_precision\n\"mixed_float16\"\n\"mixed_bfloat16\"\nkeras.mixed_precision.set_dtype_policy()\nkeras . config . set_dtype_policy ( \"mixed_float16\" ) layer1 = keras . layers . Dense ( 10 ) layer1 . dtype_policy # layer1 will automatically use mixed precision < DTypePolicy \"mixed_float16\" > # Can optionally override layer to use float32 # instead of mixed precision. layer2 = keras . layers . Dense ( 10 , dtype = \"float32\" ) layer2 . dtype_policy < DTypePolicy \"float32\" > # Set policy back to initial float32. keras . config . set_dtype_policy ( 'float32' )\nkeras . config . set_dtype_policy ( \"mixed_float16\" )\nlayer1 = keras . layers . Dense ( 10 )\nlayer1 . dtype_policy # layer1 will automatically use mixed precision\n< DTypePolicy \"mixed_float16\" >\n# Can optionally override layer to use float32\n# instead of mixed precision.\nlayer2 = keras . layers . Dense ( 10 , dtype = \"float32\" )\nlayer2 . dtype_policy\n< DTypePolicy \"float32\" >\n# Set policy back to initial float32.\nkeras . config . set_dtype_policy ( 'float32' )\nIn the example above, passing dtype=\"float32\" to the layer is\nequivalent to passing dtype=keras.config.DTypePolicy(\"float32\") .\nIn general, passing a dtype policy name to a layer is equivalent\nto passing the corresponding policy, so it is never necessary\nto explicitly construct a DTypePolicy object.\ndtype=\"float32\"\ndtype=keras.config.DTypePolicy(\"float32\")\nDTypePolicy\nAttributes\nAttributes\ncompute_dtype The compute dtype of this policy.\ncompute_dtype\nThis is the dtype layers will do their computations in. Typically layers\noutput tensors with the compute dtype as well.\nNote that even if the compute dtype is float16 or bfloat16, hardware\ndevices may not do individual adds, multiplies, and other fundamental\noperations in float16 or bfloat16, but instead may do some of them in\nfloat32 for numeric stability. The compute dtype is the dtype of the\ninputs and outputs of the ops that the layer executes.\nInternally, many ops will do certain internal calculations in\nfloat32 or some other device-internal intermediate format with higher\nprecision than float16/bfloat16, to increase numeric stability. name Returns the name of this policy. variable_dtype The variable dtype of this policy.\nname\nvariable_dtype\nThis is the dtype layers will create their variables in, unless a layer\nexplicitly chooses a different dtype. If this is different than DTypePolicy.compute_dtype , Layers will cast variables to\nthe compute dtype to avoid type errors.\nDTypePolicy.compute_dtype\nVariable regularizers are run in the variable dtype, not the compute\ndtype.\nMethods\nconvert_input\nconvert_input\nView source\nconvert_input ( x , autocast , dtype )\nconvert_input ( x , autocast , dtype )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log_softmax",
    "content": "Log-softmax activation function.\nMain aliases tf.keras.ops.nn.log_softmax\ntf.keras.ops.nn.log_softmax\ntf.keras.ops.nn.log_softmax\ntf . keras . ops . log_softmax ( x , axis =- 1 )\ntf . keras . ops . log_softmax ( x , axis =- 1 )\nf(x) = x - max(x) - log(sum(exp(x - max(x))))\nf(x) = x - max(x) - log(sum(exp(x - max(x))))\nArgs\nArgs\nx Input tensor. axis Integer, axis along which the log-softmax is applied.\nDefaults to -1 .\nx\naxis\n-1\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_log_softmax = keras . ops . log_softmax ( x ) print ( x_log_softmax ) array ([ - 2.40760596 , - 1.40760596 , - 0.40760596 ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_log_softmax = keras . ops . log_softmax ( x )\nprint ( x_log_softmax )\narray ([ - 2.40760596 , - 1.40760596 , - 0.40760596 ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/get",
    "content": "Retrieve a Keras quantizer object via an identifier.\ntf . keras . quantizers . get ( identifier , ** kwargs )\ntf . keras . quantizers . get ( identifier , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/linspace",
    "content": "Return evenly spaced numbers over a specified interval.\nMain aliases tf.keras.ops.numpy.linspace\ntf.keras.ops.numpy.linspace\ntf.keras.ops.numpy.linspace\ntf . keras . ops . linspace ( start , stop , num = 50 , endpoint = True , retstep = False , dtype = None , axis = 0 )\ntf . keras . ops . linspace ( start , stop , num = 50 , endpoint = True , retstep = False , dtype = None , axis = 0 )\nReturns num evenly spaced samples, calculated over the interval [start, stop] .\nnum\n[start, stop]\nThe endpoint of the interval can optionally be excluded.\nArgs\nArgs\nstart The starting value of the sequence. stop The end value of the sequence, unless endpoint is set to False . In that case, the sequence consists of all but the last\nof num + 1 evenly spaced samples, so that stop is excluded.\nNote that the step size changes when endpoint is False . num Number of samples to generate. Defaults to 50 . Must be\nnon-negative. endpoint If True , stop is the last sample. Otherwise, it is\nnot included. Defaults to True . retstep If True , return (samples, step) , where step is the\nspacing between samples. dtype The type of the output tensor. axis The axis in the result to store the samples. Relevant only if\nstart or stop are array-like. Defaults to 0 .\nstart\nstop\nendpoint\nFalse\nnum + 1\nstop\nendpoint\nFalse\nnum\n50\nendpoint\nTrue\nstop\nTrue\nretstep\nTrue\n(samples, step)\nstep\ndtype\naxis\n0\nNote Torch backend does not support axis argument.\nNote\naxis\nReturns A tensor of evenly spaced numbers.\nIf retstep is True , returns (samples, step)\nReturns\nretstep\nTrue\n(samples, step)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/amax",
    "content": "Returns the maximum of an array or maximum value along an axis.\nMain aliases tf.keras.ops.numpy.amax\ntf.keras.ops.numpy.amax\ntf.keras.ops.numpy.amax\ntf . keras . ops . amax ( x , axis = None , keepdims = False )\ntf . keras . ops . amax ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis along which to compute the maximum.\nBy default ( axis=None ), find the maximum value in all the\ndimensions of the input array. keepdims If True , axes which are reduced are left in the result as\ndimensions that are broadcast to the size of the original\ninput tensor. Defaults to False .\nx\naxis\naxis=None\nkeepdims\nTrue\nFalse\nReturns An array with the maximum value. If axis=None , the result is a scalar\nvalue representing the maximum element in the entire array. If axis is\ngiven, the result is an array with the maximum values along\nthe specified axis.\nReturns\naxis=None\naxis\nx = keras . ops . convert_to_tensor ([[ 1 , 3 , 5 ], [ 2 , 3 , 6 ]]) keras . ops . amax ( x ) array ( 6 , dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 3 , 5 ], [ 2 , 3 , 6 ]])\nkeras . ops . amax ( x )\narray ( 6 , dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 1 , 5 , 2 ]]) keras . ops . amax ( x , axis = 0 ) array ([ 1 , 6 , 8 ], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 1 , 5 , 2 ]])\nkeras . ops . amax ( x , axis = 0 )\narray ([ 1 , 6 , 8 ], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 1 , 5 , 2 ]]) keras . ops . amax ( x , axis = 1 , keepdims = True ) array ([[ 8 ], [ 5 ]], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 1 , 5 , 2 ]])\nkeras . ops . amax ( x , axis = 1 , keepdims = True )\narray ([[ 8 ], [ 5 ]], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/where",
    "content": "Return elements chosen from x1 or x2 depending on condition .\nx1\nx2\ncondition\nMain aliases tf.keras.ops.numpy.where\ntf.keras.ops.numpy.where\ntf.keras.ops.numpy.where\ntf . keras . ops . where ( condition , x1 = None , x2 = None )\ntf . keras . ops . where ( condition , x1 = None , x2 = None )\nArgs\nArgs\ncondition Where True , yield x1 , otherwise yield x2 . x1 Values from which to choose when condition is True . x2 Values from which to choose when condition is False .\ncondition\nTrue\nx1\nx2\nx1\ncondition\nTrue\nx2\ncondition\nFalse\nReturns A tensor with elements from x1 where condition is True , and\nelements from x2 where condition is False .\nReturns\nx1\ncondition\nTrue\nx2\ncondition\nFalse"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/deserialize",
    "content": "Return a Keras constraint object via its config.\ntf . keras . constraints . deserialize ( config , custom_objects = None )\ntf . keras . constraints . deserialize ( config , custom_objects = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Dice",
    "content": "Computes the Dice loss value between y_true and y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . Dice ( reduction = 'sum_over_batch_size' , name = 'dice' )\ntf . keras . losses . Dice ( reduction = 'sum_over_batch_size' , name = 'dice' )\nloss = 1 - ( 2 * sum ( y_true * y_pred )) / ( sum ( y_true ) + sum ( y_pred ))\nloss = 1 - ( 2 * sum ( y_true * y_pred )) / ( sum ( y_true ) + sum ( y_pred ))\nArgs\nArgs\ny_true tensor of true targets. y_pred tensor of predicted targets.\ny_true\ny_pred\nReturns Dice loss value.\nReturns\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate",
    "content": "Concatenates a list of inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Concatenate ( axis =- 1 , ** kwargs )\ntf . keras . layers . Concatenate ( axis =- 1 , ** kwargs )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nMigrate from TPU embedding_columns to TPUEmbedding layer\nLoad CSV data\npix2pix: Image-to-image translation with a conditional GAN\nImage segmentation\nNetworks\nTFX Keras Component Tutorial\nIt takes as input a list of tensors, all of the same shape except\nfor the concatenation axis, and returns a single tensor that is the\nconcatenation of all inputs.\nx = np . arange ( 20 ) . reshape ( 2 , 2 , 5 ) y = np . arange ( 20 , 30 ) . reshape ( 2 , 1 , 5 ) keras . layers . Concatenate ( axis = 1 )([ x , y ])\nx = np . arange ( 20 ) . reshape ( 2 , 2 , 5 )\ny = np . arange ( 20 , 30 ) . reshape ( 2 , 1 , 5 )\nkeras . layers . Concatenate ( axis = 1 )([ x , y ])\nUsage in a Keras model:\nx1 = keras . layers . Dense ( 8 )( np . arange ( 10 ) . reshape ( 5 , 2 )) x2 = keras . layers . Dense ( 8 )( np . arange ( 10 , 20 ) . reshape ( 5 , 2 )) y = keras . layers . Concatenate ()([ x1 , x2 ])\nx1 = keras . layers . Dense ( 8 )( np . arange ( 10 ) . reshape ( 5 , 2 ))\nx2 = keras . layers . Dense ( 8 )( np . arange ( 10 , 20 ) . reshape ( 5 , 2 ))\ny = keras . layers . Concatenate ()([ x1 , x2 ])\nArgs\nArgs\naxis Axis along which to concatenate. **kwargs Standard layer keyword arguments.\naxis\n**kwargs\nReturns A tensor, the concatenation of the inputs alongside axis axis .\nReturns\naxis\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/outer",
    "content": "Compute the outer product of two vectors.\nMain aliases tf.keras.ops.numpy.outer\ntf.keras.ops.numpy.outer\ntf.keras.ops.numpy.outer\ntf . keras . ops . outer ( x1 , x2 )\ntf . keras . ops . outer ( x1 , x2 )\nGiven two vectors x1 and x2 , the outer product is:\nx1\nx2\nout [ i , j ] = x1 [ i ] * x2 [ j ]\nout [ i , j ] = x1 [ i ] * x2 [ j ]\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Outer product of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction",
    "content": "Methods\nall\nall\nView source\n@classmethod all ()\n@classmethod\nall ()\nvalidate\nvalidate\nView source\n@classmethod validate ( key )\n@classmethod\nvalidate ( key )\nClass Variables\nClass Variables\nAUTO 'auto' NONE 'none' SUM 'sum' SUM_OVER_BATCH_SIZE 'sum_over_batch_size'\n'auto'\n'none'\n'sum'\n'sum_over_batch_size'"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/pack_x_y_sample_weight",
    "content": "Packs user-provided data into a tuple.\ntf . keras . utils . pack_x_y_sample_weight ( x , y = None , sample_weight = None )\ntf . keras . utils . pack_x_y_sample_weight ( x , y = None , sample_weight = None )\nUsed in the notebooks\nCreating a custom Counterfactual Logit Pairing Dataset\nThis is a convenience utility for packing data into the tuple formats\nthat Model.fit() uses.\nModel.fit()\nx = ops . ones (( 10 , 1 )) data = pack_x_y_sample_weight ( x ) isinstance ( data , ops . Tensor ) True y = ops . ones (( 10 , 1 )) data = pack_x_y_sample_weight ( x , y ) isinstance ( data , tuple ) True x , y = data\nx = ops . ones (( 10 , 1 ))\ndata = pack_x_y_sample_weight ( x )\nisinstance ( data , ops . Tensor )\nTrue\ny = ops . ones (( 10 , 1 ))\ndata = pack_x_y_sample_weight ( x , y )\nisinstance ( data , tuple )\nTrue\nx , y = data\nArgs\nArgs\nx Features to pass to Model . y Ground-truth targets to pass to Model . sample_weight Sample weight for each element.\nx\nModel\ny\nModel\nsample_weight\nReturns Tuple in the format used in Model.fit() .\nReturns\nModel.fit()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/FalseNegatives",
    "content": "Calculates the number of false negatives.\nInherits From: Metric\nMetric\ntf . keras . metrics . FalseNegatives ( thresholds = None , name = None , dtype = None )\ntf . keras . metrics . FalseNegatives ( thresholds = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nIf sample_weight is given, calculates the sum of the weights of\nfalse negatives. This metric creates one local variable, accumulator that is used to keep track of the number of false negatives.\nsample_weight\naccumulator\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nthresholds (Optional) Defaults to 0.5 . A float value, or a Python\nlist/tuple of float threshold values in [0, 1] . A threshold is\ncompared with prediction values to determine the truth value of\npredictions (i.e., above the threshold is True , below is False ).\nIf used with a loss function that sets from_logits=True (i.e. no\nsigmoid applied to predictions), thresholds should be set to 0.\nOne metric value is generated for each threshold value. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n0.5\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nname\ndtype\nm = keras . metrics . FalseNegatives () m . update_state ([ 0 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 ]) m . result () 2.0\nm = keras . metrics . FalseNegatives ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 ])\nm . result ()\n2.0\nm . reset_state () m . update_state ([ 0 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 0 , 1 , 0 , 0 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the metric statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/categorical",
    "content": "Draws samples from a categorical distribution.\ntf . keras . random . categorical ( logits , num_samples , dtype = 'int32' , seed = None )\ntf . keras . random . categorical ( logits , num_samples , dtype = 'int32' , seed = None )\nThis function takes as input logits , a 2-D input tensor with shape\n(batch_size, num_classes). Each row of the input represents a categorical\ndistribution, with each column index containing the log-probability for a\ngiven class.\nlogits\nThe function will output a 2-D tensor with shape (batch_size, num_samples),\nwhere each row contains samples from the corresponding row in logits .\nEach column index contains an independent samples drawn from the input\ndistribution.\nlogits\nArgs\nArgs\nlogits 2-D Tensor with shape (batch_size, num_classes). Each row\nshould define a categorical distibution with the unnormalized\nlog-probabilities for all classes. num_samples Int, the number of independent samples to draw for each\nrow of the input. This will be the second dimension of the output\ntensor's shape. dtype Optional dtype of the output tensor. seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nlogits\nnum_samples\ndtype\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator\nReturns A 2-D tensor with (batch_size, num_samples).\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/while_loop",
    "content": "While loop implementation.\ntf . keras . ops . while_loop ( cond , body , loop_vars , maximum_iterations = None )\ntf . keras . ops . while_loop ( cond , body , loop_vars , maximum_iterations = None )\nArgs\nArgs\ncond A callable that represents the termination condition of the loop.\nMust accept a loop_vars like structure as an argument. If loop_vars is a tuple or list, each element of loop_vars will be\npassed positionally to the callable. body A callable that represents the loop body. Must accept a loop_vars like structure as an argument, and return update value\nwith the same structure. If loop_vars is a tuple or list, each\nelement of loop_vars will be passed positionally to the callable. loop_vars An arbitrary nested structure of tensor state to persist\nacross loop iterations. maximum_iterations Optional maximum number of iterations of the while\nloop to run. If provided, the cond output is AND-ed with an\nadditional condition ensuring the number of iterations executed is\nno greater than maximum_iterations .\ncond\nloop_vars\nloop_vars\nloop_vars\nbody\nloop_vars\nloop_vars\nloop_vars\nloop_vars\nmaximum_iterations\ncond\nmaximum_iterations\nReturns A list/tuple of tensors, has the same shape and dtype as inputs .\nReturns\ninputs\ni = 0 cond = lambda i : i < 10 body = lambda i : i + 1 keras . ops . while_loop ( cond , body , i ) 10\ni = 0\ncond = lambda i : i < 10\nbody = lambda i : i + 1\nkeras . ops . while_loop ( cond , body , i )\n10\nx , y = 0 , 1 cond = lambda x , y : x < 10 body = lambda x , y : ( x + 1 , y + 1 ) keras . ops . while_loop ( cond , body , ( x , y )) 10 , 11\nx , y = 0 , 1\ncond = lambda x , y : x < 10\nbody = lambda x , y : ( x + 1 , y + 1 )\nkeras . ops . while_loop ( cond , body , ( x , y ))\n10 , 11"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arccosh",
    "content": "Inverse hyperbolic cosine, element-wise.\nMain aliases tf.keras.ops.numpy.arccosh\ntf.keras.ops.numpy.arccosh\ntf.keras.ops.numpy.arccosh\ntf . keras . ops . arccosh ( x )\ntf . keras . ops . arccosh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x.\nReturns\nx = keras . ops . convert_to_tensor ([ 10 , 100 ]) keras . ops . arccosh ( x ) array ([ 2.993223 , 5.298292 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 10 , 100 ])\nkeras . ops . arccosh ( x )\narray ([ 2.993223 , 5.298292 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation",
    "content": "A preprocessing layer which randomly rotates images during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomRotation ( factor , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , value_range = ( 0 , 255 ), data_format = None , ** kwargs )\ntf . keras . layers . RandomRotation ( factor , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , value_range = ( 0 , 255 ), data_format = None , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nImage classification\nData augmentation\nTransfer learning and fine-tuning\nRetraining an Image Classifier\nThis layer will apply random rotations to each image, filling empty space\naccording to fill_mode .\nfill_mode\nBy default, random rotations are only applied during training.\nAt inference time, the layer does nothing. If you need to apply random\nrotations at inference time, pass training=True when calling the layer.\ntraining=True\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\n[0., 1.)\n[0, 255]\ntf.data\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format\n(..., height, width, channels)\n\"channels_last\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format\n(..., height, width, channels)\n\"channels_last\"\nArgs\nArgs\nfactor a float represented as fraction of 2 Pi, or a tuple of size 2\nrepresenting lower and upper bound for rotating clockwise and\ncounter-clockwise. A positive values means rotating\ncounter clock-wise,\nwhile a negative value means clock-wise.\nWhen represented as a single\nfloat, this value is used for both the upper and lower bound.\nFor instance, factor=(-0.2, 0.3) results in an output rotation by a random\namount in the range [-20% * 2pi, 30% * 2pi] . factor=0.2 results in an\noutput rotating by a random amount\nin the range [-20% * 2pi, 20% * 2pi] . fill_mode Points outside the boundaries of the input are filled\naccording to the given mode\n(one of {\"constant\", \"reflect\", \"wrap\", \"nearest\"} ).\nfactor\nfactor=(-0.2, 0.3)\n[-20% * 2pi, 30% * 2pi]\nfactor=0.2\n[-20% * 2pi, 20% * 2pi]\nfill_mode\n{\"constant\", \"reflect\", \"wrap\", \"nearest\"}\nreflect : (d c b a | a b c d | d c b a) The input is extended by reflecting about\nthe edge of the last pixel.\n(d c b a | a b c d | d c b a)\nconstant : (k k k k | a b c d | k k k k) The input is extended by\nfilling all values beyond the edge with\nthe same constant value k = 0.\n(k k k k | a b c d | k k k k)\nwrap : (a b c d | a b c d | a b c d) The input is extended by\nwrapping around to the opposite edge.\n(a b c d | a b c d | a b c d)\nnearest : (a a a a | a b c d | d d d d) The input is extended by the nearest pixel. interpolation Interpolation mode. Supported values: \"nearest\" , \"bilinear\" . seed Integer. Used to create a random seed. fill_value a float represents the value to be filled outside\nthe boundaries when fill_mode=\"constant\" .\n(a a a a | a b c d | d d d d)\ninterpolation\n\"nearest\"\n\"bilinear\"\nseed\nfill_value\nfill_mode=\"constant\"\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/split_dataset",
    "content": "Splits a dataset into a left half and a right half (e.g. train / test).\ntf . keras . utils . split_dataset ( dataset , left_size = None , right_size = None , shuffle = False , seed = None )\ntf . keras . utils . split_dataset ( dataset , left_size = None , right_size = None , shuffle = False , seed = None )\nArgs\nArgs\ndataset A tf.data.Dataset , a torch.utils.data.Dataset object,\nor a list/tuple of arrays with the same length. left_size If float (in the range [0, 1] ), it signifies\nthe fraction of the data to pack in the left dataset. If integer, it\nsignifies the number of samples to pack in the left dataset. If None , defaults to the complement to right_size .\nDefaults to None . right_size If float (in the range [0, 1] ), it signifies\nthe fraction of the data to pack in the right dataset.\nIf integer, it signifies the number of samples to pack\nin the right dataset.\nIf None , defaults to the complement to left_size .\nDefaults to None . shuffle Boolean, whether to shuffle the data before splitting it. seed A random seed for shuffling.\ndataset\ntf.data.Dataset\ntorch.utils.data.Dataset\nleft_size\n[0, 1]\nNone\nright_size\nNone\nright_size\n[0, 1]\nNone\nleft_size\nNone\nshuffle\nseed\nReturns A tuple of two tf.data.Dataset objects:\nthe left and right splits.\nReturns\ntf.data.Dataset\ndata = np . random . random ( size = ( 1000 , 4 )) left_ds , right_ds = keras . utils . split_dataset ( data , left_size = 0.8 ) int ( left_ds . cardinality ()) 800 int ( right_ds . cardinality ()) 200\ndata = np . random . random ( size = ( 1000 , 4 ))\nleft_ds , right_ds = keras . utils . split_dataset ( data , left_size = 0.8 )\nint ( left_ds . cardinality ())\n800\nint ( right_ds . cardinality ())\n200"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_top_k_categorical_accuracy",
    "content": "tf . keras . metrics . sparse_top_k_categorical_accuracy ( y_true , y_pred , k = 5 )\ntf . keras . metrics . sparse_top_k_categorical_accuracy ( y_true , y_pred , k = 5 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tensordot",
    "content": "Compute the tensor dot product along specified axes.\nMain aliases tf.keras.ops.numpy.tensordot\ntf.keras.ops.numpy.tensordot\ntf.keras.ops.numpy.tensordot\ntf . keras . ops . tensordot ( x1 , x2 , axes = 2 )\ntf . keras . ops . tensordot ( x1 , x2 , axes = 2 )\nArgs\nArgs\nx1 First tensor. x2 Second tensor. axes\nx1\nx2\naxes\nIf an integer, N, sum over the last N axes of x1 and the\nfirst N axes of x2 in order. The sizes of the corresponding\naxes must match.\nx1\nx2\nOr, a list of axes to be summed over, first sequence applying\nto x1 , second to x2 . Both sequences must be of the\nsame length.\nx1\nx2\nReturns The tensor dot product of the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/count_nonzero",
    "content": "Counts the number of non-zero values in x along the given axis .\nx\naxis\nMain aliases tf.keras.ops.numpy.count_nonzero\ntf.keras.ops.numpy.count_nonzero\ntf.keras.ops.numpy.count_nonzero\ntf . keras . ops . count_nonzero ( x , axis = None )\ntf . keras . ops . count_nonzero ( x , axis = None )\nIf no axis is specified then all non-zeros in the tensor are counted.\nArgs\nArgs\nx Input tensor. axis Axis or tuple of axes along which to count the number of\nnon-zeros. Defaults to None .\nx\naxis\nNone\nReturns int or tensor of ints.\nReturns\nx = keras . ops . array ([[ 0 , 1 , 7 , 0 ], [ 3 , 0 , 2 , 19 ]]) keras . ops . count_nonzero ( x ) 5 keras . ops . count_nonzero ( x , axis = 0 ) array ([ 1 , 1 , 2 , 1 ], dtype = int64 ) keras . ops . count_nonzero ( x , axis = 1 ) array ([ 2 , 3 ], dtype = int64 )\nx = keras . ops . array ([[ 0 , 1 , 7 , 0 ], [ 3 , 0 , 2 , 19 ]])\nkeras . ops . count_nonzero ( x )\n5\nkeras . ops . count_nonzero ( x , axis = 0 )\narray ([ 1 , 1 , 2 , 1 ], dtype = int64 )\nkeras . ops . count_nonzero ( x , axis = 1 )\narray ([ 2 , 3 ], dtype = int64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/squeeze",
    "content": "DEPRECATED.\ntf . keras . backend . squeeze ( x , axis )\ntf . keras . backend . squeeze ( x , axis )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/multiply",
    "content": "Multiply arguments element-wise.\nMain aliases tf.keras.ops.numpy.multiply\ntf.keras.ops.numpy.multiply\ntf.keras.ops.numpy.multiply\ntf . keras . ops . multiply ( x1 , x2 )\ntf . keras . ops . multiply ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise product of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Maximum",
    "content": "Computes element-wise maximum on a list of inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Maximum ( ** kwargs )\ntf . keras . layers . Maximum ( ** kwargs )\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Maximum ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Maximum ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `y = keras.layers.maximum([x1, x2])` y = keras . layers . Maximum ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `y = keras.layers.maximum([x1, x2])`\ny = keras . layers . Maximum ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/istft",
    "content": "Inverse Short-Time Fourier Transform along the last axis of the input.\ntf . keras . ops . istft ( x , sequence_length , sequence_stride , fft_length , length = None , window = 'hann' , center = True )\ntf . keras . ops . istft ( x , sequence_length , sequence_stride , fft_length , length = None , window = 'hann' , center = True )\nTo reconstruct an original waveform, the parameters should be the same in stft .\nstft\nArgs\nArgs\nx Tuple of the real and imaginary parts of the input tensor. Both\ntensors in the tuple should be of floating type. sequence_length An integer representing the sequence length. sequence_stride An integer representing the sequence hop size. fft_length An integer representing the size of the FFT that produced stft . length An integer representing the output is clipped to exactly length.\nIf not specified, no padding or clipping take place. Defaults to None . window A string, a tensor of the window or None . If window is a\nstring, available values are \"hann\" and \"hamming\" . If window is a tensor, it will be used directly as the window and its length\nmust be sequence_length . If window is None , no windowing is\nused. Defaults to \"hann\" . center Whether x was padded on both sides so that the t-th sequence\nis centered at time t * sequence_stride . Defaults to True .\nx\nsequence_length\nsequence_stride\nfft_length\nstft\nlength\nNone\nwindow\nNone\nwindow\n\"hann\"\n\"hamming\"\nwindow\nsequence_length\nwindow\nNone\n\"hann\"\ncenter\nx\nt * sequence_stride\nTrue\nReturns A tensor containing the inverse Short-Time Fourier Transform along the\nlast axis of x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ]) istft ( stft ( x , 1 , 1 , 1 ), 1 , 1 , 1 ) array ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nistft ( stft ( x , 1 , 1 , 1 ), 1 , 1 , 1 )\narray ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer",
    "content": "DEPRECATED.\ntf . keras . preprocessing . text . Tokenizer ( num_words = None , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , char_level = False , oov_token = None , analyzer = None , ** kwargs )\ntf . keras . preprocessing . text . Tokenizer ( num_words = None , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , char_level = False , oov_token = None , analyzer = None , ** kwargs )\nUsed in the notebooks\nWiki Talk Comments Toxicity Prediction\nMethods\nfit_on_sequences\nfit_on_sequences\nView source\nfit_on_sequences ( sequences )\nfit_on_sequences ( sequences )\nfit_on_texts\nfit_on_texts\nView source\nfit_on_texts ( texts )\nfit_on_texts ( texts )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nsequences_to_matrix\nsequences_to_matrix\nView source\nsequences_to_matrix ( sequences , mode = 'binary' )\nsequences_to_matrix ( sequences , mode = 'binary' )\nsequences_to_texts\nsequences_to_texts\nView source\nsequences_to_texts ( sequences )\nsequences_to_texts ( sequences )\nsequences_to_texts_generator\nsequences_to_texts_generator\nView source\nsequences_to_texts_generator ( sequences )\nsequences_to_texts_generator ( sequences )\ntexts_to_matrix\ntexts_to_matrix\nView source\ntexts_to_matrix ( texts , mode = 'binary' )\ntexts_to_matrix ( texts , mode = 'binary' )\ntexts_to_sequences\ntexts_to_sequences\nView source\ntexts_to_sequences ( texts )\ntexts_to_sequences ( texts )\ntexts_to_sequences_generator\ntexts_to_sequences_generator\nView source\ntexts_to_sequences_generator ( texts )\ntexts_to_sequences_generator ( texts )\nto_json\nto_json\nView source\nto_json ( ** kwargs )\nto_json ( ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nget_word_index(...) : Retrieves a dict mapping words to their index in the IMDB dataset.\nget_word_index(...)\nload_data(...) : Loads the IMDB dataset .\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/UnitNorm",
    "content": "Constrains the weights incident to each hidden unit to have unit norm.\nInherits From: Constraint\nConstraint\nMain aliases tf.keras.constraints.unit_norm\ntf.keras.constraints.unit_norm\ntf.keras.constraints.unit_norm\ntf . keras . constraints . UnitNorm ( axis = 0 )\ntf . keras . constraints . UnitNorm ( axis = 0 )\nArgs\nArgs\naxis integer, axis along which to calculate weight norms.\nFor instance, in a Dense layer the weight matrix\nhas shape (input_dim, output_dim) ,\nset axis to 0 to constrain each weight vector\nof length (input_dim,) .\nIn a Conv2D layer with data_format=\"channels_last\" ,\nthe weight tensor has shape (rows, cols, input_depth, output_depth) ,\nset axis to [0, 1, 2] to constrain the weights of each filter tensor of size (rows, cols, input_depth) .\naxis\nDense\n(input_dim, output_dim)\naxis\n0\n(input_dim,)\nConv2D\ndata_format=\"channels_last\"\n(rows, cols, input_depth, output_depth)\naxis\n[0, 1, 2]\n(rows, cols, input_depth)\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a weight constraint from a configuration dictionary.\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns A keras.constraints.Constraint instance.\nkeras.constraints.Constraint\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns a Python dict of the object config.\nA constraint config is a Python dictionary (JSON-serializable) that can\nbe used to reinstantiate the same object.\nReturns Python dict containing the configuration of the constraint object.\n__call__\n__call__\nView source\n__call__ ( w )\n__call__ ( w )\nApplies the constraint to the input weight variable.\nBy default, the inputs weight variable is not modified.\nUsers should override this method to implement their own projection\nfunction.\nArgs\nw Input weight variable.\nw\nReturns Projected variable (by default, returns unmodified inputs)."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Ones",
    "content": "Initializer that generates tensors initialized to 1.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.ones\ntf.keras.initializers.ones\ntf.keras.initializers.ones\nAlso available via the shortcut function ones .\nones\n# Standalone usage: initializer = Ones () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = Ones ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = Ones () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = Ones ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor. Only numeric or boolean dtypes\nare supported. If not specified, keras.backend.floatx() is used, which default to float32 unless you configured it\notherwise (via keras.backend.set_floatx(float_dtype) ).\nshape\ndtype\nkeras.backend.floatx()\nfloat32\nkeras.backend.set_floatx(float_dtype)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop",
    "content": "A preprocessing layer which randomly crops images during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomCrop ( height , width , seed = None , data_format = None , name = None , ** kwargs )\ntf . keras . layers . RandomCrop ( height , width , seed = None , data_format = None , name = None , ** kwargs )\nDuring training, this layer will randomly choose a location to crop images\ndown to a target size. The layer will crop all the images in the same batch\nto the same cropping location.\nAt inference time, and during training if an input image is smaller than the\ntarget size, the input will be resized and cropped so as to return the\nlargest possible window in the image that matches the target aspect ratio.\nIf you need to apply random cropping at inference time, set training to\nTrue when calling the layer.\ntraining\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nof integer or floating point dtype. By default, the layer will output\nfloats.\n[0., 1.)\n[0, 255]\ntf.data\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format.\n(..., height, width, channels)\n\"channels_last\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., target_height, target_width, channels) .\n(..., target_height, target_width, channels)\nArgs\nArgs\nheight Integer, the height of the output shape. width Integer, the width of the output shape. seed Integer. Used to create a random seed. **kwargs Base layer keyword arguments, such as name and dtype .\nheight\nwidth\nseed\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . resnet_v2 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . resnet_v2 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/rfft",
    "content": "Real-valued Fast Fourier Transform along the last axis of the input.\ntf . keras . ops . rfft ( x , fft_length = None )\ntf . keras . ops . rfft ( x , fft_length = None )\nComputes the 1D Discrete Fourier Transform of a real-valued signal over the\ninner-most dimension of input.\nSince the Discrete Fourier Transform of a real-valued signal is\nHermitian-symmetric, RFFT only returns the fft_length / 2 + 1 unique\ncomponents of the FFT: the zero-frequency term, followed by the fft_length / 2 positive-frequency terms.\nfft_length / 2 + 1\nfft_length / 2\nAlong the axis RFFT is computed on, if fft_length is smaller than the\ncorresponding dimension of the input, the dimension is cropped. If it is\nlarger, the dimension is padded with zeros.\nfft_length\nArgs\nArgs\nx Input tensor. fft_length An integer representing the number of the fft length. If not\nspecified, it is inferred from the length of the last axis of x .\nDefaults to None .\nx\nfft_length\nx\nNone\nReturns A tuple containing two tensors - the real and imaginary parts of the\noutput.\nReturns\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ]) rfft ( x ) ( array ([ 10.0 , - 2.5 , - 2.5 ]), array ([ 0.0 , 3.4409548 , 0.81229924 ]))\nx = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nrfft ( x )\n( array ([ 10.0 , - 2.5 , - 2.5 ]), array ([ 0.0 , 3.4409548 , 0.81229924 ]))\nrfft ( x , 3 ) ( array ([ 3.0 , - 1.5 ]), array ([ 0.0 , 0.8660254 ]))\nrfft ( x , 3 )\n( array ([ 3.0 , - 1.5 ]), array ([ 0.0 , 0.8660254 ]))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_dot",
    "content": "DEPRECATED.\ntf . keras . backend . batch_dot ( x , y , axes = None )\ntf . keras . backend . batch_dot ( x , y , axes = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness",
    "content": "A preprocessing layer which randomly adjusts brightness during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomBrightness ( factor , value_range = ( 0 , 255 ), seed = None , ** kwargs )\ntf . keras . layers . RandomBrightness ( factor , value_range = ( 0 , 255 ), seed = None , ** kwargs )\nThis layer will randomly increase/reduce the brightness for the input RGB\nimages. At inference time, the output will be identical to the input.\nCall the layer with training=True to adjust the brightness of the input.\ntraining=True\ntf.data\nArgs\nArgs\nfactor Float or a list/tuple of 2 floats between -1.0 and 1.0. The\nfactor is used to determine the lower bound and upper bound of the\nbrightness adjustment. A float value will be chosen randomly between\nthe limits. When -1.0 is chosen, the output image will be black, and\nwhen 1.0 is chosen, the image will be fully white.\nWhen only one float is provided, eg, 0.2,\nthen -0.2 will be used for lower bound and 0.2\nwill be used for upper bound. value_range Optional list/tuple of 2 floats\nfor the lower and upper limit\nof the values of the input data.\nTo make no change, use [0.0, 1.0] , e.g., if the image input\nhas been scaled before this layer. Defaults to [0.0, 255.0] .\nThe brightness adjustment will be scaled to this range, and the\noutput values will be clipped to this range. seed optional integer, for fixed RNG behavior.\nfactor\nvalue_range\n[0.0, 1.0]\n[0.0, 255.0]\nseed\nInputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel\n    values can be of any range (e.g. [0., 1.) or [0, 255] )\n[0., 1.)\n[0, 255]\nOutput: 3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the factor . By default, the layer will output floats.\n    The output value will be clipped to the range [0, 255] ,\n    the valid range of RGB colors, and\n    rescaled based on the value_range if needed.\nfactor\n[0, 255]\nvalue_range\nrandom_bright = keras . layers . RandomBrightness ( factor = 0.2 ) # An image with shape [2, 2, 3] image = [[[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], [[ 7 , 8 , 9 ], [ 10 , 11 , 12 ]]] # Assume we randomly select the factor to be 0.1, then it will apply # 0.1 * 255 to all the channel output = random_bright ( image , training = True ) # output will be int64 with 25.5 added to each channel and round down.\nrandom_bright = keras . layers . RandomBrightness ( factor = 0.2 ) # An image with shape [2, 2, 3] image = [[[ 1 , 2 , 3 ], [ 4 , 5 , 6 ]], [[ 7 , 8 , 9 ], [ 10 , 11 , 12 ]]] # Assume we randomly select the factor to be 0.1, then it will apply # 0.1 * 255 to all the channel output = random_bright ( image , training = True ) # output will be int64 with 25.5 added to each channel and round down.\narray([[[26.5, 27.5, 28.5]\n            [29.5, 30.5, 31.5]]\n           [[32.5, 33.5, 34.5]\n            [35.5, 36.5, 37.5]]],\n          shape=(2, 2, 3), dtype=int64)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/deserialize_keras_object",
    "content": "Retrieve the object by deserializing the config dict.\ntf . keras . utils . deserialize_keras_object ( config , custom_objects = None , safe_mode = True , ** kwargs )\ntf . keras . utils . deserialize_keras_object ( config , custom_objects = None , safe_mode = True , ** kwargs )\nThe config dict is a Python dictionary that consists of a set of key-value\npairs, and represents a Keras object, such as an Optimizer , Layer , Metrics , etc. The saving and loading library uses the following keys to\nrecord information of a Keras object:\nOptimizer\nLayer\nMetrics\nclass_name : String. This is the name of the class,\nas exactly defined in the source\ncode, such as \"LossesContainer\".\nclass_name\nconfig : Dict. Library-defined or user-defined key-value pairs that store\nthe configuration of the object, as obtained by object.get_config() .\nconfig\nobject.get_config()\nmodule : String. The path of the python module. Built-in Keras classes\nexpect to have prefix keras .\nmodule\nkeras\nregistered_name : String. The key the class is registered under via keras.saving.register_keras_serializable(package, name) API. The\nkey has the format of '{package}>{name}', where package and name are\nthe arguments passed to register_keras_serializable() . If name is not\nprovided, it uses the class name. If registered_name successfully\nresolves to a class (that was registered), the class_name and config values in the dict will not be used. registered_name is only used for\nnon-built-in classes.\nregistered_name\nkeras.saving.register_keras_serializable(package, name)\npackage\nname\nregister_keras_serializable()\nname\nregistered_name\nclass_name\nconfig\nregistered_name\nFor example, the following dictionary represents the built-in Adam optimizer\nwith the relevant config:\ndict_structure = { \"class_name\" : \"Adam\" , \"config\" : { \"amsgrad\" : false , \"beta_1\" : 0.8999999761581421 , \"beta_2\" : 0.9990000128746033 , \"decay\" : 0.0 , \"epsilon\" : 1e-07 , \"learning_rate\" : 0.0010000000474974513 , \"name\" : \"Adam\" }, \"module\" : \"keras.optimizers\" , \"registered_name\" : None } # Returns an `Adam` instance identical to the original one. deserialize_keras_object ( dict_structure )\ndict_structure = { \"class_name\" : \"Adam\" , \"config\" : { \"amsgrad\" : false , \"beta_1\" : 0.8999999761581421 , \"beta_2\" : 0.9990000128746033 , \"decay\" : 0.0 , \"epsilon\" : 1e-07 , \"learning_rate\" : 0.0010000000474974513 , \"name\" : \"Adam\" }, \"module\" : \"keras.optimizers\" , \"registered_name\" : None } # Returns an `Adam` instance identical to the original one. deserialize_keras_object ( dict_structure )\nIf the class does not have an exported Keras namespace, the library tracks\nit by its module and class_name . For example:\nmodule\nclass_name\ndict_structure = { \"class_name\" : \"MetricsList\" , \"config\" : { ... }, \"module\" : \"keras.trainers.compile_utils\" , \"registered_name\" : \"MetricsList\" } # Returns a `MetricsList` instance identical to the original one. deserialize_keras_object ( dict_structure )\ndict_structure = { \"class_name\" : \"MetricsList\" , \"config\" : { ... }, \"module\" : \"keras.trainers.compile_utils\" , \"registered_name\" : \"MetricsList\" } # Returns a `MetricsList` instance identical to the original one. deserialize_keras_object ( dict_structure )\nAnd the following dictionary represents a user-customized MeanSquaredError loss:\nMeanSquaredError\n@keras . saving . register_keras_serializable ( package = 'my_package' ) class ModifiedMeanSquaredError ( keras . losses . MeanSquaredError ): ... dict_structure = { \"class_name\" : \"ModifiedMeanSquaredError\" , \"config\" : { \"fn\" : \"mean_squared_error\" , \"name\" : \"mean_squared_error\" , \"reduction\" : \"auto\" }, \"registered_name\" : \"my_package>ModifiedMeanSquaredError\" } # Returns the `ModifiedMeanSquaredError` object deserialize_keras_object ( dict_structure )\n@keras . saving . register_keras_serializable ( package = 'my_package' ) class ModifiedMeanSquaredError ( keras . losses . MeanSquaredError ): ... dict_structure = { \"class_name\" : \"ModifiedMeanSquaredError\" , \"config\" : { \"fn\" : \"mean_squared_error\" , \"name\" : \"mean_squared_error\" , \"reduction\" : \"auto\" }, \"registered_name\" : \"my_package>ModifiedMeanSquaredError\" } # Returns the `ModifiedMeanSquaredError` object deserialize_keras_object ( dict_structure )\nArgs\nArgs\nconfig Python dict describing the object. custom_objects Python dict containing a mapping between custom\nobject names the corresponding classes or functions. safe_mode Boolean, whether to disallow unsafe lambda deserialization.\nWhen safe_mode=False , loading an object has the potential to\ntrigger arbitrary code execution. This argument is only\napplicable to the Keras v3 model format. Defaults to True .\nconfig\ncustom_objects\nsafe_mode\nlambda\nsafe_mode=False\nTrue\nReturns The object described by the config dictionary.\nReturns\nconfig"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/diag",
    "content": "Extract a diagonal or construct a diagonal array.\nMain aliases tf.keras.ops.numpy.diag\ntf.keras.ops.numpy.diag\ntf.keras.ops.numpy.diag\ntf . keras . ops . diag ( x , k = 0 )\ntf . keras . ops . diag ( x , k = 0 )\nArgs\nArgs\nx Input tensor. If x is 2-D, returns the k-th diagonal of x .\nIf x is 1-D, return a 2-D tensor with x on the k-th diagonal. k The diagonal to consider. Defaults to 0 . Use k > 0 for diagonals\nabove the main diagonal, and k < 0 for diagonals below\nthe main diagonal.\nx\nx\nx\nx\nx\nk\n0\nk > 0\nk < 0\nReturns The extracted diagonal or constructed diagonal tensor.\nReturns\nfrom keras.src import ops x = ops . arange ( 9 ) . reshape (( 3 , 3 )) x array ([[ 0 , 1 , 2 ], [ 3 , 4 , 5 ], [ 6 , 7 , 8 ]])\nfrom keras.src import ops\nx = ops . arange ( 9 ) . reshape (( 3 , 3 ))\nx\narray ([[ 0 , 1 , 2 ],\n[ 3 , 4 , 5 ],\n[ 6 , 7 , 8 ]])\nops . diag ( x ) array ([ 0 , 4 , 8 ]) ops . diag ( x , k = 1 ) array ([ 1 , 5 ]) ops . diag ( x , k =- 1 ) array ([ 3 , 7 ])\nops . diag ( x )\narray ([ 0 , 4 , 8 ])\nops . diag ( x , k = 1 )\narray ([ 1 , 5 ])\nops . diag ( x , k =- 1 )\narray ([ 3 , 7 ])\nops . diag ( ops . diag ( x ))) array ([[ 0 , 0 , 0 ], [ 0 , 4 , 0 ], [ 0 , 0 , 8 ]])\nops . diag ( ops . diag ( x )))\narray ([[ 0 , 0 , 0 ],\n[ 0 , 4 , 0 ],\n[ 0 , 0 , 8 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/eval",
    "content": "DEPRECATED.\ntf . keras . backend . eval ( x )\ntf . keras . backend . eval ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanAbsoluteError",
    "content": "Computes the mean absolute error between the labels and predictions.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . MeanAbsoluteError ( name = 'mean_absolute_error' , dtype = None )\ntf . keras . metrics . MeanAbsoluteError ( name = 'mean_absolute_error' , dtype = None )\nUsed in the notebooks\nTime series forecasting\nloss = mean ( abs ( y_true - y_pred ))\nloss = mean ( abs ( y_true - y_pred ))\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . MeanAbsoluteError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.25 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 0.5\nm = keras . metrics . MeanAbsoluteError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.25\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.5\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanAbsoluteError ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanAbsoluteError ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalFocalCrossentropy",
    "content": "Computes the alpha balanced focal crossentropy loss.\nInherits From: Loss\nLoss\ntf . keras . losses . CategoricalFocalCrossentropy ( alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'categorical_focal_crossentropy' )\ntf . keras . losses . CategoricalFocalCrossentropy ( alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'categorical_focal_crossentropy' )\nUse this crossentropy loss function when there are two or more label\nclasses and if you want to handle class imbalance without using class_weights . We expect labels to be provided in a one_hot representation.\nclass_weights\none_hot\nAccording to Lin et al., 2018 , it\nhelps to apply a focal factor to down-weight easy examples and focus more on\nhard examples. The general formula for the focal loss (FL)\nis as follows:\nFL(p_t) = (1 - p_t) ** gamma * log(p_t)\nFL(p_t) = (1 - p_t) ** gamma * log(p_t)\nwhere p_t is defined as follows: p_t = output if y_true == 1, else 1 - output\np_t\np_t = output if y_true == 1, else 1 - output\n(1 - p_t) ** gamma is the modulating_factor , where gamma is a focusing\nparameter. When gamma = 0, there is no focal effect on the cross entropy. gamma reduces the importance given to simple examples in a smooth manner.\n(1 - p_t) ** gamma\nmodulating_factor\ngamma\ngamma\ngamma\nThe authors use alpha-balanced variant of focal loss (FL) in the paper: FL(p_t) = -alpha * (1 - p_t) ** gamma * log(p_t)\nFL(p_t) = -alpha * (1 - p_t) ** gamma * log(p_t)\nwhere alpha is the weight factor for the classes. If alpha = 1, the\nloss won't be able to handle class imbalance properly as all\nclasses will have the same weight. This can be a constant or a list of\nconstants. If alpha is a list, it must have the same length as the number\nof classes.\nalpha\nalpha\nThe formula above can be generalized to: FL(p_t) = alpha * (1 - p_t) ** gamma * CrossEntropy(y_true, y_pred)\nFL(p_t) = alpha * (1 - p_t) ** gamma * CrossEntropy(y_true, y_pred)\nwhere minus comes from CrossEntropy(y_true, y_pred) (CE).\nCrossEntropy(y_true, y_pred)\nExtending this to multi-class case is straightforward: FL(p_t) = alpha * (1 - p_t) ** gamma * CategoricalCE(y_true, y_pred)\nFL(p_t) = alpha * (1 - p_t) ** gamma * CategoricalCE(y_true, y_pred)\nIn the snippet below, there is num_classes floating pointing values per\nexample. The shape of both y_pred and y_true are (batch_size, num_classes) .\nnum_classes\ny_pred\ny_true\n(batch_size, num_classes)\nArgs\nArgs\nalpha A weight balancing factor for all classes, default is 0.25 as\nmentioned in the reference. It can be a list of floats or a scalar.\nIn the multi-class case, alpha may be set by inverse class\nfrequency by using compute_class_weight from sklearn.utils . gamma A focusing parameter, default is 2.0 as mentioned in the\nreference. It helps to gradually reduce the importance given to\nsimple (easy) examples in a smooth manner. from_logits Whether output is expected to be a logits tensor. By\ndefault, we consider that output encodes a probability\ndistribution. label_smoothing Float in [0, 1]. When > 0, label values are smoothed,\nmeaning the confidence on label values are relaxed. For example, if 0.1 , use 0.1 / num_classes for non-target labels and 0.9 + 0.1 / num_classes for target labels. axis The axis along which to compute crossentropy (the features\naxis). Defaults to -1 . reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nalpha\n0.25\ncompute_class_weight\nsklearn.utils\ngamma\n2.0\nfrom_logits\noutput\noutput\nlabel_smoothing\n0.1\n0.1 / num_classes\n0.9 + 0.1 / num_classes\naxis\n-1\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\ny_true = [[ 0. , 1. , 0. ], [ 0. , 0. , 1. ]] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # Using 'auto'/'sum_over_batch_size' reduction type. cce = keras . losses . CategoricalFocalCrossentropy () cce ( y_true , y_pred ) 0.23315276\ny_true = [[ 0. , 1. , 0. ], [ 0. , 0. , 1. ]]\ny_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]\n# Using 'auto'/'sum_over_batch_size' reduction type.\ncce = keras . losses . CategoricalFocalCrossentropy ()\ncce ( y_true , y_pred )\n0.23315276\n# Calling with 'sample_weight'. cce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ])) 0.1632\n# Calling with 'sample_weight'.\ncce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ]))\n0.1632\n# Using 'sum' reduction type. cce = keras . losses . CategoricalFocalCrossentropy ( reduction = \"sum\" ) cce ( y_true , y_pred ) 0.46631\n# Using 'sum' reduction type.\ncce = keras . losses . CategoricalFocalCrossentropy (\nreduction = \"sum\" )\ncce ( y_true , y_pred )\n0.46631\n# Using 'none' reduction type. cce = keras . losses . CategoricalFocalCrossentropy ( reduction = None ) cce ( y_true , y_pred ) array ([ 3.2058331e-05 , 4.6627346e-01 ], dtype = float32 )\n# Using 'none' reduction type.\ncce = keras . losses . CategoricalFocalCrossentropy (\nreduction = None )\ncce ( y_true , y_pred )\narray ([ 3.2058331e-05 , 4.6627346e-01 ], dtype = float32 )\nUsage with the compile() API:\ncompile()\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . CategoricalFocalCrossentropy ())\nmodel . compile ( optimizer = 'adam' , loss = keras . losses . CategoricalFocalCrossentropy ())\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/equal",
    "content": "DEPRECATED.\ntf . keras . backend . equal ( x , y )\ntf . keras . backend . equal ( x , y )\nUsed in the notebooks\nQuantum Convolutional Neural Network"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/R2Score",
    "content": "Computes R2 score.\nInherits From: Metric\nMetric\ntf . keras . metrics . R2Score ( class_aggregation = 'uniform_average' , num_regressors = 0 , name = 'r2_score' , dtype = None )\ntf . keras . metrics . R2Score ( class_aggregation = 'uniform_average' , num_regressors = 0 , name = 'r2_score' , dtype = None )\nsum_squares_residuals = sum (( y_true - y_pred ) ** 2 ) sum_squares = sum (( y_true - mean ( y_true )) ** 2 ) R2 = 1 - sum_squares_residuals / sum_squares\nsum_squares_residuals = sum (( y_true - y_pred ) ** 2 ) sum_squares = sum (( y_true - mean ( y_true )) ** 2 ) R2 = 1 - sum_squares_residuals / sum_squares\nThis is also called the coefficient of determination .\nIt indicates how close the fitted regression line\nis to ground-truth data.\nThe highest score possible is 1.0. It indicates that the predictors\nperfectly accounts for variation in the target.\nA score of 0.0 indicates that the predictors do not\naccount for variation in the target.\nIt can also be negative if the model is worse than random.\nThis metric can also compute the \"Adjusted R2\" score.\nArgs\nArgs\nclass_aggregation Specifies how to aggregate scores corresponding to\ndifferent output classes (or target dimensions),\ni.e. different dimensions on the last axis of the predictions.\nEquivalent to multioutput argument in Scikit-Learn.\nShould be one of None (no aggregation), \"uniform_average\" , \"variance_weighted_average\" . num_regressors Number of independent regressors used\n(\"Adjusted R2\" score). 0 is the standard R2 score.\nDefaults to 0 . name Optional. string name of the metric instance. dtype Optional. data type of the metric result.\nclass_aggregation\nmultioutput\nNone\n\"uniform_average\"\n\"variance_weighted_average\"\nnum_regressors\n0\nname\ndtype\ny_true = np . array ([[ 1 ], [ 4 ], [ 3 ]], dtype = np . float32 ) y_pred = np . array ([[ 2 ], [ 4 ], [ 4 ]], dtype = np . float32 ) metric = keras . metrics . R2Score () metric . update_state ( y_true , y_pred ) result = metric . result () result 0.57142854\ny_true = np . array ([[ 1 ], [ 4 ], [ 3 ]], dtype = np . float32 )\ny_pred = np . array ([[ 2 ], [ 4 ], [ 4 ]], dtype = np . float32 )\nmetric = keras . metrics . R2Score ()\nmetric . update_state ( y_true , y_pred )\nresult = metric . result ()\nresult\n0.57142854\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates root mean squared error statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\nDefaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tril",
    "content": "Return lower triangle of a tensor.\nMain aliases tf.keras.ops.numpy.tril\ntf.keras.ops.numpy.tril\ntf.keras.ops.numpy.tril\ntf . keras . ops . tril ( x , k = 0 )\ntf . keras . ops . tril ( x , k = 0 )\nFor tensors with ndim exceeding 2, tril will apply to the\nfinal two axes.\nndim\ntril\nArgs\nArgs\nx Input tensor. k Diagonal above which to zero elements. Defaults to 0 . the\nmain diagonal. k < 0 is below it, and k > 0 is above it.\nx\nk\n0\nk < 0\nk > 0\nReturns Lower triangle of x , of same shape and data type as x .\nReturns\nx\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/conv3d",
    "content": "DEPRECATED.\ntf . keras . backend . conv3d ( x , kernel , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ) )\ntf . keras . backend . conv3d ( x , kernel , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells",
    "content": "Wrapper allowing a stack of RNN cells to behave as a single cell.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . StackedRNNCells ( cells , ** kwargs )\ntf . keras . layers . StackedRNNCells ( cells , ** kwargs )\nUsed to implement efficient stacked RNNs.\nArgs\nArgs\ncells List of RNN cell instances.\ncells\nbatch_size = 3 sentence_length = 5 num_features = 2 new_shape = ( batch_size , sentence_length , num_features ) x = np . reshape ( np . arange ( 30 ), new_shape ) rnn_cells = [ keras . layers . LSTMCell ( 128 ) for _ in range ( 2 )] stacked_lstm = keras . layers . StackedRNNCells ( rnn_cells ) lstm_layer = keras . layers . RNN ( stacked_lstm ) result = lstm_layer ( x )\nbatch_size = 3 sentence_length = 5 num_features = 2 new_shape = ( batch_size , sentence_length , num_features ) x = np . reshape ( np . arange ( 30 ), new_shape ) rnn_cells = [ keras . layers . LSTMCell ( 128 ) for _ in range ( 2 )] stacked_lstm = keras . layers . StackedRNNCells ( rnn_cells ) lstm_layer = keras . layers . RNN ( stacked_lstm ) result = lstm_layer ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output_size\noutput_size\nstate_size\nstate_size\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size = None )\nget_initial_state ( batch_size = None )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout2D",
    "content": "Spatial 2D version of Dropout.\nInherits From: Dropout , Layer , Operation\nDropout\nLayer\nOperation\ntf . keras . layers . SpatialDropout2D ( rate , data_format = None , seed = None , name = None , dtype = None )\ntf . keras . layers . SpatialDropout2D ( rate , data_format = None , seed = None , name = None , dtype = None )\nThis version performs the same function as Dropout, however, it drops\nentire 2D feature maps instead of individual elements. If adjacent pixels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout2D will help promote independence\nbetween feature maps and should be used instead.\nSpatialDropout2D\nArgs\nArgs\nrate Float between 0 and 1. Fraction of the input units to drop. data_format \"channels_first\" or \"channels_last\" .\nIn \"channels_first\" mode, the channels dimension (the depth)\nis at index 1, in \"channels_last\" mode is it at index 3.\nIt defaults to the image_data_format value found in your\nKeras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" .\nrate\ndata_format\n\"channels_first\"\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nCall arguments\nCall arguments\ninputs A 4D tensor. training Python boolean indicating whether the layer\nshould behave in training mode (applying dropout)\nor in inference mode (pass-through).\ninputs\ntraining\nInput shape 4D tensor with shape: (samples, channels, rows, cols) if\n    data_format='channels_first'\nor 4D tensor with shape: (samples, rows, cols, channels) if\n    data_format='channels_last'.\nInput shape\n(samples, channels, rows, cols)\n(samples, rows, cols, channels)\nOutput shape: Same as input.\nTompson et al., 2014\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/categorical_crossentropy",
    "content": "Computes categorical cross-entropy loss between target and output tensor.\nMain aliases tf.keras.ops.nn.categorical_crossentropy\ntf.keras.ops.nn.categorical_crossentropy\ntf.keras.ops.nn.categorical_crossentropy\ntf . keras . ops . categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )\ntf . keras . ops . categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )\nThe categorical cross-entropy loss is commonly used in multi-class\nclassification tasks where each input sample can belong to one of\nmultiple classes. It measures the dissimilarity\nbetween the target and output probabilities or logits.\nArgs\nArgs\ntarget The target tensor representing the true categorical labels.\nIts shape should match the shape of the output tensor\nexcept for the last dimension. output The output tensor representing the predicted probabilities\nor logits. Its shape should match the shape of the target tensor except for the last dimension. from_logits (optional) Whether output is a tensor of logits or\nprobabilities.\nSet it to True if output represents logits; otherwise,\nset it to False if output represents probabilities.\nDefaults to False . axis (optional) The axis along which the categorical cross-entropy\nis computed.\nDefaults to -1 , which corresponds to the last dimension of\nthe tensors.\ntarget\noutput\noutput\ntarget\nfrom_logits\noutput\nTrue\noutput\nFalse\noutput\nFalse\naxis\n-1\nReturns Integer tensor: The computed categorical cross-entropy loss between target and output .\nReturns\ntarget\noutput\ntarget = keras . ops . convert_to_tensor ( [[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ]]) output = keras . ops . convert_to_tensor ( [[ 0.9 , 0.05 , 0.05 ], [ 0.1 , 0.8 , 0.1 ], [ 0.2 , 0.3 , 0.5 ]]) categorical_crossentropy ( target , output ) array ([ 0.10536054 0.22314355 0.6931472 ], shape = ( 3 ,), dtype = float32 )\ntarget = keras . ops . convert_to_tensor (\n[[ 1 , 0 , 0 ],\n[ 0 , 1 , 0 ],\n[ 0 , 0 , 1 ]])\noutput = keras . ops . convert_to_tensor (\n[[ 0.9 , 0.05 , 0.05 ],\n[ 0.1 , 0.8 , 0.1 ],\n[ 0.2 , 0.3 , 0.5 ]])\ncategorical_crossentropy ( target , output )\narray ([ 0.10536054 0.22314355 0.6931472 ], shape = ( 3 ,), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/legacy/saving",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ndeserialize_keras_object(...) : Turns the serialized form of a Keras object back into an actual object.\ndeserialize_keras_object(...)\nserialize_keras_object(...) : Serialize a Keras object into a JSON-compatible representation.\nserialize_keras_object(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\naffine_transform(...) : Applies the given transform(s) to the image(s).\naffine_transform(...)\ncrop_images(...) : Crop images to a specified height and width .\ncrop_images(...)\nimages\nheight\nwidth\nextract_patches(...) : Extracts patches from the image(s).\nextract_patches(...)\nmap_coordinates(...) : Map the input array to new coordinates by interpolation..\nmap_coordinates(...)\npad_images(...) : Pad images with zeros to the specified height and width .\npad_images(...)\nimages\nheight\nwidth\nresize(...) : Resize images to size using the specified interpolation method.\nresize(...)\nrgb_to_grayscale(...) : Convert RGB images to grayscale.\nrgb_to_grayscale(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CallbackList",
    "content": "Container abstracting a list of callbacks.\nInherits From: Callback\nCallback\ntf . keras . callbacks . CallbackList ( callbacks = None , add_history = False , add_progbar = False , model = None , ** params )\ntf . keras . callbacks . CallbackList ( callbacks = None , add_history = False , add_progbar = False , model = None , ** params )\nArgs\nArgs\ncallbacks List of Callback instances. add_history Whether a History callback should be added, if one\ndoes not already exist in the callbacks list. add_progbar Whether a ProgbarLogger callback should be added, if\none does not already exist in the callbacks list. model The Model these callbacks are used with. **params If provided, parameters will be passed to each Callback via Callback.set_params .\ncallbacks\nCallback\nadd_history\nHistory\ncallbacks\nadd_progbar\nProgbarLogger\ncallbacks\nmodel\nModel\n**params\nCallback\nCallback.set_params\nAttributes\nAttributes\nmodel\nmodel\nMethods\nappend\nappend\nView source\nappend ( callback )\nappend ( callback )\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/serialize_keras_object",
    "content": "Retrieve the config dict by serializing the Keras object.\ntf . keras . utils . serialize_keras_object ( obj )\ntf . keras . utils . serialize_keras_object ( obj )\nserialize_keras_object() serializes a Keras object to a python dictionary\nthat represents the object, and is a reciprocal function of deserialize_keras_object() . See deserialize_keras_object() for more\ninformation about the config format.\nserialize_keras_object()\ndeserialize_keras_object()\ndeserialize_keras_object()\nArgs\nArgs\nobj the Keras object to serialize.\nobj\nReturns A python dict that represents the object. The python dict can be\ndeserialized via deserialize_keras_object() .\nReturns\ndeserialize_keras_object()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D",
    "content": "Upsampling layer for 2D inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . UpSampling2D ( size = ( 2 , 2 ), data_format = None , interpolation = 'nearest' , ** kwargs )\ntf . keras . layers . UpSampling2D ( size = ( 2 , 2 ), data_format = None , interpolation = 'nearest' , ** kwargs )\nThe implementation uses interpolative resizing, given the resize method\n(specified by the interpolation argument). Use interpolation=nearest to repeat the rows and columns of the data.\ninterpolation\ninterpolation=nearest\ninput_shape = ( 2 , 2 , 1 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) print ( x ) [[[[ 0 1 2 ]] [[ 3 4 5 ]]] [[[ 6 7 8 ]] [[ 9 10 11 ]]]] y = keras . layers . UpSampling2D ( size = ( 1 , 2 ))( x ) print ( y ) [[[[ 0 1 2 ] [ 0 1 2 ]] [[ 3 4 5 ] [ 3 4 5 ]]] [[[ 6 7 8 ] [ 6 7 8 ]] [[ 9 10 11 ] [ 9 10 11 ]]]]\ninput_shape = ( 2 , 2 , 1 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\nprint ( x )\n[[[[ 0 1 2 ]]\n[[ 3 4 5 ]]]\n[[[ 6 7 8 ]]\n[[ 9 10 11 ]]]]\ny = keras . layers . UpSampling2D ( size = ( 1 , 2 ))( x )\nprint ( y )\n[[[[ 0 1 2 ]\n[ 0 1 2 ]]\n[[ 3 4 5 ]\n[ 3 4 5 ]]]\n[[[ 6 7 8 ]\n[ 6 7 8 ]]\n[[ 9 10 11 ]\n[ 9 10 11 ]]]]\nArgs\nArgs\nsize Int, or tuple of 2 integers.\nThe upsampling factors for rows and columns. data_format A string,\none of \"channels_last\" (default) or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, height, width) .\nWhen unspecified, uses image_data_format value found in your Keras config file at ~/.keras/keras.json (if exists) else \"channels_last\" .\nDefaults to \"channels_last\" . interpolation A string, one of \"bicubic\" , \"bilinear\" , \"lanczos3\" , \"lanczos5\" , \"nearest\" .\nsize\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, height, width, channels)\n\"channels_first\"\n(batch_size, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\n\"channels_last\"\ninterpolation\n\"bicubic\"\n\"bilinear\"\n\"lanczos3\"\n\"lanczos5\"\n\"nearest\"\nInput shape 4D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, rows, cols, channels)\ndata_format\n\"channels_last\"\n(batch_size, rows, cols, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, rows, cols)\ndata_format\n\"channels_first\"\n(batch_size, channels, rows, cols)\nOutput shape 4D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, upsampled_rows, upsampled_cols, channels)\ndata_format\n\"channels_last\"\n(batch_size, upsampled_rows, upsampled_cols, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, upsampled_rows, upsampled_cols)\ndata_format\n\"channels_first\"\n(batch_size, channels, upsampled_rows, upsampled_cols)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cosh",
    "content": "Hyperbolic cosine, element-wise.\nMain aliases tf.keras.ops.numpy.cosh\ntf.keras.ops.numpy.cosh\ntf.keras.ops.numpy.cosh\ntf . keras . ops . cosh ( x )\ntf . keras . ops . cosh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical",
    "content": "Converts a class vector (integers) to binary class matrix.\ntf . keras . utils . to_categorical ( x , num_classes = None )\ntf . keras . utils . to_categorical ( x , num_classes = None )\nUsed in the notebooks\nImplement Differential Privacy with TensorFlow Privacy\nAssess privacy risks with the TensorFlow Privacy Report\nOn-Device Training with TensorFlow Lite\nHuman Pose Classification with MoveNet and TensorFlow Lite\nClassifying CIFAR-10 with XLA\nE.g. for use with categorical_crossentropy .\ncategorical_crossentropy\nArgs\nArgs\nx Array-like with class values to be converted into a matrix\n(integers from 0 to num_classes - 1 ). num_classes Total number of classes. If None , this would be inferred\nas max(x) + 1 . Defaults to None .\nx\nnum_classes - 1\nnum_classes\nNone\nmax(x) + 1\nNone\nReturns A binary matrix representation of the input as a NumPy array. The class\naxis is placed last.\nReturns\na = keras . utils . to_categorical ([ 0 , 1 , 2 , 3 ], num_classes = 4 ) print ( a ) [[ 1. 0. 0. 0. ] [ 0. 1. 0. 0. ] [ 0. 0. 1. 0. ] [ 0. 0. 0. 1. ]]\na = keras . utils . to_categorical ([ 0 , 1 , 2 , 3 ], num_classes = 4 )\nprint ( a )\n[[ 1. 0. 0. 0. ]\n[ 0. 1. 0. 0. ]\n[ 0. 0. 1. 0. ]\n[ 0. 0. 0. 1. ]]\nb = np . array ([ .9 , .04 , .03 , .03 , .3 , .45 , .15 , .13 , .04 , .01 , .94 , .05 , .12 , .21 , .5 , .17 ], shape = [ 4 , 4 ]) loss = keras . ops . categorical_crossentropy ( a , b ) print ( np . around ( loss , 5 )) [ 0.10536 0.82807 0.1011 1.77196 ]\nb = np . array ([ .9 , .04 , .03 , .03 ,\n.3 , .45 , .15 , .13 ,\n.04 , .01 , .94 , .05 ,\n.12 , .21 , .5 , .17 ],\nshape = [ 4 , 4 ])\nloss = keras . ops . categorical_crossentropy ( a , b )\nprint ( np . around ( loss , 5 ))\n[ 0.10536 0.82807 0.1011 1.77196 ]\nloss = keras . ops . categorical_crossentropy ( a , a ) print ( np . around ( loss , 5 )) [ 0. 0. 0. 0. ]\nloss = keras . ops . categorical_crossentropy ( a , a )\nprint ( np . around ( loss , 5 ))\n[ 0. 0. 0. 0. ]"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Identity",
    "content": "Initializer that generates the identity matrix.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.IdentityInitializer , tf.keras.initializers.identity\ntf.keras.initializers.IdentityInitializer , tf.keras.initializers.identity\ntf.keras.initializers.IdentityInitializer\ntf.keras.initializers.identity\ntf . keras . initializers . Identity ( gain = 1.0 )\ntf . keras . initializers . Identity ( gain = 1.0 )\nOnly usable for generating 2D matrices.\n# Standalone usage: initializer = Identity () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = Identity ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = Identity () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = Identity ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\ngain Multiplicative factor to apply to the identity matrix.\ngain\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor. Only numeric or boolean dtypes\nare supported. If not specified, keras.backend.floatx() is used, which default to float32 unless you configured it\notherwise (via keras.backend.set_floatx(float_dtype) ).\nshape\ndtype\nkeras.backend.floatx()\nfloat32\nkeras.backend.set_floatx(float_dtype)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D",
    "content": "Global max pooling operation for temporal data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalMaxPooling1D\ntf.keras.layers.GlobalMaxPooling1D\ntf.keras.layers.GlobalMaxPooling1D\ntf . keras . layers . GlobalMaxPool1D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalMaxPool1D ( data_format = None , keepdims = False , ** kwargs )\nUsed in the notebooks\nLoad text\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\ntemporal dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nIf data_format='channels_last' :\n3D tensor with shape: (batch_size, steps, features)\ndata_format='channels_last'\n(batch_size, steps, features)\nIf data_format='channels_first' :\n3D tensor with shape: (batch_size, features, steps)\ndata_format='channels_first'\n(batch_size, features, steps)\nIf keepdims=False :\n2D tensor with shape (batch_size, features) .\nkeepdims=False\n(batch_size, features)\nIf keepdims=True : If data_format=\"channels_last\" :\n3D tensor with shape (batch_size, 1, features) If data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, 1, features)\ndata_format=\"channels_last\"\n(batch_size, 1, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, 1)\ndata_format=\"channels_first\"\n(batch_size, features, 1)\nx = np . random . rand ( 2 , 3 , 4 ) y = keras . layers . GlobalMaxPooling1D ()( x ) y . shape ( 2 , 4 )\nx = np . random . rand ( 2 , 3 , 4 )\ny = keras . layers . GlobalMaxPooling1D ()( x )\ny . shape\n( 2 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU",
    "content": "Computes the mean Intersection-Over-Union metric.\nInherits From: IoU , Metric\nIoU\nMetric\ntf . keras . metrics . MeanIoU ( num_classes , name = None , dtype = None , ignore_class = None , sparse_y_true = True , sparse_y_pred = True , axis =- 1 )\ntf . keras . metrics . MeanIoU ( num_classes , name = None , dtype = None , ignore_class = None , sparse_y_true = True , sparse_y_pred = True , axis =- 1 )\niou = true_positives / ( true_positives + false_positives + false_negatives )\niou = true_positives / ( true_positives + false_positives + false_negatives )\nIntersection-Over-Union is a common evaluation metric for semantic image\nsegmentation.\nTo compute IoUs, the predictions are accumulated in a confusion matrix,\nweighted by sample_weight and the metric is then calculated from it.\nsample_weight\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nNote that this class first computes IoUs for all individual classes, then\nreturns the mean of these values.\nArgs\nArgs\nnum_classes The possible number of labels the prediction task can have.\nThis value must be provided, since a confusion matrix of dimension =\n[num_classes, num_classes] will be allocated. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. ignore_class Optional integer. The ID of a class to be ignored during\nmetric computation. This is useful, for example, in segmentation\nproblems featuring a \"void\" class (commonly -1 or 255) in\nsegmentation maps. By default ( ignore_class=None ), all classes are\nconsidered. sparse_y_true Whether labels are encoded using integers or\ndense floating point vectors. If False , the argmax function\nis used to determine each sample's most likely associated label. sparse_y_pred Whether predictions are encoded using integers or\ndense floating point vectors. If False , the argmax function\nis used to determine each sample's most likely associated label. axis (Optional) The dimension containing the logits. Defaults to -1 .\nnum_classes\nname\ndtype\nignore_class\nignore_class=None\nsparse_y_true\nFalse\nargmax\nsparse_y_pred\nFalse\nargmax\naxis\n-1\n# cm = [[1, 1], #        [1, 1]] # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1] # iou = true_positives / (sum_row + sum_col - true_positives)) # result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2 = 0.33 m = keras . metrics . MeanIoU ( num_classes = 2 ) m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ]) m . result () 0.33333334\n# cm = [[1, 1],\n#        [1, 1]]\n# sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n# iou = true_positives / (sum_row + sum_col - true_positives))\n# result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2 = 0.33\nm = keras . metrics . MeanIoU ( num_classes = 2 )\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ])\nm . result ()\n0.33333334\nm . reset_state () m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ], sample_weight = [ 0.3 , 0.3 , 0.3 , 0.1 ]) m . result () . numpy () 0.23809525\nm . reset_state ()\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 1 , 0 , 1 ],\nsample_weight = [ 0.3 , 0.3 , 0.3 , 0.1 ])\nm . result () . numpy ()\n0.23809525\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanIoU ( num_classes = 2 )])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanIoU ( num_classes = 2 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the intersection-over-union via the confusion matrix.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same as y_true ,\nand must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/affine_transform",
    "content": "Applies the given transform(s) to the image(s).\ntf . keras . ops . image . affine_transform ( image , transform , interpolation = 'bilinear' , fill_mode = 'constant' , fill_value = 0 , data_format = 'channels_last' )\ntf . keras . ops . image . affine_transform ( image , transform , interpolation = 'bilinear' , fill_mode = 'constant' , fill_value = 0 , data_format = 'channels_last' )\nArgs\nArgs\nimage Input image or batch of images. Must be 3D or 4D. transform Projective transform matrix/matrices. A vector of length 8 or\ntensor of size N x 8. If one row of transform is [a0, a1, a2, b0, b1, b2, c0, c1] , then it maps the output point (x, y) to a transformed input point (x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k) ,\nwhere k = c0 x + c1 y + 1 . The transform is inverted compared to\nthe transform mapping input points to output points. Note that\ngradients are not backpropagated into transformation parameters.\nNote that c0 and c1 are only effective when using TensorFlow\nbackend and will be considered as 0 when using other backends. interpolation Interpolation method. Available methods are \"nearest\" ,\nand \"bilinear\" . Defaults to \"bilinear\" . fill_mode Points outside the boundaries of the input are filled\naccording to the given mode. Available methods are \"constant\" , \"nearest\" , \"wrap\" and \"reflect\" . Defaults to \"constant\" .\nimage\ntransform\n[a0, a1, a2, b0, b1, b2, c0, c1]\n(x, y)\n(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k)\nk = c0 x + c1 y + 1\nc0\nc1\n0\ninterpolation\n\"nearest\"\n\"bilinear\"\n\"bilinear\"\nfill_mode\n\"constant\"\n\"nearest\"\n\"wrap\"\n\"reflect\"\n\"constant\"\n\"reflect\" : (d c b a | a b c d | d c b a) The input is extended by reflecting about the edge of the last\npixel.\n\"reflect\"\n(d c b a | a b c d | d c b a)\n\"constant\" : (k k k k | a b c d | k k k k) The input is extended by filling all values beyond\nthe edge with the same constant value k specified by fill_value .\n\"constant\"\n(k k k k | a b c d | k k k k)\nfill_value\n\"wrap\" : (a b c d | a b c d | a b c d) The input is extended by wrapping around to the opposite edge.\n\"wrap\"\n(a b c d | a b c d | a b c d)\n\"nearest\" : (a a a a | a b c d | d d d d) The input is extended by the nearest pixel. fill_value Value used for points outside the boundaries of the input if fill_mode=\"constant\" . Defaults to 0 . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, weight) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\n\"nearest\"\n(a a a a | a b c d | d d d d)\nfill_value\nfill_mode=\"constant\"\n0\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, weight)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nReturns Applied affine transform image or batch of images.\nReturns\nx = np . random . random (( 2 , 64 , 80 , 3 )) # batch of 2 RGB images transform = np . array ( [ [ 1.5 , 0 , - 20 , 0 , 1.5 , - 16 , 0 , 0 ], # zoom [ 1 , 0 , - 20 , 0 , 1 , - 16 , 0 , 0 ], # translation ] ) y = keras . ops . image . affine_transform ( x , transform ) y . shape ( 2 , 64 , 80 , 3 )\nx = np . random . random (( 2 , 64 , 80 , 3 )) # batch of 2 RGB images\ntransform = np . array (\n[\n[ 1.5 , 0 , - 20 , 0 , 1.5 , - 16 , 0 , 0 ], # zoom\n[ 1 , 0 , - 20 , 0 , 1 , - 16 , 0 , 0 ], # translation\n]\n)\ny = keras . ops . image . affine_transform ( x , transform )\ny . shape\n( 2 , 64 , 80 , 3 )\nx = np . random . random (( 64 , 80 , 3 )) # single RGB image transform = np . array ([ 1.0 , 0.5 , - 20 , 0.5 , 1.0 , - 16 , 0 , 0 ]) # shear y = keras . ops . image . affine_transform ( x , transform ) y . shape ( 64 , 80 , 3 )\nx = np . random . random (( 64 , 80 , 3 )) # single RGB image\ntransform = np . array ([ 1.0 , 0.5 , - 20 , 0.5 , 1.0 , - 16 , 0 , 0 ]) # shear\ny = keras . ops . image . affine_transform ( x , transform )\ny . shape\n( 64 , 80 , 3 )\nx = np . random . random (( 2 , 3 , 64 , 80 )) # batch of 2 RGB images transform = np . array ( [ [ 1.5 , 0 , - 20 , 0 , 1.5 , - 16 , 0 , 0 ], # zoom [ 1 , 0 , - 20 , 0 , 1 , - 16 , 0 , 0 ], # translation ] ) y = keras . ops . image . affine_transform ( x , transform , data_format = \"channels_first\" ) y . shape ( 2 , 3 , 64 , 80 )\nx = np . random . random (( 2 , 3 , 64 , 80 )) # batch of 2 RGB images\ntransform = np . array (\n[\n[ 1.5 , 0 , - 20 , 0 , 1.5 , - 16 , 0 , 0 ], # zoom\n[ 1 , 0 , - 20 , 0 , 1 , - 16 , 0 , 0 ], # translation\n]\n)\ny = keras . ops . image . affine_transform ( x , transform ,\ndata_format = \"channels_first\" )\ny . shape\n( 2 , 3 , 64 , 80 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/lists_to_tuples",
    "content": "tf . keras . tree . lists_to_tuples ( structure )\ntf . keras . tree . lists_to_tuples ( structure )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/moveaxis",
    "content": "Move axes of a tensor to new positions.\nMain aliases tf.keras.ops.numpy.moveaxis\ntf.keras.ops.numpy.moveaxis\ntf.keras.ops.numpy.moveaxis\ntf . keras . ops . moveaxis ( x , source , destination )\ntf . keras . ops . moveaxis ( x , source , destination )\nOther axes remain in their original order.\nArgs\nArgs\nx Tensor whose axes should be reordered. source Original positions of the axes to move. These must be unique. destination Destinations positions for each of the original axes.\nThese must also be unique.\nx\nsource\ndestination\nReturns Tensor with moved axes.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/deserialize",
    "content": "Return a Keras regularizer object via its config.\ntf . keras . regularizers . deserialize ( config , custom_objects = None )\ntf . keras . regularizers . deserialize ( config , custom_objects = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass SeedGenerator : Generates variable seeds upon each call to a RNG-using function.\nclass SeedGenerator\nFunctions\nbeta(...) : Draw samples from a Beta distribution.\nbeta(...)\nbinomial(...) : Draw samples from a Binomial distribution.\nbinomial(...)\ncategorical(...) : Draws samples from a categorical distribution.\ncategorical(...)\ndropout(...)\ndropout(...)\ngamma(...) : Draw random samples from the Gamma distribution.\ngamma(...)\nnormal(...) : Draw random samples from a normal (Gaussian) distribution.\nnormal(...)\nrandint(...) : Draw random integers from a uniform distribution.\nrandint(...)\nshuffle(...) : Shuffle the elements of a tensor uniformly at random along an axis.\nshuffle(...)\ntruncated_normal(...) : Draw samples from a truncated normal distribution.\ntruncated_normal(...)\nuniform(...) : Draw samples from a uniform distribution.\nuniform(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/correlate",
    "content": "Compute the cross-correlation of two 1-dimensional tensors.\nMain aliases tf.keras.ops.numpy.correlate\ntf.keras.ops.numpy.correlate\ntf.keras.ops.numpy.correlate\ntf . keras . ops . correlate ( x1 , x2 , mode = 'valid' )\ntf . keras . ops . correlate ( x1 , x2 , mode = 'valid' )\nArgs\nArgs\nx1 First 1-dimensional input tensor of length M. x2 Second 1-dimensional input tensor of length N. mode Either valid , same or full .\nBy default the mode is set to valid , which returns\nan output of length max(M, N) - min(M, N) + 1. same returns an output of length max(M, N). full mode returns the convolution at each point of\noverlap, with an output length of N+M-1\nx1\nx2\nmode\nvalid\nsame\nfull\nvalid\nsame\nfull\nReturns Output tensor, cross-correlation of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/ModelParallel",
    "content": "Distribution that shards model variables.\ntf . keras . distribution . ModelParallel ( device_mesh , layout_map , batch_dim_name = None )\ntf . keras . distribution . ModelParallel ( device_mesh , layout_map , batch_dim_name = None )\nCompare to DataParallel which replicates the variables across all devices, ModelParallel allows you to shard variables in addition to the input data.\nDataParallel\nModelParallel\nTo construct a ModelParallel distribution, you need to provide a DeviceMesh and a LayoutMap .\nModelParallel\nDeviceMesh\nLayoutMap\nDeviceMesh contains physical device information. The axis names in\nthe mesh will be used to map the variable and data layout.\nDeviceMesh\nLayoutMap contains the mapping between variable paths to their\ncorresponding TensorLayout .\nLayoutMap\nTensorLayout\ndevices = list_devices () # Assume there are 8 devices. # Create a mesh with 2 devices for data parallelism and 4 devices for # model parallelism. device_mesh = DeviceMesh ( shape = ( 2 , 4 ), axis_names = ( 'batch' , 'model' ), devices = devices ) # Create a layout map that shard the `Dense` layer and `Conv2D` # layer variables on the last dimension. # Based on the `device_mesh`, this means the variables # will be split across 4 devices. Any other variable that doesn't # match any key in the layout map will be fully replicated. layout_map = LayoutMap ( device_mesh ) layout_map [ 'dense.*kernel' ] = ( None , 'model' ) layout_map [ 'dense.*bias' ] = ( 'model' ,) layout_map [ 'conv2d.*kernel' ] = ( None , None , None , 'model' ) layout_map [ 'conv2d.*bias' ] = ( 'model' ,) distribution = ModelParallel ( device_mesh = device_mesh , layout_map = layout_map , batch_dim_name = 'batch' ) # Set the global distribution, or via `with distribution.scope():` set_distribution ( distribution ) model = model_creation () model . compile () model . fit ( data )\ndevices = list_devices () # Assume there are 8 devices. # Create a mesh with 2 devices for data parallelism and 4 devices for # model parallelism. device_mesh = DeviceMesh ( shape = ( 2 , 4 ), axis_names = ( 'batch' , 'model' ), devices = devices ) # Create a layout map that shard the `Dense` layer and `Conv2D` # layer variables on the last dimension. # Based on the `device_mesh`, this means the variables # will be split across 4 devices. Any other variable that doesn't # match any key in the layout map will be fully replicated. layout_map = LayoutMap ( device_mesh ) layout_map [ 'dense.*kernel' ] = ( None , 'model' ) layout_map [ 'dense.*bias' ] = ( 'model' ,) layout_map [ 'conv2d.*kernel' ] = ( None , None , None , 'model' ) layout_map [ 'conv2d.*bias' ] = ( 'model' ,) distribution = ModelParallel ( device_mesh = device_mesh , layout_map = layout_map , batch_dim_name = 'batch' ) # Set the global distribution, or via `with distribution.scope():` set_distribution ( distribution ) model = model_creation () model . compile () model . fit ( data )\nYou can quickly update the device mesh shape to change the sharding factor\nof the variables. E.g.\n# With only the shape change for the device mesh, the variables will be # sharded across 8 devices instead of 4, which further reduces the memory # footprint of variables on each of the device. device_mesh = DeviceMesh ( shape = ( 1 , 8 ), axis_names = ( 'batch' , 'model' ), devices = devices )\n# With only the shape change for the device mesh, the variables will be # sharded across 8 devices instead of 4, which further reduces the memory # footprint of variables on each of the device. device_mesh = DeviceMesh ( shape = ( 1 , 8 ), axis_names = ( 'batch' , 'model' ), devices = devices )\nTo figure out a proper layout mapping rule for all the model variables, you\ncan first list out all the model variable paths, which will be used as the\nkey to map the variables to TensorLayout .\nTensorLayout\ne.g.\nmodel = create_model () for v in model . variables : print ( v . path )\nmodel = create_model () for v in model . variables : print ( v . path )\nArgs\nArgs\ndevice_mesh DeviceMesh instance for physical device and its\nlogical mapping. layout_map LayoutMap instance which map the variable path to the\ncorresponding TensorLayout . The axis names of the TensorLayout s should match to the axis names in the\ndevice_mesh, or exception will be raised. batch_dim_name optional string, the axis name in the device_mesh that will be used to distribute data. If unspecified, the\nfirst axis from the device_mesh will be used.\ndevice_mesh\nDeviceMesh\nlayout_map\nLayoutMap\nTensorLayout\nTensorLayout\nbatch_dim_name\ndevice_mesh\ndevice_mesh\nAttributes\nAttributes\ndevice_mesh\ndevice_mesh\nMethods\ndistribute_dataset\ndistribute_dataset\nView source\ndistribute_dataset ( dataset )\ndistribute_dataset ( dataset )\nCreate a distributed dataset instance from the original user dataset.\nArgs\ndataset the original global dataset instance. Only tf.data.Dataset is supported at the moment.\ndataset\ntf.data.Dataset\nReturns a sharded tf.data.Dataset instance, which will produce data for\nthe current local worker/process.\ntf.data.Dataset\nget_data_layout\nget_data_layout\nView source\nget_data_layout ( data_shape )\nget_data_layout ( data_shape )\nRetrieve the TensorLayout for the input data.\nTensorLayout\nArgs\ndata_shape shape for the input data in list or tuple format.\ndata_shape\nReturns The TensorLayout for the data, which can be used by backend.distribute_value() to redistribute a input data.\nTensorLayout\nbackend.distribute_value()\nget_tensor_layout\nget_tensor_layout\nView source\nget_tensor_layout ( path )\nget_tensor_layout ( path )\nRetrieve the TensorLayout for the intermediate tensor.\nTensorLayout\nArgs\npath a string path for the corresponding tensor.\npath\nreturn:\n    The TensorLayout for the intermediate tensor, which can be used\n    by backend.relayout() to reshard the tensor. Could also return\n    None.\nTensorLayout\nbackend.relayout()\nget_variable_layout\nget_variable_layout\nView source\nget_variable_layout ( variable )\nget_variable_layout ( variable )\nRetrieve the TensorLayout for the variable.\nTensorLayout\nArgs\nvariable A KerasVariable instance.\nvariable\nKerasVariable\nreturn:\n    The TensorLayout for the variable, which can be used by backend.distribute_value() to redistribute a variable.\nTensorLayout\nbackend.distribute_value()\nscope\nscope\nView source\n@contextlib . contextmanager scope ()\n@contextlib . contextmanager\nscope ()\nContext manager to make the Distribution current.\nDistribution"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log_sigmoid",
    "content": "Logarithm of the sigmoid activation function.\nMain aliases tf.keras.ops.nn.log_sigmoid\ntf.keras.ops.nn.log_sigmoid\ntf.keras.ops.nn.log_sigmoid\ntf . keras . ops . log_sigmoid ( x )\ntf . keras . ops . log_sigmoid ( x )\nIt is defined as f(x) = log(1 / (1 + exp(-x))) .\nf(x) = log(1 / (1 + exp(-x)))\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 0.541391 , 0.0 , 0.50 , 5.0 ]) keras . ops . log_sigmoid ( x ) array ([ - 1.0000418 , - 0.6931472 , - 0.474077 , - 0.00671535 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 0.541391 , 0.0 , 0.50 , 5.0 ])\nkeras . ops . log_sigmoid ( x )\narray ([ - 1.0000418 , - 0.6931472 , - 0.474077 , - 0.00671535 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/slice",
    "content": "Return a slice of an input tensor.\ntf . keras . ops . slice ( inputs , start_indices , shape )\ntf . keras . ops . slice ( inputs , start_indices , shape )\nAt a high level, this operation is an explicit replacement for array slicing\ne.g. inputs[start_indices: start_indices + shape] .\nUnlike slicing via brackets, this operation will accept tensor start\nindices on all backends, which is useful when indices dynamically computed\nvia other tensor operations.\ninputs[start_indices: start_indices + shape]\ninputs = np . zeros (( 5 , 5 )) start_indices = np . array ([ 3 , 3 ]) shape = np . array ([ 2 , 2 ]) inputs = keras . ops . slice ( inputs , start_indices , updates )\ninputs = np . zeros (( 5 , 5 )) start_indices = np . array ([ 3 , 3 ]) shape = np . array ([ 2 , 2 ]) inputs = keras . ops . slice ( inputs , start_indices , updates )\nArgs\nArgs\ninputs A tensor, the tensor to be updated. start_indices A list/tuple of shape (inputs.ndim,) , specifying\nthe starting indices for updating. shape The full shape of the returned slice.\ninputs\nstart_indices\n(inputs.ndim,)\nshape\nReturns A tensor, has the same shape and dtype as inputs .\nReturns\ninputs"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/legacy",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ndeserialize_keras_object(...) : Turns the serialized form of a Keras object back into an actual object.\ndeserialize_keras_object(...)\nserialize_keras_object(...) : Serialize a Keras object into a JSON-compatible representation.\nserialize_keras_object(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/list_devices",
    "content": "Return all the available devices based on the device type.\ntf . keras . distribution . list_devices ( device_type = None )\ntf . keras . distribution . list_devices ( device_type = None )\nArgs\nArgs\ndevice_type string, one of \"cpu\" , \"gpu\" or \"tpu\" .\nDefaults to \"gpu\" or \"tpu\" if available when device_type is not provided. Otherwise\nwill return the \"cpu\" devices.\ndevice_type\n\"cpu\"\n\"gpu\"\n\"tpu\"\n\"gpu\"\n\"tpu\"\ndevice_type\n\"cpu\"\nReturn List of devices that are available for distribute computation.\nReturn"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/NumpyArrayIterator",
    "content": "Iterator yielding data from a Numpy array.\nInherits From: Iterator , PyDataset\nIterator\nPyDataset\ntf . keras . preprocessing . image . NumpyArrayIterator ( x , y , image_data_generator , batch_size = 32 , shuffle = False , sample_weight = None , seed = None , data_format = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , subset = None , ignore_class_split = False , dtype = None )\ntf . keras . preprocessing . image . NumpyArrayIterator ( x , y , image_data_generator , batch_size = 32 , shuffle = False , sample_weight = None , seed = None , data_format = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , subset = None , ignore_class_split = False , dtype = None )\nDEPRECATED.\nAttributes\nAttributes\nmax_queue_size\nmax_queue_size\nnum_batches Number of batches in the PyDataset. use_multiprocessing\nnum_batches\nuse_multiprocessing\nworkers\nworkers\nMethods\non_epoch_end\non_epoch_end\nView source\non_epoch_end ()\non_epoch_end ()\nMethod called at the end of every epoch.\nreset\nreset\nView source\nreset ()\nreset ()\n__getitem__\n__getitem__\nView source\n__getitem__ ( idx )\n__getitem__ ( idx )\nGets batch at position index .\nindex\nArgs\nindex position of the batch in the PyDataset.\nindex\nReturns A batch\n__iter__\n__iter__\nView source\n__iter__ ()\n__iter__ ()\n__len__\n__len__\nView source\n__len__ ()\n__len__ ()\nClass Variables\nClass Variables\nwhite_list_formats ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')\n('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logical_xor",
    "content": "Compute the truth value of x1 XOR x2 , element-wise.\nx1 XOR x2\nMain aliases tf.keras.ops.numpy.logical_xor\ntf.keras.ops.numpy.logical_xor\ntf.keras.ops.numpy.logical_xor\ntf . keras . ops . logical_xor ( x1 , x2 )\ntf . keras . ops . logical_xor ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output boolean tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tanh",
    "content": "Hyperbolic tangent, element-wise.\nMain aliases tf.keras.ops.numpy.tanh\ntf.keras.ops.numpy.tanh\ntf.keras.ops.numpy.tanh\ntf . keras . ops . tanh ( x )\ntf . keras . ops . tanh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_set_value",
    "content": "DEPRECATED.\ntf . keras . backend . batch_set_value ( tuples )\ntf . keras . backend . batch_set_value ( tuples )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ActivityRegularization",
    "content": "Layer that applies an update to the cost function based input activity.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ActivityRegularization ( l1 = 0.0 , l2 = 0.0 , ** kwargs )\ntf . keras . layers . ActivityRegularization ( l1 = 0.0 , l2 = 0.0 , ** kwargs )\nArgs\nArgs\nl1 L1 regularization factor (positive float). l2 L2 regularization factor (positive float).\nl1\nl2\nInput shape Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.\nInput shape\ninput_shape\nOutput shape Same shape as input.\nOutput shape\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_channel_shift",
    "content": "Performs a random channel shift.\ntf . keras . preprocessing . image . random_channel_shift ( x , intensity_range , channel_axis = 0 )\ntf . keras . preprocessing . image . random_channel_shift ( x , intensity_range , channel_axis = 0 )\nDEPRECATED.\nArgs\nArgs\nx Input tensor. Must be 3D. intensity_range Transformation intensity. channel_axis Index of axis for channels in the input tensor.\nx\nintensity_range\nchannel_axis\nReturns Numpy image tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/models",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Model : A model grouping layers into an object with training/inference features.\nclass Model\nclass Sequential : Sequential groups a linear stack of layers into a Model .\nclass Sequential\nSequential\nModel\nFunctions\nclone_model(...) : Clone a Functional or Sequential Model instance.\nclone_model(...)\nModel\nload_model(...) : Loads a model saved via model.save() .\nload_model(...)\nmodel.save()\nmodel_from_json(...) : Parses a JSON model configuration string and returns a model instance.\nmodel_from_json(...)\nsave_model(...) : Saves a model as a .keras file.\nsave_model(...)\n.keras"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/deserialize",
    "content": "Deserializes a serialized loss class/function instance.\ntf . keras . losses . deserialize ( name , custom_objects = None )\ntf . keras . losses . deserialize ( name , custom_objects = None )\nArgs\nArgs\nname Loss configuration. custom_objects Optional dictionary mapping names (strings) to custom\nobjects (classes and functions) to be considered during\ndeserialization.\nname\ncustom_objects\nReturns A Keras Loss instance or a loss function.\nReturns\nLoss"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/minimum",
    "content": "Element-wise minimum of x1 and x2 .\nx1\nx2\nMain aliases tf.keras.ops.numpy.minimum\ntf.keras.ops.numpy.minimum\ntf.keras.ops.numpy.minimum\ntf . keras . ops . minimum ( x1 , x2 )\ntf . keras . ops . minimum ( x1 , x2 )\nArgs\nArgs\nx1 First tensor. x2 Second tensor.\nx1\nx2\nReturns Output tensor, element-wise minimum of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_resnet_v2/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . inception_resnet_v2 . preprocess_input ( x , data_format = None )\ntf . keras . applications . inception_resnet_v2 . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet201",
    "content": "Instantiates the Densenet201 architecture.\nMain aliases tf.keras.applications.densenet.DenseNet201\ntf.keras.applications.densenet.DenseNet201\ntf.keras.applications.densenet.DenseNet201\ntf . keras . applications . DenseNet201 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . DenseNet201 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nDensely Connected Convolutional Networks (CVPR 2017)\nOptionally loads weights pre-trained on ImageNet.\nNote that the data format convention used by the model is\nthe one specified in your Keras config at ~/.keras/keras.json .\n~/.keras/keras.json\nkeras.applications.densenet.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) (with 'channels_last' data format)\nor (3, 224, 224) (with 'channels_first' data format).\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\n(224, 224, 3)\n'channels_last'\n(3, 224, 224)\n'channels_first'\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable.\nThe activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits\nof the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Keras model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseTopKCategoricalAccuracy",
    "content": "Computes how often integer targets are in the top K predictions.\nK\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . SparseTopKCategoricalAccuracy ( k = 5 , name = 'sparse_top_k_categorical_accuracy' , dtype = None )\ntf . keras . metrics . SparseTopKCategoricalAccuracy ( k = 5 , name = 'sparse_top_k_categorical_accuracy' , dtype = None )\nArgs\nArgs\nk (Optional) Number of top elements to look at for computing accuracy.\nDefaults to 5 . name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nk\n5\nname\ndtype\nm = keras . metrics . SparseTopKCategoricalAccuracy ( k = 1 ) m . update_state ([ 2 , 1 ], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]]) m . result () 0.5\nm = keras . metrics . SparseTopKCategoricalAccuracy ( k = 1 )\nm . update_state ([ 2 , 1 ], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]])\nm . result ()\n0.5\nm . reset_state () m . update_state ([ 2 , 1 ], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]], sample_weight = [ 0.7 , 0.3 ]) m . result () 0.3\nm . reset_state ()\nm . update_state ([ 2 , 1 ], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]],\nsample_weight = [ 0.7 , 0.3 ])\nm . result ()\n0.3\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'sparse_categorical_crossentropy' , metrics = [ keras . metrics . SparseTopKCategoricalAccuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'sparse_categorical_crossentropy' , metrics = [ keras . metrics . SparseTopKCategoricalAccuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool3D",
    "content": "Max pooling operation for 3D data (spatial or spatio-temporal).\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.MaxPooling3D\ntf.keras.layers.MaxPooling3D\ntf.keras.layers.MaxPooling3D\ntf . keras . layers . MaxPool3D ( pool_size = ( 2 , 2 , 2 ), strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . MaxPool3D ( pool_size = ( 2 , 2 , 2 ), strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the maximum value over an input window (of size defined by pool_size ) for each channel of the input. The window is shifted by strides along each dimension.\npool_size\nstrides\nArgs\nArgs\npool_size int or tuple of 3 integers, factors by which to downscale\n(dim1, dim2, dim3). If only one integer is specified, the same\nwindow length will be used for all dimensions. strides int or tuple of 3 integers, or None. Strides values. If None,\nit will default to pool_size . If only one int is specified, the\nsame stride size will be used for all dimensions. padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)\ndepth = 30 height = 30 width = 30 channels = 3 inputs = keras . layers . Input ( shape = ( depth , height , width , channels )) layer = keras . layers . MaxPooling3D ( pool_size = 3 ) outputs = layer ( inputs ) # Shape: (batch_size, 10, 10, 10, 3)\ndepth = 30 height = 30 width = 30 channels = 3 inputs = keras . layers . Input ( shape = ( depth , height , width , channels )) layer = keras . layers . MaxPooling3D ( pool_size = 3 ) outputs = layer ( inputs ) # Shape: (batch_size, 10, 10, 10, 3)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/norm",
    "content": "Matrix or vector norm.\nMain aliases tf.keras.ops.linalg.norm\ntf.keras.ops.linalg.norm\ntf.keras.ops.linalg.norm\ntf . keras . ops . norm ( x , ord = None , axis = None , keepdims = False )\ntf . keras . ops . norm ( x , ord = None , axis = None , keepdims = False )\nThis function is able to return one of eight different matrix norms, or one\nof an infinite number of vector norms (described below), depending on the\nvalue of the ord parameter.\nord\nArgs\nArgs\nx Input tensor. ord Order of the norm (see table under Notes). The default is None . axis If axis is an integer, it specifies the axis of x along which\nto compute the vector norms. If axis is a 2-tuple, it specifies\nthe axes that hold 2-D matrices, and the matrix norms of these\nmatrices are computed. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one.\nx\nord\nNone\naxis\naxis\nx\naxis\nkeepdims\nTrue\nNote For values of ord < 1 , the result is, strictly speaking, not a\nmathematical 'norm', but it may still be useful for various numerical\npurposes. The following norms can be calculated:\nNote\nord < 1\nFor matrices: ord=None : Frobenius norm ord=\"fro\" : Frobenius norm ord=\"nuc\" : nuclear norm ord=np.inf : max(sum(abs(x), axis=1)) ord=-np.inf : min(sum(abs(x), axis=1)) ord=0 : not supported ord=1 : max(sum(abs(x), axis=0)) ord=-1 : min(sum(abs(x), axis=0)) ord=2 : 2-norm (largest sing. value) ord=-2 : smallest singular value other: not supported\nord=None : Frobenius norm\nord=None\nord=\"fro\" : Frobenius norm\nord=\"fro\"\nord=\"nuc\" : nuclear norm\nord=\"nuc\"\nord=np.inf : max(sum(abs(x), axis=1))\nord=np.inf\nmax(sum(abs(x), axis=1))\nord=-np.inf : min(sum(abs(x), axis=1))\nord=-np.inf\nmin(sum(abs(x), axis=1))\nord=0 : not supported\nord=0\nord=1 : max(sum(abs(x), axis=0))\nord=1\nmax(sum(abs(x), axis=0))\nord=-1 : min(sum(abs(x), axis=0))\nord=-1\nmin(sum(abs(x), axis=0))\nord=2 : 2-norm (largest sing. value)\nord=2\nord=-2 : smallest singular value\nord=-2\nother: not supported\nFor vectors: ord=None : 2-norm ord=\"fro\" : not supported ord=\"nuc\" : not supported ord=np.inf : max(abs(x)) ord=-np.inf : min(abs(x)) ord=0 : sum(x != 0) ord=1 : as below ord=-1 : as below ord=2 : as below ord=-2 : as below other: sum(abs(x)**ord)**(1./ord)\nord=None : 2-norm\nord=None\nord=\"fro\" : not supported\nord=\"fro\"\nord=\"nuc\" : not supported\nord=\"nuc\"\nord=np.inf : max(abs(x))\nord=np.inf\nmax(abs(x))\nord=-np.inf : min(abs(x))\nord=-np.inf\nmin(abs(x))\nord=0 : sum(x != 0)\nord=0\nsum(x != 0)\nord=1 : as below\nord=1\nord=-1 : as below\nord=-1\nord=2 : as below\nord=2\nord=-2 : as below\nord=-2\nother: sum(abs(x)**ord)**(1./ord)\nsum(abs(x)**ord)**(1./ord)\nReturns Norm of the matrix or vector(s).\nReturns\nx = keras . ops . reshape ( keras . ops . arange ( 9 , dtype = \"float32\" ) - 4 , ( 3 , 3 )) keras . ops . linalg . norm ( x ) 7.7459664\nx = keras . ops . reshape ( keras . ops . arange ( 9 , dtype = \"float32\" ) - 4 , ( 3 , 3 ))\nkeras . ops . linalg . norm ( x )\n7.7459664"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D",
    "content": "Global average pooling operation for 2D data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalAvgPool2D\ntf.keras.layers.GlobalAvgPool2D\ntf.keras.layers.GlobalAvgPool2D\ntf . keras . layers . GlobalAveragePooling2D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalAveragePooling2D ( data_format = None , keepdims = False , ** kwargs )\nUsed in the notebooks\nEstimators\nPruning for on-device inference w/ XNNPACK\nTransfer learning and fine-tuning\nTFF simulations with accelerators\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, features, height, weight) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\nspatial dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, features, height, weight)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nIf data_format='channels_last' :\n4D tensor with shape: (batch_size, height, width, channels)\ndata_format='channels_last'\n(batch_size, height, width, channels)\nIf data_format='channels_first' :\n4D tensor with shape: (batch_size, channels, height, width)\ndata_format='channels_first'\n(batch_size, channels, height, width)\nIf keepdims=False :\n2D tensor with shape (batch_size, channels) .\nkeepdims=False\n(batch_size, channels)\nIf keepdims=True : If data_format=\"channels_last\" :\n4D tensor with shape (batch_size, 1, 1, channels) If data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, 1, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, 1, 1, channels)\ndata_format=\"channels_last\"\n(batch_size, 1, 1, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, 1, 1)\ndata_format=\"channels_first\"\n(batch_size, channels, 1, 1)\nx = np . random . rand ( 2 , 4 , 5 , 3 ) y = keras . layers . GlobalAveragePooling2D ()( x ) y . shape ( 2 , 3 )\nx = np . random . rand ( 2 , 4 , 5 , 3 )\ny = keras . layers . GlobalAveragePooling2D ()( x )\ny . shape\n( 2 , 3 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/preprocess_input",
    "content": "A placeholder method for backward compatibility.\ntf . keras . applications . efficientnet_v2 . preprocess_input ( x , data_format = None )\ntf . keras . applications . efficientnet_v2 . preprocess_input ( x , data_format = None )\nThe preprocessing logic has been included in the EfficientNetV2 model\nimplementation. Users are no longer required to call this method to\nnormalize the input data. This method does nothing and only kept as a\nplaceholder to align the API surface between old and new version of model.\nArgs\nArgs\nx A floating point numpy.array or a tensor. data_format Optional data format of the image tensor/array. Defaults to\nNone, in which case the global setting keras.backend.image_data_format() is used\n(unless you changed it, it defaults to \"channels_last\").{mode}\nx\nnumpy.array\ndata_format\nkeras.backend.image_data_format()\nReturns Unchanged numpy.array or tensor.\nReturns\nnumpy.array"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TopKCategoricalAccuracy",
    "content": "Computes how often targets are in the top K predictions.\nK\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . TopKCategoricalAccuracy ( k = 5 , name = 'top_k_categorical_accuracy' , dtype = None )\ntf . keras . metrics . TopKCategoricalAccuracy ( k = 5 , name = 'top_k_categorical_accuracy' , dtype = None )\nArgs\nArgs\nk (Optional) Number of top elements to look at for computing accuracy.\nDefaults to 5 . name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nk\n5\nname\ndtype\nm = keras . metrics . TopKCategoricalAccuracy ( k = 1 ) m . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]]) m . result () 0.5\nm = keras . metrics . TopKCategoricalAccuracy ( k = 1 )\nm . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]],\n[[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]])\nm . result ()\n0.5\nm . reset_state () m . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]], [[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]], sample_weight = [ 0.7 , 0.3 ]) m . result () 0.3\nm . reset_state ()\nm . update_state ([[ 0 , 0 , 1 ], [ 0 , 1 , 0 ]],\n[[ 0.1 , 0.9 , 0.8 ], [ 0.05 , 0.95 , 0 ]],\nsample_weight = [ 0.7 , 0.3 ])\nm . result ()\n0.3\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'categorical_crossentropy' , metrics = [ keras . metrics . TopKCategoricalAccuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'categorical_crossentropy' , metrics = [ keras . metrics . TopKCategoricalAccuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . vgg16 . preprocess_input ( x , data_format = None )\ntf . keras . applications . vgg16 . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe images are converted from RGB to BGR, then each color channel is\nzero-centered with respect to the ImageNet dataset, without scaling.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . vgg19 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . vgg19 . decode_predictions ( preds , top = 5 )\nUsed in the notebooks\nNeural style transfer\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/resize_images",
    "content": "DEPRECATED.\ntf . keras . backend . resize_images ( x , height_factor , width_factor , data_format , interpolation = 'nearest' )\ntf . keras . backend . resize_images ( x , height_factor , width_factor , data_format , interpolation = 'nearest' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/nn",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\naverage_pool(...) : Average pooling operation.\naverage_pool(...)\nbatch_normalization(...) : Normalizes x by mean and variance .\nbatch_normalization(...)\nx\nmean\nvariance\nbinary_crossentropy(...) : Computes binary cross-entropy loss between target and output tensor.\nbinary_crossentropy(...)\ncategorical_crossentropy(...) : Computes categorical cross-entropy loss between target and output tensor.\ncategorical_crossentropy(...)\nconv(...) : General N-D convolution.\nconv(...)\nconv_transpose(...) : General N-D convolution transpose.\nconv_transpose(...)\nctc_decode(...) : Decodes the output of a CTC model.\nctc_decode(...)\nctc_loss(...) : CTC (Connectionist Temporal Classification) loss.\nctc_loss(...)\ndepthwise_conv(...) : General N-D depthwise convolution.\ndepthwise_conv(...)\nelu(...) : Exponential Linear Unit activation function.\nelu(...)\ngelu(...) : Gaussian Error Linear Unit (GELU) activation function.\ngelu(...)\nhard_sigmoid(...) : Hard sigmoid activation function.\nhard_sigmoid(...)\nhard_silu(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_silu(...)\nhard_swish(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_swish(...)\nleaky_relu(...) : Leaky version of a Rectified Linear Unit activation function.\nleaky_relu(...)\nlog_sigmoid(...) : Logarithm of the sigmoid activation function.\nlog_sigmoid(...)\nlog_softmax(...) : Log-softmax activation function.\nlog_softmax(...)\nmax_pool(...) : Max pooling operation.\nmax_pool(...)\nmoments(...) : Calculates the mean and variance of x .\nmoments(...)\nx\nmulti_hot(...) : Encodes integer labels as multi-hot vectors.\nmulti_hot(...)\nnormalize(...) : Normalizes x over the specified axis.\nnormalize(...)\nx\none_hot(...) : Converts integer tensor x into a one-hot tensor.\none_hot(...)\nx\npsnr(...) : Peak Signal-to-Noise Ratio (PSNR) function.\npsnr(...)\nrelu(...) : Rectified linear unit activation function.\nrelu(...)\nrelu6(...) : Rectified linear unit activation function with upper bound of 6.\nrelu6(...)\nselu(...) : Scaled Exponential Linear Unit (SELU) activation function.\nselu(...)\nseparable_conv(...) : General N-D separable convolution.\nseparable_conv(...)\nsigmoid(...) : Sigmoid activation function.\nsigmoid(...)\nsilu(...) : Sigmoid Linear Unit (SiLU) activation function, also known as Swish.\nsilu(...)\nsoftmax(...) : Softmax activation function.\nsoftmax(...)\nsoftplus(...) : Softplus activation function.\nsoftplus(...)\nsoftsign(...) : Softsign activation function.\nsoftsign(...)\nsparse_categorical_crossentropy(...) : Computes sparse categorical cross-entropy loss.\nsparse_categorical_crossentropy(...)\nswish(...) : Sigmoid Linear Unit (SiLU) activation function, also known as Swish.\nswish(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop",
    "content": "Optimizer that implements the RMSprop algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'rmsprop' , ** kwargs )\ntf . keras . optimizers . RMSprop ( learning_rate = 0.001 , rho = 0.9 , momentum = 0.0 , epsilon = 1e-07 , centered = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'rmsprop' , ** kwargs )\nUsed in the notebooks\nMixed precision\nCustom training loop with Keras and MultiWorkerMirroredStrategy\nTransfer learning and fine-tuning\nLoad NumPy data\nClassifying CIFAR-10 with XLA\nThe gist of RMSprop is to:\nMaintain a moving (discounted) average of the square of gradients\nDivide the gradient by the root of this average\nThis implementation of RMSprop uses plain momentum, not Nesterov momentum.\nThe centered version additionally maintains a moving average of the\ngradients, and uses that average to estimate the variance.\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . rho float, defaults to 0.9. Discounting factor for the old gradients. momentum float, defaults to 0.0. If not 0.0., the optimizer tracks the\nmomentum value, with a decay rate equals to 1 - momentum . epsilon A small constant for numerical stability. This epsilon is\n\"epsilon hat\" in the Kingma and Ba paper (in the formula just before\nSection 2.1), not the epsilon in Algorithm 1 of the paper. Defaults\nto 1e-7. centered Boolean. If True , gradients are normalized by the estimated\nvariance of the gradient; if False, by the uncentered second moment.\nSetting this to True may help with training, but is slightly more\nexpensive in terms of computation and memory. Defaults to False . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nrho\nmomentum\n1 - momentum\nepsilon\ncentered\nTrue\nTrue\nFalse\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nopt = keras . optimizers . RMSprop ( learning_rate = 0.1 ) var1 = keras . backend . Variable ( 10.0 ) loss = lambda : ( var1 ** 2 ) / 2.0 # d(loss) / d(var1) = var1 opt . minimize ( loss , [ var1 ]) var1 9.683772\nopt = keras . optimizers . RMSprop ( learning_rate = 0.1 )\nvar1 = keras . backend . Variable ( 10.0 )\nloss = lambda : ( var1 ** 2 ) / 2.0 # d(loss) / d(var1) = var1\nopt . minimize ( loss , [ var1 ])\nvar1\n9.683772\nHinton, 2012\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nimage module: DO NOT EDIT.\nimage\nsequence module: DO NOT EDIT.\nsequence\ntext module: DO NOT EDIT.\ntext\nFunctions\nimage_dataset_from_directory(...) : Generates a tf.data.Dataset from image files in a directory.\nimage_dataset_from_directory(...)\ntf.data.Dataset\ntext_dataset_from_directory(...) : Generates a tf.data.Dataset from text files in a directory.\ntext_dataset_from_directory(...)\ntf.data.Dataset\ntimeseries_dataset_from_array(...) : Creates a dataset of sliding windows over a timeseries provided as array.\ntimeseries_dataset_from_array(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/segment_sum",
    "content": "Computes the sum of segments in a tensor.\ntf . keras . ops . segment_sum ( data , segment_ids , num_segments = None , sorted = False )\ntf . keras . ops . segment_sum ( data , segment_ids , num_segments = None , sorted = False )\nArgs\nArgs\ndata Input tensor. segment_ids A 1-D tensor containing segment indices for each\nelement in data . num_segments An integer representing the total number of\nsegments. If not specified, it is inferred from the maximum\nvalue in segment_ids . sorted A boolean indicating whether segment_ids is sorted.\nDefaults to False .\ndata\nsegment_ids\ndata\nnum_segments\nsegment_ids\nsorted\nsegment_ids\nFalse\nReturns A tensor containing the sum of segments, where each element\nrepresents the sum of the corresponding segment in data .\nReturns\ndata\ndata = keras . ops . convert_to_tensor ([ 1 , 2 , 10 , 20 , 100 , 200 ]) segment_ids = keras . ops . convert_to_tensor ([ 0 , 0 , 1 , 1 , 2 , 2 ]) num_segments = 3 keras . ops . segment_sum ( data , segment_ids , num_segments ) array ([ 3 , 30 , 300 ], dtype = int32 )\ndata = keras . ops . convert_to_tensor ([ 1 , 2 , 10 , 20 , 100 , 200 ])\nsegment_ids = keras . ops . convert_to_tensor ([ 0 , 0 , 1 , 1 , 2 , 2 ])\nnum_segments = 3\nkeras . ops . segment_sum ( data , segment_ids , num_segments )\narray ([ 3 , 30 , 300 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/cosine_similarity",
    "content": "Computes the cosine similarity between labels and predictions.\ntf . keras . losses . cosine_similarity ( y_true , y_pred , axis =- 1 )\ntf . keras . losses . cosine_similarity ( y_true , y_pred , axis =- 1 )\nloss = - sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nloss = - sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nNote that it is a number between -1 and 1. When it is a negative number\nbetween -1 and 0, 0 indicates orthogonality and values closer to -1\nindicate greater similarity. This makes it usable as a loss function in a\nsetting where you try to maximize the proximity between predictions and\ntargets. If either y_true or y_pred is a zero vector, cosine\nsimilarity will be 0 regardless of the proximity between predictions\nand targets.\ny_true\ny_pred\nArgs\nArgs\ny_true Tensor of true targets. y_pred Tensor of predicted targets. axis Axis along which to determine similarity. Defaults to -1 .\ny_true\ny_pred\naxis\n-1\nReturns Cosine similarity tensor.\nReturns\ny_true = [[ 0. , 1. ], [ 1. , 1. ], [ 1. , 1. ]] y_pred = [[ 1. , 0. ], [ 1. , 1. ], [ - 1. , - 1. ]] loss = keras . losses . cosine_similarity ( y_true , y_pred , axis =- 1 ) [ - 0. , - 0.99999994 , 0.99999994 ]\ny_true = [[ 0. , 1. ], [ 1. , 1. ], [ 1. , 1. ]]\ny_pred = [[ 1. , 0. ], [ 1. , 1. ], [ - 1. , - 1. ]]\nloss = keras . losses . cosine_similarity ( y_true , y_pred , axis =- 1 )\n[ - 0. , - 0.99999994 , 0.99999994 ]"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/fori_loop",
    "content": "For loop implementation.\ntf . keras . ops . fori_loop ( lower , upper , body_fun , init_val )\ntf . keras . ops . fori_loop ( lower , upper , body_fun , init_val )\nArgs\nArgs\nlower The initial value of the loop variable. upper The upper bound of the loop variable. body_fun A callable that represents the loop body. Must take two\narguments: the loop variable and the loop state. The loop state\nshould be updated and returned by this function. init_val The initial value of the loop state.\nlower\nupper\nbody_fun\ninit_val\nReturns The final state after the loop.\nReturns\nlower = 0 upper = 10 body_fun = lambda i , s : ( i + 1 , s + i ) init_val = 0 keras . ops . fori_loop ( lower , upper , body_fun , init_val ) 45\nlower = 0\nupper = 10\nbody_fun = lambda i , s : ( i + 1 , s + i )\ninit_val = 0\nkeras . ops . fori_loop ( lower , upper , body_fun , init_val )\n45"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/solve",
    "content": "Solves a linear system of equations given by a x = b .\na x = b\nMain aliases tf.keras.ops.linalg.solve\ntf.keras.ops.linalg.solve\ntf.keras.ops.linalg.solve\ntf . keras . ops . solve ( a , b )\ntf . keras . ops . solve ( a , b )\nArgs\nArgs\na A tensor of shape (..., M, M) representing the coefficients matrix. b A tensor of shape (..., M) or (..., M, N) represeting the\nright-hand side or \"dependent variable\" matrix.\na\n(..., M, M)\nb\n(..., M)\n(..., M, N)\nReturns A tensor of shape (..., M) or (..., M, N) representing the solution\nof the linear system. Returned shape is identical to b .\nReturns\n(..., M)\n(..., M, N)\nb"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/det",
    "content": "Computes the determinant of a square tensor.\nMain aliases tf.keras.ops.linalg.det\ntf.keras.ops.linalg.det\ntf.keras.ops.linalg.det\ntf . keras . ops . det ( x )\ntf . keras . ops . det ( x )\nArgs\nArgs\nx Input tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tensor of shape (...,) represeting the determinant of x .\nReturns\n(...,)\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_registered_object",
    "content": "Returns the class associated with name if it is registered with Keras.\nname\ntf . keras . utils . get_registered_object ( name , custom_objects = None , module_objects = None )\ntf . keras . utils . get_registered_object ( name , custom_objects = None , module_objects = None )\nThis function is part of the Keras serialization and deserialization\nframework. It maps strings to the objects associated with them for\nserialization/deserialization.\ndef from_config ( cls , config , custom_objects = None ): if 'my_custom_object_name' in config : config [ 'hidden_cls' ] = tf . keras . saving . get_registered_object ( config [ 'my_custom_object_name' ], custom_objects = custom_objects )\ndef from_config ( cls , config , custom_objects = None ): if 'my_custom_object_name' in config : config [ 'hidden_cls' ] = tf . keras . saving . get_registered_object ( config [ 'my_custom_object_name' ], custom_objects = custom_objects )\nArgs\nArgs\nname The name to look up. custom_objects A dictionary of custom objects to look the name up in.\nGenerally, custom_objects is provided by the user. module_objects A dictionary of custom objects to look the name up in.\nGenerally, module_objects is provided by midlevel library\nimplementers.\nname\ncustom_objects\nmodule_objects\nReturns An instantiable class associated with name , or None if no such class\nexists.\nReturns\nname\nNone"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . mobilenet . decode_predictions ( preds , top = 5 )\ntf . keras . applications . mobilenet . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/make_sampling_table",
    "content": "Generates a word rank-based probabilistic sampling table.\ntf . keras . preprocessing . sequence . make_sampling_table ( size , sampling_factor = 1e-05 )\ntf . keras . preprocessing . sequence . make_sampling_table ( size , sampling_factor = 1e-05 )\nUsed in the notebooks\nword2vec\nDEPRECATED.\nUsed for generating the sampling_table argument for skipgrams . sampling_table[i] is the probability of sampling\nthe word i-th most common word in a dataset\n(more common words should be sampled less frequently, for balance).\nsampling_table\nskipgrams\nsampling_table[i]\nThe sampling probabilities are generated according\nto the sampling distribution used in word2vec:\np ( word ) = ( min ( 1 , sqrt ( word_frequency / sampling_factor ) / ( word_frequency / sampling_factor )))\np ( word ) = ( min ( 1 , sqrt ( word_frequency / sampling_factor ) / ( word_frequency / sampling_factor )))\nWe assume that the word frequencies follow Zipf's law (s=1) to derive\na numerical approximation of frequency(rank):\nfrequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank)) where gamma is the Euler-Mascheroni constant.\nfrequency(rank) ~ 1/(rank * (log(rank) + gamma) + 1/2 - 1/(12*rank))\ngamma\nArgs\nArgs\nsize Int, number of possible words to sample. sampling_factor The sampling factor in the word2vec formula.\nsize\nsampling_factor\nReturns A 1D Numpy array of length size where the ith entry\nis the probability that a word of rank i should be sampled.\nReturns\nsize"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/svd",
    "content": "Computes the singular value decomposition of a matrix.\nMain aliases tf.keras.ops.linalg.svd\ntf.keras.ops.linalg.svd\ntf.keras.ops.linalg.svd\ntf . keras . ops . svd ( x , full_matrices = True , compute_uv = True )\ntf . keras . ops . svd ( x , full_matrices = True , compute_uv = True )\nArgs\nArgs\nx Input tensor of shape (..., M, N) .\nx\n(..., M, N)\nReturns A tuple of three tensors: a tensor of shape (..., M, M) containing the\nleft singular vectors, a tensor of shape (..., M, N) containing the\nsingular values and a tensor of shape (..., N, N) containing the\nright singular vectors.\nReturns\n(..., M, M)\n(..., M, N)\n(..., N, N)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/hard_silu",
    "content": "Hard SiLU activation function, also known as Hard Swish.\nMain aliases tf.keras.ops.hard_swish , tf.keras.ops.nn.hard_silu , tf.keras.ops.nn.hard_swish\ntf.keras.ops.hard_swish , tf.keras.ops.nn.hard_silu , tf.keras.ops.nn.hard_swish\ntf.keras.ops.hard_swish\ntf.keras.ops.nn.hard_silu\ntf.keras.ops.nn.hard_swish\ntf . keras . ops . hard_silu ( x )\ntf . keras . ops . hard_silu ( x )\n0 if if x < -3\n0\nif x < -3\nx if x > 3\nx\nx > 3\nx * (x + 3) / 6 if -3 <= x <= 3\nx * (x + 3) / 6\n-3 <= x <= 3\nIt's a faster, piecewise linear approximation of the silu activation.\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 3.0 , - 1.0 , 0.0 , 1.0 , 3.0 ]) keras . ops . hard_silu ( x ) array ([ - 0.0 , - 0.3333333 , 0.0 , 0.6666667 , 3.0 ], shape = ( 5 ,), dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 3.0 , - 1.0 , 0.0 , 1.0 , 3.0 ])\nkeras . ops . hard_silu ( x )\narray ([ - 0.0 , - 0.3333333 , 0.0 , 0.6666667 , 3.0 ], shape = ( 5 ,), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D",
    "content": "2D Convolutional LSTM.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . ConvLSTM2D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\ntf . keras . layers . ConvLSTM2D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 2 integers, specifying the size of the\nconvolution window. strides int or tuple/list of 2 integers, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 2 integers, specifying the dilation\nrate to use for dilated convolution. activation Activation function to use. By default hyperbolic tangent\nactivation function is applied ( tanh(x) ). recurrent_activation Activation function to use for the recurrent step. use_bias Boolean, whether the layer uses a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. recurrent_initializer Initializer for the recurrent_kernel weights\nmatrix, used for the linear transformation of the recurrent state. bias_initializer Initializer for the bias vector. unit_forget_bias Boolean. If True , add 1 to the bias of the forget\ngate at initialization.\nUse in combination with bias_initializer=\"zeros\" .\nThis is recommended in Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. bias_regularizer Regularizer function applied to the bias vector. activity_regularizer Regularizer function applied to. kernel_constraint Constraint function applied to the kernel weights\nmatrix. recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. bias_constraint Constraint function applied to the bias vector. dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. seed Random seed for dropout. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state in addition\nto the output. Default: False . go_backwards Boolean (default: False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default False). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default: False ).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences.\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\ntanh(x)\nrecurrent_activation\nuse_bias\nkernel_initializer\nkernel\nrecurrent_initializer\nrecurrent_kernel\nbias_initializer\nunit_forget_bias\nTrue\nbias_initializer=\"zeros\"\nkernel_regularizer\nkernel\nrecurrent_regularizer\nrecurrent_kernel\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nkernel\nrecurrent_constraint\nrecurrent_kernel\nbias_constraint\ndropout\nrecurrent_dropout\nseed\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nTrue\nunroll\nFalse\nTrue\nCall arguments\nCall arguments\ninputs A 5D tensor. mask Binary tensor of shape (samples, timesteps) indicating whether a\ngiven timestep should be masked. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode.\nThis is only relevant if dropout or recurrent_dropout are set. initial_state List of initial state tensors to be passed to the first\ncall of the cell.\ninputs\nmask\n(samples, timesteps)\ntraining\ndropout\nrecurrent_dropout\ninitial_state\nIf data_format='channels_first' :\n5D tensor with shape: (samples, time, channels, rows, cols)\ndata_format='channels_first'\n(samples, time, channels, rows, cols)\nIf data_format='channels_last' :\n5D tensor with shape: (samples, time, rows, cols, channels)\ndata_format='channels_last'\n(samples, time, rows, cols, channels)\nIf return_state : a list of tensors. The first tensor is the output.\nThe remaining tensors are the last states,\neach 4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or shape: (samples, new_rows, new_cols, filters) if data_format='channels_last' . rows and cols values might have\nchanged due to padding.\nreturn_state\n(samples, filters, new_rows, new_cols)\ndata_format='channels_first'\n(samples, new_rows, new_cols, filters)\ndata_format='channels_last'\nrows\ncols\nIf return_sequences : 5D tensor with shape: (samples, timesteps,\nfilters, new_rows, new_cols) if data_format='channels_first'\nor shape: (samples, timesteps, new_rows, new_cols, filters) if data_format='channels_last' .\nreturn_sequences\n(samples, timesteps,\nfilters, new_rows, new_cols)\n(samples, timesteps, new_rows, new_cols, filters)\ndata_format='channels_last'\nElse, 4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format='channels_first' or shape: (samples, new_rows, new_cols, filters) if data_format='channels_last' .\n(samples, filters, new_rows, new_cols)\ndata_format='channels_first'\n(samples, new_rows, new_cols, filters)\ndata_format='channels_last'\nShi et al., 2015 (the current implementation does not include the feedback loop on the\ncells output).\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndata_format\ndata_format\ndilation_rate\ndilation_rate\ndropout\ndropout\nfilters\nfilters\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\nkernel_size\nkernel_size\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. padding\npadding\nrecurrent_activation\nrecurrent_activation\nrecurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nstrides\nstrides\nunit_forget_bias\nunit_forget_bias\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/map_structure_up_to",
    "content": "Maps func through given structures up to shallow_structure .\nfunc\nshallow_structure\ntf . keras . tree . map_structure_up_to ( shallow_structure , func , * structures )\ntf . keras . tree . map_structure_up_to ( shallow_structure , func , * structures )\nThis is a variant of map_structure which only maps the given structures\nup to shallow_structure . All further nested components are retained as-is.\nmap_structure\nshallow_structure\nshallow_structure = [ None , None ] structure = [[ 1 , 1 ], [ 2 , 2 ]] keras . tree . map_structure_up_to ( shallow_structure , len , structure ) [ 2 , 2 ]\nshallow_structure = [ None , None ]\nstructure = [[ 1 , 1 ], [ 2 , 2 ]]\nkeras . tree . map_structure_up_to ( shallow_structure , len , structure )\n[ 2 , 2 ]\nshallow_structure = [ None , [ None , None ]] keras . tree . map_structure_up_to ( shallow_structure , str , structure ) [ '[1, 1]' , [ '2' , '2' ]]\nshallow_structure = [ None , [ None , None ]]\nkeras . tree . map_structure_up_to ( shallow_structure , str , structure )\n[ '[1, 1]' , [ '2' , '2' ]]\nArgs\nArgs\nshallow_structure A structure with layout common to all structures . func A callable that accepts as many arguments as there are structures. *structures Arbitrarily nested structures of the same layout.\nshallow_structure\nstructures\nfunc\n*structures\nReturns A new structure with the same layout as shallow_structure .\nReturns\nshallow_structure"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/vdot",
    "content": "Return the dot product of two vectors.\nMain aliases tf.keras.ops.numpy.vdot\ntf.keras.ops.numpy.vdot\ntf.keras.ops.numpy.vdot\ntf . keras . ops . vdot ( x1 , x2 )\ntf . keras . ops . vdot ( x1 , x2 )\nIf the first argument is complex, the complex conjugate of the first\nargument is used for the calculation of the dot product.\nMultidimensional tensors are flattened before the dot product is taken.\nArgs\nArgs\nx1 First input tensor. If complex, its complex conjugate is taken\nbefore calculation of the dot product. x2 Second input tensor.\nx1\nx2\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/full_like",
    "content": "Return a full tensor with the same shape and type as the given tensor.\nMain aliases tf.keras.ops.numpy.full_like\ntf.keras.ops.numpy.full_like\ntf.keras.ops.numpy.full_like\ntf . keras . ops . full_like ( x , fill_value , dtype = None )\ntf . keras . ops . full_like ( x , fill_value , dtype = None )\nArgs\nArgs\nx Input tensor. fill_value Fill value. dtype Overrides data type of the result.\nx\nfill_value\ndtype\nReturns Tensor of fill_value with the same shape and type as x .\nReturns\nfill_value\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/argmin",
    "content": "DEPRECATED.\ntf . keras . backend . argmin ( x , axis =- 1 )\ntf . keras . backend . argmin ( x , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity",
    "content": "Computes the cosine similarity between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . CosineSimilarity ( axis =- 1 , reduction = 'sum_over_batch_size' , name = 'cosine_similarity' )\ntf . keras . losses . CosineSimilarity ( axis =- 1 , reduction = 'sum_over_batch_size' , name = 'cosine_similarity' )\nNote that it is a number between -1 and 1. When it is a negative number\nbetween -1 and 0, 0 indicates orthogonality and values closer to -1\nindicate greater similarity. This makes it usable as a loss function in a\nsetting where you try to maximize the proximity between predictions and\ntargets. If either y_true or y_pred is a zero vector, cosine similarity\nwill be 0 regardless of the proximity between predictions and targets.\ny_true\ny_pred\nloss = - sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nloss = - sum ( l2_norm ( y_true ) * l2_norm ( y_pred ))\nArgs\nArgs\naxis The axis along which the cosine similarity is computed\n(the features axis). Defaults to -1 . reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\naxis\n-1\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/binary_crossentropy",
    "content": "Computes binary cross-entropy loss between target and output tensor.\nMain aliases tf.keras.ops.nn.binary_crossentropy\ntf.keras.ops.nn.binary_crossentropy\ntf.keras.ops.nn.binary_crossentropy\ntf . keras . ops . binary_crossentropy ( target , output , from_logits = False )\ntf . keras . ops . binary_crossentropy ( target , output , from_logits = False )\nThe binary cross-entropy loss is commonly used in binary\nclassification tasks where each input sample belongs to one\nof the two classes. It measures the dissimilarity between the\ntarget and output probabilities or logits.\nArgs\nArgs\ntarget The target tensor representing the true binary labels.\nIts shape should match the shape of the output tensor. output The output tensor representing the predicted probabilities\nor logits. Its shape should match the shape of the target tensor. from_logits (optional) Whether output is a tensor of logits or\nprobabilities.\nSet it to True if output represents logits; otherwise,\nset it to False if output represents probabilities.\nDefaults to False .\ntarget\noutput\noutput\ntarget\nfrom_logits\noutput\nTrue\noutput\nFalse\noutput\nFalse\nReturns Integer tensor: The computed binary cross-entropy loss between target and output .\nReturns\ntarget\noutput\ntarget = keras . ops . convert_to_tensor ([ 0 , 1 , 1 , 0 ]) output = keras . ops . convert_to_tensor ([ 0.1 , 0.9 , 0.8 , 0.2 ]) binary_crossentropy ( target , output ) array ([ 0.10536054 0.10536054 0.22314355 0.22314355 ], shape = ( 4 ,), dtype = float32 )\ntarget = keras . ops . convert_to_tensor ([ 0 , 1 , 1 , 0 ])\noutput = keras . ops . convert_to_tensor ([ 0.1 , 0.9 , 0.8 , 0.2 ])\nbinary_crossentropy ( target , output )\narray ([ 0.10536054 0.10536054 0.22314355 0.22314355 ],\nshape = ( 4 ,), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/flip",
    "content": "Reverse the order of elements in the tensor along the given axis.\nMain aliases tf.keras.ops.numpy.flip\ntf.keras.ops.numpy.flip\ntf.keras.ops.numpy.flip\ntf . keras . ops . flip ( x , axis = None )\ntf . keras . ops . flip ( x , axis = None )\nThe shape of the tensor is preserved, but the elements are reordered.\nArgs\nArgs\nx Input tensor. axis Axis or axes along which to flip the tensor. The default, axis=None , will flip over all of the axes of the input tensor.\nx\naxis\naxis=None\nReturns Output tensor with entries of axis reversed.\nReturns\naxis"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/KLD",
    "content": "Computes Kullback-Leibler divergence loss between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.losses.kld , tf.keras.losses.kullback_leibler_divergence , tf.keras.metrics.KLD , tf.keras.metrics.kld , tf.keras.metrics.kullback_leibler_divergence\ntf.keras.losses.kld , tf.keras.losses.kullback_leibler_divergence , tf.keras.metrics.KLD , tf.keras.metrics.kld , tf.keras.metrics.kullback_leibler_divergence\ntf.keras.losses.kld\ntf.keras.losses.kullback_leibler_divergence\ntf.keras.metrics.KLD\ntf.keras.metrics.kld\ntf.keras.metrics.kullback_leibler_divergence\ntf . keras . losses . KLD ( y_true , y_pred )\ntf . keras . losses . KLD ( y_true , y_pred )\nloss = y_true * log ( y_true / y_pred )\nloss = y_true * log ( y_true / y_pred )\ny_true and y_pred are expected to be probability\ndistributions, with values between 0 and 1. They will get\nclipped to the [0, 1] range.\ny_true\ny_pred\n[0, 1]\nArgs\nArgs\ny_true Tensor of true targets. y_pred Tensor of predicted targets.\ny_true\ny_pred\nReturns KL Divergence loss values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) . astype ( np . float32 ) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . kl_divergence ( y_true , y_pred ) assert loss . shape == ( 2 ,) y_true = ops . clip ( y_true , 1e-7 , 1 ) y_pred = ops . clip ( y_pred , 1e-7 , 1 ) assert np . array_equal ( loss , np . sum ( y_true * np . log ( y_true / y_pred ), axis =- 1 ))\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) . astype ( np . float32 )\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . kl_divergence ( y_true , y_pred )\nassert loss . shape == ( 2 ,)\ny_true = ops . clip ( y_true , 1e-7 , 1 )\ny_pred = ops . clip ( y_pred , 1e-7 , 1 )\nassert np . array_equal (\nloss , np . sum ( y_true * np . log ( y_true / y_pred ), axis =- 1 ))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/LogCoshError",
    "content": "Computes the logarithm of the hyperbolic cosine of the prediction error.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . LogCoshError ( name = 'logcosh' , dtype = None )\ntf . keras . metrics . LogCoshError ( name = 'logcosh' , dtype = None )\nerror = y_pred - y_true logcosh = mean ( log (( exp ( error ) + exp ( - error )) / 2 ), axis =- 1 )\nerror = y_pred - y_true logcosh = mean ( log (( exp ( error ) + exp ( - error )) / 2 ), axis =- 1 )\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . LogCoshError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.10844523 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 0.21689045\nm = keras . metrics . LogCoshError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.10844523\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.21689045\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . LogCoshError ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . LogCoshError ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/size",
    "content": "Return the number of elements in a tensor.\nMain aliases tf.keras.ops.numpy.size\ntf.keras.ops.numpy.size\ntf.keras.ops.numpy.size\ntf . keras . ops . size ( x )\ntf . keras . ops . size ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Number of elements in x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/set_backend",
    "content": "Reload the backend (and the Keras package).\ntf . keras . config . set_backend ( backend )\ntf . keras . config . set_backend ( backend )\nkeras . config . set_backend ( \"jax\" )\nkeras . config . set_backend ( \"jax\" )\n\u26a0\ufe0f WARNING \u26a0\ufe0f: Using this function is dangerous and should be done\ncarefully. Changing the backend will NOT convert\nthe type of any already-instantiated objects.\nThus, any layers / tensors / etc. already created will no\nlonger be usable without errors. It is strongly recommended not to keep around any Keras-originated objects instances created\nbefore calling set_backend() .\nset_backend()\nThis includes any function or class instance that uses any Keras\nfunctionality. All such code needs to be re-executed after calling set_backend() .\nset_backend()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/rsqrt",
    "content": "Computes reciprocal of square root of x element-wise.\ntf . keras . ops . rsqrt ( x )\ntf . keras . ops . rsqrt ( x )\nArgs\nArgs\nx input tensor\nx\nReturns A tensor with the same dtype as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ 1.0 , 10.0 , 100.0 ]) keras . ops . rsqrt ( x ) array ([ 1.0 , 0.31622776 , 0.1 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 1.0 , 10.0 , 100.0 ])\nkeras . ops . rsqrt ( x )\narray ([ 1.0 , 0.31622776 , 0.1 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session",
    "content": "Resets all state generated by Keras.\nMain aliases tf.keras.utils.clear_session\ntf.keras.utils.clear_session\ntf.keras.utils.clear_session\ntf . keras . backend . clear_session ( free_memory = True )\ntf . keras . backend . clear_session ( free_memory = True )\nUsed in the notebooks\nEstimators\nTransfer learning for video classification with MoViNet\nClassifying CIFAR-10 with XLA\nGraph regularization for sentiment classification using synthesized graphs\nGraph regularization for document classification using natural graphs\nKeras manages a global state, which it uses to implement the Functional\nmodel-building API and to uniquify autogenerated layer names.\nIf you are creating many models in a loop, this global state will consume\nan increasing amount of memory over time, and you may want to clear it.\nCalling clear_session() releases the global state: this helps avoid\nclutter from old models and layers, especially when memory is limited.\nclear_session()\nArgs\nArgs\nfree_memory Whether to call Python garbage collection.\nIt's usually a good practice to call it to make sure\nmemory used by deleted objects is immediately freed.\nHowever, it may take a few seconds to execute, so\nwhen using clear_session() in a short loop,\nyou may want to skip it.\nfree_memory\nclear_session()\nExample 1: calling clear_session() when creating models in a loop\nclear_session()\nfor _ in range ( 100 ): # Without `clear_session()`, each iteration of this loop will # slightly increase the size of the global state managed by Keras model = keras . Sequential ([ keras . layers . Dense ( 10 ) for _ in range ( 10 )]) for _ in range ( 100 ): # With `clear_session()` called at the beginning, # Keras starts with a blank state at each iteration # and memory consumption is constant over time. keras . backend . clear_session () model = keras . Sequential ([ keras . layers . Dense ( 10 ) for _ in range ( 10 )])\nfor _ in range ( 100 ): # Without `clear_session()`, each iteration of this loop will # slightly increase the size of the global state managed by Keras model = keras . Sequential ([ keras . layers . Dense ( 10 ) for _ in range ( 10 )]) for _ in range ( 100 ): # With `clear_session()` called at the beginning, # Keras starts with a blank state at each iteration # and memory consumption is constant over time. keras . backend . clear_session () model = keras . Sequential ([ keras . layers . Dense ( 10 ) for _ in range ( 10 )])\nExample 2: resetting the layer name generation counter\nlayers = [ keras . layers . Dense ( 10 ) for _ in range ( 10 )] new_layer = keras . layers . Dense ( 10 ) print ( new_layer . name ) dense_10 keras . backend . clear_session () new_layer = keras . layers . Dense ( 10 ) print ( new_layer . name ) dense\nlayers = [ keras . layers . Dense ( 10 ) for _ in range ( 10 )]\nnew_layer = keras . layers . Dense ( 10 )\nprint ( new_layer . name )\ndense_10\nkeras . backend . clear_session ()\nnew_layer = keras . layers . Dense ( 10 )\nprint ( new_layer . name )\ndense"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass CosineDecay : A LearningRateSchedule that uses a cosine decay with optional warmup.\nclass CosineDecay\nLearningRateSchedule\nclass CosineDecayRestarts : A LearningRateSchedule that uses a cosine decay schedule with restarts.\nclass CosineDecayRestarts\nLearningRateSchedule\nclass ExponentialDecay : A LearningRateSchedule that uses an exponential decay schedule.\nclass ExponentialDecay\nLearningRateSchedule\nclass InverseTimeDecay : A LearningRateSchedule that uses an inverse time decay schedule.\nclass InverseTimeDecay\nLearningRateSchedule\nclass LearningRateSchedule : The learning rate schedule base class.\nclass LearningRateSchedule\nclass PiecewiseConstantDecay : A LearningRateSchedule that uses a piecewise constant decay schedule.\nclass PiecewiseConstantDecay\nLearningRateSchedule\nclass PolynomialDecay : A LearningRateSchedule that uses a polynomial decay schedule.\nclass PolynomialDecay\nLearningRateSchedule\nFunctions\ndeserialize(...) : Instantiates a LearningRateSchedule object from a serialized form.\ndeserialize(...)\nLearningRateSchedule\nserialize(...) : Serializes a LearningRateSchedule into a JSON-compatible dict.\nserialize(...)\nLearningRateSchedule"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nVGG16(...) : Instantiates the VGG16 model.\nVGG16(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB1",
    "content": "Instantiates the EfficientNetB1 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB1\ntf.keras.applications.efficientnet.EfficientNetB1\ntf.keras.applications.efficientnet.EfficientNetB1\ntf . keras . applications . EfficientNetB1 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB1 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/batch_normalization",
    "content": "Normalizes x by mean and variance .\nx\nmean\nvariance\nMain aliases tf.keras.ops.nn.batch_normalization\ntf.keras.ops.nn.batch_normalization\ntf.keras.ops.nn.batch_normalization\ntf . keras . ops . batch_normalization ( x , mean , variance , axis , offset = None , scale = None , epsilon = 0.001 )\ntf . keras . ops . batch_normalization ( x , mean , variance , axis , offset = None , scale = None , epsilon = 0.001 )\nThis op is typically used by the batch normalization step in a neural\nnetwork. It normalizes the input tensor along the given axis.\nArgs\nArgs\nx Input tensor. mean A mean vector of the same length as the axis dimension of the\ninput thensor. variance A variance vector of the same length as the axis dimension\nof the input tensor. axis Integer, the axis that should be normalized. offset An offset vector of the same length as the axis dimension of\nthe input tensor. If not None , offset is added to the normalized\ntensor. Defaults to None . scale A scale vector of the same length as the axis dimension of the\ninput tensor. If not None , the normalized tensor is multiplied by scale . Defaults to None . epsilon Small float added to variance to avoid dividing by zero.\nDefaults to 1e-3.\nx\nmean\naxis\nvariance\naxis\naxis\noffset\naxis\nNone\noffset\nNone\nscale\naxis\nNone\nscale\nNone\nepsilon\nReturns The normalized tensor.\nReturns\nx = keras . ops . convert_to_tensor ( [[ 0.1 , 0.2 , 0.3 ], [ 0.4 , 0.5 , 0.6 ], [ 0.7 , 0.8 , 0.9 ]] ) keras . ops . batch_normalization ( x , mean = [ 0.4 , 0.5 , 0.6 ], variance = [ 0.67 , 0.67 , 0.67 ], axis =- 1 ) array ([[ - 3.6624e-01 , - 3.6624e-01 , - 3.6624e-01 ], [ - 4.6445e-09 , 0.0000e+00 , - 1.8578e-08 ], [ 3.6624e-01 , 3.6624e-01 , 3.6624e-01 ]])\nx = keras . ops . convert_to_tensor (\n[[ 0.1 , 0.2 , 0.3 ], [ 0.4 , 0.5 , 0.6 ], [ 0.7 , 0.8 , 0.9 ]]\n)\nkeras . ops . batch_normalization (\nx ,\nmean = [ 0.4 , 0.5 , 0.6 ],\nvariance = [ 0.67 , 0.67 , 0.67 ],\naxis =- 1\n)\narray ([[ - 3.6624e-01 , - 3.6624e-01 , - 3.6624e-01 ],\n[ - 4.6445e-09 , 0.0000e+00 , - 1.8578e-08 ],\n[ 3.6624e-01 , 3.6624e-01 , 3.6624e-01 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer",
    "content": "This is the class from which all layers inherit.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . InputLayer ( shape = None , batch_size = None , dtype = None , sparse = None , batch_shape = None , input_tensor = None , name = None , ** kwargs )\ntf . keras . layers . InputLayer ( shape = None , batch_size = None , dtype = None , sparse = None , batch_shape = None , input_tensor = None , name = None , ** kwargs )\nUsed in the notebooks\nPruning for on-device inference w/ XNNPACK\nConvolutional Variational Autoencoder\nMulti-worker training with Keras\nPost-training dynamic range quantization\nRetraining an Image Classifier\nFederated Learning for Image Classification\nA layer is a callable object that takes as input one or more tensors and\nthat outputs one or more tensors. It involves computation , defined\nin the call() method, and a state (weight variables). State can be\ncreated:\ncall()\nin __init__() , for instance via self.add_weight() ;\n__init__()\nself.add_weight()\nin the optional build() method, which is invoked by the first __call__() to the layer, and supplies the shape(s) of the input(s),\nwhich may not have been known at initialization time.\nbuild()\n__call__()\nLayers are recursively composable: If you assign a Layer instance as an\nattribute of another Layer, the outer layer will start tracking the weights\ncreated by the inner layer. Nested layers should be instantiated in the __init__() method or build() method.\n__init__()\nbuild()\nUsers will just instantiate a layer and then treat it as a callable.\nArgs\nArgs\ntrainable Boolean, whether the layer's variables should be trainable. name String name of the layer. dtype The dtype of the layer's computations and weights. Can also be a keras.DTypePolicy ,\nwhich allows the computation and\nweight dtype to differ. Defaults to None . None means to use keras.config.dtype_policy() ,\nwhich is a float32 policy unless set to different value\n(via keras.config.set_dtype_policy() ).\ntrainable\nname\ndtype\nkeras.DTypePolicy\nNone\nNone\nkeras.config.dtype_policy()\nfloat32\nkeras.config.set_dtype_policy()\nWe recommend that descendants of Layer implement the following methods:\nLayer\n__init__() : Defines custom layer attributes, and creates layer weights\nthat do not depend on input shapes, using add_weight() ,\nor other state.\n__init__()\nadd_weight()\nbuild(self, input_shape) : This method can be used to create weights that\ndepend on the shape(s) of the input(s), using add_weight() , or other\nstate. __call__() will automatically build the layer\n(if it has not been built yet) by calling build() .\nbuild(self, input_shape)\nadd_weight()\n__call__()\nbuild()\ncall(self, *args, **kwargs) : Called in __call__ after making\nsure build() has been called. call() performs the logic of applying\nthe layer to the input arguments.\nTwo reserved keyword arguments you can optionally use in call() are:\n    1. training (boolean, whether the call is in inference mode or\n        training mode).\n    2. mask (boolean tensor encoding masked timesteps in the input,\n        used e.g. in RNN layers).\nA typical signature for this method is call(self, inputs) , and user\ncould optionally add training and mask if the layer need them.\ncall(self, *args, **kwargs)\n__call__\nbuild()\ncall()\ncall()\ntraining\nmask\ncall(self, inputs)\ntraining\nmask\nget_config(self) : Returns a dictionary containing the configuration\nused to initialize this layer. If the keys differ from the arguments\nin __init__() , then override from_config(self) as well.\nThis method is used when saving\nthe layer or a model that contains this layer.\nget_config(self)\n__init__()\nfrom_config(self)\nHere's a basic example: a layer with two variables, w and b ,\nthat returns y = w . x + b .\nIt shows how to implement build() and call() .\nVariables set as attributes of a layer are tracked as weights\nof the layers (in layer.weights ).\nw\nb\ny = w . x + b\nbuild()\ncall()\nlayer.weights\nclass SimpleDense ( Layer ): def __init__ ( self , units = 32 ): super () . __init__ () self . units = units # Create the state of the layer (weights) def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = \"glorot_uniform\" , trainable = True , name = \"kernel\" , ) self . bias = self . add_weight ( shape = ( self . units ,), initializer = \"zeros\" , trainable = True , name = \"bias\" , ) # Defines the computation def call ( self , inputs ): return ops . matmul ( inputs , self . kernel ) + self . bias # Instantiates the layer. linear_layer = SimpleDense ( 4 ) # This will also call `build(input_shape)` and create the weights. y = linear_layer ( ops . ones (( 2 , 2 ))) assert len ( linear_layer . weights ) == 2 # These weights are trainable, so they're listed in `trainable_weights`: assert len ( linear_layer . trainable_weights ) == 2\nclass SimpleDense ( Layer ): def __init__ ( self , units = 32 ): super () . __init__ () self . units = units # Create the state of the layer (weights) def build ( self , input_shape ): self . kernel = self . add_weight ( shape = ( input_shape [ - 1 ], self . units ), initializer = \"glorot_uniform\" , trainable = True , name = \"kernel\" , ) self . bias = self . add_weight ( shape = ( self . units ,), initializer = \"zeros\" , trainable = True , name = \"bias\" , ) # Defines the computation def call ( self , inputs ): return ops . matmul ( inputs , self . kernel ) + self . bias # Instantiates the layer. linear_layer = SimpleDense ( 4 ) # This will also call `build(input_shape)` and create the weights. y = linear_layer ( ops . ones (( 2 , 2 ))) assert len ( linear_layer . weights ) == 2 # These weights are trainable, so they're listed in `trainable_weights`: assert len ( linear_layer . trainable_weights ) == 2\nBesides trainable weights, updated via backpropagation during training,\nlayers can also have non-trainable weights. These weights are meant to\nbe updated manually during call() . Here's a example layer that computes\nthe running sum of its inputs:\ncall()\nclass ComputeSum ( Layer ): def __init__ ( self , input_dim ): super ( ComputeSum , self ) . __init__ () # Create a non-trainable weight. self . total = self . add_weight ( shape = (), initializer = \"zeros\" , trainable = False , name = \"total\" , ) def call ( self , inputs ): self . total . assign ( self . total + ops . sum ( inputs )) return self . total my_sum = ComputeSum ( 2 ) x = ops . ones (( 2 , 2 )) y = my_sum ( x ) assert my_sum . weights == [ my_sum . total ] assert my_sum . non_trainable_weights == [ my_sum . total ] assert my_sum . trainable_weights == []\nclass ComputeSum ( Layer ): def __init__ ( self , input_dim ): super ( ComputeSum , self ) . __init__ () # Create a non-trainable weight. self . total = self . add_weight ( shape = (), initializer = \"zeros\" , trainable = False , name = \"total\" , ) def call ( self , inputs ): self . total . assign ( self . total + ops . sum ( inputs )) return self . total my_sum = ComputeSum ( 2 ) x = ops . ones (( 2 , 2 )) y = my_sum ( x ) assert my_sum . weights == [ my_sum . total ] assert my_sum . non_trainable_weights == [ my_sum . total ] assert my_sum . trainable_weights == []\nAttributes\nAttributes\nname The name of the layer (string). dtype Dtype of the layer's weights. Alias of layer.variable_dtype . variable_dtype Dtype of the layer's weights. compute_dtype The dtype of the layer's computations.\nLayers automatically cast inputs to this dtype, which causes\nthe computations and output to also be in this dtype.\nWhen mixed precision is used with a keras.DTypePolicy , this will be different\nthan variable_dtype . trainable_weights List of variables to be included in backprop. non_trainable_weights List of variables that should not be\nincluded in backprop. weights The concatenation of the lists trainable_weights and\nnon_trainable_weights (in this order). trainable Whether the layer should be trained (boolean), i.e.\nwhether its potentially-trainable weights should be returned\nas part of layer.trainable_weights . input_spec Optional (list of) InputSpec object(s) specifying the\nconstraints on inputs that can be accepted by the layer. input Retrieves the input tensor(s) of a symbolic operation.\nname\ndtype\nlayer.variable_dtype\nvariable_dtype\ncompute_dtype\nkeras.DTypePolicy\nvariable_dtype\ntrainable_weights\nnon_trainable_weights\nweights\ntrainable\nlayer.trainable_weights\ninput_spec\nInputSpec\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/scatter_update",
    "content": "Update inputs via updates at scattered (sparse) indices.\ntf . keras . ops . scatter_update ( inputs , indices , updates )\ntf . keras . ops . scatter_update ( inputs , indices , updates )\nAt a high level, this operation does inputs[indices] = updates .\nAssume inputs is a tensor of shape (D0, D1, ..., Dn) , there are 2 main\nusages of scatter_update .\ninputs[indices] = updates\ninputs\n(D0, D1, ..., Dn)\nscatter_update\nindices is a 2D tensor of shape (num_updates, n) , where num_updates is the number of updates to perform, and updates is a 1D tensor of\nshape (num_updates,) . For example, if inputs is zeros((4, 4, 4)) ,\nand we want to update inputs[1, 2, 3] and inputs[0, 1, 3] as 1, then\nwe can use:\nindices\n(num_updates, n)\nnum_updates\nupdates\n(num_updates,)\ninputs\nzeros((4, 4, 4))\ninputs[1, 2, 3]\ninputs[0, 1, 3]\ninputs = np . zeros (( 4 , 4 , 4 )) indices = [[ 1 , 2 , 3 ], [ 0 , 1 , 3 ]] updates = np . array ([ 1. , 1. ]) inputs = keras . ops . scatter_update ( inputs , indices , updates )\ninputs = np . zeros (( 4 , 4 , 4 )) indices = [[ 1 , 2 , 3 ], [ 0 , 1 , 3 ]] updates = np . array ([ 1. , 1. ]) inputs = keras . ops . scatter_update ( inputs , indices , updates )\n2 indices is a 2D tensor of shape (num_updates, k) , where num_updates is the number of updates to perform, and k ( k < n ) is the size of\n    each index in indices . updates is a n - k -D tensor of shape (num_updates, inputs.shape[k:]) . For example, if inputs = np.zeros((4, 4, 4)) , and we want to update inputs[1, 2, :] and inputs[2, 3, :] as [1, 1, 1, 1] , then indices would have shape (num_updates, 2) ( k = 2 ), and updates would have shape (num_updates, 4) ( inputs.shape[2:] = 4 ). See the code below:\nindices\n(num_updates, k)\nnum_updates\nk\nk < n\nindices\nupdates\nn - k\n(num_updates, inputs.shape[k:])\ninputs = np.zeros((4, 4, 4))\ninputs[1, 2, :]\ninputs[2, 3, :]\n[1, 1, 1, 1]\nindices\n(num_updates, 2)\nk = 2\nupdates\n(num_updates, 4)\ninputs.shape[2:] = 4\ninputs = np . zeros (( 4 , 4 , 4 )) indices = [[ 1 , 2 ], [ 2 , 3 ]] updates = np . array ([[ 1. , 1. , 1 , 1 ,], [ 1. , 1. , 1 , 1 ,]) inputs = keras . ops . scatter_update ( inputs , indices , updates )\ninputs = np . zeros (( 4 , 4 , 4 )) indices = [[ 1 , 2 ], [ 2 , 3 ]] updates = np . array ([[ 1. , 1. , 1 , 1 ,], [ 1. , 1. , 1 , 1 ,]) inputs = keras . ops . scatter_update ( inputs , indices , updates )\nArgs\nArgs\ninputs A tensor, the tensor to be updated. indices A tensor or list/tuple of shape (N, inputs.ndim) , specifying\nindices to update. N is the number of indices to update, must be\nequal to the first dimension of updates . updates A tensor, the new values to be put to inputs at indices .\ninputs\nindices\n(N, inputs.ndim)\nN\nupdates\nupdates\ninputs\nindices\nReturns A tensor, has the same shape and dtype as inputs .\nReturns\ninputs"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/zeros_like",
    "content": "DEPRECATED.\ntf . keras . backend . zeros_like ( x , dtype = None , name = None )\ntf . keras . backend . zeros_like ( x , dtype = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation",
    "content": "A preprocessing layer which randomly translates images during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomTranslation ( height_factor , width_factor , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , data_format = None , ** kwargs )\ntf . keras . layers . RandomTranslation ( height_factor , width_factor , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , data_format = None , ** kwargs )\nUsed in the notebooks\nRetraining an Image Classifier\nThis layer will apply random translations to each image during training,\nfilling empty space according to fill_mode .\nfill_mode\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nof integer or floating point dtype. By default, the layer will output\nfloats.\n[0., 1.)\n[0, 255]\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format,\nor (..., channels, height, width) , in \"channels_first\" format.\n(..., height, width, channels)\n\"channels_last\"\n(..., channels, height, width)\n\"channels_first\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., target_height, target_width, channels) ,\nor (..., channels, target_height, target_width) ,\nin \"channels_first\" format.\n(..., target_height, target_width, channels)\n(..., channels, target_height, target_width)\n\"channels_first\"\ntf.data\nArgs\nArgs\nheight_factor a float represented as fraction of value, or a tuple of\nsize 2 representing lower and upper bound for shifting vertically. A\nnegative value means shifting image up, while a positive value means\nshifting image down. When represented as a single positive float,\nthis value is used for both the upper and lower bound. For instance, height_factor=(-0.2, 0.3) results in an output shifted by a random\namount in the range [-20%, +30%] . height_factor=0.2 results in\nan output height shifted by a random amount in the range [-20%, +20%] . width_factor a float represented as fraction of value, or a tuple of\nsize 2 representing lower and upper bound for shifting horizontally.\nA negative value means shifting image left, while a positive value\nmeans shifting image right. When represented as a single positive\nfloat, this value is used for both the upper and lower bound. For\ninstance, width_factor=(-0.2, 0.3) results in an output shifted\nleft by 20%, and shifted right by 30%. width_factor=0.2 results\nin an output height shifted left or right by 20%. fill_mode Points outside the boundaries of the input are filled\naccording to the given mode. Available methods are \"constant\" , \"nearest\" , \"wrap\" and \"reflect\" . Defaults to \"constant\" .\nheight_factor\nheight_factor=(-0.2, 0.3)\n[-20%, +30%]\nheight_factor=0.2\n[-20%, +20%]\nwidth_factor\nwidth_factor=(-0.2, 0.3)\nwidth_factor=0.2\nfill_mode\n\"constant\"\n\"nearest\"\n\"wrap\"\n\"reflect\"\n\"constant\"\n\"reflect\" : (d c b a | a b c d | d c b a) The input is extended by reflecting about the edge of the last\npixel.\n\"reflect\"\n(d c b a | a b c d | d c b a)\n\"constant\" : (k k k k | a b c d | k k k k) The input is extended by filling all values beyond\nthe edge with the same constant value k specified by fill_value .\n\"constant\"\n(k k k k | a b c d | k k k k)\nfill_value\n\"wrap\" : (a b c d | a b c d | a b c d) The input is extended by wrapping around to the opposite edge.\n\"wrap\"\n(a b c d | a b c d | a b c d)\n\"nearest\" : (a a a a | a b c d | d d d d) The input is extended by the nearest pixel.\nNote that when using torch backend, \"reflect\" is redirected to \"mirror\" (c d c b | a b c d | c b a b) because torch does not\nsupport \"reflect\" .\nNote that torch backend does not support \"wrap\" . interpolation Interpolation mode. Supported values: \"nearest\" , \"bilinear\" . seed Integer. Used to create a random seed. fill_value a float represents the value to be filled outside the\nboundaries when fill_mode=\"constant\" . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . **kwargs Base layer keyword arguments, such as name and dtype .\n\"nearest\"\n(a a a a | a b c d | d d d d)\n\"reflect\"\n\"mirror\"\n(c d c b | a b c d | c b a b)\n\"reflect\"\n\"wrap\"\ninterpolation\n\"nearest\"\n\"bilinear\"\nseed\nfill_value\nfill_mode=\"constant\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/triu",
    "content": "Return upper triangle of a tensor.\nMain aliases tf.keras.ops.numpy.triu\ntf.keras.ops.numpy.triu\ntf.keras.ops.numpy.triu\ntf . keras . ops . triu ( x , k = 0 )\ntf . keras . ops . triu ( x , k = 0 )\nFor tensors with ndim exceeding 2, triu will apply to the\nfinal two axes.\nndim\ntriu\nArgs\nArgs\nx Input tensor. k Diagonal below which to zero elements. Defaults to 0 . the\nmain diagonal. k < 0 is below it, and k > 0 is above it.\nx\nk\n0\nk < 0\nk > 0\nReturns Upper triangle of x , of same shape and data type as x .\nReturns\nx\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array",
    "content": "Creates a dataset of sliding windows over a timeseries provided as array.\nMain aliases tf.keras.utils.timeseries_dataset_from_array\ntf.keras.utils.timeseries_dataset_from_array\ntf.keras.utils.timeseries_dataset_from_array\ntf . keras . preprocessing . timeseries_dataset_from_array ( data , targets , sequence_length , sequence_stride = 1 , sampling_rate = 1 , batch_size = 128 , shuffle = False , seed = None , start_index = None , end_index = None )\ntf . keras . preprocessing . timeseries_dataset_from_array ( data , targets , sequence_length , sequence_stride = 1 , sampling_rate = 1 , batch_size = 128 , shuffle = False , seed = None , start_index = None , end_index = None )\nUsed in the notebooks\nTime series forecasting\nThis function takes in a sequence of data-points gathered at\nequal intervals, along with time series parameters such as\nlength of the sequences/windows, spacing between two sequence/windows, etc.,\nto produce batches of timeseries inputs and targets.\nArgs\nArgs\ndata Numpy array or eager tensor\ncontaining consecutive data points (timesteps).\nAxis 0 is expected to be the time dimension. targets Targets corresponding to timesteps in data . targets[i] should be the target\ncorresponding to the window that starts at index i (see example 2 below).\nPass None if you don't have target data (in this case the dataset\nwill only yield the input data). sequence_length Length of the output sequences\n(in number of timesteps). sequence_stride Period between successive output sequences.\nFor stride s , output samples would\nstart at index data[i] , data[i + s] , data[i + 2 * s] , etc. sampling_rate Period between successive individual timesteps\nwithin sequences. For rate r , timesteps data[i], data[i + r], ... data[i + sequence_length] are used for creating a sample sequence. batch_size Number of timeseries samples in each batch\n(except maybe the last one). If None , the data will not be batched\n(the dataset will yield individual samples). shuffle Whether to shuffle output samples,\nor instead draw them in chronological order. seed Optional int; random seed for shuffling. start_index Optional int; data points earlier (exclusive)\nthan start_index will not be used\nin the output sequences. This is useful to reserve part of the\ndata for test or validation. end_index Optional int; data points later (exclusive) than end_index will not be used in the output sequences.\nThis is useful to reserve part of the data for test or validation.\ndata\ntargets\ndata\ntargets[i]\ni\nNone\nsequence_length\nsequence_stride\ns\ndata[i]\ndata[i + s]\ndata[i + 2 * s]\nsampling_rate\nr\ndata[i], data[i + r], ... data[i + sequence_length]\nbatch_size\nNone\nshuffle\nseed\nstart_index\nstart_index\nend_index\nend_index\nReturns\nReturns\nA tf.data.Dataset instance. If targets was passed, the dataset yields\ntuple (batch_of_sequences, batch_of_targets) . If not, the dataset yields\nonly batch_of_sequences .\ntf.data.Dataset\ntargets\n(batch_of_sequences, batch_of_targets)\nbatch_of_sequences\nConsider indices [0, 1, ... 98] .\nWith sequence_length=10,  sampling_rate=2, sequence_stride=3 , shuffle=False , the dataset will yield batches of sequences\ncomposed of the following indices:\n[0, 1, ... 98]\nsequence_length=10,  sampling_rate=2, sequence_stride=3\nshuffle=False\nFirst sequence : [ 0 2 4 6 8 10 12 14 16 18 ] Second sequence : [ 3 5 7 9 11 13 15 17 19 21 ] Third sequence : [ 6 8 10 12 14 16 18 20 22 24 ] ... Last sequence : [ 78 80 82 84 86 88 90 92 94 96 ]\nFirst sequence : [ 0 2 4 6 8 10 12 14 16 18 ] Second sequence : [ 3 5 7 9 11 13 15 17 19 21 ] Third sequence : [ 6 8 10 12 14 16 18 20 22 24 ] ... Last sequence : [ 78 80 82 84 86 88 90 92 94 96 ]\nIn this case the last 2 data points are discarded since no full sequence\ncan be generated to include them (the next sequence would have started\nat index 81, and thus its last step would have gone over 98).\nExample 2: Temporal regression.\nConsider an array data of scalar values, of shape (steps,) .\nTo generate a dataset that uses the past 10\ntimesteps to predict the next timestep, you would use:\ndata\n(steps,)\ninput_data = data [: - 10 ] targets = data [ 10 :] dataset = timeseries_dataset_from_array ( input_data , targets , sequence_length = 10 ) for batch in dataset : inputs , targets = batch assert np . array_equal ( inputs [ 0 ], data [: 10 ]) # First sequence: steps [0-9] # Corresponding target: step 10 assert np . array_equal ( targets [ 0 ], data [ 10 ]) break\ninput_data = data [: - 10 ] targets = data [ 10 :] dataset = timeseries_dataset_from_array ( input_data , targets , sequence_length = 10 ) for batch in dataset : inputs , targets = batch assert np . array_equal ( inputs [ 0 ], data [: 10 ]) # First sequence: steps [0-9] # Corresponding target: step 10 assert np . array_equal ( targets [ 0 ], data [ 10 ]) break\nExample 3: Temporal regression for many-to-many architectures.\nConsider two arrays of scalar values X and Y ,\nboth of shape (100,) . The resulting dataset should consist samples with\n20 timestamps each. The samples should not overlap.\nTo generate a dataset that uses the current timestamp\nto predict the corresponding target timestep, you would use:\nX\nY\n(100,)\nX = np . arange ( 100 ) Y = X * 2 sample_length = 20 input_dataset = timeseries_dataset_from_array ( X , None , sequence_length = sample_length , sequence_stride = sample_length ) target_dataset = timeseries_dataset_from_array ( Y , None , sequence_length = sample_length , sequence_stride = sample_length ) for batch in zip ( input_dataset , target_dataset ): inputs , targets = batch assert np . array_equal ( inputs [ 0 ], X [: sample_length ]) # second sample equals output timestamps 20-40 assert np . array_equal ( targets [ 1 ], Y [ sample_length : 2 * sample_length ]) break\nX = np . arange ( 100 ) Y = X * 2 sample_length = 20 input_dataset = timeseries_dataset_from_array ( X , None , sequence_length = sample_length , sequence_stride = sample_length ) target_dataset = timeseries_dataset_from_array ( Y , None , sequence_length = sample_length , sequence_stride = sample_length ) for batch in zip ( input_dataset , target_dataset ): inputs , targets = batch assert np . array_equal ( inputs [ 0 ], X [: sample_length ]) # second sample equals output timestamps 20-40 assert np . array_equal ( targets [ 1 ], Y [ sample_length : 2 * sample_length ]) break"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/pool2d",
    "content": "DEPRECATED.\ntf . keras . backend . pool2d ( x , pool_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , pool_mode = 'max' )\ntf . keras . backend . pool2d ( x , pool_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , pool_mode = 'max' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . imagenet_utils . decode_predictions ( preds , top = 5 )\ntf . keras . applications . imagenet_utils . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/normalize",
    "content": "Normalizes an array.\ntf . keras . utils . normalize ( x , axis =- 1 , order = 2 )\ntf . keras . utils . normalize ( x , axis =- 1 , order = 2 )\nIf the input is a NumPy array, a NumPy array will be returned.\nIf it's a backend tensor, a backend tensor will be returned.\nArgs\nArgs\nx Array to normalize. axis axis along which to normalize. order Normalization order (e.g. order=2 for L2 norm).\nx\naxis\norder\norder=2\nReturns A normalized copy of the array.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/AbsMaxQuantizer",
    "content": "Inherits From: Quantizer\nQuantizer\ntf . keras . quantizers . AbsMaxQuantizer ( axis , value_range = ( - 127 , 127 ), epsilon = backend . epsilon (), output_dtype = 'int8' )\ntf . keras . quantizers . AbsMaxQuantizer ( axis , value_range = ( - 127 , 127 ), epsilon = backend . epsilon (), output_dtype = 'int8' )\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a quantizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same quantizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A quantizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the quantizer.\nAn quantizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the quantizer.\nThe same quantizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a quantized output from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/binary_focal_crossentropy",
    "content": "DEPRECATED.\ntf . keras . backend . binary_focal_crossentropy ( target , output , apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False )\ntf . keras . backend . binary_focal_crossentropy ( target , output , apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/exp",
    "content": "Calculate the exponential of all elements in the input tensor.\nMain aliases tf.keras.ops.numpy.exp\ntf.keras.ops.numpy.exp\ntf.keras.ops.numpy.exp\ntf . keras . ops . exp ( x )\ntf . keras . ops . exp ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise exponential of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/foldr",
    "content": "DEPRECATED.\ntf . keras . backend . foldr ( fn , elems , initializer = None , name = None )\ntf . keras . backend . foldr ( fn , elems , initializer = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax",
    "content": "Softmax converts a vector of values to a probability distribution.\ntf . keras . activations . softmax ( x , axis =- 1 )\ntf . keras . activations . softmax ( x , axis =- 1 )\nThe elements of the output vector are in range [0, 1] and sum to 1.\n[0, 1]\nEach input vector is handled independently.\nThe axis argument sets which axis of the input the function\nis applied along.\naxis\nSoftmax is often used as the activation for the last\nlayer of a classification network because the result could be interpreted as\na probability distribution.\nThe softmax of each vector x is computed as exp(x) / sum(exp(x)) .\nexp(x) / sum(exp(x))\nThe input values in are the log-odds of the resulting probability.\nArgs\nArgs\nx Input tensor. axis Integer, axis along which the softmax is applied.\nx\naxis"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/to_dense",
    "content": "DEPRECATED.\ntf . keras . backend . to_dense ( tensor )\ntf . keras . backend . to_dense ( tensor )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nVGG19(...) : Instantiates the VGG19 model.\nVGG19(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/hard_sigmoid",
    "content": "Hard sigmoid activation function.\ntf . keras . activations . hard_sigmoid ( x )\ntf . keras . activations . hard_sigmoid ( x )\nThe hard sigmoid activation is defined as:\n0 if if x <= -3\n0\nif x <= -3\n1 if x >= 3\n1\nx >= 3\n(x/6) + 0.5 if -3 < x < 3\n(x/6) + 0.5\n-3 < x < 3\nIt's a faster, piecewise linear approximation\nof the sigmoid activation.\nArgs\nArgs\nx Input tensor.\nx\nWikipedia \"Hard sigmoid\""
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/densenet",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nDenseNet121(...) : Instantiates the Densenet121 architecture.\nDenseNet121(...)\nDenseNet169(...) : Instantiates the Densenet169 architecture.\nDenseNet169(...)\nDenseNet201(...) : Instantiates the Densenet201 architecture.\nDenseNet201(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sqrt",
    "content": "Return the non-negative square root of a tensor, element-wise.\nMain aliases tf.keras.ops.numpy.sqrt\ntf.keras.ops.numpy.sqrt\ntf.keras.ops.numpy.sqrt\ntf . keras . ops . sqrt ( x )\ntf . keras . ops . sqrt ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, the non-negative square root of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/std",
    "content": "Compute the standard deviation along the specified axis.\nMain aliases tf.keras.ops.numpy.std\ntf.keras.ops.numpy.std\ntf.keras.ops.numpy.std\ntf . keras . ops . std ( x , axis = None , keepdims = False )\ntf . keras . ops . std ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis along which to compute standard deviation.\nDefault is to compute the standard deviation of the\nflattened tensor. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one.\nx\naxis\nkeepdims\nTrue\nReturns Output tensor containing the standard deviation values.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Constant",
    "content": "Initializer that generates tensors with constant values.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.constant\ntf.keras.initializers.constant\ntf.keras.initializers.constant\ntf . keras . initializers . Constant ( value = 0.0 )\ntf . keras . initializers . Constant ( value = 0.0 )\nUsed in the notebooks\nClassification on imbalanced data\nTrain a Deep Q Network with TF-Agents\nOnly scalar values are allowed.\nThe constant value provided must be convertible to the dtype requested\nwhen calling the initializer.\n# Standalone usage: initializer = Constant ( 10. ) values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = Constant ( 10. )\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = Constant ( 10. ) layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = Constant ( 10. )\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nvalue A Python scalar.\nvalue\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/segment_max",
    "content": "Computes the max of segments in a tensor.\ntf . keras . ops . segment_max ( data , segment_ids , num_segments = None , sorted = False )\ntf . keras . ops . segment_max ( data , segment_ids , num_segments = None , sorted = False )\nArgs\nArgs\ndata Input tensor. segment_ids A 1-D tensor containing segment indices for each\nelement in data . num_segments An integer representing the total number of\nsegments. If not specified, it is inferred from the maximum\nvalue in segment_ids . sorted A boolean indicating whether segment_ids is sorted.\nDefaults to False .\ndata\nsegment_ids\ndata\nnum_segments\nsegment_ids\nsorted\nsegment_ids\nFalse\nReturns A tensor containing the max of segments, where each element\nrepresents the max of the corresponding segment in data .\nReturns\ndata\ndata = keras . ops . convert_to_tensor ([ 1 , 2 , 10 , 20 , 100 , 200 ]) segment_ids = keras . ops . convert_to_tensor ([ 0 , 0 , 1 , 1 , 2 , 2 ]) num_segments = 3 keras . ops . segment_max ( data , segment_ids , num_segments ) array ([ 2 , 20 , 200 ], dtype = int32 )\ndata = keras . ops . convert_to_tensor ([ 1 , 2 , 10 , 20 , 100 , 200 ])\nsegment_ids = keras . ops . convert_to_tensor ([ 0 , 0 , 1 , 1 , 2 , 2 ])\nnum_segments = 3\nkeras . ops . segment_max ( data , segment_ids , num_segments )\narray ([ 2 , 20 , 200 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/serialize",
    "content": "tf . keras . activations . serialize ( activation )\ntf . keras . activations . serialize ( activation )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose",
    "content": "1D transposed convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution1DTranspose\ntf.keras.layers.Convolution1DTranspose\ntf.keras.layers.Convolution1DTranspose\ntf . keras . layers . Conv1DTranspose ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv1DTranspose ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the transpose convolution). kernel_size int or tuple/list of 1 integer, specifying the size of the\ntransposed convolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the transposed convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated transposed convolution. activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, steps, channels)\ndata_format=\"channels_last\"\n(batch_shape, steps, channels)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, channels, steps)\ndata_format=\"channels_first\"\n(batch_shape, channels, steps)\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, new_steps, filters)\ndata_format=\"channels_last\"\n(batch_shape, new_steps, filters)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, filters, new_steps)\ndata_format=\"channels_first\"\n(batch_shape, filters, new_steps)\nReturns A 3D tensor representing activation(conv1d_transpose(inputs, kernel) + bias) .\nReturns\nactivation(conv1d_transpose(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nA guide to convolution arithmetic for deep learning\nDeconvolutional Networks\nx = np . random . rand ( 4 , 10 , 128 ) y = keras . layers . Conv1DTranspose ( 32 , 3 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 21 , 32 )\nx = np . random . rand ( 4 , 10 , 128 )\ny = keras . layers . Conv1DTranspose ( 32 , 3 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 21 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ndeserialize(...) : Return a Keras activation function via its config.\ndeserialize(...)\nelu(...) : Exponential Linear Unit.\nelu(...)\nexponential(...) : Exponential activation function.\nexponential(...)\ngelu(...) : Gaussian error linear unit (GELU) activation function.\ngelu(...)\nget(...) : Retrieve a Keras activation function via an identifier.\nget(...)\nhard_sigmoid(...) : Hard sigmoid activation function.\nhard_sigmoid(...)\nhard_silu(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_silu(...)\nhard_swish(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_swish(...)\nleaky_relu(...) : Leaky relu activation function.\nleaky_relu(...)\nlinear(...) : Linear activation function (pass-through).\nlinear(...)\nlog_softmax(...) : Log-Softmax activation function.\nlog_softmax(...)\nmish(...) : Mish activation function.\nmish(...)\nrelu(...) : Applies the rectified linear unit activation function.\nrelu(...)\nrelu6(...) : Relu6 activation function.\nrelu6(...)\nselu(...) : Scaled Exponential Linear Unit (SELU).\nselu(...)\nserialize(...)\nserialize(...)\nsigmoid(...) : Sigmoid activation function.\nsigmoid(...)\nsilu(...) : Swish (or Silu) activation function.\nsilu(...)\nsoftmax(...) : Softmax converts a vector of values to a probability distribution.\nsoftmax(...)\nsoftplus(...) : Softplus activation function.\nsoftplus(...)\nsoftsign(...) : Softsign activation function.\nsoftsign(...)\nswish(...) : Swish (or Silu) activation function.\nswish(...)\ntanh(...) : Hyperbolic tangent activation function.\ntanh(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Identity",
    "content": "Identity layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Identity ( ** kwargs )\ntf . keras . layers . Identity ( ** kwargs )\nThis layer should be used as a placeholder when no operation is to be\nperformed. The layer just returns its inputs argument as output.\ninputs\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Hinge",
    "content": "Computes the hinge metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . Hinge ( name = 'hinge' , dtype = None )\ntf . keras . metrics . Hinge ( name = 'hinge' , dtype = None )\ny_true values are expected to be -1 or 1. If binary (0 or 1) labels are\nprovided we will convert them to -1 or 1.\ny_true\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . Hinge () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]) m . result () 1.3 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]], sample_weight = [ 1 , 0 ]) m . result () 1.1\nm = keras . metrics . Hinge ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]])\nm . result ()\n1.3\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n1.1\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/argmax",
    "content": "Returns the indices of the maximum values along an axis.\nMain aliases tf.keras.ops.numpy.argmax\ntf.keras.ops.numpy.argmax\ntf.keras.ops.numpy.argmax\ntf . keras . ops . argmax ( x , axis = None , keepdims = False )\ntf . keras . ops . argmax ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis By default, the index is into the flattened tensor, otherwise\nalong the specified axis. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one. Defaults to False .\nx\naxis\nkeepdims\nTrue\nFalse\nReturns Tensor of indices. It has the same shape as x , with the dimension\nalong axis removed.\nReturns\nx\naxis\nx = keras . ops . arange ( 6 ) . reshape ( 2 , 3 ) + 10 x array ([[ 10 , 11 , 12 ], [ 13 , 14 , 15 ]], dtype = int32 ) keras . ops . argmax ( x ) array ( 5 , dtype = int32 ) keras . ops . argmax ( x , axis = 0 ) array ([ 1 , 1 , 1 ], dtype = int32 ) keras . ops . argmax ( x , axis = 1 ) array ([ 2 , 2 ], dtype = int32 )\nx = keras . ops . arange ( 6 ) . reshape ( 2 , 3 ) + 10\nx\narray ([[ 10 , 11 , 12 ],\n[ 13 , 14 , 15 ]], dtype = int32 )\nkeras . ops . argmax ( x )\narray ( 5 , dtype = int32 )\nkeras . ops . argmax ( x , axis = 0 )\narray ([ 1 , 1 , 1 ], dtype = int32 )\nkeras . ops . argmax ( x , axis = 1 )\narray ([ 2 , 2 ], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/hard_silu",
    "content": "Hard SiLU activation function, also known as Hard Swish.\nMain aliases tf.keras.activations.hard_swish\ntf.keras.activations.hard_swish\ntf.keras.activations.hard_swish\ntf . keras . activations . hard_silu ( x )\ntf . keras . activations . hard_silu ( x )\n0 if if x < -3\n0\nif x < -3\nx if x > 3\nx\nx > 3\nx * (x + 3) / 6 if -3 <= x <= 3\nx * (x + 3) / 6\n-3 <= x <= 3\nIt's a faster, piecewise linear approximation of the silu activation.\nArgs\nArgs\nx Input tensor.\nx\nA Howard, 2019"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_normal",
    "content": "DEPRECATED.\ntf . keras . backend . random_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\ntf . keras . backend . random_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/StatelessScope",
    "content": "Scope to prevent any update to Keras Variables.\nCompat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.StatelessScope\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.StatelessScope\ntf.compat.v1.keras.StatelessScope\ntf . keras . StatelessScope ( state_mapping = None , collect_losses = False , initialize_variables = True )\ntf . keras . StatelessScope ( state_mapping = None , collect_losses = False , initialize_variables = True )\nThe values of variables to be used inside the scope\nshould be passed via the state_mapping argument, a\nlist of tuples (k, v) where k is a KerasVariable and v is the intended value for this variable\n(a backend tensor).\nstate_mapping\n(k, v)\nk\nKerasVariable\nv\nUpdated values can be collected on scope exit via value = scope.get_current_value(variable) . No updates\nwill be applied in-place to any variables for the duration\nof the scope.\nvalue = scope.get_current_value(variable)\nstate_mapping = [( k , ops . ones ( k . shape , k . dtype )) for k in model . weights ] with keras . StatelessScope ( state_mapping ) as scope : outputs = model . some_function ( inputs ) # All model variables remain unchanged. Their new values can be # collected via: for k in model . weights : new_value = scope . get_current_value ( k ) print ( f \"New value for { k } : { new_value } )\nstate_mapping = [( k , ops . ones ( k . shape , k . dtype )) for k in model . weights ] with keras . StatelessScope ( state_mapping ) as scope : outputs = model . some_function ( inputs ) # All model variables remain unchanged. Their new values can be # collected via: for k in model . weights : new_value = scope . get_current_value ( k ) print ( f \"New value for { k } : { new_value } )\nMethods\nadd_loss\nadd_loss\nView source\nadd_loss ( loss )\nadd_loss ( loss )\nadd_update\nadd_update\nView source\nadd_update ( update )\nadd_update ( update )\nget_current_value\nget_current_value\nView source\nget_current_value ( variable )\nget_current_value ( variable )\n__enter__\n__enter__\nView source\n__enter__ ()\n__enter__ ()\n__exit__\n__exit__\nView source\n__exit__ ( * args , ** kwargs )\n__exit__ ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_epsilon",
    "content": "Set the value of the fuzz factor used in numeric expressions.\nMain aliases tf.keras.config.set_epsilon\ntf.keras.config.set_epsilon\ntf.keras.config.set_epsilon\ntf . keras . backend . set_epsilon ( value )\ntf . keras . backend . set_epsilon ( value )\nArgs\nArgs\nvalue float. New value of epsilon.\nvalue\nkeras . config . epsilon () 1e-07\nkeras . config . epsilon ()\n1e-07\nkeras . config . set_epsilon ( 1e-5 ) keras . config . epsilon () 1e-05\nkeras . config . set_epsilon ( 1e-5 )\nkeras . config . epsilon ()\n1e-05\n# Set it back to the default value. keras . config . set_epsilon ( 1e-7 )\n# Set it back to the default value.\nkeras . config . set_epsilon ( 1e-7 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nimage module: DO NOT EDIT.\nimage\nlinalg module: DO NOT EDIT.\nlinalg\nnn module: DO NOT EDIT.\nnn\nnumpy module: DO NOT EDIT.\nnumpy\nFunctions\nabs(...) : Shorthand for keras.ops.absolute .\nabs(...)\nkeras.ops.absolute\nabsolute(...) : Compute the absolute value element-wise.\nabsolute(...)\nadd(...) : Add arguments element-wise.\nadd(...)\nall(...) : Test whether all array elements along a given axis evaluate to True .\nall(...)\nTrue\namax(...) : Returns the maximum of an array or maximum value along an axis.\namax(...)\namin(...) : Returns the minimum of an array or minimum value along an axis.\namin(...)\nany(...) : Test whether any array element along a given axis evaluates to True .\nany(...)\nTrue\nappend(...) : Append tensor x2 to the end of tensor x1 .\nappend(...)\nx2\nx1\narange(...) : Return evenly spaced values within a given interval.\narange(...)\narccos(...) : Trigonometric inverse cosine, element-wise.\narccos(...)\narccosh(...) : Inverse hyperbolic cosine, element-wise.\narccosh(...)\narcsin(...) : Inverse sine, element-wise.\narcsin(...)\narcsinh(...) : Inverse hyperbolic sine, element-wise.\narcsinh(...)\narctan(...) : Trigonometric inverse tangent, element-wise.\narctan(...)\narctan2(...) : Element-wise arc tangent of x1/x2 choosing the quadrant correctly.\narctan2(...)\nx1/x2\narctanh(...) : Inverse hyperbolic tangent, element-wise.\narctanh(...)\nargmax(...) : Returns the indices of the maximum values along an axis.\nargmax(...)\nargmin(...) : Returns the indices of the minium values along an axis.\nargmin(...)\nargsort(...) : Returns the indices that would sort a tensor.\nargsort(...)\narray(...) : Create a tensor.\narray(...)\naverage(...) : Compute the weighted average along the specified axis.\naverage(...)\naverage_pool(...) : Average pooling operation.\naverage_pool(...)\nbatch_normalization(...) : Normalizes x by mean and variance .\nbatch_normalization(...)\nx\nmean\nvariance\nbinary_crossentropy(...) : Computes binary cross-entropy loss between target and output tensor.\nbinary_crossentropy(...)\nbincount(...) : Count the number of occurrences of each value in a tensor of integers.\nbincount(...)\nbroadcast_to(...) : Broadcast a tensor to a new shape.\nbroadcast_to(...)\ncast(...) : Cast a tensor to the desired dtype.\ncast(...)\ncategorical_crossentropy(...) : Computes categorical cross-entropy loss between target and output tensor.\ncategorical_crossentropy(...)\nceil(...) : Return the ceiling of the input, element-wise.\nceil(...)\ncholesky(...) : Computes the Cholesky decomposition of a positive semi-definite matrix.\ncholesky(...)\nclip(...) : Clip (limit) the values in a tensor.\nclip(...)\nconcatenate(...) : Join a sequence of tensors along an existing axis.\nconcatenate(...)\ncond(...) : Conditionally applies true_fn or false_fn .\ncond(...)\ntrue_fn\nfalse_fn\nconj(...) : Shorthand for keras.ops.conjugate .\nconj(...)\nkeras.ops.conjugate\nconjugate(...) : Returns the complex conjugate, element-wise.\nconjugate(...)\nconv(...) : General N-D convolution.\nconv(...)\nconv_transpose(...) : General N-D convolution transpose.\nconv_transpose(...)\nconvert_to_numpy(...) : Convert a tensor to a NumPy array.\nconvert_to_numpy(...)\nconvert_to_tensor(...) : Convert a NumPy array to a tensor.\nconvert_to_tensor(...)\ncopy(...) : Returns a copy of x .\ncopy(...)\nx\ncorrelate(...) : Compute the cross-correlation of two 1-dimensional tensors.\ncorrelate(...)\ncos(...) : Cosine, element-wise.\ncos(...)\ncosh(...) : Hyperbolic cosine, element-wise.\ncosh(...)\ncount_nonzero(...) : Counts the number of non-zero values in x along the given axis .\ncount_nonzero(...)\nx\naxis\ncross(...) : Returns the cross product of two (arrays of) vectors.\ncross(...)\nctc_decode(...) : Decodes the output of a CTC model.\nctc_decode(...)\nctc_loss(...) : CTC (Connectionist Temporal Classification) loss.\nctc_loss(...)\ncumprod(...) : Return the cumulative product of elements along a given axis.\ncumprod(...)\ncumsum(...) : Returns the cumulative sum of elements along a given axis.\ncumsum(...)\ncustom_gradient(...) : Decorator to define a function with a custom gradient.\ncustom_gradient(...)\ndepthwise_conv(...) : General N-D depthwise convolution.\ndepthwise_conv(...)\ndet(...) : Computes the determinant of a square tensor.\ndet(...)\ndiag(...) : Extract a diagonal or construct a diagonal array.\ndiag(...)\ndiagonal(...) : Return specified diagonals.\ndiagonal(...)\ndiff(...) : Calculate the n-th discrete difference along the given axis.\ndiff(...)\ndigitize(...) : Returns the indices of the bins to which each value in x belongs.\ndigitize(...)\nx\ndivide(...) : Divide arguments element-wise.\ndivide(...)\ndivide_no_nan(...) : Safe element-wise division which returns 0 where the denominator is 0.\ndivide_no_nan(...)\ndot(...) : Dot product of two tensors.\ndot(...)\neig(...) : Computes the eigenvalues and eigenvectors of a square matrix.\neig(...)\neigh(...) : Computes the eigenvalues and eigenvectors of a complex Hermitian.\neigh(...)\neinsum(...) : Evaluates the Einstein summation convention on the operands.\neinsum(...)\nelu(...) : Exponential Linear Unit activation function.\nelu(...)\nempty(...) : Return a tensor of given shape and type filled with uninitialized data.\nempty(...)\nequal(...) : Returns (x1 == x2) element-wise.\nequal(...)\n(x1 == x2)\nerf(...) : Computes the error function of x , element-wise.\nerf(...)\nx\nerfinv(...) : Computes the inverse error function of x , element-wise.\nerfinv(...)\nx\nexp(...) : Calculate the exponential of all elements in the input tensor.\nexp(...)\nexpand_dims(...) : Expand the shape of a tensor.\nexpand_dims(...)\nexpm1(...) : Calculate exp(x) - 1 for all elements in the tensor.\nexpm1(...)\nexp(x) - 1\nextract_sequences(...) : Expands the dimension of last axis into sequences of sequence_length .\nextract_sequences(...)\nsequence_length\neye(...) : Return a 2-D tensor with ones on the diagonal and zeros elsewhere.\neye(...)\nfft(...) : Computes the Fast Fourier Transform along last axis of input.\nfft(...)\nfft2(...) : Computes the 2D Fast Fourier Transform along the last two axes of input.\nfft2(...)\nflip(...) : Reverse the order of elements in the tensor along the given axis.\nflip(...)\nfloor(...) : Return the floor of the input, element-wise.\nfloor(...)\nfloor_divide(...) : Returns the largest integer smaller or equal to the division of inputs.\nfloor_divide(...)\nfori_loop(...) : For loop implementation.\nfori_loop(...)\nfull(...) : Return a new tensor of given shape and type, filled with fill_value .\nfull(...)\nfill_value\nfull_like(...) : Return a full tensor with the same shape and type as the given tensor.\nfull_like(...)\ngelu(...) : Gaussian Error Linear Unit (GELU) activation function.\ngelu(...)\nget_item(...) : Return x[key] .\nget_item(...)\nx[key]\ngreater(...) : Return the truth value of x1 > x2 element-wise.\ngreater(...)\nx1 > x2\ngreater_equal(...) : Return the truth value of x1 >= x2 element-wise.\ngreater_equal(...)\nx1 >= x2\nhard_sigmoid(...) : Hard sigmoid activation function.\nhard_sigmoid(...)\nhard_silu(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_silu(...)\nhard_swish(...) : Hard SiLU activation function, also known as Hard Swish.\nhard_swish(...)\nhstack(...) : Stack tensors in sequence horizontally (column wise).\nhstack(...)\nidentity(...) : Return the identity tensor.\nidentity(...)\nimag(...) : Return the imaginary part of the complex argument.\nimag(...)\nin_top_k(...) : Checks if the targets are in the top-k predictions.\nin_top_k(...)\ninv(...) : Computes the inverse of a square tensor.\ninv(...)\nirfft(...) : Inverse real-valued Fast Fourier transform along the last axis.\nirfft(...)\nis_tensor(...) : Check whether the given object is a tensor.\nis_tensor(...)\nisclose(...) : Return whether two tensors are element-wise almost equal.\nisclose(...)\nisfinite(...) : Return whether a tensor is finite, element-wise.\nisfinite(...)\nisinf(...) : Test element-wise for positive or negative infinity.\nisinf(...)\nisnan(...) : Test element-wise for NaN and return result as a boolean tensor.\nisnan(...)\nistft(...) : Inverse Short-Time Fourier Transform along the last axis of the input.\nistft(...)\nleaky_relu(...) : Leaky version of a Rectified Linear Unit activation function.\nleaky_relu(...)\nless(...) : Return the truth value of x1 < x2 element-wise.\nless(...)\nx1 < x2\nless_equal(...) : Return the truth value of x1 <= x2 element-wise.\nless_equal(...)\nx1 <= x2\nlinspace(...) : Return evenly spaced numbers over a specified interval.\nlinspace(...)\nlog(...) : Natural logarithm, element-wise.\nlog(...)\nlog10(...) : Return the base 10 logarithm of the input tensor, element-wise.\nlog10(...)\nlog1p(...) : Returns the natural logarithm of one plus the x , element-wise.\nlog1p(...)\nx\nlog2(...) : Base-2 logarithm of x , element-wise.\nlog2(...)\nx\nlog_sigmoid(...) : Logarithm of the sigmoid activation function.\nlog_sigmoid(...)\nlog_softmax(...) : Log-softmax activation function.\nlog_softmax(...)\nlogaddexp(...) : Logarithm of the sum of exponentiations of the inputs.\nlogaddexp(...)\nlogical_and(...) : Computes the element-wise logical AND of the given input tensors.\nlogical_and(...)\nlogical_not(...) : Computes the element-wise NOT of the given input tensor.\nlogical_not(...)\nlogical_or(...) : Computes the element-wise logical OR of the given input tensors.\nlogical_or(...)\nlogical_xor(...) : Compute the truth value of x1 XOR x2 , element-wise.\nlogical_xor(...)\nx1 XOR x2\nlogspace(...) : Returns numbers spaced evenly on a log scale.\nlogspace(...)\nlogsumexp(...) : Computes the logarithm of sum of exponentials of elements in a tensor.\nlogsumexp(...)\nlu_factor(...) : Computes the lower-upper decomposition of a square matrix.\nlu_factor(...)\nmatmul(...) : Matrix product of two tensors.\nmatmul(...)\nmax(...) : Return the maximum of a tensor or maximum along an axis.\nmax(...)\nmax_pool(...) : Max pooling operation.\nmax_pool(...)\nmaximum(...) : Element-wise maximum of x1 and x2 .\nmaximum(...)\nx1\nx2\nmean(...) : Compute the arithmetic mean along the specified axes.\nmean(...)\nmedian(...) : Compute the median along the specified axis.\nmedian(...)\nmeshgrid(...) : Creates grids of coordinates from coordinate vectors.\nmeshgrid(...)\nmin(...) : Return the minimum of a tensor or minimum along an axis.\nmin(...)\nminimum(...) : Element-wise minimum of x1 and x2 .\nminimum(...)\nx1\nx2\nmod(...) : Returns the element-wise remainder of division.\nmod(...)\nmoments(...) : Calculates the mean and variance of x .\nmoments(...)\nx\nmoveaxis(...) : Move axes of a tensor to new positions.\nmoveaxis(...)\nmulti_hot(...) : Encodes integer labels as multi-hot vectors.\nmulti_hot(...)\nmultiply(...) : Multiply arguments element-wise.\nmultiply(...)\nnan_to_num(...) : Replace NaN with zero and infinity with large finite numbers.\nnan_to_num(...)\nndim(...) : Return the number of dimensions of a tensor.\nndim(...)\nnegative(...) : Numerical negative, element-wise.\nnegative(...)\nnonzero(...) : Return the indices of the elements that are non-zero.\nnonzero(...)\nnorm(...) : Matrix or vector norm.\nnorm(...)\nnormalize(...) : Normalizes x over the specified axis.\nnormalize(...)\nx\nnot_equal(...) : Return (x1 != x2) element-wise.\nnot_equal(...)\n(x1 != x2)\none_hot(...) : Converts integer tensor x into a one-hot tensor.\none_hot(...)\nx\nones(...) : Return a new tensor of given shape and type, filled with ones.\nones(...)\nones_like(...) : Return a tensor of ones with the same shape and type of x .\nones_like(...)\nx\nouter(...) : Compute the outer product of two vectors.\nouter(...)\npad(...) : Pad a tensor.\npad(...)\npower(...) : First tensor elements raised to powers from second tensor, element-wise.\npower(...)\nprod(...) : Return the product of tensor elements over a given axis.\nprod(...)\npsnr(...) : Peak Signal-to-Noise Ratio (PSNR) function.\npsnr(...)\nqr(...) : Computes the QR decomposition of a tensor.\nqr(...)\nquantile(...) : Compute the q-th quantile(s) of the data along the specified axis.\nquantile(...)\nravel(...) : Return a contiguous flattened tensor.\nravel(...)\nreal(...) : Return the real part of the complex argument.\nreal(...)\nreciprocal(...) : Return the reciprocal of the argument, element-wise.\nreciprocal(...)\nrelu(...) : Rectified linear unit activation function.\nrelu(...)\nrelu6(...) : Rectified linear unit activation function with upper bound of 6.\nrelu6(...)\nrepeat(...) : Repeat each element of a tensor after themselves.\nrepeat(...)\nreshape(...) : Gives a new shape to a tensor without changing its data.\nreshape(...)\nrfft(...) : Real-valued Fast Fourier Transform along the last axis of the input.\nrfft(...)\nroll(...) : Roll tensor elements along a given axis.\nroll(...)\nround(...) : Evenly round to the given number of decimals.\nround(...)\nrsqrt(...) : Computes reciprocal of square root of x element-wise.\nrsqrt(...)\nscatter(...) : Returns a tensor of shape shape where indices are set to values .\nscatter(...)\nshape\nindices\nvalues\nscatter_update(...) : Update inputs via updates at scattered (sparse) indices.\nscatter_update(...)\nsegment_max(...) : Computes the max of segments in a tensor.\nsegment_max(...)\nsegment_sum(...) : Computes the sum of segments in a tensor.\nsegment_sum(...)\nselect(...) : Return elements from choicelist , based on conditions in condlist .\nselect(...)\nchoicelist\ncondlist\nselu(...) : Scaled Exponential Linear Unit (SELU) activation function.\nselu(...)\nseparable_conv(...) : General N-D separable convolution.\nseparable_conv(...)\nshape(...) : Gets the shape of the tensor input.\nshape(...)\nsigmoid(...) : Sigmoid activation function.\nsigmoid(...)\nsign(...) : Returns a tensor with the signs of the elements of x .\nsign(...)\nx\nsilu(...) : Sigmoid Linear Unit (SiLU) activation function, also known as Swish.\nsilu(...)\nsin(...) : Trigonometric sine, element-wise.\nsin(...)\nsinh(...) : Hyperbolic sine, element-wise.\nsinh(...)\nsize(...) : Return the number of elements in a tensor.\nsize(...)\nslice(...) : Return a slice of an input tensor.\nslice(...)\nslice_update(...) : Update an input by slicing in a tensor of updated values.\nslice_update(...)\nslogdet(...) : Compute the sign and natural logarithm of the determinant of a matrix.\nslogdet(...)\nsoftmax(...) : Softmax activation function.\nsoftmax(...)\nsoftplus(...) : Softplus activation function.\nsoftplus(...)\nsoftsign(...) : Softsign activation function.\nsoftsign(...)\nsolve(...) : Solves a linear system of equations given by a x = b .\nsolve(...)\na x = b\nsolve_triangular(...) : Solves a linear system of equations given by a x = b .\nsolve_triangular(...)\na x = b\nsort(...) : Sorts the elements of x along a given axis in ascending order.\nsort(...)\nx\nsparse_categorical_crossentropy(...) : Computes sparse categorical cross-entropy loss.\nsparse_categorical_crossentropy(...)\nsplit(...) : Split a tensor into chunks.\nsplit(...)\nsqrt(...) : Return the non-negative square root of a tensor, element-wise.\nsqrt(...)\nsquare(...) : Return the element-wise square of the input.\nsquare(...)\nsqueeze(...) : Remove axes of length one from x .\nsqueeze(...)\nx\nstack(...) : Join a sequence of tensors along a new axis.\nstack(...)\nstd(...) : Compute the standard deviation along the specified axis.\nstd(...)\nstft(...) : Short-Time Fourier Transform along the last axis of the input.\nstft(...)\nstop_gradient(...) : Stops gradient computation.\nstop_gradient(...)\nsubtract(...) : Subtract arguments element-wise.\nsubtract(...)\nsum(...) : Sum of a tensor over the given axes.\nsum(...)\nsvd(...) : Computes the singular value decomposition of a matrix.\nsvd(...)\nswapaxes(...) : Interchange two axes of a tensor.\nswapaxes(...)\nswish(...) : Sigmoid Linear Unit (SiLU) activation function, also known as Swish.\nswish(...)\ntake(...) : Take elements from a tensor along an axis.\ntake(...)\ntake_along_axis(...) : Select values from x at the 1-D indices along the given axis.\ntake_along_axis(...)\nx\nindices\ntan(...) : Compute tangent, element-wise.\ntan(...)\ntanh(...) : Hyperbolic tangent, element-wise.\ntanh(...)\ntensordot(...) : Compute the tensor dot product along specified axes.\ntensordot(...)\ntile(...) : Repeat x the number of times given by repeats .\ntile(...)\nx\nrepeats\ntop_k(...) : Finds the top-k values and their indices in a tensor.\ntop_k(...)\ntrace(...) : Return the sum along diagonals of the tensor.\ntrace(...)\ntranspose(...) : Returns a tensor with axes transposed.\ntranspose(...)\naxes\ntri(...) : Return a tensor with ones at and below a diagonal and zeros elsewhere.\ntri(...)\ntril(...) : Return lower triangle of a tensor.\ntril(...)\ntriu(...) : Return upper triangle of a tensor.\ntriu(...)\ntrue_divide(...) : Alias for keras.ops.divide .\ntrue_divide(...)\nkeras.ops.divide\nunstack(...) : Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\nunstack(...)\nvar(...) : Compute the variance along the specified axes.\nvar(...)\nvdot(...) : Return the dot product of two vectors.\nvdot(...)\nvectorize(...) : Turn a function into a vectorized function.\nvectorize(...)\nvectorized_map(...) : Parallel map of function on axis 0 of tensor(s) elements .\nvectorized_map(...)\nfunction\nelements\nvstack(...) : Stack tensors in sequence vertically (row wise).\nvstack(...)\nwhere(...) : Return elements chosen from x1 or x2 depending on condition .\nwhere(...)\nx1\nx2\ncondition\nwhile_loop(...) : While loop implementation.\nwhile_loop(...)\nzeros(...) : Return a new tensor of given shape and type, filled with zeros.\nzeros(...)\nzeros_like(...) : Return a tensor of zeros with the same shape and type as x .\nzeros_like(...)\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Subtract",
    "content": "Performs elementwise subtraction.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Subtract ( ** kwargs )\ntf . keras . layers . Subtract ( ** kwargs )\nIt takes as input a list of tensors of size 2 both of the\nsame shape, and returns a single tensor (inputs[0] - inputs[1])\nof same shape.\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Subtract ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Subtract ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `subtracted = keras.layers.subtract([x1, x2])` subtracted = keras . layers . Subtract ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( subtracted ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `subtracted = keras.layers.subtract([x1, x2])`\nsubtracted = keras . layers . Subtract ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( subtracted )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/standardize_dtype",
    "content": "Main aliases tf.keras.utils.standardize_dtype\ntf.keras.utils.standardize_dtype\ntf.keras.utils.standardize_dtype\ntf . keras . backend . standardize_dtype ( dtype )\ntf . keras . backend . standardize_dtype ( dtype )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/argsort",
    "content": "Returns the indices that would sort a tensor.\nMain aliases tf.keras.ops.numpy.argsort\ntf.keras.ops.numpy.argsort\ntf.keras.ops.numpy.argsort\ntf . keras . ops . argsort ( x , axis =- 1 )\ntf . keras . ops . argsort ( x , axis =- 1 )\nArgs\nArgs\nx Input tensor. axis Axis along which to sort. Defaults to -1 (the last axis). If None , the flattened tensor is used.\nx\naxis\n-1\nNone\nReturns Tensor of indices that sort x along the specified axis .\nReturns\nx\naxis\nx = keras . ops . array ([ 3 , 1 , 2 ]) keras . ops . argsort ( x ) array ([ 1 , 2 , 0 ], dtype = int32 )\nx = keras . ops . array ([ 3 , 1 , 2 ])\nkeras . ops . argsort ( x )\narray ([ 1 , 2 , 0 ], dtype = int32 )\nTwo-dimensional array:\n>>> x = keras . ops . array ([[ 0 , 3 ], [ 3 , 2 ], [ 4 , 5 ]]) >>> x array ([[ 0 , 3 ], [ 3 , 2 ], [ 4 , 5 ]], dtype = int32 ) >>> keras . ops . argsort ( x , axis = 0 ) array ([[ 0 , 1 ], [ 1 , 0 ], [ 2 , 2 ]], dtype = int32 ) >>> keras . ops . argsort ( x , axis = 1 ) array ([[ 0 , 1 ], [ 1 , 0 ], [ 0 , 1 ]], dtype = int32 )\n>>> x = keras . ops . array ([[ 0 , 3 ], [ 3 , 2 ], [ 4 , 5 ]]) >>> x array ([[ 0 , 3 ], [ 3 , 2 ], [ 4 , 5 ]], dtype = int32 ) >>> keras . ops . argsort ( x , axis = 0 ) array ([[ 0 , 1 ], [ 1 , 0 ], [ 2 , 2 ]], dtype = int32 ) >>> keras . ops . argsort ( x , axis = 1 ) array ([[ 0 , 1 ], [ 1 , 0 ], [ 0 , 1 ]], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/round",
    "content": "Evenly round to the given number of decimals.\nMain aliases tf.keras.ops.numpy.round\ntf.keras.ops.numpy.round\ntf.keras.ops.numpy.round\ntf . keras . ops . round ( x , decimals = 0 )\ntf . keras . ops . round ( x , decimals = 0 )\nArgs\nArgs\nx Input tensor. decimals Number of decimal places to round to. Defaults to 0 .\nx\ndecimals\n0\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Tokenizer : DEPRECATED.\nclass Tokenizer\nFunctions\nhashing_trick(...) : DEPRECATED.\nhashing_trick(...)\none_hot(...) : DEPRECATED.\none_hot(...)\ntext_to_word_sequence(...) : DEPRECATED.\ntext_to_word_sequence(...)\ntokenizer_from_json(...) : DEPRECATED.\ntokenizer_from_json(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/elu",
    "content": "Exponential Linear Unit.\ntf . keras . activations . elu ( x , alpha = 1.0 )\ntf . keras . activations . elu ( x , alpha = 1.0 )\nThe exponential linear unit (ELU) with alpha > 0 is define as:\nalpha > 0\nx if x > 0\nx\nx > 0\nalpha * exp(x) - 1 if x < 0\nexp(x) - 1\nx < 0\nELUs have negative values which pushes the mean of the activations\ncloser to zero.\nMean activations that are closer to zero enable faster learning as they\nbring the gradient closer to the natural gradient.\nELUs saturate to a negative value when the argument gets smaller.\nSaturation means a small derivative which decreases the variation\nand the information that is propagated to the next layer.\nArgs\nArgs\nx Input tensor.\nx\nClevert et al., 2016"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeUniform",
    "content": "He uniform variance scaling initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.he_uniform\ntf.keras.initializers.he_uniform\ntf.keras.initializers.he_uniform\ntf . keras . initializers . HeUniform ( seed = None )\ntf . keras . initializers . HeUniform ( seed = None )\nDraws samples from a uniform distribution within [-limit, limit] , where limit = sqrt(6 / fan_in) ( fan_in is the number of input units in the\nweight tensor).\n[-limit, limit]\nlimit = sqrt(6 / fan_in)\nfan_in\n# Standalone usage: initializer = HeUniform () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = HeUniform ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = HeUniform () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = HeUniform ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nHe et al., 2015\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/cos",
    "content": "DEPRECATED.\ntf . keras . backend . cos ( x )\ntf . keras . backend . cos ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/preprocess_input",
    "content": "A placeholder method for backward compatibility.\ntf . keras . applications . efficientnet . preprocess_input ( x , data_format = None )\ntf . keras . applications . efficientnet . preprocess_input ( x , data_format = None )\nThe preprocessing logic has been included in the efficientnet model\nimplementation. Users are no longer required to call this method to\nnormalize the input data. This method does nothing and only kept as a\nplaceholder to align the API surface between old and new version of model.\nArgs\nArgs\nx A floating point numpy.array or a tensor. data_format Optional data format of the image tensor/array. None means the global setting keras.backend.image_data_format() is used (unless you changed it, it uses \"channels_last\" ).\nDefaults to None .\nx\nnumpy.array\ndata_format\nNone\nkeras.backend.image_data_format()\n\"channels_last\"\nNone\nReturns Unchanged numpy.array or tensor.\nReturns\nnumpy.array"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LambdaCallback",
    "content": "Callback for creating simple, custom callbacks on-the-fly.\nInherits From: Callback\nCallback\ntf . keras . callbacks . LambdaCallback ( on_epoch_begin = None , on_epoch_end = None , on_train_begin = None , on_train_end = None , on_train_batch_begin = None , on_train_batch_end = None , ** kwargs )\ntf . keras . callbacks . LambdaCallback ( on_epoch_begin = None , on_epoch_end = None , on_train_begin = None , on_train_end = None , on_train_batch_begin = None , on_train_batch_end = None , ** kwargs )\nUsed in the notebooks\nDisplaying image data in TensorBoard\nThis callback is constructed with anonymous functions that will be called at the appropriate time ( during ` Model . { fit | evaluate | predict } ` ) . Note that the callbacks expects positional arguments , as : - ` on_epoch_begin ` and ` on_epoch_end ` expect two positional arguments : ` epoch ` , ` logs ` - ` on_train_begin ` and ` on_train_end ` expect one positional argument : ` logs ` - ` on_train_batch_begin ` and ` on_train_batch_end ` expect two positional arguments : ` batch ` , ` logs ` - See ` Callback ` class definition for the full list of functions and their expected arguments . Args : on_epoch_begin : called at the beginning of every epoch . on_epoch_end : called at the end of every epoch . on_train_begin : called at the beginning of model training . on_train_end : called at the end of model training . on_train_batch_begin : called at the beginning of every train batch . on_train_batch_end : called at the end of every train batch . kwargs : Any function in ` Callback ` that you want to override by passing ` function_name = function ` . For example , ` LambdaCallback ( .. , on_train_end = train_end_fn ) ` . The custom function needs to have same arguments as the ones defined in ` Callback ` . Example : ``` python # Print the batch number at the beginning of every batch. batch_print_callback = LambdaCallback ( on_train_batch_begin = lambda batch , logs : print ( batch )) # Stream the epoch loss to a file in JSON format. The file content # is not well-formed JSON but rather has a JSON object per line. import json json_log = open ( 'loss_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ({ 'epoch' : epoch , 'loss' : logs [ 'loss' ]}) + ' '), on_train_end = lambda logs : json_log . close () ) # Terminate some processes after having finished model training. processes = ... cleanup_callback = LambdaCallback ( on_train_end = lambda logs : [ p . terminate () for p in processes if p . is_alive ()]) model . fit ( ... , callbacks = [ batch_print_callback , json_logging_callback , cleanup_callback ]) ```\nThis callback is constructed with anonymous functions that will be called at the appropriate time ( during ` Model . { fit | evaluate | predict } ` ) . Note that the callbacks expects positional arguments , as : - ` on_epoch_begin ` and ` on_epoch_end ` expect two positional arguments : ` epoch ` , ` logs ` - ` on_train_begin ` and ` on_train_end ` expect one positional argument : ` logs ` - ` on_train_batch_begin ` and ` on_train_batch_end ` expect two positional arguments : ` batch ` , ` logs ` - See ` Callback ` class definition for the full list of functions and their expected arguments . Args : on_epoch_begin : called at the beginning of every epoch . on_epoch_end : called at the end of every epoch . on_train_begin : called at the beginning of model training . on_train_end : called at the end of model training . on_train_batch_begin : called at the beginning of every train batch . on_train_batch_end : called at the end of every train batch . kwargs : Any function in ` Callback ` that you want to override by passing ` function_name = function ` . For example , ` LambdaCallback ( .. , on_train_end = train_end_fn ) ` . The custom function needs to have same arguments as the ones defined in ` Callback ` . Example : ``` python # Print the batch number at the beginning of every batch. batch_print_callback = LambdaCallback ( on_train_batch_begin = lambda batch , logs : print ( batch )) # Stream the epoch loss to a file in JSON format. The file content # is not well-formed JSON but rather has a JSON object per line. import json json_log = open ( 'loss_log.json' , mode = 'wt' , buffering = 1 ) json_logging_callback = LambdaCallback ( on_epoch_end = lambda epoch , logs : json_log . write ( json . dumps ({ 'epoch' : epoch , 'loss' : logs [ 'loss' ]}) + ' '), on_train_end = lambda logs : json_log . close () ) # Terminate some processes after having finished model training. processes = ... cleanup_callback = LambdaCallback ( on_train_end = lambda logs : [ p . terminate () for p in processes if p . is_alive ()]) model . fit ( ... , callbacks = [ batch_print_callback , json_logging_callback , cleanup_callback ]) ```\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB5",
    "content": "Instantiates the EfficientNetB5 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB5\ntf.keras.applications.efficientnet.EfficientNetB5\ntf.keras.applications.efficientnet.EfficientNetB5\ntf . keras . applications . EfficientNetB5 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB5 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/name_scope",
    "content": "DEPRECATED.\ntf . keras . backend . name_scope ( name )\ntf . keras . backend . name_scope ( name )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecayRestarts",
    "content": "A LearningRateSchedule that uses a cosine decay schedule with restarts.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . CosineDecayRestarts ( initial_learning_rate , first_decay_steps , t_mul = 2.0 , m_mul = 1.0 , alpha = 0.0 , name = 'SGDRDecay' )\ntf . keras . optimizers . schedules . CosineDecayRestarts ( initial_learning_rate , first_decay_steps , t_mul = 2.0 , m_mul = 1.0 , alpha = 0.0 , name = 'SGDRDecay' )\nSee Loshchilov & Hutter, ICLR2016 ,\nSGDR: Stochastic Gradient Descent with Warm Restarts.\nWhen training a model, it is often useful to lower the learning rate as\nthe training progresses. This schedule applies a cosine decay function with\nrestarts to an optimizer step, given a provided initial learning rate.\nIt requires a step value to compute the decayed learning rate. You can\njust pass a backend variable that you increment at each training step.\nstep\nThe schedule is a 1-arg callable that produces a decayed learning\nrate when passed the current optimizer step. This can be useful for changing\nthe learning rate value across different invocations of optimizer functions.\nThe learning rate multiplier first decays\nfrom 1 to alpha for first_decay_steps steps. Then, a warm\nrestart is performed. Each new warm restart runs for t_mul times more\nsteps and with m_mul times initial learning rate as the new learning rate.\nalpha\nfirst_decay_steps\nt_mul\nm_mul\nfirst_decay_steps = 1000 lr_decayed_fn = ( keras . optimizers . schedules . CosineDecayRestarts ( initial_learning_rate , first_decay_steps ))\nfirst_decay_steps = 1000 lr_decayed_fn = ( keras . optimizers . schedules . CosineDecayRestarts ( initial_learning_rate , first_decay_steps ))\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate. The learning rate schedule is also serializable and\ndeserializable using keras.optimizers.schedules.serialize and keras.optimizers.schedules.deserialize .\nkeras.optimizers.Optimizer\nkeras.optimizers.schedules.serialize\nkeras.optimizers.schedules.deserialize\nArgs\nArgs\ninitial_learning_rate A Python float. The initial learning rate. first_decay_steps A Python integer. Number of steps to decay over. t_mul A Python float. Used to derive the number of iterations in\nthe i-th period. m_mul A Python float. Used to derive the initial learning rate of\nthe i-th period. alpha A Python float. Minimum learning rate value as a fraction of\nthe initial_learning_rate . name String. Optional name of the operation. Defaults to \"SGDRDecay\" .\ninitial_learning_rate\nfirst_decay_steps\nt_mul\nm_mul\nalpha\ninitial_learning_rate\nname\n\"SGDRDecay\"\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as initial_learning_rate .\nReturns\ninitial_learning_rate\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/unpack_x_y_sample_weight",
    "content": "Unpacks user-provided data tuple.\ntf . keras . utils . unpack_x_y_sample_weight ( data )\ntf . keras . utils . unpack_x_y_sample_weight ( data )\nUsed in the notebooks\nIntegrating MinDiff without MinDiffModel\nCreating a custom Counterfactual Logit Pairing Dataset\nThis is a convenience utility to be used when overriding Model.train_step , Model.test_step , or Model.predict_step .\nThis utility makes it easy to support data of the form (x,) , (x, y) , or (x, y, sample_weight) .\nModel.train_step\nModel.test_step\nModel.predict_step\n(x,)\n(x, y)\n(x, y, sample_weight)\nfeatures_batch = ops . ones (( 10 , 5 )) labels_batch = ops . zeros (( 10 , 5 )) data = ( features_batch , labels_batch ) # `y` and `sample_weight` will default to `None` if not provided. x , y , sample_weight = unpack_x_y_sample_weight ( data ) sample_weight is None True\nfeatures_batch = ops . ones (( 10 , 5 ))\nlabels_batch = ops . zeros (( 10 , 5 ))\ndata = ( features_batch , labels_batch )\n# `y` and `sample_weight` will default to `None` if not provided.\nx , y , sample_weight = unpack_x_y_sample_weight ( data )\nsample_weight is None\nTrue\nArgs\nArgs\ndata A tuple of the form (x,) , (x, y) , or (x, y, sample_weight) .\ndata\n(x,)\n(x, y)\n(x, y, sample_weight)\nReturns The unpacked tuple, with None s for y and sample_weight if they are\nnot provided.\nReturns\nNone\ny\nsample_weight"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/gather",
    "content": "DEPRECATED.\ntf . keras . backend . gather ( reference , indices )\ntf . keras . backend . gather ( reference , indices )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/convert_to_numpy",
    "content": "Convert a tensor to a NumPy array.\ntf . keras . ops . convert_to_numpy ( x )\ntf . keras . ops . convert_to_numpy ( x )\nArgs\nArgs\nx A tensor.\nx\nReturns A NumPy array.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing",
    "content": "A preprocessing layer which resizes images.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Resizing ( height , width , interpolation = 'bilinear' , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , fill_mode = 'constant' , fill_value = 0.0 , data_format = None , ** kwargs )\ntf . keras . layers . Resizing ( height , width , interpolation = 'bilinear' , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , fill_mode = 'constant' , fill_value = 0.0 , data_format = None , ** kwargs )\nUsed in the notebooks\nSimple audio recognition: Recognizing keywords\nData augmentation\nThis layer resizes an image input to a target height and width. The input\nshould be a 4D (batched) or 3D (unbatched) tensor in \"channels_last\" format. Input pixel values can be of any range\n(e.g. [0., 1.) or [0, 255] ).\n\"channels_last\"\n[0., 1.)\n[0, 255]\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format,\nor (..., channels, height, width) , in \"channels_first\" format.\n(..., height, width, channels)\n\"channels_last\"\n(..., channels, height, width)\n\"channels_first\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., target_height, target_width, channels) ,\nor (..., channels, target_height, target_width) ,\nin \"channels_first\" format.\n(..., target_height, target_width, channels)\n(..., channels, target_height, target_width)\n\"channels_first\"\ntf.data\nArgs\nArgs\nheight Integer, the height of the output shape. width Integer, the width of the output shape. interpolation String, the interpolation method.\nSupports \"bilinear\" , \"nearest\" , \"bicubic\" , \"lanczos3\" , \"lanczos5\" . Defaults to \"bilinear\" . crop_to_aspect_ratio If True , resize the images without aspect\nratio distortion. When the original aspect ratio differs\nfrom the target aspect ratio, the output image will be\ncropped so as to return the\nlargest possible window in the image (of size (height, width) )\nthat matches the target aspect ratio. By default\n( crop_to_aspect_ratio=False ), aspect ratio may not be preserved. pad_to_aspect_ratio If True , pad the images without aspect\nratio distortion. When the original aspect ratio differs\nfrom the target aspect ratio, the output image will be\nevenly padded on the short side. fill_mode When using pad_to_aspect_ratio=True , padded areas\nare filled according to the given mode. Only \"constant\" is\nsupported at this time\n(fill with constant value, equal to fill_value ). fill_value Float. Padding value to use when pad_to_aspect_ratio=True . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . **kwargs Base layer keyword arguments, such as name and dtype .\nheight\nwidth\ninterpolation\n\"bilinear\"\n\"nearest\"\n\"bicubic\"\n\"lanczos3\"\n\"lanczos5\"\n\"bilinear\"\ncrop_to_aspect_ratio\nTrue\n(height, width)\ncrop_to_aspect_ratio=False\npad_to_aspect_ratio\nTrue\nfill_mode\npad_to_aspect_ratio=True\n\"constant\"\nfill_value\nfill_value\npad_to_aspect_ratio=True\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/serialize",
    "content": "tf . keras . regularizers . serialize ( initializer )\ntf . keras . regularizers . serialize ( initializer )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . nasnet . preprocess_input ( x , data_format = None )\ntf . keras . applications . nasnet . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D",
    "content": "Global average pooling operation for temporal data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalAvgPool1D\ntf.keras.layers.GlobalAvgPool1D\ntf.keras.layers.GlobalAvgPool1D\ntf . keras . layers . GlobalAveragePooling1D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalAveragePooling1D ( data_format = None , keepdims = False , ** kwargs )\nUsed in the notebooks\nBasic text classification\nGraph regularization for sentiment classification using synthesized graphs\nTaking advantage of context features\nBuilding deep retrieval models\nUsing side features: feature preprocessing\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\ntemporal dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nCall arguments\nCall arguments\ninputs A 3D tensor. mask Binary tensor of shape (batch_size, steps) indicating whether\na given step should be masked (excluded from the average).\ninputs\nmask\n(batch_size, steps)\nIf data_format='channels_last' :\n3D tensor with shape: (batch_size, steps, features)\ndata_format='channels_last'\n(batch_size, steps, features)\nIf data_format='channels_first' :\n3D tensor with shape: (batch_size, features, steps)\ndata_format='channels_first'\n(batch_size, features, steps)\nIf keepdims=False :\n2D tensor with shape (batch_size, features) .\nkeepdims=False\n(batch_size, features)\nIf keepdims=True : If data_format=\"channels_last\" :\n3D tensor with shape (batch_size, 1, features) If data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n3D tensor with shape (batch_size, 1, features)\ndata_format=\"channels_last\"\n(batch_size, 1, features)\nIf data_format=\"channels_first\" :\n3D tensor with shape (batch_size, features, 1)\ndata_format=\"channels_first\"\n(batch_size, features, 1)\nx = np . random . rand ( 2 , 3 , 4 ) y = keras . layers . GlobalAveragePooling1D ()( x ) y . shape ( 2 , 4 )\nx = np . random . rand ( 2 , 3 , 4 )\ny = keras . layers . GlobalAveragePooling1D ()( x )\ny . shape\n( 2 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal",
    "content": "He normal initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.he_normal\ntf.keras.initializers.he_normal\ntf.keras.initializers.he_normal\ntf . keras . initializers . HeNormal ( seed = None )\ntf . keras . initializers . HeNormal ( seed = None )\nIt draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in\nthe weight tensor.\nstddev = sqrt(2 / fan_in)\nfan_in\n# Standalone usage: initializer = HeNormal () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = HeNormal ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = HeNormal () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = HeNormal ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nHe et al., 2015\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/linalg",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\ncholesky(...) : Computes the Cholesky decomposition of a positive semi-definite matrix.\ncholesky(...)\ndet(...) : Computes the determinant of a square tensor.\ndet(...)\neig(...) : Computes the eigenvalues and eigenvectors of a square matrix.\neig(...)\neigh(...) : Computes the eigenvalues and eigenvectors of a complex Hermitian.\neigh(...)\ninv(...) : Computes the inverse of a square tensor.\ninv(...)\nlu_factor(...) : Computes the lower-upper decomposition of a square matrix.\nlu_factor(...)\nnorm(...) : Matrix or vector norm.\nnorm(...)\nqr(...) : Computes the QR decomposition of a tensor.\nqr(...)\nsolve(...) : Solves a linear system of equations given by a x = b .\nsolve(...)\na x = b\nsolve_triangular(...) : Solves a linear system of equations given by a x = b .\nsolve_triangular(...)\na x = b\nsvd(...) : Computes the singular value decomposition of a matrix.\nsvd(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/compute_float8_scale",
    "content": "tf . keras . quantizers . compute_float8_scale ( amax , scale , dtype_max , margin = 0 )\ntf . keras . quantizers . compute_float8_scale ( amax , scale , dtype_max , margin = 0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies/get",
    "content": "Retrieves a Keras DTypePolicy instance.\nDTypePolicy\ntf . keras . dtype_policies . get ( identifier )\ntf . keras . dtype_policies . get ( identifier )\nThe identifier may be the string name of a DTypePolicy class.\nidentifier\nDTypePolicy\npolicy = dtype_policies . get ( \"mixed_bfloat16\" ) type ( loss ) < class '... FloatDTypePolicy ' >\npolicy = dtype_policies . get ( \"mixed_bfloat16\" )\ntype ( loss )\n< class '... FloatDTypePolicy ' >\nYou can also specify config of the dtype policy to this function by\npassing dict containing class_name and config as an identifier. Also\nnote that the class_name must map to a DTypePolicy class\nconfig\nclass_name\nconfig\nclass_name\nDTypePolicy\nidentifier = { \"class_name\" : \"FloatDTypePolicy\" , \"config\" : { \"name\" : \"float32\" } } policy = dtype_policies . get ( identifier ) type ( loss ) < class '... FloatDTypePolicy ' >\nidentifier = { \"class_name\" : \"FloatDTypePolicy\" ,\n\"config\" : { \"name\" : \"float32\" } }\npolicy = dtype_policies . get ( identifier )\ntype ( loss )\n< class '... FloatDTypePolicy ' >\nArgs\nArgs\nidentifier A dtype policy identifier. One of None or string name of a DTypePolicy or DTypePolicy configuration dictionary or a DTypePolicy instance.\nidentifier\nNone\nDTypePolicy\nDTypePolicy\nDTypePolicy\nReturns A Keras DTypePolicy instance.\nReturns\nDTypePolicy"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/broadcast_to",
    "content": "Broadcast a tensor to a new shape.\nMain aliases tf.keras.ops.numpy.broadcast_to\ntf.keras.ops.numpy.broadcast_to\ntf.keras.ops.numpy.broadcast_to\ntf . keras . ops . broadcast_to ( x , shape )\ntf . keras . ops . broadcast_to ( x , shape )\nArgs\nArgs\nx The tensor to broadcast. shape The shape of the desired tensor. A single integer i is\ninterpreted as (i,) .\nx\nshape\ni\n(i,)\nReturns A tensor with the desired shape.\nReturns\nx = keras . ops . array ([ 1 , 2 , 3 ]) keras . ops . broadcast_to ( x , ( 3 , 3 )) array ([[ 1 , 2 , 3 ], [ 1 , 2 , 3 ], [ 1 , 2 , 3 ]])\nx = keras . ops . array ([ 1 , 2 , 3 ])\nkeras . ops . broadcast_to ( x , ( 3 , 3 ))\narray ([[ 1 , 2 , 3 ],\n[ 1 , 2 , 3 ],\n[ 1 , 2 , 3 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg19/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . vgg19 . preprocess_input ( x , data_format = None )\ntf . keras . applications . vgg19 . preprocess_input ( x , data_format = None )\nUsed in the notebooks\nNeural style transfer\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe images are converted from RGB to BGR, then each color channel is\nzero-centered with respect to the ImageNet dataset, without scaling.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/exponential",
    "content": "Exponential activation function.\ntf . keras . activations . exponential ( x )\ntf . keras . activations . exponential ( x )\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3",
    "content": "Instantiates the Inception v3 architecture.\nMain aliases tf.keras.applications.inception_v3.InceptionV3\ntf.keras.applications.inception_v3.InceptionV3\ntf.keras.applications.inception_v3.InceptionV3\ntf . keras . applications . InceptionV3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . InceptionV3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nUsed in the notebooks\nDeepDream\nRethinking the Inception Architecture for Computer Vision (CVPR 2016)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nInceptionV3\nkeras.applications.inception_v3.preprocess_input\ninception_v3.preprocess_input\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top, as the last layer of the network.\nDefaults to True . weights One of None (random initialization), imagenet (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_tensor is useful for\nsharing inputs between multiple different networks.\nDefaults to None . input_shape Optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (299, 299, 3) (with channels_last data format)\nor (3, 299, 299) (with channels_first data format).\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 75.\nE.g. (150, 150, 3) would be one valid value. input_shape will be ignored if the input_tensor is provided. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nTrue\nweights\nNone\nimagenet\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_tensor\nNone\ninput_shape\ninclude_top\n(299, 299, 3)\nchannels_last\n(3, 299, 299)\nchannels_first\n(150, 150, 3)\ninput_shape\ninput_tensor\npooling\ninclude_top\nFalse\nNone (default) means that the output of the model will be\nthe 4D tensor output of the last convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000. classifier_activation A str or callable. The activation function\nto use on the \"top\" layer. Ignored unless include_top=True .\nSet classifier_activation=None to return the logits of the \"top\"\nlayer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass BinaryCrossentropy : Computes the cross-entropy loss between true labels and predicted labels.\nclass BinaryCrossentropy\nclass BinaryFocalCrossentropy : Computes focal cross-entropy loss between true labels and predictions.\nclass BinaryFocalCrossentropy\nclass CTC : CTC (Connectionist Temporal Classification) loss.\nclass CTC\nclass CategoricalCrossentropy : Computes the crossentropy loss between the labels and predictions.\nclass CategoricalCrossentropy\nclass CategoricalFocalCrossentropy : Computes the alpha balanced focal crossentropy loss.\nclass CategoricalFocalCrossentropy\nclass CategoricalHinge : Computes the categorical hinge loss between y_true & y_pred .\nclass CategoricalHinge\ny_true\ny_pred\nclass CosineSimilarity : Computes the cosine similarity between y_true & y_pred .\nclass CosineSimilarity\ny_true\ny_pred\nclass Dice : Computes the Dice loss value between y_true and y_pred .\nclass Dice\ny_true\ny_pred\nclass Hinge : Computes the hinge loss between y_true & y_pred .\nclass Hinge\ny_true\ny_pred\nclass Huber : Computes the Huber loss between y_true & y_pred .\nclass Huber\ny_true\ny_pred\nclass KLDivergence : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nclass KLDivergence\ny_true\ny_pred\nclass LogCosh : Computes the logarithm of the hyperbolic cosine of the prediction error.\nclass LogCosh\nclass Loss : Loss base class.\nclass Loss\nclass MeanAbsoluteError : Computes the mean of absolute difference between labels and predictions.\nclass MeanAbsoluteError\nclass MeanAbsolutePercentageError : Computes the mean absolute percentage error between y_true & y_pred .\nclass MeanAbsolutePercentageError\ny_true\ny_pred\nclass MeanSquaredError : Computes the mean of squares of errors between labels and predictions.\nclass MeanSquaredError\nclass MeanSquaredLogarithmicError : Computes the mean squared logarithmic error between y_true & y_pred .\nclass MeanSquaredLogarithmicError\ny_true\ny_pred\nclass Poisson : Computes the Poisson loss between y_true & y_pred .\nclass Poisson\ny_true\ny_pred\nclass Reduction\nclass Reduction\nclass SparseCategoricalCrossentropy : Computes the crossentropy loss between the labels and predictions.\nclass SparseCategoricalCrossentropy\nclass SquaredHinge : Computes the squared hinge loss between y_true & y_pred .\nclass SquaredHinge\ny_true\ny_pred\nclass Tversky : Computes the Tversky loss value between y_true and y_pred .\nclass Tversky\ny_true\ny_pred\nFunctions\nKLD(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nKLD(...)\ny_true\ny_pred\nMAE(...) : Computes the mean absolute error between labels and predictions.\nMAE(...)\nMAPE(...) : Computes the mean absolute percentage error between y_true & y_pred .\nMAPE(...)\ny_true\ny_pred\nMSE(...) : Computes the mean squared error between labels and predictions.\nMSE(...)\nMSLE(...) : Computes the mean squared logarithmic error between y_true & y_pred .\nMSLE(...)\ny_true\ny_pred\nbinary_crossentropy(...) : Computes the binary crossentropy loss.\nbinary_crossentropy(...)\nbinary_focal_crossentropy(...) : Computes the binary focal crossentropy loss.\nbinary_focal_crossentropy(...)\ncategorical_crossentropy(...) : Computes the categorical crossentropy loss.\ncategorical_crossentropy(...)\ncategorical_focal_crossentropy(...) : Computes the categorical focal crossentropy loss.\ncategorical_focal_crossentropy(...)\ncategorical_hinge(...) : Computes the categorical hinge loss between y_true & y_pred .\ncategorical_hinge(...)\ny_true\ny_pred\ncosine_similarity(...) : Computes the cosine similarity between labels and predictions.\ncosine_similarity(...)\nctc(...) : CTC (Connectionist Temporal Classification) loss.\nctc(...)\ndeserialize(...) : Deserializes a serialized loss class/function instance.\ndeserialize(...)\ndice(...) : Computes the Dice loss value between y_true and y_pred .\ndice(...)\ny_true\ny_pred\nget(...) : Retrieves a Keras loss as a function / Loss class instance.\nget(...)\nfunction\nLoss\nhinge(...) : Computes the hinge loss between y_true & y_pred .\nhinge(...)\ny_true\ny_pred\nhuber(...) : Computes Huber loss value.\nhuber(...)\nkld(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nkld(...)\ny_true\ny_pred\nkullback_leibler_divergence(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nkullback_leibler_divergence(...)\ny_true\ny_pred\nlogcosh(...) : Logarithm of the hyperbolic cosine of the prediction error.\nlogcosh(...)\nmae(...) : Computes the mean absolute error between labels and predictions.\nmae(...)\nmape(...) : Computes the mean absolute percentage error between y_true & y_pred .\nmape(...)\ny_true\ny_pred\nmse(...) : Computes the mean squared error between labels and predictions.\nmse(...)\nmsle(...) : Computes the mean squared logarithmic error between y_true & y_pred .\nmsle(...)\ny_true\ny_pred\npoisson(...) : Computes the Poisson loss between y_true and y_pred.\npoisson(...)\nserialize(...) : Serializes loss function or Loss instance.\nserialize(...)\nLoss\nsparse_categorical_crossentropy(...) : Computes the sparse categorical crossentropy loss.\nsparse_categorical_crossentropy(...)\nsquared_hinge(...) : Computes the squared hinge loss between y_true & y_pred .\nsquared_hinge(...)\ny_true\ny_pred\ntversky(...) : Computes the Tversky loss value between y_true and y_pred .\ntversky(...)\ny_true\ny_pred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/less_equal",
    "content": "Return the truth value of x1 <= x2 element-wise.\nx1 <= x2\nMain aliases tf.keras.ops.numpy.less_equal\ntf.keras.ops.numpy.less_equal\ntf.keras.ops.numpy.less_equal\ntf . keras . ops . less_equal ( x1 , x2 )\ntf . keras . ops . less_equal ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise comparison of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_registered_name",
    "content": "Returns the name registered to an object within the Keras framework.\ntf . keras . utils . get_registered_name ( obj )\ntf . keras . utils . get_registered_name ( obj )\nThis function is part of the Keras serialization and deserialization\nframework. It maps objects to the string names associated with those objects\nfor serialization/deserialization.\nArgs\nArgs\nobj The object to look up.\nobj\nReturns The name associated with the object, or the default Python name if the\nobject is not registered.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/models/model_from_json",
    "content": "Parses a JSON model configuration string and returns a model instance.\ntf . keras . models . model_from_json ( json_string , custom_objects = None )\ntf . keras . models . model_from_json ( json_string , custom_objects = None )\nmodel = keras . Sequential ([ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax ()]) config = model . to_json () loaded_model = keras . models . model_from_json ( config )\nmodel = keras . Sequential ([\nkeras . layers . Dense ( 5 , input_shape = ( 3 ,)),\nkeras . layers . Softmax ()])\nconfig = model . to_json ()\nloaded_model = keras . models . model_from_json ( config )\nArgs\nArgs\njson_string JSON string encoding a model configuration. custom_objects Optional dictionary mapping names\n(strings) to custom classes or functions to be\nconsidered during deserialization.\njson_string\ncustom_objects\nReturns A Keras model instance (uncompiled).\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/count_params",
    "content": "DEPRECATED.\ntf . keras . backend . count_params ( x )\ntf . keras . backend . count_params ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay",
    "content": "A LearningRateSchedule that uses a polynomial decay schedule.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . PolynomialDecay ( initial_learning_rate , decay_steps , end_learning_rate = 0.0001 , power = 1.0 , cycle = False , name = 'PolynomialDecay' )\ntf . keras . optimizers . schedules . PolynomialDecay ( initial_learning_rate , decay_steps , end_learning_rate = 0.0001 , power = 1.0 , cycle = False , name = 'PolynomialDecay' )\nUsed in the notebooks\nDebug a TensorFlow 2 migrated training pipeline\nFine-tuning a BERT model\nUncertainty-aware Deep Language Learning with BERT-SNGP\nIt is commonly observed that a monotonically decreasing learning rate, whose\ndegree of change is carefully chosen, results in a better performing model.\nThis schedule applies a polynomial decay function to an optimizer step,\ngiven a provided initial_learning_rate , to reach an end_learning_rate in the given decay_steps .\ninitial_learning_rate\nend_learning_rate\ndecay_steps\nIt requires a step value to compute the decayed learning rate. You\ncan just pass a backend variable that you increment at each training\nstep.\nstep\nThe schedule is a 1-arg callable that produces a decayed learning rate\nwhen passed the current optimizer step. This can be useful for changing the\nlearning rate value across different invocations of optimizer functions.\nIt is computed as:\ndef decayed_learning_rate ( step ): step = min ( step , decay_steps ) return (( initial_learning_rate - end_learning_rate ) * ( 1 - step / decay_steps ) ^ ( power ) ) + end_learning_rate\ndef decayed_learning_rate ( step ): step = min ( step , decay_steps ) return (( initial_learning_rate - end_learning_rate ) * ( 1 - step / decay_steps ) ^ ( power ) ) + end_learning_rate\nIf cycle is True then a multiple of decay_steps is used, the first one\nthat is bigger than step .\ncycle\ndecay_steps\nstep\ndef decayed_learning_rate ( step ): decay_steps = decay_steps * ceil ( step / decay_steps ) return (( initial_learning_rate - end_learning_rate ) * ( 1 - step / decay_steps ) ^ ( power ) ) + end_learning_rate\ndef decayed_learning_rate ( step ): decay_steps = decay_steps * ceil ( step / decay_steps ) return (( initial_learning_rate - end_learning_rate ) * ( 1 - step / decay_steps ) ^ ( power ) ) + end_learning_rate\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate.\nExample: Fit a model while decaying from 0.1 to 0.01 in 10000 steps using\nsqrt (i.e. power=0.5):\nkeras.optimizers.Optimizer\n... starter_learning_rate = 0.1 end_learning_rate = 0.01 decay_steps = 10000 learning_rate_fn = keras . optimizers . schedules . PolynomialDecay ( starter_learning_rate , decay_steps , end_learning_rate , power = 0.5 ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = learning_rate_fn ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\n... starter_learning_rate = 0.1 end_learning_rate = 0.01 decay_steps = 10000 learning_rate_fn = keras . optimizers . schedules . PolynomialDecay ( starter_learning_rate , decay_steps , end_learning_rate , power = 0.5 ) model . compile ( optimizer = keras . optimizers . SGD ( learning_rate = learning_rate_fn ), loss = 'sparse_categorical_crossentropy' , metrics = [ 'accuracy' ]) model . fit ( data , labels , epochs = 5 )\nThe learning rate schedule is also serializable and deserializable using keras.optimizers.schedules.serialize and keras.optimizers.schedules.deserialize .\nkeras.optimizers.schedules.serialize\nkeras.optimizers.schedules.deserialize\nArgs\nArgs\ninitial_learning_rate A Python float. The initial learning rate. decay_steps A Python integer. Must be positive. See the decay\ncomputation above. end_learning_rate A Python float. The minimal end learning rate. power A Python float. The power of the polynomial. Defaults to 1.0 . cycle A boolean, whether it should cycle beyond decay_steps. name String.  Optional name of the operation. Defaults to \"PolynomialDecay\" .\ninitial_learning_rate\ndecay_steps\nend_learning_rate\npower\n1.0\ncycle\nname\n\"PolynomialDecay\"\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as initial_learning_rate .\nReturns\ninitial_learning_rate\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/audio_dataset_from_directory",
    "content": "Generates a tf.data.Dataset from audio files in a directory.\ntf.data.Dataset\ntf . keras . utils . audio_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , batch_size = 32 , sampling_rate = None , output_sequence_length = None , ragged = False , shuffle = True , seed = None , validation_split = None , subset = None , follow_links = False , verbose = True )\ntf . keras . utils . audio_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , batch_size = 32 , sampling_rate = None , output_sequence_length = None , ragged = False , shuffle = True , seed = None , validation_split = None , subset = None , follow_links = False , verbose = True )\nUsed in the notebooks\nSimple audio recognition: Recognizing keywords\nIf your directory structure is:\nmain_directory / ... class_a / ...... a_audio_1 . wav ...... a_audio_2 . wav ... class_b / ...... b_audio_1 . wav ...... b_audio_2 . wav\nmain_directory / ... class_a / ...... a_audio_1 . wav ...... a_audio_2 . wav ... class_b / ...... b_audio_1 . wav ...... b_audio_2 . wav\nThen calling audio_dataset_from_directory(main_directory,\nlabels='inferred') will return a tf.data.Dataset that yields batches of audio files from\nthe subdirectories class_a and class_b , together with labels\n0 and 1 (0 corresponding to class_a and 1 corresponding to class_b ).\naudio_dataset_from_directory(main_directory,\nlabels='inferred')\ntf.data.Dataset\nclass_a\nclass_b\nclass_a\nclass_b\nOnly .wav files are supported at this time.\n.wav\nArgs\nArgs\ndirectory Directory where the data is located.\nIf labels is \"inferred\" , it should contain subdirectories,\neach containing audio files for a class. Otherwise, the directory\nstructure is ignored. labels Either \"inferred\" (labels are generated from the directory\nstructure), None (no labels), or a list/tuple of integer labels\nof the same size as the number of audio files found in\nthe directory. Labels should be sorted according to the\nalphanumeric order of the audio file paths\n(obtained via os.walk(directory) in Python). label_mode String describing the encoding of labels . Options are:\ndirectory\nlabels\n\"inferred\"\nlabels\nNone\nos.walk(directory)\nlabel_mode\nlabels\n\"int\" : means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n\"int\"\nsparse_categorical_crossentropy\n\"categorical\" means that the labels are encoded as a categorical\nvector (e.g. for categorical_crossentropy loss)\n\"categorical\"\ncategorical_crossentropy\n\"binary\" means that the labels (there can be only 2)\nare encoded as float32 scalars with values 0\nor 1 (e.g. for binary_crossentropy ).\n\"binary\"\nfloat32\nbinary_crossentropy\nNone (no labels). class_names Only valid if \"labels\" is \"inferred\" .\nThis is the explicit list of class names\n(must match names of subdirectories). Used to control the order\nof the classes (otherwise alphanumerical order is used). batch_size Size of the batches of data. Default: 32. If None ,\nthe data will not be batched\n(the dataset will yield individual samples). sampling_rate Audio sampling rate (in samples per second). output_sequence_length Maximum length of an audio sequence. Audio files\nlonger than this will be truncated to output_sequence_length .\nIf set to None , then all sequences in the same batch will\nbe padded to the\nlength of the longest sequence in the batch. ragged Whether to return a Ragged dataset (where each sequence has its\nown length). Defaults to False . shuffle Whether to shuffle the data. Defaults to True .\nIf set to False , sorts the data in alphanumeric order. seed Optional random seed for shuffling and transformations. validation_split Optional float between 0 and 1, fraction of data to\nreserve for validation. subset Subset of the data to return. One of \"training\" , \"validation\" or \"both\" . Only used if validation_split is set. follow_links Whether to visits subdirectories pointed to by symlinks.\nDefaults to False . verbose Whether to display number information on classes and\nnumber of files found. Defaults to True .\nNone\nclass_names\n\"inferred\"\nbatch_size\nNone\nsampling_rate\noutput_sequence_length\noutput_sequence_length\nNone\nragged\nFalse\nshuffle\nTrue\nFalse\nseed\nvalidation_split\nsubset\n\"training\"\n\"validation\"\n\"both\"\nvalidation_split\nfollow_links\nFalse\nverbose\nTrue\nReturns\nReturns\nA tf.data.Dataset object.\ntf.data.Dataset\nIf label_mode is None , it yields string tensors of shape (batch_size,) , containing the contents of a batch of audio files.\nlabel_mode\nNone\nstring\n(batch_size,)\nOtherwise, it yields a tuple (audio, labels) , where audio has shape (batch_size, sequence_length, num_channels) and labels follows the format described\nbelow.\n(audio, labels)\naudio\n(batch_size, sequence_length, num_channels)\nlabels\nRules regarding labels format:\nif label_mode is int , the labels are an int32 tensor of shape (batch_size,) .\nlabel_mode\nint\nint32\n(batch_size,)\nif label_mode is binary , the labels are a float32 tensor of\n1s and 0s of shape (batch_size, 1) .\nlabel_mode\nbinary\nfloat32\n(batch_size, 1)\nif label_mode is categorical , the labels are a float32 tensor\nof shape (batch_size, num_classes) , representing a one-hot\nencoding of the class index.\nlabel_mode\ncategorical\nfloat32\n(batch_size, num_classes)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/roll",
    "content": "Roll tensor elements along a given axis.\nMain aliases tf.keras.ops.numpy.roll\ntf.keras.ops.numpy.roll\ntf.keras.ops.numpy.roll\ntf . keras . ops . roll ( x , shift , axis = None )\ntf . keras . ops . roll ( x , shift , axis = None )\nElements that roll beyond the last position are re-introduced at the first.\nArgs\nArgs\nx Input tensor. shift The number of places by which elements are shifted. axis The axis along which elements are shifted. By default, the\narray is flattened before shifting, after which the original\nshape is restored.\nx\nshift\naxis\nReturns Output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ndim",
    "content": "Return the number of dimensions of a tensor.\nMain aliases tf.keras.ops.numpy.ndim\ntf.keras.ops.numpy.ndim\ntf.keras.ops.numpy.ndim\ntf . keras . ops . ndim ( x )\ntf . keras . ops . ndim ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns The number of dimensions in x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Sum",
    "content": "Compute the (weighted) sum of the given values.\nInherits From: Metric\nMetric\ntf . keras . metrics . Sum ( name = 'sum' , dtype = None )\ntf . keras . metrics . Sum ( name = 'sum' , dtype = None )\nFor example, if values is [1, 3, 5, 7] then their sum is 16.\nIf sample_weight was specified as [1, 1, 0, 0] then the sum would be 4.\nvalues\n[1, 3, 5, 7]\nsample_weight\n[1, 1, 0, 0]\nThis metric creates one variable, total .\nThis is ultimately returned as the sum value.\ntotal\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = metrics . Sum () m . update_state ([ 1 , 3 , 5 , 7 ]) m . result () 16.0\nm = metrics . Sum ()\nm . update_state ([ 1 , 3 , 5 , 7 ])\nm . result ()\n16.0\nm = metrics . Sum () m . update_state ([ 1 , 3 , 5 , 7 ], sample_weight = [ 1 , 1 , 0 , 0 ]) m . result () 4.0\nm = metrics . Sum ()\nm . update_state ([ 1 , 3 , 5 , 7 ], sample_weight = [ 1 , 1 , 0 , 0 ])\nm . result ()\n4.0\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( values , sample_weight = None )\nupdate_state ( values , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/tokenizer_from_json",
    "content": "DEPRECATED.\ntf . keras . preprocessing . text . tokenizer_from_json ( json_string )\ntf . keras . preprocessing . text . tokenizer_from_json ( json_string )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/slice_update",
    "content": "Update an input by slicing in a tensor of updated values.\ntf . keras . ops . slice_update ( inputs , start_indices , updates )\ntf . keras . ops . slice_update ( inputs , start_indices , updates )\nAt a high level, this operation does inputs[start_indices: start_indices + updates.shape] = updates .\nAssume inputs is a tensor of shape (D0, D1, ..., Dn) , start_indices must be a list/tuple of n integers, specifying the starting\nindices. updates must have the same rank as inputs , and the size of each\ndim must not exceed Di - start_indices[i] . For example, if we have 2D\ninputs inputs = np.zeros((5, 5)) , and we want to update the intersection\nof last 2 rows and last 2 columns as 1, i.e., inputs[3:, 3:] = np.ones((2, 2)) , then we can use the code below:\ninputs[start_indices: start_indices + updates.shape] = updates\n(D0, D1, ..., Dn)\nstart_indices\nupdates\ninputs\nDi - start_indices[i]\ninputs = np.zeros((5, 5))\ninputs[3:, 3:] = np.ones((2, 2))\ninputs = np . zeros (( 5 , 5 )) start_indices = [ 3 , 3 ] updates = np . ones (( 2 , 2 )) inputs = keras . ops . slice_update ( inputs , start_indices , updates )\ninputs = np . zeros (( 5 , 5 )) start_indices = [ 3 , 3 ] updates = np . ones (( 2 , 2 )) inputs = keras . ops . slice_update ( inputs , start_indices , updates )\nArgs\nArgs\ninputs A tensor, the tensor to be updated. start_indices A list/tuple of shape (inputs.ndim,) , specifying\nthe starting indices for updating. updates A tensor, the new values to be put to inputs at indices . updates must have the same rank as inputs .\ninputs\nstart_indices\n(inputs.ndim,)\nupdates\ninputs\nindices\nupdates\ninputs\nReturns A tensor, has the same shape and dtype as inputs .\nReturns\ninputs"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator",
    "content": "Iterator capable of reading images from a directory on disk.\nInherits From: Iterator , PyDataset\nIterator\nPyDataset\ntf . keras . preprocessing . image . DirectoryIterator ( directory , image_data_generator , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , data_format = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , follow_links = False , subset = None , interpolation = 'nearest' , keep_aspect_ratio = False , dtype = None )\ntf . keras . preprocessing . image . DirectoryIterator ( directory , image_data_generator , target_size = ( 256 , 256 ), color_mode = 'rgb' , classes = None , class_mode = 'categorical' , batch_size = 32 , shuffle = True , seed = None , data_format = None , save_to_dir = None , save_prefix = '' , save_format = 'png' , follow_links = False , subset = None , interpolation = 'nearest' , keep_aspect_ratio = False , dtype = None )\nDEPRECATED.\nAttributes\nAttributes\nfilepaths List of absolute paths to image files. labels Class labels of every observation. max_queue_size\nfilepaths\nlabels\nmax_queue_size\nnum_batches Number of batches in the PyDataset. sample_weight\nnum_batches\nsample_weight\nuse_multiprocessing\nuse_multiprocessing\nworkers\nworkers\nMethods\non_epoch_end\non_epoch_end\nView source\non_epoch_end ()\non_epoch_end ()\nMethod called at the end of every epoch.\nreset\nreset\nView source\nreset ()\nreset ()\nset_processing_attrs\nset_processing_attrs\nView source\nset_processing_attrs ( image_data_generator , target_size , color_mode , data_format , save_to_dir , save_prefix , save_format , subset , interpolation , keep_aspect_ratio )\nset_processing_attrs ( image_data_generator , target_size , color_mode , data_format , save_to_dir , save_prefix , save_format , subset , interpolation , keep_aspect_ratio )\nSets attributes to use later for processing files into a batch.\nArgs\nimage_data_generator Instance of ImageDataGenerator to use for random transformations and normalization. target_size tuple of integers, dimensions to resize input images\nto. color_mode One of \"rgb\" , \"rgba\" , \"grayscale\" .\nColor mode to read images. data_format String, one of channels_first , channels_last . save_to_dir Optional directory where to save the pictures\nbeing yielded, in a viewable format. This is useful\nfor visualizing the random transformations being\napplied, for debugging purposes. save_prefix String prefix to use for saving sample\nimages (if save_to_dir is set). save_format Format to use for saving sample images\n(if save_to_dir is set). subset Subset of data ( \"training\" or \"validation\" ) if\nvalidation_split is set in ImageDataGenerator. interpolation Interpolation method used to resample the image if\nthe target size is different from that of the loaded image.\nSupported methods are \"nearest\", \"bilinear\", and \"bicubic\". If\nPIL version 1.1.3 or newer is installed, \"lanczos\" is also\nsupported. If PIL version 3.4.0 or newer is installed, \"box\" and\n\"hamming\" are also supported. By default, \"nearest\" is used. keep_aspect_ratio Boolean, whether to resize images to a target\nsize without aspect ratio distortion. The image is cropped in\nthe center with target aspect ratio before resizing.\nimage_data_generator\nImageDataGenerator\ntarget_size\ncolor_mode\n\"rgb\"\n\"rgba\"\n\"grayscale\"\ndata_format\nchannels_first\nchannels_last\nsave_to_dir\nsave_prefix\nsave_to_dir\nsave_format\nsave_to_dir\nsubset\n\"training\"\n\"validation\"\ninterpolation\nkeep_aspect_ratio\n__getitem__\n__getitem__\nView source\n__getitem__ ( idx )\n__getitem__ ( idx )\nGets batch at position index .\nindex\nArgs\nindex position of the batch in the PyDataset.\nindex\nReturns A batch\n__iter__\n__iter__\nView source\n__iter__ ()\n__iter__ ()\n__len__\n__len__\nView source\n__len__ ()\n__len__ ()\nClass Variables\nClass Variables\nallowed_class_modes\n{ 'binary' , 'categorical' , 'input' , 'sparse' , None }\n{ 'binary' , 'categorical' , 'input' , 'sparse' , None }\nwhite_list_formats ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')\n('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/expm1",
    "content": "Calculate exp(x) - 1 for all elements in the tensor.\nexp(x) - 1\nMain aliases tf.keras.ops.numpy.expm1\ntf.keras.ops.numpy.expm1\ntf.keras.ops.numpy.expm1\ntf . keras . ops . expm1 ( x )\ntf . keras . ops . expm1 ( x )\nArgs\nArgs\nx Input values.\nx\nReturns Output tensor, element-wise exponential minus one.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tile",
    "content": "Repeat x the number of times given by repeats .\nx\nrepeats\nMain aliases tf.keras.ops.numpy.tile\ntf.keras.ops.numpy.tile\ntf.keras.ops.numpy.tile\ntf . keras . ops . tile ( x , repeats )\ntf . keras . ops . tile ( x , repeats )\nIf repeats has length d , the result will have dimension of max(d, x.ndim) .\nrepeats\nd\nmax(d, x.ndim)\nIf x.ndim < d , x is promoted to be d-dimensional by prepending\nnew axes.\nx.ndim < d\nx\nIf x.ndim > d , repeats is promoted to x.ndim by prepending 1's to it.\nx.ndim > d\nrepeats\nx.ndim\nArgs\nArgs\nx Input tensor. repeats The number of repetitions of x along each axis.\nx\nrepeats\nx\nReturns The tiled output tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Lion",
    "content": "Optimizer that implements the Lion algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Lion ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.99 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'lion' , ** kwargs )\ntf . keras . optimizers . Lion ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.99 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'lion' , ** kwargs )\nThe Lion optimizer is a stochastic-gradient-descent method that uses the\nsign operator to control the magnitude of the update, unlike other adaptive\noptimizers such as Adam that rely on second-order moments. This make\nLion more memory-efficient as it only keeps track of the momentum. According\nto the authors (see reference), its performance gain over Adam grows with\nthe batch size. Because the update of Lion is produced through the sign\noperation, resulting in a larger norm, a suitable learning rate for Lion is\ntypically 3-10x smaller than that for AdamW. The weight decay for Lion\nshould be in turn 3-10x larger than that for AdamW to maintain a\nsimilar strength (lr * wd).\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_1 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nrate to combine the current gradient and the 1st moment estimate.\nDefaults to 0.9 . beta_2 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 1st moment estimate. Defaults to 0.99 . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_1\n0.9\nbeta_2\n0.99\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nChen et al., 2023\nAuthors' implementation\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nLion optimizer has one variable momentums .\nmomentums\nArgs\nvar_list list of model variables to build Lion variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers/deserialize",
    "content": "Return a Keras quantizer object via its config.\ntf . keras . quantizers . deserialize ( config , custom_objects = None )\ntf . keras . quantizers . deserialize ( config , custom_objects = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/greater",
    "content": "DEPRECATED.\ntf . keras . backend . greater ( x , y )\ntf . keras . backend . greater ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/name_scope",
    "content": "Creates a sub-namespace for variable paths.\nCompat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.name_scope\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.name_scope\ntf.compat.v1.keras.name_scope\ntf . keras . name_scope ( name , ** kwargs )\ntf . keras . name_scope ( name , ** kwargs )\nArgs\nArgs\nname Name of the current scope (string). caller Optional ID of a caller object (e.g. class instance). deduplicate If True , if caller was passed,\nand the previous caller matches the current caller,\nand the previous name matches the current name,\ndo not reenter a new namespace. override_parent Can be used to provide an absolute path\nwhich would override any previously opened name scopes.\nname\ncaller\ndeduplicate\nTrue\ncaller\noverride_parent\nMethods\n__enter__\n__enter__\nView source\n__enter__ ()\n__enter__ ()\n__exit__\n__exit__\nView source\n__exit__ ( * args , ** kwargs )\n__exit__ ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell",
    "content": "Cell class for the LSTM layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . LSTMCell ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , ** kwargs )\ntf . keras . layers . LSTMCell ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , ** kwargs )\nUsed in the notebooks\nEffective Tensorflow 2\nTime series forecasting\nThis class processes one step within the whole time sequence input, whereas keras.layer.LSTM processes the whole sequence.\nkeras.layer.LSTM\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use. Default: hyperbolic tangent\n( tanh ). If you pass None, no activation is applied\n(ie. \"linear\" activation: a(x) = x ). recurrent_activation Activation function to use for the recurrent step.\nDefault: sigmoid ( sigmoid ). If you pass None , no activation is\napplied (ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer\nshould use a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation\nof the recurrent state. Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . unit_forget_bias Boolean (default True ). If True ,\nadd 1 to the bias of the forget gate at initialization.\nSetting it to True will also force bias_initializer=\"zeros\" .\nThis is recommended in Jozefowicz et al. kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. Default: 0. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. Default: 0. seed Random seed for dropout.\nunits\nactivation\ntanh\na(x) = x\nrecurrent_activation\nsigmoid\nNone\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nunit_forget_bias\nTrue\nTrue\nTrue\nbias_initializer=\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nseed\nCall arguments\nCall arguments\ninputs A 2D tensor, with shape (batch, features) . states A 2D tensor with shape (batch, units) , which is the state\nfrom the previous time step. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. Only relevant when dropout or recurrent_dropout is used.\ninputs\n(batch, features)\nstates\n(batch, units)\ntraining\ndropout\nrecurrent_dropout\ninputs = np . random . random (( 32 , 10 , 8 )) rnn = keras . layers . RNN ( keras . layers . LSTMCell ( 4 )) output = rnn ( inputs ) output . shape ( 32 , 4 ) rnn = keras . layers . RNN ( keras . layers . LSTMCell ( 4 ), return_sequences = True , return_state = True ) whole_sequence_output , final_state = rnn ( inputs ) whole_sequence_output . shape ( 32 , 10 , 4 ) final_state . shape ( 32 , 4 )\ninputs = np . random . random (( 32 , 10 , 8 ))\nrnn = keras . layers . RNN ( keras . layers . LSTMCell ( 4 ))\noutput = rnn ( inputs )\noutput . shape\n( 32 , 4 )\nrnn = keras . layers . RNN (\nkeras . layers . LSTMCell ( 4 ),\nreturn_sequences = True ,\nreturn_state = True )\nwhole_sequence_output , final_state = rnn ( inputs )\nwhole_sequence_output . shape\n( 32 , 10 , 4 )\nfinal_state . shape\n( 32 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_dropout_mask\nget_dropout_mask\nView source\nget_dropout_mask ( step_input )\nget_dropout_mask ( step_input )\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size = None )\nget_initial_state ( batch_size = None )\nget_recurrent_dropout_mask\nget_recurrent_dropout_mask\nView source\nget_recurrent_dropout_mask ( step_input )\nget_recurrent_dropout_mask ( step_input )\nreset_dropout_mask\nreset_dropout_mask\nView source\nreset_dropout_mask ()\nreset_dropout_mask ()\nReset the cached dropout mask if any.\nThe RNN layer invokes this in the call() method\nso that the cached mask is cleared after calling cell.call() . The\nmask should be cached across all timestep within the same batch, but\nshouldn't be cached between batches.\ncall()\ncell.call()\nreset_recurrent_dropout_mask\nreset_recurrent_dropout_mask\nView source\nreset_recurrent_dropout_mask ()\nreset_recurrent_dropout_mask ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model",
    "content": "Converts a Keras model to dot format and save to a file.\ntf . keras . utils . plot_model ( model , to_file = 'model.png' , show_shapes = False , show_dtype = False , show_layer_names = False , rankdir = 'TB' , expand_nested = False , dpi = 200 , show_layer_activations = False , show_trainable = False , ** kwargs )\ntf . keras . utils . plot_model ( model , to_file = 'model.png' , show_shapes = False , show_dtype = False , show_layer_names = False , rankdir = 'TB' , expand_nested = False , dpi = 200 , show_layer_activations = False , show_trainable = False , ** kwargs )\nUsed in the notebooks\nLoad text\npix2pix: Image-to-image translation with a conditional GAN\nLoad a pandas DataFrame\nTransfer learning with YAMNet for environmental sound classification\nImage segmentation\ninputs = ... outputs = ... model = keras . Model ( inputs = inputs , outputs = outputs ) dot_img_file = '/tmp/model_1.png' keras . utils . plot_model ( model , to_file = dot_img_file , show_shapes = True )\ninputs = ... outputs = ... model = keras . Model ( inputs = inputs , outputs = outputs ) dot_img_file = '/tmp/model_1.png' keras . utils . plot_model ( model , to_file = dot_img_file , show_shapes = True )\nArgs\nArgs\nmodel A Keras model instance to_file File name of the plot image. show_shapes whether to display shape information. show_dtype whether to display layer dtypes. show_layer_names whether to display layer names. rankdir rankdir argument passed to PyDot,\na string specifying the format of the plot: \"TB\" creates a vertical plot; \"LR\" creates a horizontal plot. expand_nested whether to expand nested Functional models\ninto clusters. dpi Image resolution in dots per inch. show_layer_activations Display layer activations (only for layers that\nhave an activation property). show_trainable whether to display if a layer is trainable.\nmodel\nto_file\nshow_shapes\nshow_dtype\nshow_layer_names\nrankdir\nrankdir\n\"TB\"\n\"LR\"\nexpand_nested\ndpi\nshow_layer_activations\nactivation\nshow_trainable\nReturns A Jupyter notebook Image object if Jupyter is installed.\nThis enables in-line display of the model plots in notebooks.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0",
    "content": "Instantiates the EfficientNetB0 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB0\ntf.keras.applications.efficientnet.EfficientNetB0\ntf.keras.applications.efficientnet.EfficientNetB0\ntf . keras . applications . EfficientNetB0 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB0 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nUsed in the notebooks\nLoad video data\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/RemoteMonitor",
    "content": "Callback used to stream events to a server.\nInherits From: Callback\nCallback\ntf . keras . callbacks . RemoteMonitor ( root = 'http://localhost:9000' , path = '/publish/epoch/end/' , field = 'data' , headers = None , send_as_json = False )\ntf . keras . callbacks . RemoteMonitor ( root = 'http://localhost:9000' , path = '/publish/epoch/end/' , field = 'data' , headers = None , send_as_json = False )\nRequires the requests library.\nEvents are sent to root + '/publish/epoch/end/' by default. Calls are\nHTTP POST, with a data argument which is a\nJSON-encoded dictionary of event data.\nIf send_as_json=True , the content type of the request will be \"application/json\" .\nOtherwise the serialized JSON will be sent within a form.\nrequests\nroot + '/publish/epoch/end/'\ndata\nsend_as_json=True\n\"application/json\"\nArgs\nArgs\nroot String; root url of the target server. path String; path relative to root to which the events will be sent. field String; JSON field under which the data will be stored.\nThe field is used only if the payload is sent within a form\n(i.e. when send_as_json=False ). headers Dictionary; optional custom HTTP headers. send_as_json Boolean; whether the request should be\nsent as \"application/json\" .\nroot\npath\nroot\nfield\nsend_as_json=False\nheaders\nsend_as_json\n\"application/json\"\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log10",
    "content": "Return the base 10 logarithm of the input tensor, element-wise.\nMain aliases tf.keras.ops.numpy.log10\ntf.keras.ops.numpy.log10\ntf.keras.ops.numpy.log10\ntf . keras . ops . log10 ( x )\ntf . keras . ops . log10 ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise base 10 logarithm of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences",
    "content": "Pads sequences to the same length.\nMain aliases tf.keras.preprocessing.sequence.pad_sequences\ntf.keras.preprocessing.sequence.pad_sequences\ntf.keras.preprocessing.sequence.pad_sequences\ntf . keras . utils . pad_sequences ( sequences , maxlen = None , dtype = 'int32' , padding = 'pre' , truncating = 'pre' , value = 0.0 )\ntf . keras . utils . pad_sequences ( sequences , maxlen = None , dtype = 'int32' , padding = 'pre' , truncating = 'pre' , value = 0.0 )\nUsed in the notebooks\nUnderstanding masking & padding\nWiki Talk Comments Toxicity Prediction\nThis function transforms a list (of length num_samples )\nof sequences (lists of integers)\ninto a 2D NumPy array of shape (num_samples, num_timesteps) . num_timesteps is either the maxlen argument if provided,\nor the length of the longest sequence in the list.\nnum_samples\n(num_samples, num_timesteps)\nnum_timesteps\nmaxlen\nSequences that are shorter than num_timesteps are padded with value until they are num_timesteps long.\nnum_timesteps\nvalue\nnum_timesteps\nSequences longer than num_timesteps are truncated\nso that they fit the desired length.\nnum_timesteps\nThe position where padding or truncation happens is determined by\nthe arguments padding and truncating , respectively.\nPre-padding or removing values from the beginning of the sequence is the\ndefault.\npadding\ntruncating\nsequence = [[ 1 ], [ 2 , 3 ], [ 4 , 5 , 6 ]] keras . utils . pad_sequences ( sequence ) array ([[ 0 , 0 , 1 ], [ 0 , 2 , 3 ], [ 4 , 5 , 6 ]], dtype = int32 )\nsequence = [[ 1 ], [ 2 , 3 ], [ 4 , 5 , 6 ]]\nkeras . utils . pad_sequences ( sequence )\narray ([[ 0 , 0 , 1 ],\n[ 0 , 2 , 3 ],\n[ 4 , 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , value =- 1 ) array ([[ - 1 , - 1 , 1 ], [ - 1 , 2 , 3 ], [ 4 , 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , value =- 1 )\narray ([[ - 1 , - 1 , 1 ],\n[ - 1 , 2 , 3 ],\n[ 4 , 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , padding = 'post' ) array ([[ 1 , 0 , 0 ], [ 2 , 3 , 0 ], [ 4 , 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , padding = 'post' )\narray ([[ 1 , 0 , 0 ],\n[ 2 , 3 , 0 ],\n[ 4 , 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , maxlen = 2 ) array ([[ 0 , 1 ], [ 2 , 3 ], [ 5 , 6 ]], dtype = int32 )\nkeras . utils . pad_sequences ( sequence , maxlen = 2 )\narray ([[ 0 , 1 ],\n[ 2 , 3 ],\n[ 5 , 6 ]], dtype = int32 )\nArgs\nArgs\nsequences List of sequences (each sequence is a list of integers). maxlen Optional Int, maximum length of all sequences. If not provided,\nsequences will be padded to the length of the longest individual\nsequence. dtype (Optional, defaults to \"int32\" ). Type of the output sequences.\nTo pad sequences with variable length strings, you can use object . padding String, \"pre\" or \"post\" (optional, defaults to \"pre\" ):\npad either before or after each sequence. truncating String, \"pre\" or \"post\" (optional, defaults to \"pre\" ):\nremove values from sequences larger than maxlen , either at the beginning or at the end of the sequences. value Float or String, padding value. (Optional, defaults to 0.)\nsequences\nmaxlen\ndtype\n\"int32\"\nobject\npadding\n\"pre\"\ntruncating\n\"pre\"\nmaxlen\nvalue\nReturns NumPy array with shape (len(sequences), maxlen)\nReturns\n(len(sequences), maxlen)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/get",
    "content": "Retrieves a Keras metric as a function / Metric class instance.\nfunction\nMetric\ntf . keras . metrics . get ( identifier )\ntf . keras . metrics . get ( identifier )\nThe identifier may be the string name of a metric function or class.\nidentifier\nmetric = metrics . get ( \"categorical_crossentropy\" ) type ( metric ) < class ' function ' > metric = metrics . get ( \"CategoricalCrossentropy\" ) type ( metric ) < class '... metrics . CategoricalCrossentropy ' >\nmetric = metrics . get ( \"categorical_crossentropy\" )\ntype ( metric )\n< class ' function ' >\nmetric = metrics . get ( \"CategoricalCrossentropy\" )\ntype ( metric )\n< class '... metrics . CategoricalCrossentropy ' >\nYou can also specify config of the metric to this function by passing dict\ncontaining class_name and config as an identifier. Also note that the class_name must map to a Metric class\nconfig\nclass_name\nconfig\nclass_name\nMetric\nidentifier = { \"class_name\" : \"CategoricalCrossentropy\" , \"config\" : { \"from_logits\" : True } } metric = metrics . get ( identifier ) type ( metric ) < class '... metrics . CategoricalCrossentropy ' >\nidentifier = { \"class_name\" : \"CategoricalCrossentropy\" ,\n\"config\" : { \"from_logits\" : True } }\nmetric = metrics . get ( identifier )\ntype ( metric )\n< class '... metrics . CategoricalCrossentropy ' >\nArgs\nArgs\nidentifier A metric identifier. One of None or string name of a metric\nfunction/class or metric configuration dictionary or a metric\nfunction or a metric class instance\nidentifier\nReturns A Keras metric as a function / Metric class instance.\nReturns\nfunction\nMetric"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add",
    "content": "Performs elementwise addition operation.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Add ( ** kwargs )\ntf . keras . layers . Add ( ** kwargs )\nUsed in the notebooks\nImage captioning with visual attention\nNeural machine translation with a Transformer and Keras\nNeural machine translation with attention\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Add ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Add ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `added = keras.layers.add([x1, x2])` added = keras . layers . Add ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( added ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `added = keras.layers.add([x1, x2])`\nadded = keras . layers . Add ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( added )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/imag",
    "content": "Return the imaginary part of the complex argument.\nMain aliases tf.keras.ops.numpy.imag\ntf.keras.ops.numpy.imag\ntf.keras.ops.numpy.imag\ntf . keras . ops . imag ( x )\ntf . keras . ops . imag ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns The imaginary component of the complex argument.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar100",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the CIFAR100 dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad",
    "content": "Optimizer that implements the Adagrad algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adagrad' , ** kwargs )\ntf . keras . optimizers . Adagrad ( learning_rate = 0.001 , initial_accumulator_value = 0.1 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adagrad' , ** kwargs )\nUsed in the notebooks\nMigrate from Estimator to Keras APIs\nMigrate LoggingTensorHook and StopAtStepHook to Keras callbacks\nMigrate metrics and optimizers\nMigrate single-worker multiple-GPU training\nMigrate SessionRunHook to Keras callbacks\nBuilding deep retrieval models\nListwise ranking\nMulti-task recommenders\nClient-efficient large-model federated learning via `federated_select` and sparse aggregation\nTaking advantage of context features\nAdagrad is an optimizer with parameter-specific learning rates,\nwhich are adapted relative to how frequently a parameter gets\nupdated during training. The more updates a parameter receives,\nthe smaller the updates.\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . Note that Adagrad tends to benefit from higher initial learning rate values compared\nto other optimizers. To match the exact form in the original paper,\nuse 1.0 . initial_accumulator_value Floating point value. Starting value for the\naccumulators (per-parameter momentum values). Must be non-negative. epsilon Small floating point value for maintaining numerical stability. name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nAdagrad\n1.0\ninitial_accumulator_value\nepsilon\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nDuchi et al., 2011 .\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/conv_transpose",
    "content": "General N-D convolution transpose.\nMain aliases tf.keras.ops.nn.conv_transpose\ntf.keras.ops.nn.conv_transpose\ntf.keras.ops.nn.conv_transpose\ntf . keras . ops . conv_transpose ( inputs , kernel , strides , padding = 'valid' , output_padding = None , data_format = None , dilation_rate = 1 )\ntf . keras . ops . conv_transpose ( inputs , kernel , strides , padding = 'valid' , output_padding = None , data_format = None , dilation_rate = 1 )\nAlso known as de-convolution. This ops supports 1D, 2D and 3D convolution.\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . kernel Tensor of rank N+2. kernel has shape\n[kernel_spatial_shape, num_output_channels, num_input_channels], num_input_channels should match the number of channels in inputs . strides int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the strides of the convolution along each spatial\ndimension. If strides is int, then every spatial dimension shares\nthe same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . output_padding int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the amount of padding along the height and width of\nthe output tensor. Can be a single integer to specify the same\nvalue for all spatial dimensions. The amount of output padding\nalong a given dimension must be lower than the stride along that\nsame dimension. If set to None (default), the output shape is\ninferred. data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) . dilation_rate int or int tuple/list of len(inputs_spatial_shape) ,\nspecifying the dilation rate to use for dilated convolution. If dilation_rate is int, then every spatial dimension shares\nthe same dilation_rate .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\nkernel\nkernel\nnum_input_channels\ninputs\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\noutput_padding\nlen(inputs_spatial_shape)\nNone\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\ndilation_rate\nlen(inputs_spatial_shape)\ndilation_rate\ndilation_rate\nReturns A tensor of rank N+2, the result of the conv operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/flatten",
    "content": "Flattens a possibly nested structure into a list.\ntf . keras . tree . flatten ( structure )\ntf . keras . tree . flatten ( structure )\nIn the case of dict instances, the sequence consists of the values,\nsorted by key to ensure deterministic behavior. This is true also for collections.OrderedDict instances: their sequence order is\nconsidered. The same convention is followed in unflatten_as .\nThis correctly unflattens dicts and OrderedDict after they have been\nflattened, or vice-versa.\ncollections.OrderedDict\nunflatten_as\nOrderedDict\nDictionaries with non-sortable keys cannot be flattened.\nkeras . tree . flatten ([[ 1 , 2 , 3 ], [ 4 , [ 5 ], [[ 6 ]]]]) [ 1 , 2 , 3 , 4 , 5 , 6 ] keras . tree . flatten ( None ) [ None ] keras . tree . flatten ( 1 ) [ 1 ] keras . tree . flatten ({ 100 : 'world!' , 6 : 'Hello' }) [ 'Hello' , 'world!' ]\nkeras . tree . flatten ([[ 1 , 2 , 3 ], [ 4 , [ 5 ], [[ 6 ]]]])\n[ 1 , 2 , 3 , 4 , 5 , 6 ]\nkeras . tree . flatten ( None )\n[ None ]\nkeras . tree . flatten ( 1 )\n[ 1 ]\nkeras . tree . flatten ({ 100 : 'world!' , 6 : 'Hello' })\n[ 'Hello' , 'world!' ]\nArgs\nArgs\nstructure An arbitrarily nested structure.\nstructure\nReturns A list, the flattened version of the input structure .\nReturns\nstructure"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data",
    "content": "Loads the Fashion-MNIST dataset.\ntf . keras . datasets . fashion_mnist . load_data ()\ntf . keras . datasets . fashion_mnist . load_data ()\nUsed in the notebooks\ntf.data: Build TensorFlow input pipelines\nIntro to Autoencoders\nIntroduction to the Keras Tuner\nQuantum data\nExamining the TensorFlow Graph\nThis is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\nalong with a test set of 10,000 images. This dataset can be used as\na drop-in replacement for MNIST.\nReturns\nReturns\nTuple of NumPy arrays: (x_train, y_train), (x_test, y_test) .\n(x_train, y_train), (x_test, y_test)\nx_train : uint8 NumPy array of grayscale image data with shapes (60000, 28, 28) , containing the training data.\nx_train\nuint8\n(60000, 28, 28)\ny_train : uint8 NumPy array of labels (integers in range 0-9)\n  with shape (60000,) for the training data.\ny_train\nuint8\n(60000,)\nx_test : uint8 NumPy array of grayscale image data with shapes\n  (10000, 28, 28), containing the test data.\nx_test\nuint8\ny_test : uint8 NumPy array of labels (integers in range 0-9)\n  with shape (10000,) for the test data.\ny_test\nuint8\n(10000,)\n( x_train , y_train ), ( x_test , y_test ) = fashion_mnist . load_data () assert x_train . shape == ( 60000 , 28 , 28 ) assert x_test . shape == ( 10000 , 28 , 28 ) assert y_train . shape == ( 60000 ,) assert y_test . shape == ( 10000 ,)\n( x_train , y_train ), ( x_test , y_test ) = fashion_mnist . load_data () assert x_train . shape == ( 60000 , 28 , 28 ) assert x_test . shape == ( 10000 , 28 , 28 ) assert y_train . shape == ( 60000 ,) assert y_test . shape == ( 10000 ,)\nThe copyright for Fashion-MNIST is held by Zalando SE.\nFashion-MNIST is licensed under the MIT license ."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Model",
    "content": "A model grouping layers into an object with training/inference features.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.models.Model Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Model\ntf.keras.models.Model\ntf.keras.models.Model\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Model\ntf.compat.v1.keras.Model\ntf . keras . Model ( * args , ** kwargs )\ntf . keras . Model ( * args , ** kwargs )\nUsed in the notebooks\nUse TF1.x models in TF2 workflows\nMigrate `tf.feature_column`s to Keras preprocessing layers\nDebug a TensorFlow 2 migrated training pipeline\nIntroduction to modules, layers, and models\nBasic training loops\nTime series forecasting\nLoad a pandas DataFrame\nParameter server training with ParameterServerStrategy\nIntro to Autoencoders\nLearned data compression\nThere are three ways to instantiate a Model :\nModel\nWith the \"Functional API\"\nYou start from Input ,\nyou chain layer calls to specify the model's forward pass,\nand finally you create your model from inputs and outputs:\nInput\ninputs = keras . Input ( shape = ( 37 ,)) x = keras . layers . Dense ( 32 , activation = \"relu\" )( inputs ) outputs = keras . layers . Dense ( 5 , activation = \"softmax\" )( x ) model = keras . Model ( inputs = inputs , outputs = outputs )\ninputs = keras . Input ( shape = ( 37 ,)) x = keras . layers . Dense ( 32 , activation = \"relu\" )( inputs ) outputs = keras . layers . Dense ( 5 , activation = \"softmax\" )( x ) model = keras . Model ( inputs = inputs , outputs = outputs )\nA new Functional API model can also be created by using the\nintermediate tensors. This enables you to quickly extract sub-components\nof the model.\ninputs = keras . Input ( shape = ( None , None , 3 )) processed = keras . layers . RandomCrop ( width = 128 , height = 128 )( inputs ) conv = keras . layers . Conv2D ( filters = 32 , kernel_size = 3 )( processed ) pooling = keras . layers . GlobalAveragePooling2D ()( conv ) feature = keras . layers . Dense ( 10 )( pooling ) full_model = keras . Model ( inputs , feature ) backbone = keras . Model ( processed , conv ) activations = keras . Model ( conv , feature )\ninputs = keras . Input ( shape = ( None , None , 3 )) processed = keras . layers . RandomCrop ( width = 128 , height = 128 )( inputs ) conv = keras . layers . Conv2D ( filters = 32 , kernel_size = 3 )( processed ) pooling = keras . layers . GlobalAveragePooling2D ()( conv ) feature = keras . layers . Dense ( 10 )( pooling ) full_model = keras . Model ( inputs , feature ) backbone = keras . Model ( processed , conv ) activations = keras . Model ( conv , feature )\nNote that the backbone and activations models are not\ncreated with keras.Input objects, but with the tensors that originate\nfrom keras.Input objects. Under the hood, the layers and weights will\nbe shared across these models, so that user can train the full_model , and\nuse backbone or activations to do feature extraction.\nThe inputs and outputs of the model can be nested structures of tensors as\nwell, and the created models are standard Functional API models that support\nall the existing APIs.\nbackbone\nactivations\nkeras.Input\nkeras.Input\nfull_model\nbackbone\nactivations\nBy subclassing the Model class\nModel\nIn that case, you should define your\nlayers in __init__() and you should implement the model's forward pass\nin call() .\n__init__()\ncall()\nclass MyModel ( keras . Model ): def __init__ ( self ): super () . __init__ () self . dense1 = keras . layers . Dense ( 32 , activation = \"relu\" ) self . dense2 = keras . layers . Dense ( 5 , activation = \"softmax\" ) def call ( self , inputs ): x = self . dense1 ( inputs ) return self . dense2 ( x ) model = MyModel ()\nclass MyModel ( keras . Model ): def __init__ ( self ): super () . __init__ () self . dense1 = keras . layers . Dense ( 32 , activation = \"relu\" ) self . dense2 = keras . layers . Dense ( 5 , activation = \"softmax\" ) def call ( self , inputs ): x = self . dense1 ( inputs ) return self . dense2 ( x ) model = MyModel ()\nIf you subclass Model , you can optionally have\na training argument (boolean) in call() , which you can use to specify\na different behavior in training and inference:\nModel\ntraining\ncall()\nclass MyModel ( keras . Model ): def __init__ ( self ): super () . __init__ () self . dense1 = keras . layers . Dense ( 32 , activation = \"relu\" ) self . dense2 = keras . layers . Dense ( 5 , activation = \"softmax\" ) self . dropout = keras . layers . Dropout ( 0.5 ) def call ( self , inputs , training = False ): x = self . dense1 ( inputs ) x = self . dropout ( x , training = training ) return self . dense2 ( x ) model = MyModel ()\nclass MyModel ( keras . Model ): def __init__ ( self ): super () . __init__ () self . dense1 = keras . layers . Dense ( 32 , activation = \"relu\" ) self . dense2 = keras . layers . Dense ( 5 , activation = \"softmax\" ) self . dropout = keras . layers . Dropout ( 0.5 ) def call ( self , inputs , training = False ): x = self . dense1 ( inputs ) x = self . dropout ( x , training = training ) return self . dense2 ( x ) model = MyModel ()\nOnce the model is created, you can config the model with losses and metrics\nwith model.compile() , train the model with model.fit() , or use the model\nto do prediction with model.predict() .\nmodel.compile()\nmodel.fit()\nmodel.predict()\nWith the Sequential class\nSequential\nIn addition, keras.Sequential is a special case of model where\nthe model is purely a stack of single-input, single-output layers.\nkeras.Sequential\nmodel = keras . Sequential ([ keras . Input ( shape = ( None , None , 3 )), keras . layers . Conv2D ( filters = 32 , kernel_size = 3 ), ])\nmodel = keras . Sequential ([ keras . Input ( shape = ( None , None , 3 )), keras . layers . Conv2D ( filters = 32 , kernel_size = 3 ), ])\nAttributes\nAttributes\ncompiled_metrics\ncompiled_metrics\ndistribute_reduction_method\ndistribute_reduction_method\ndistribute_strategy\ndistribute_strategy\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. jit_compile\njit_compile\nlayers\nlayers\nmetrics_names\nmetrics_names\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. run_eagerly\nrun_eagerly\nMethods\ncompile\ncompile\nView source\ncompile ( optimizer = 'rmsprop' , loss = None , loss_weights = None , metrics = None , weighted_metrics = None , run_eagerly = False , steps_per_execution = 1 , jit_compile = 'auto' , auto_scale_loss = True )\ncompile ( optimizer = 'rmsprop' , loss = None , loss_weights = None , metrics = None , weighted_metrics = None , run_eagerly = False , steps_per_execution = 1 , jit_compile = 'auto' , auto_scale_loss = True )\nConfigures the model for training.\nmodel . compile ( optimizer = keras . optimizers . Adam ( learning_rate = 1e-3 ), loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . BinaryAccuracy (), keras . metrics . FalseNegatives (), ], )\nmodel . compile ( optimizer = keras . optimizers . Adam ( learning_rate = 1e-3 ), loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . BinaryAccuracy (), keras . metrics . FalseNegatives (), ], )\nArgs\noptimizer String (name of optimizer) or optimizer instance. See keras.optimizers . loss Loss function. May be a string (name of loss function), or\na keras.losses.Loss instance. See keras.losses . A\nloss function is any callable with the signature loss = fn(y_true, y_pred) , where y_true are the ground truth\nvalues, and y_pred are the model's predictions. y_true should have shape (batch_size, d0, .. dN) (except in the case of sparse loss functions such as\nsparse categorical crossentropy which expects integer arrays of\nshape (batch_size, d0, .. dN-1) ). y_pred should have shape (batch_size, d0, .. dN) .\nThe loss function should return a float tensor. loss_weights Optional list or dictionary specifying scalar\ncoefficients (Python floats) to weight the loss contributions of\ndifferent model outputs. The loss value that will be minimized\nby the model will then be the weighted sum of all individual\nlosses, weighted by the loss_weights coefficients.  If a list,\nit is expected to have a 1:1 mapping to the model's outputs. If\na dict, it is expected to map output names (strings) to scalar\ncoefficients. metrics List of metrics to be evaluated by the model during\ntraining and testing. Each of this can be a string (name of a\nbuilt-in function), function or a keras.metrics.Metric instance. See keras.metrics . Typically you will use metrics=['accuracy'] . A function is any callable with the\nsignature result = fn(y_true, _pred) . To specify different\nmetrics for different outputs of a multi-output model, you could\nalso pass a dictionary, such as metrics={'a':'accuracy', 'b':['accuracy', 'mse']} .\nYou can also pass a list to specify a metric or a list of\nmetrics for each output, such as metrics=[['accuracy'], ['accuracy', 'mse']] or metrics=['accuracy', ['accuracy', 'mse']] . When you pass\nthe strings 'accuracy' or 'acc', we convert this to one of keras.metrics.BinaryAccuracy , keras.metrics.CategoricalAccuracy , keras.metrics.SparseCategoricalAccuracy based on the\nshapes of the targets and of the model output. A similar\nconversion is done for the strings \"crossentropy\" and \"ce\" as well.\nThe metrics passed here are evaluated without sample weighting;\nif you would like sample weighting to apply, you can specify\nyour metrics via the weighted_metrics argument instead. weighted_metrics List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing. run_eagerly Bool. If True , this model's forward pass\nwill never be compiled. It is recommended to leave this\nas False when training (for best performance),\nand to set it to True when debugging. steps_per_execution Int. The number of batches to run\nduring each a single compiled function call. Running multiple\nbatches inside a single compiled function call can\ngreatly improve performance on TPUs or small models with a large\nPython overhead. At most, one full epoch will be run each\nexecution. If a number larger than the size of the epoch is\npassed, the execution will be truncated to the size of the\nepoch. Note that if steps_per_execution is set to N , Callback.on_batch_begin and Callback.on_batch_end methods\nwill only be called every N batches (i.e. before/after\neach compiled function execution).\nNot supported with the PyTorch backend. jit_compile Bool or \"auto\" . Whether to use XLA compilation when\ncompiling a model. For jax and tensorflow backends, jit_compile=\"auto\" enables XLA compilation if the model\nsupports it, and disabled otherwise.\nFor torch backend, \"auto\" will default to eager\nexecution and jit_compile=True will run with torch.compile with the \"inductor\" backend. auto_scale_loss Bool. If True and the model dtype policy is \"mixed_float16\" , the passed optimizer will be automatically\nwrapped in a LossScaleOptimizer , which will dynamically\nscale the loss to prevent underflow.\noptimizer\nkeras.optimizers\nloss\nkeras.losses.Loss\nkeras.losses\nloss = fn(y_true, y_pred)\ny_true\ny_pred\ny_true\n(batch_size, d0, .. dN)\n(batch_size, d0, .. dN-1)\ny_pred\n(batch_size, d0, .. dN)\nloss_weights\nloss_weights\nmetrics\nkeras.metrics.Metric\nkeras.metrics\nmetrics=['accuracy']\nresult = fn(y_true, _pred)\nmetrics={'a':'accuracy', 'b':['accuracy', 'mse']}\nmetrics=[['accuracy'], ['accuracy', 'mse']]\nmetrics=['accuracy', ['accuracy', 'mse']]\nkeras.metrics.BinaryAccuracy\nkeras.metrics.CategoricalAccuracy\nkeras.metrics.SparseCategoricalAccuracy\n\"crossentropy\"\n\"ce\"\nweighted_metrics\nweighted_metrics\nsample_weight\nclass_weight\nrun_eagerly\nTrue\nFalse\nTrue\nsteps_per_execution\nsteps_per_execution\nN\nCallback.on_batch_begin\nCallback.on_batch_end\nN\njit_compile\n\"auto\"\njax\ntensorflow\njit_compile=\"auto\"\ntorch\n\"auto\"\njit_compile=True\ntorch.compile\n\"inductor\"\nauto_scale_loss\nTrue\n\"mixed_float16\"\nLossScaleOptimizer\ncompile_from_config\ncompile_from_config\nView source\ncompile_from_config ( config )\ncompile_from_config ( config )\nCompiles the model with the information given in config.\nThis method uses the information in the config (optimizer, loss,\nmetrics, etc.) to compile the model.\nArgs\nconfig Dict containing information for compiling the model.\nconfig\ncompiled_loss\ncompiled_loss\nView source\ncompiled_loss ( y , y_pred , sample_weight = None , regularization_losses = None )\ncompiled_loss ( y , y_pred , sample_weight = None , regularization_losses = None )\ncompute_loss\ncompute_loss\nView source\ncompute_loss ( x = None , y = None , y_pred = None , sample_weight = None )\ncompute_loss ( x = None , y = None , y_pred = None , sample_weight = None )\nCompute the total loss, validate it, and return it.\nSubclasses can optionally override this method to provide custom loss\ncomputation logic.\nclass MyModel ( Model ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . loss_tracker = metrics . Mean ( name = 'loss' ) def compute_loss ( self , x , y , y_pred , sample_weight ): loss = ops . means (( y_pred - y ) ** 2 ) loss += ops . sum ( self . losses ) self . loss_tracker . update_state ( loss ) return loss def reset_metrics ( self ): self . loss_tracker . reset_state () @property def metrics ( self ): return [ self . loss_tracker ] inputs = layers . Input ( shape = ( 10 ,), name = 'my_input' ) outputs = layers . Dense ( 10 )( inputs ) model = MyModel ( inputs , outputs ) model . add_loss ( ops . sum ( outputs )) optimizer = SGD () model . compile ( optimizer , loss = 'mse' , steps_per_execution = 10 ) dataset = ... model . fit ( dataset , epochs = 2 , steps_per_epoch = 10 ) print ( f \"Custom loss: { model . loss_tracker . result () } \" )\nclass MyModel ( Model ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . loss_tracker = metrics . Mean ( name = 'loss' ) def compute_loss ( self , x , y , y_pred , sample_weight ): loss = ops . means (( y_pred - y ) ** 2 ) loss += ops . sum ( self . losses ) self . loss_tracker . update_state ( loss ) return loss def reset_metrics ( self ): self . loss_tracker . reset_state () @property def metrics ( self ): return [ self . loss_tracker ] inputs = layers . Input ( shape = ( 10 ,), name = 'my_input' ) outputs = layers . Dense ( 10 )( inputs ) model = MyModel ( inputs , outputs ) model . add_loss ( ops . sum ( outputs )) optimizer = SGD () model . compile ( optimizer , loss = 'mse' , steps_per_execution = 10 ) dataset = ... model . fit ( dataset , epochs = 2 , steps_per_epoch = 10 ) print ( f \"Custom loss: { model . loss_tracker . result () } \" )\nArgs\nx Input data. y Target data. y_pred Predictions returned by the model (output of model(x) ) sample_weight Sample weights for weighting the loss function.\nx\ny\ny_pred\nmodel(x)\nsample_weight\nReturns The total loss as a scalar tensor, or None if no loss results\n(which is the case when called by Model.test_step ).\nNone\nModel.test_step\ncompute_metrics\ncompute_metrics\nView source\ncompute_metrics ( x , y , y_pred , sample_weight = None )\ncompute_metrics ( x , y , y_pred , sample_weight = None )\nUpdate metric states and collect all metrics to be returned.\nSubclasses can optionally override this method to provide custom metric\nupdating and collection logic.\nclass MyModel ( Sequential ): def compute_metrics ( self , x , y , y_pred , sample_weight ): # This super call updates `self.compiled_metrics` and returns # results for all metrics listed in `self.metrics`. metric_results = super () . compute_metrics ( x , y , y_pred , sample_weight ) # Note that `self.custom_metric` is not listed # in `self.metrics`. self . custom_metric . update_state ( x , y , y_pred , sample_weight ) metric_results [ 'metric_name' ] = self . custom_metric . result () return metric_results\nclass MyModel ( Sequential ): def compute_metrics ( self , x , y , y_pred , sample_weight ): # This super call updates `self.compiled_metrics` and returns # results for all metrics listed in `self.metrics`. metric_results = super () . compute_metrics ( x , y , y_pred , sample_weight ) # Note that `self.custom_metric` is not listed # in `self.metrics`. self . custom_metric . update_state ( x , y , y_pred , sample_weight ) metric_results [ 'metric_name' ] = self . custom_metric . result () return metric_results\nArgs\nx Input data. y Target data. y_pred Predictions returned by the model output of model.call(x) . sample_weight Sample weights for weighting the loss function.\nx\ny\ny_pred\nmodel.call(x)\nsample_weight\nReturns A dict containing values that will be passed to keras.callbacks.CallbackList.on_train_batch_end() . Typically,\nthe values of the metrics listed in self.metrics are returned. Example {'loss': 0.2, 'accuracy': 0.7} .\ndict\nkeras.callbacks.CallbackList.on_train_batch_end()\nself.metrics\nExample\n{'loss': 0.2, 'accuracy': 0.7}\nevaluate\nevaluate\nView source\nevaluate ( x = None , y = None , batch_size = None , verbose = 'auto' , sample_weight = None , steps = None , callbacks = None , return_dict = False , ** kwargs )\nevaluate ( x = None , y = None , batch_size = None , verbose = 'auto' , sample_weight = None , steps = None , callbacks = None , return_dict = False , ** kwargs )\nReturns the loss value & metrics values for the model in test mode.\nComputation is done in batches (see the batch_size arg.)\nbatch_size\nArgs\nx Input data. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.\nA tf.data.Dataset . Should return a tuple\nof either (inputs, targets) or (inputs, targets, sample_weights) .\ntf.data.Dataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nA generator or keras.utils.PyDataset returning (inputs, targets) or (inputs, targets, sample_weights) . y Target data. Like the input data x , it could be either NumPy\narray(s) or backend-native tensor(s).\nIf x is a tf.data.Dataset or keras.utils.PyDataset instance, y should not be specified\n(since targets will be obtained from the iterator/dataset). batch_size Integer or None . Number of samples per batch of\ncomputation. If unspecified, batch_size will default to 32. Do\nnot specify the batch_size if your data is in the form of a\ndataset, generators, or keras.utils.PyDataset instances\n(since they generate batches). verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = single line. \"auto\" becomes 1 for most cases.\nNote that the progress bar is not\nparticularly useful when logged to a file, so verbose=2 is\nrecommended when not running interactively\n(e.g. in a production environment). Defaults to \"auto\" . sample_weight Optional NumPy array of weights for the test samples,\nused for weighting the loss function. You can either pass a flat\n(1D) NumPy array with the same length as the input samples\n(1:1 mapping between weights and samples), or in the case of\ntemporal data, you can pass a 2D array with shape (samples,\nsequence_length) , to apply a different weight to every\ntimestep of every sample. This argument is not supported when x is a dataset, instead pass sample weights as the third\nelement of x . steps Integer or None . Total number of steps (batches of samples)\nbefore declaring the evaluation round finished. Ignored with the\ndefault value of None . If x is a tf.data.Dataset and steps is None , evaluation will run until the dataset\nis exhausted. callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during evaluation. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric.\nIf False , they are returned as a list.\nkeras.utils.PyDataset\n(inputs, targets)\n(inputs, targets, sample_weights)\ny\nx\nx\ntf.data.Dataset\nkeras.utils.PyDataset\ny\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nverbose\n\"auto\"\n\"auto\"\nverbose=2\n\"auto\"\nsample_weight\n(samples,\nsequence_length)\nx\nx\nsteps\nNone\nNone\nx\ntf.data.Dataset\nsteps\nNone\ncallbacks\nkeras.callbacks.Callback\nreturn_dict\nTrue\nFalse\nReturns Scalar test loss (if the model has a single output and no metrics)\nor list of scalars (if the model has multiple outputs\nand/or metrics). The attribute model.metrics_names will give you\nthe display labels for the scalar outputs.\nmodel.metrics_names\nexport\nexport\nView source\nexport ( filepath , format = 'tf_saved_model' )\nexport ( filepath , format = 'tf_saved_model' )\nCreate a TF SavedModel artifact for inference.\nThis method lets you export a model to a lightweight SavedModel artifact\nthat contains the model's forward pass only (its call() method)\nand can be served via e.g. TF-Serving. The forward pass is registered\nunder the name serve() (see example below).\ncall()\nserve()\nThe original code of the model (including any custom layers you may\nhave used) is no longer necessary to reload the artifact -- it is\nentirely standalone.\nArgs\nfilepath str or pathlib.Path object. Path where to save\nthe artifact.\nfilepath\nstr\npathlib.Path\n# Create the artifact model . export ( \"path/to/location\" ) # Later, in a different process / environment... reloaded_artifact = tf . saved_model . load ( \"path/to/location\" ) predictions = reloaded_artifact . serve ( input_data )\n# Create the artifact model . export ( \"path/to/location\" ) # Later, in a different process / environment... reloaded_artifact = tf . saved_model . load ( \"path/to/location\" ) predictions = reloaded_artifact . serve ( input_data )\nIf you would like to customize your serving endpoints, you can\nuse the lower-level keras.export.ExportArchive class. The export() method relies on ExportArchive internally.\nkeras.export.ExportArchive\nexport()\nExportArchive\nfit\nfit\nView source\nfit ( x = None , y = None , batch_size = None , epochs = 1 , verbose = 'auto' , callbacks = None , validation_split = 0.0 , validation_data = None , shuffle = True , class_weight = None , sample_weight = None , initial_epoch = 0 , steps_per_epoch = None , validation_steps = None , validation_batch_size = None , validation_freq = 1 )\nfit ( x = None , y = None , batch_size = None , epochs = 1 , verbose = 'auto' , callbacks = None , validation_split = 0.0 , validation_data = None , shuffle = True , class_weight = None , sample_weight = None , initial_epoch = 0 , steps_per_epoch = None , validation_steps = None , validation_batch_size = None , validation_freq = 1 )\nTrains the model for a fixed number of epochs (dataset iterations).\nArgs\nx Input data. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA dict mapping input names to the corresponding array/tensors,\nif the model has named inputs.\nA tf.data.Dataset . Should return a tuple\nof either (inputs, targets) or (inputs, targets, sample_weights) .\ntf.data.Dataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nA keras.utils.PyDataset returning (inputs,\ntargets) or (inputs, targets, sample_weights) . y Target data. Like the input data x ,\nit could be either NumPy array(s) or backend-native tensor(s).\nIf x is a dataset, generator,\nor keras.utils.PyDataset instance, y should\nnot be specified (since targets will be obtained from x ). batch_size Integer or None .\nNumber of samples per gradient update.\nIf unspecified, batch_size will default to 32.\nDo not specify the batch_size if your data is in the\nform of datasets, generators, or keras.utils.PyDataset instances (since they generate batches). epochs Integer. Number of epochs to train the model.\nAn epoch is an iteration over the entire x and y data provided\n(unless the steps_per_epoch flag is set to\nsomething other than None).\nNote that in conjunction with initial_epoch , epochs is to be understood as \"final epoch\".\nThe model is not trained for a number of iterations\ngiven by epochs , but merely until the epoch\nof index epochs is reached. verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = one line per epoch.\n\"auto\" becomes 1 for most cases.\nNote that the progress bar is not\nparticularly useful when logged to a file,\nso verbose=2 is recommended when not running interactively\n(e.g., in a production environment). Defaults to \"auto\" . callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during training.\nSee keras.callbacks . Note keras.callbacks.ProgbarLogger and keras.callbacks.History callbacks are created\nautomatically and need not be passed to model.fit() . keras.callbacks.ProgbarLogger is created\nor not based on the verbose argument in model.fit() . validation_split Float between 0 and 1.\nFraction of the training data to be used as validation data.\nThe model will set apart this fraction of the training data,\nwill not train on it, and will evaluate\nthe loss and any model metrics\non this data at the end of each epoch.\nThe validation data is selected from the last samples\nin the x and y data provided, before shuffling. This\nargument is not supported when x is a dataset, generator or keras.utils.PyDataset instance.\nIf both validation_data and validation_split are provided, validation_data will override validation_split . validation_data Data on which to evaluate\nthe loss and any model metrics at the end of each epoch.\nThe model will not be trained on this data. Thus, note the fact\nthat the validation loss of data provided using validation_split or validation_data is not affected by\nregularization layers like noise and dropout. validation_data will override validation_split .\nIt could be:\nkeras.utils.PyDataset\n(inputs,\ntargets)\n(inputs, targets, sample_weights)\ny\nx\nx\nkeras.utils.PyDataset\ny\nx\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nepochs\nx\ny\nsteps_per_epoch\ninitial_epoch\nepochs\nepochs\nepochs\nverbose\n\"auto\"\nverbose=2\n\"auto\"\ncallbacks\nkeras.callbacks.Callback\nkeras.callbacks\nkeras.callbacks.ProgbarLogger\nkeras.callbacks.History\nmodel.fit()\nkeras.callbacks.ProgbarLogger\nverbose\nmodel.fit()\nvalidation_split\nx\ny\nx\nkeras.utils.PyDataset\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_split\nvalidation_data\nvalidation_data\nvalidation_split\nA tuple (x_val, y_val) of NumPy arrays or tensors.\n(x_val, y_val)\nA tuple (x_val, y_val, val_sample_weights) of NumPy\narrays.\n(x_val, y_val, val_sample_weights)\nA tf.data.Dataset .\ntf.data.Dataset\nA Python generator or keras.utils.PyDataset returning (inputs, targets) or (inputs, targets, sample_weights) . shuffle Boolean, whether to shuffle the training data\nbefore each epoch. This argument is\nignored when x is a generator or a tf.data.Dataset . class_weight Optional dictionary mapping class indices (integers)\nto a weight (float) value, used for weighting the loss function\n(during training only).\nThis can be useful to tell the model to\n\"pay more attention\" to samples from\nan under-represented class. When class_weight is specified\nand targets have a rank of 2 or greater, either y must be\none-hot encoded, or an explicit final dimension of 1 must\nbe included for sparse class labels. sample_weight Optional NumPy array of weights for\nthe training samples, used for weighting the loss function\n(during training only). You can either pass a flat (1D)\nNumPy array with the same length as the input samples\n(1:1 mapping between weights and samples),\nor in the case of temporal data,\nyou can pass a 2D array with shape (samples, sequence_length) ,\nto apply a different weight to every timestep of every sample.\nThis argument is not supported when x is a dataset, generator,\nor keras.utils.PyDataset instance, instead provide the\nsample_weights as the third element of x .\nNote that sample weighting does not apply to metrics specified\nvia the metrics argument in compile() . To apply sample\nweighting to your metrics, you can specify them via the weighted_metrics in compile() instead. initial_epoch Integer.\nEpoch at which to start training\n(useful for resuming a previous training run). steps_per_epoch Integer or None .\nTotal number of steps (batches of samples)\nbefore declaring one epoch finished and starting the\nnext epoch. When training with input tensors such as\nbackend-native tensors, the default None is equal to\nthe number of samples in your dataset divided by\nthe batch size, or 1 if that cannot be determined. If x is a tf.data.Dataset , and steps_per_epoch is None , the epoch will run until the input dataset is\nexhausted.  When passing an infinitely repeating dataset, you\nmust specify the steps_per_epoch argument. If steps_per_epoch=-1 the training will run indefinitely with an\ninfinitely repeating dataset. validation_steps Only relevant if validation_data is provided.\nTotal number of steps (batches of\nsamples) to draw before stopping when performing validation\nat the end of every epoch. If validation_steps is None ,\nvalidation will run until the validation_data dataset is\nexhausted. In the case of an infinitely repeated dataset, it\nwill run into an infinite loop. If validation_steps is\nspecified and only part of the dataset will be consumed, the\nevaluation will start from the beginning of the dataset at each\nepoch. This ensures that the same validation samples are used\nevery time. validation_batch_size Integer or None .\nNumber of samples per validation batch.\nIf unspecified, will default to batch_size .\nDo not specify the validation_batch_size if your data is in\nthe form of datasets or keras.utils.PyDataset instances (since they generate batches). validation_freq Only relevant if validation data is provided.\nSpecifies how many training epochs to run\nbefore a new validation run is performed,\ne.g. validation_freq=2 runs validation every 2 epochs.\nkeras.utils.PyDataset\n(inputs, targets)\n(inputs, targets, sample_weights)\nshuffle\nx\ntf.data.Dataset\nclass_weight\nclass_weight\ny\n1\nsample_weight\n(samples, sequence_length)\nx\nkeras.utils.PyDataset\nx\nmetrics\ncompile()\nweighted_metrics\ncompile()\ninitial_epoch\nsteps_per_epoch\nNone\nNone\nx\ntf.data.Dataset\nsteps_per_epoch\nNone\nsteps_per_epoch\nsteps_per_epoch=-1\nvalidation_steps\nvalidation_data\nvalidation_steps\nNone\nvalidation_data\nvalidation_steps\nvalidation_batch_size\nNone\nbatch_size\nvalidation_batch_size\nkeras.utils.PyDataset\nvalidation_freq\nvalidation_freq=2\nUnpacking behavior for iterator-like inputs:\n    A common pattern is to pass an iterator like object such as a tf.data.Dataset or a keras.utils.PyDataset to fit() ,\n    which will in fact yield not only features ( x )\n    but optionally targets ( y ) and sample weights ( sample_weight ).\n    Keras requires that the output of such iterator-likes be\n    unambiguous. The iterator should return a tuple\n    of length 1, 2, or 3, where the optional second and third elements\n    will be used for y and sample_weight respectively.\n    Any other type provided will be wrapped in\n    a length-one tuple, effectively treating everything as x . When\n    yielding dicts, they should still adhere to the top-level tuple\n    structure,\n    e.g. ({\"x0\": x0, \"x1\": x1}, y) . Keras will not attempt to separate\n    features, targets, and weights from the keys of a single dict.\n    A notable unsupported data type is the namedtuple . The reason is\n    that it behaves like both an ordered datatype (tuple) and a mapping\n    datatype (dict). So given a namedtuple of the form: namedtuple(\"example_tuple\", [\"y\", \"x\"]) it is ambiguous whether to reverse the order of the elements when\n    interpreting the value. Even worse is a tuple of the form: namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"]) where it is unclear if the tuple was intended to be unpacked\n    into x , y , and sample_weight or passed through\n    as a single element to x .\ntf.data.Dataset\nkeras.utils.PyDataset\nfit()\nx\ny\nsample_weight\ny\nsample_weight\nx\n({\"x0\": x0, \"x1\": x1}, y)\nnamedtuple\nnamedtuple(\"example_tuple\", [\"y\", \"x\"])\nnamedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])\nx\ny\nsample_weight\nx\nReturns A History object. Its History.history attribute is\na record of training loss values and metrics values\nat successive epochs, as well as validation loss values\nand validation metrics values (if applicable).\nHistory\nHistory.history\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_compile_config\nget_compile_config\nView source\nget_compile_config ()\nget_compile_config ()\nReturns a serialized config with information for compiling the model.\nThis method returns a config dictionary containing all the information\n(optimizer, loss, metrics, etc.) with which the model was compiled.\nReturns A dict containing information for compiling the model.\nget_layer\nget_layer\nView source\nget_layer ( name = None , index = None )\nget_layer ( name = None , index = None )\nRetrieves a layer based on either its name (unique) or index.\nIf name and index are both provided, index will take precedence.\nIndices are based on order of horizontal graph traversal (bottom-up).\nname\nindex\nindex\nArgs\nname String, name of layer. index Integer, index of layer.\nname\nindex\nReturns A layer instance.\nget_metrics_result\nget_metrics_result\nView source\nget_metrics_result ()\nget_metrics_result ()\nReturns the model's metrics values as a dict.\nIf any of the metric result is a dict (containing multiple metrics),\neach of them gets added to the top level returned dict of this method.\nReturns A dict containing values of the metrics listed in self.metrics . Example {'loss': 0.2, 'accuracy': 0.7} .\ndict\nself.metrics\nExample\n{'loss': 0.2, 'accuracy': 0.7}\nload_weights\nload_weights\nView source\nload_weights ( filepath , skip_mismatch = False , ** kwargs )\nload_weights ( filepath , skip_mismatch = False , ** kwargs )\nLoad weights from a file saved via save_weights() .\nsave_weights()\nWeights are loaded based on the network's\ntopology. This means the architecture should be the same as when the\nweights were saved. Note that layers that don't have weights are not\ntaken into account in the topological ordering, so adding or removing\nlayers is fine as long as they don't have weights.\nPartial weight loading\nIf you have modified your model, for instance by adding a new layer\n(with weights) or by changing the shape of the weights of a layer,\nyou can choose to ignore errors and continue loading\nby setting skip_mismatch=True . In this case any layer with\nmismatching weights will be skipped. A warning will be displayed\nfor each skipped layer.\nskip_mismatch=True\nArgs\nfilepath String, path to the weights file to load.\nIt can either be a .weights.h5 file\nor a legacy .h5 weights file. skip_mismatch Boolean, whether to skip loading of layers where\nthere is a mismatch in the number of weights, or a mismatch in\nthe shape of the weights.\nfilepath\n.weights.h5\n.h5\nskip_mismatch\nloss\nloss\nView source\nloss ( y , y_pred , sample_weight = None )\nloss ( y , y_pred , sample_weight = None )\nmake_predict_function\nmake_predict_function\nView source\nmake_predict_function ( force = False )\nmake_predict_function ( force = False )\nmake_test_function\nmake_test_function\nView source\nmake_test_function ( force = False )\nmake_test_function ( force = False )\nmake_train_function\nmake_train_function\nView source\nmake_train_function ( force = False )\nmake_train_function ( force = False )\npredict\npredict\nView source\npredict ( x , batch_size = None , verbose = 'auto' , steps = None , callbacks = None )\npredict ( x , batch_size = None , verbose = 'auto' , steps = None , callbacks = None )\nGenerates output predictions for the input samples.\nComputation is done in batches. This method is designed for batch\nprocessing of large numbers of inputs. It is not intended for use inside\nof loops that iterate over your data and process small numbers of inputs\nat a time.\nFor small numbers of inputs that fit in one batch,\ndirectly use __call__() for faster execution, e.g., model(x) , or model(x, training=False) if you have layers such as BatchNormalization that behave differently during\ninference.\n__call__()\nmodel(x)\nmodel(x, training=False)\nBatchNormalization\nModel\npredict()\n__call__()\nArgs\nx Input samples. It could be:\nx\nA NumPy array (or array-like), or a list of arrays\n(in case the model has multiple inputs).\nA tensor, or a list of tensors\n(in case the model has multiple inputs).\nA tf.data.Dataset .\ntf.data.Dataset\nA keras.utils.PyDataset instance. batch_size Integer or None .\nNumber of samples per batch.\nIf unspecified, batch_size will default to 32.\nDo not specify the batch_size if your data is in the\nform of dataset, generators, or keras.utils.PyDataset instances (since they generate batches). verbose \"auto\" , 0, 1, or 2. Verbosity mode.\n0 = silent, 1 = progress bar, 2 = single line. \"auto\" becomes 1 for most cases. Note that the progress bar\nis not particularly useful when logged to a file,\nso verbose=2 is recommended when not running interactively\n(e.g. in a production environment). Defaults to \"auto\" . steps Total number of steps (batches of samples)\nbefore declaring the prediction round finished.\nIgnored with the default value of None .\nIf x is a tf.data.Dataset and steps is None , predict() will run until the input dataset is exhausted. callbacks List of keras.callbacks.Callback instances.\nList of callbacks to apply during prediction.\nkeras.utils.PyDataset\nbatch_size\nNone\nbatch_size\nbatch_size\nkeras.utils.PyDataset\nverbose\n\"auto\"\n\"auto\"\nverbose=2\n\"auto\"\nsteps\nNone\nx\ntf.data.Dataset\nsteps\nNone\npredict()\ncallbacks\nkeras.callbacks.Callback\nReturns NumPy array(s) of predictions.\npredict_on_batch\npredict_on_batch\nView source\npredict_on_batch ( x )\npredict_on_batch ( x )\nReturns predictions for a single batch of samples.\nArgs\nx Input data. It must be array-like.\nx\nReturns NumPy array(s) of predictions.\npredict_step\npredict_step\nView source\npredict_step ( data )\npredict_step ( data )\nreset_metrics\nreset_metrics\nView source\nreset_metrics ()\nreset_metrics ()\nsave\nsave\nView source\nsave ( filepath , overwrite = True , ** kwargs )\nsave ( filepath , overwrite = True , ** kwargs )\nSaves a model as a .keras file.\n.keras\nArgs\nfilepath str or pathlib.Path object. Path where to save\nthe model. Must end in .keras . overwrite Whether we should overwrite any existing model at\nthe target location, or instead ask the user via\nan interactive prompt. save_format The save_format argument is deprecated in Keras 3.\nFormat to use, as a string. Only the \"keras\" format is\nsupported at this time.\nfilepath\nstr\npathlib.Path\n.keras\noverwrite\nsave_format\nsave_format\n\"keras\"\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nNote that model.save() is an alias for keras.saving.save_model() .\nmodel.save()\nkeras.saving.save_model()\nThe saved .keras file contains:\n.keras\nThe model's configuration (architecture)\nThe model's weights\nThe model's optimizer's state (if any)\nThus models can be reinstantiated in the exact same state.\nsave_weights\nsave_weights\nView source\nsave_weights ( filepath , overwrite = True )\nsave_weights ( filepath , overwrite = True )\nSaves all layer weights to a .weights.h5 file.\n.weights.h5\nArgs\nfilepath str or pathlib.Path object.\nPath where to save the model. Must end in .weights.h5 . overwrite Whether we should overwrite any existing model\nat the target location, or instead ask the user\nvia an interactive prompt.\nfilepath\nstr\npathlib.Path\n.weights.h5\noverwrite\nstateless_compute_loss\nstateless_compute_loss\nView source\nstateless_compute_loss ( trainable_variables , non_trainable_variables , metrics_variables , x = None , y = None , y_pred = None , sample_weight = None )\nstateless_compute_loss ( trainable_variables , non_trainable_variables , metrics_variables , x = None , y = None , y_pred = None , sample_weight = None )\nsummary\nsummary\nView source\nsummary ( line_length = None , positions = None , print_fn = None , expand_nested = False , show_trainable = False , layer_range = None )\nsummary ( line_length = None , positions = None , print_fn = None , expand_nested = False , show_trainable = False , layer_range = None )\nPrints a string summary of the network.\nArgs\nline_length Total length of printed lines\n(e.g. set this to adapt the display to different\nterminal window sizes). positions Relative or absolute positions of log elements\nin each line. If not provided, becomes [0.3, 0.6, 0.70, 1.] . Defaults to None . print_fn Print function to use. By default, prints to stdout .\nIf stdout doesn't work in your environment, change to print .\nIt will be called on each line of the summary.\nYou can set it to a custom function\nin order to capture the string summary. expand_nested Whether to expand the nested models.\nDefaults to False . show_trainable Whether to show if a layer is trainable.\nDefaults to False . layer_range a list or tuple of 2 strings,\nwhich is the starting layer name and ending layer name\n(both inclusive) indicating the range of layers to be printed\nin summary. It also accepts regex patterns instead of exact\nname. In such case, start predicate will be the first element\nit matches to layer_range[0] and the end predicate will be\nthe last element it matches to layer_range[1] .\nBy default None which considers all layers of model.\nline_length\npositions\n[0.3, 0.6, 0.70, 1.]\nNone\nprint_fn\nstdout\nstdout\nprint\nexpand_nested\nFalse\nshow_trainable\nFalse\nlayer_range\nlayer_range[0]\nlayer_range[1]\nNone\nRaises\nValueError if summary() is called before the model is built.\nValueError\nsummary()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\ntest_on_batch\ntest_on_batch\nView source\ntest_on_batch ( x , y = None , sample_weight = None , return_dict = False )\ntest_on_batch ( x , y = None , sample_weight = None , return_dict = False )\nTest the model on a single batch of samples.\nArgs\nx Input data. Must be array-like. y Target data. Must be array-like. sample_weight Optional array of the same length as x, containing\nweights to apply to the model's loss for each sample.\nIn the case of temporal data, you can pass a 2D array\nwith shape (samples, sequence_length) , to apply a different\nweight to every timestep of every sample. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric. If False ,\nthey are returned as a list.\nx\ny\nsample_weight\n(samples, sequence_length)\nreturn_dict\nTrue\nFalse\nReturns A scalar loss value (when no metrics and return_dict=False ),\na list of loss and metric values\n(if there are metrics and return_dict=False ), or a dict of\nmetric and loss values (if return_dict=True ).\nreturn_dict=False\nreturn_dict=False\nreturn_dict=True\ntest_step\ntest_step\nView source\ntest_step ( data )\ntest_step ( data )\nto_json\nto_json\nView source\nto_json ( ** kwargs )\nto_json ( ** kwargs )\nReturns a JSON string containing the network configuration.\nTo load a network from a JSON save file, use keras.models.model_from_json(json_string, custom_objects={...}) .\nkeras.models.model_from_json(json_string, custom_objects={...})\nArgs\n**kwargs Additional keyword arguments to be passed to json.dumps() .\n**kwargs\njson.dumps()\nReturns A JSON string.\ntrain_on_batch\ntrain_on_batch\nView source\ntrain_on_batch ( x , y = None , sample_weight = None , class_weight = None , return_dict = False )\ntrain_on_batch ( x , y = None , sample_weight = None , class_weight = None , return_dict = False )\nRuns a single gradient update on a single batch of data.\nArgs\nx Input data. Must be array-like. y Target data. Must be array-like. sample_weight Optional array of the same length as x, containing\nweights to apply to the model's loss for each sample.\nIn the case of temporal data, you can pass a 2D array\nwith shape (samples, sequence_length) , to apply a different\nweight to every timestep of every sample. class_weight Optional dictionary mapping class indices (integers)\nto a weight (float) to apply to the model's loss for the samples\nfrom this class during training. This can be useful to tell the\nmodel to \"pay more attention\" to samples from an\nunder-represented class. When class_weight is specified\nand targets have a rank of 2 or greater, either y must\nbe one-hot encoded, or an explicit final dimension of 1\nmust be included for sparse class labels. return_dict If True , loss and metric results are returned as a\ndict, with each key being the name of the metric. If False ,\nthey are returned as a list.\nx\ny\nsample_weight\n(samples, sequence_length)\nclass_weight\nclass_weight\ny\nreturn_dict\nTrue\nFalse\nReturns A scalar loss value (when no metrics and return_dict=False ),\na list of loss and metric values\n(if there are metrics and return_dict=False ), or a dict of\nmetric and loss values (if return_dict=True ).\nreturn_dict=False\nreturn_dict=False\nreturn_dict=True\ntrain_step\ntrain_step\nView source\ntrain_step ( data )\ntrain_step ( data )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/average_pool",
    "content": "Average pooling operation.\nMain aliases tf.keras.ops.nn.average_pool\ntf.keras.ops.nn.average_pool\ntf.keras.ops.nn.average_pool\ntf . keras . ops . average_pool ( inputs , pool_size , strides = None , padding = 'valid' , data_format = None )\ntf . keras . ops . average_pool ( inputs , pool_size , strides = None , padding = 'valid' , data_format = None )\nArgs\nArgs\ninputs Tensor of rank N+2. inputs has shape (batch_size,) + inputs_spatial_shape + (num_channels,) if data_format=\"channels_last\" , or (batch_size, num_channels) + inputs_spatial_shape if data_format=\"channels_first\" . Pooling happens over the spatial\ndimensions only. pool_size int or tuple/list of integers of size len(inputs_spatial_shape) , specifying the size of the pooling\nwindow for each spatial dimension of the input tensor. If pool_size is int, then every spatial dimension shares the same pool_size . strides int or tuple/list of integers of size len(inputs_spatial_shape) . The stride of the sliding window for\neach spatial dimension of the input tensor. If strides is int,\nthen every spatial dimension shares the same strides . padding string, either \"valid\" or \"same\" . \"valid\" means no\npadding is applied, and \"same\" results in padding evenly to the\nleft/right or up/down of the input such that output has the\nsame height/width dimension as the input when strides=1 . data_format A string, either \"channels_last\" or \"channels_first\" . data_format determines the ordering of the dimensions in the\ninputs. If data_format=\"channels_last\" , inputs is of shape (batch_size, ..., channels) while if data_format=\"channels_first\" , inputs is of shape (batch_size, channels, ...) .\ninputs\ninputs\n(batch_size,) + inputs_spatial_shape + (num_channels,)\ndata_format=\"channels_last\"\n(batch_size, num_channels) + inputs_spatial_shape\ndata_format=\"channels_first\"\npool_size\nlen(inputs_spatial_shape)\npool_size\npool_size\nstrides\nlen(inputs_spatial_shape)\nstrides\nstrides\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\ndata_format\ndata_format=\"channels_last\"\ninputs\n(batch_size, ..., channels)\ndata_format=\"channels_first\"\ninputs\n(batch_size, channels, ...)\nReturns A tensor of rank N+2, the result of the average pooling operation.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/true_divide",
    "content": "Alias for keras.ops.divide .\nkeras.ops.divide\nMain aliases tf.keras.ops.numpy.true_divide\ntf.keras.ops.numpy.true_divide\ntf.keras.ops.numpy.true_divide\ntf . keras . ops . true_divide ( x1 , x2 )\ntf . keras . ops . true_divide ( x1 , x2 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies/serialize",
    "content": "Serializes DTypePolicy instance.\nDTypePolicy\ntf . keras . dtype_policies . serialize ( dtype_policy )\ntf . keras . dtype_policies . serialize ( dtype_policy )\nArgs\nArgs\ndtype_policy A Keras DTypePolicy instance.\ndtype_policy\nDTypePolicy\nReturns DTypePolicy configuration dictionary.\nReturns\nDTypePolicy"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform",
    "content": "The Glorot uniform initializer, also called Xavier uniform initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.glorot_uniform\ntf.keras.initializers.glorot_uniform\ntf.keras.initializers.glorot_uniform\ntf . keras . initializers . GlorotUniform ( seed = None )\ntf . keras . initializers . GlorotUniform ( seed = None )\nUsed in the notebooks\nScalable model compression\nDraws samples from a uniform distribution within [-limit, limit] , where limit = sqrt(6 / (fan_in + fan_out)) ( fan_in is the number of input\nunits in the weight tensor and fan_out is the number of output units).\n[-limit, limit]\nlimit = sqrt(6 / (fan_in + fan_out))\nfan_in\nfan_out\n# Standalone usage: initializer = GlorotUniform () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = GlorotUniform ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = GlorotUniform () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = GlorotUniform ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nGlorot et al., 2010\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/tri",
    "content": "Return a tensor with ones at and below a diagonal and zeros elsewhere.\nMain aliases tf.keras.ops.numpy.tri\ntf.keras.ops.numpy.tri\ntf.keras.ops.numpy.tri\ntf . keras . ops . tri ( N , M = None , k = 0 , dtype = None )\ntf . keras . ops . tri ( N , M = None , k = 0 , dtype = None )\nArgs\nArgs\nN Number of rows in the tensor. M Number of columns in the tensor. k The sub-diagonal at and below which the array is filled. k = 0 is the main diagonal, while k < 0 is below it, and k > 0 is above. The default is 0. dtype Data type of the returned tensor. The default is \"float32\".\nN\nM\nk\nk = 0\nk < 0\nk > 0\ndtype\nReturns Tensor with its lower triangle filled with ones and zeros elsewhere. T[i, j] == 1 for j <= i + k , 0 otherwise.\nReturns\nT[i, j] == 1\nj <= i + k"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Function",
    "content": "Class that encapsulates a computation graph of Keras operations.\nInherits From: Operation\nOperation\nCompat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Function\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Function\ntf.compat.v1.keras.Function\ntf . keras . Function ( inputs , outputs , name = None )\ntf . keras . Function ( inputs , outputs , name = None )\nYou can use a Function to capture the computation graph linking\nsome input tensors to some output tensors, and reapply the same\ncomputation on new inputs.\nFunction\nA Function is similar to a Functional Model, with the difference\nthat it is stateless (it does not track state variables)\nand does not implement the Layer API.\nFunction\nLayer\ninput_1 = keras . KerasTensor ( shape = ( None , 2 , 3 )) input_2 = keras . KerasTensor ( shape = ( None , 2 , 3 )) x = input_1 + input_2 output = keras . ops . sigmoid ( x ) fn = keras . Function ( inputs = [ input_1 , input_2 ], outputs = output ) input_1_val = np . random . random (( 4 , 2 , 3 )) input_2_val = np . random . random (( 4 , 2 , 3 )) output_val = fn ([ input_1_val , input_2_val ])\ninput_1 = keras . KerasTensor ( shape = ( None , 2 , 3 )) input_2 = keras . KerasTensor ( shape = ( None , 2 , 3 )) x = input_1 + input_2 output = keras . ops . sigmoid ( x ) fn = keras . Function ( inputs = [ input_1 , input_2 ], outputs = output ) input_1_val = np . random . random (( 4 , 2 , 3 )) input_2_val = np . random . random (( 4 , 2 , 3 )) output_val = fn ([ input_1_val , input_2_val ])\nArgs\nArgs\ninputs KerasTensor instance or nested structured of KerasTensor instances. outputs KerasTensor instance or nested structured of KerasTensor instances. They should be computable\ngiven only the values of inputs . name String. The name of the function.\ninputs\nKerasTensor\nKerasTensor\noutputs\nKerasTensor\nKerasTensor\ninputs\nname\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. inputs\ninputs\noperations\noperations\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. outputs\noutputs\nMethods\ncall\ncall\nView source\ncall ( inputs )\ncall ( inputs )\nComputes output tensors for new inputs.\ncompute_output_spec\ncompute_output_spec\nView source\ncompute_output_spec ( inputs )\ncompute_output_spec ( inputs )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the object.\nAn object config is a Python dictionary (serializable)\ncontaining the information needed to re-instantiate it.\nquantized_call\nquantized_call\nView source\nquantized_call ( * args , ** kwargs )\nquantized_call ( * args , ** kwargs )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/rnn",
    "content": "DEPRECATED.\ntf . keras . backend . rnn ( step_function , inputs , initial_states , go_backwards = False , mask = None , constants = None , unroll = False , input_length = None , time_major = False , zero_output_for_mask = False , return_all_outputs = True )\ntf . keras . backend . rnn ( step_function , inputs , initial_states , go_backwards = False , mask = None , constants = None , unroll = False , input_length = None , time_major = False , zero_output_for_mask = False , return_all_outputs = True )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2M",
    "content": "Instantiates the EfficientNetV2M architecture.\nMain aliases tf.keras.applications.efficientnet_v2.EfficientNetV2M\ntf.keras.applications.efficientnet_v2.EfficientNetV2M\ntf.keras.applications.efficientnet_v2.EfficientNetV2M\ntf . keras . applications . EfficientNetV2M ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . EfficientNetV2M ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , include_preprocessing = True )\nEfficientNetV2: Smaller Models and Faster Training (ICML 2021)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet_v2.preprocess_input\n[0, 255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninclude_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False .\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None.\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\n\"avg\" means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\n\"avg\"\n\"max\" means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. Defaults to 1000 (number of\nImageNet classes). classifier_activation A string or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to \"softmax\" .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\n\"max\"\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\ninclude_top=True\nclassifier_activation=None\n\"softmax\"\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Metric",
    "content": "Encapsulates metric logic and state.\nMain aliases tf.keras.metrics.Metric Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Metric\ntf.keras.metrics.Metric\ntf.keras.metrics.Metric\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Metric\ntf.compat.v1.keras.Metric\ntf . keras . Metric ( dtype = None , name = None )\ntf . keras . Metric ( dtype = None , name = None )\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = SomeMetric ( ... ) for input in ... : m . update_state ( input ) print ( 'Final result: ' , m . result ())\nm = SomeMetric ( ... ) for input in ... : m . update_state ( input ) print ( 'Final result: ' , m . result ())\nUsage with compile() API:\ncompile()\nmodel = keras . Sequential () model . add ( keras . layers . Dense ( 64 , activation = 'relu' )) model . add ( keras . layers . Dense ( 64 , activation = 'relu' )) model . add ( keras . layers . Dense ( 10 , activation = 'softmax' )) model . compile ( optimizer = keras . optimizers . RMSprop ( 0.01 ), loss = keras . losses . CategoricalCrossentropy (), metrics = [ keras . metrics . CategoricalAccuracy ()]) data = np . random . random (( 1000 , 32 )) labels = np . random . random (( 1000 , 10 )) model . fit ( data , labels , epochs = 10 )\nmodel = keras . Sequential () model . add ( keras . layers . Dense ( 64 , activation = 'relu' )) model . add ( keras . layers . Dense ( 64 , activation = 'relu' )) model . add ( keras . layers . Dense ( 10 , activation = 'softmax' )) model . compile ( optimizer = keras . optimizers . RMSprop ( 0.01 ), loss = keras . losses . CategoricalCrossentropy (), metrics = [ keras . metrics . CategoricalAccuracy ()]) data = np . random . random (( 1000 , 32 )) labels = np . random . random (( 1000 , 10 )) model . fit ( data , labels , epochs = 10 )\nTo be implemented by subclasses:\n__init__() : All state variables should be created in this method by\ncalling self.add_variable() like: self.var = self.add_variable(...)\n__init__()\nself.add_variable()\nself.var = self.add_variable(...)\nupdate_state() : Has all updates to the state variables like: self.var.assign(...) .\nupdate_state()\nself.var.assign(...)\nresult() : Computes and returns a scalar value or a dict of scalar values\nfor the metric from the state variables.\nresult()\nExample subclass implementation:\nclass BinaryTruePositives ( Metric ): def __init__ ( self , name = 'binary_true_positives' , ** kwargs ): super () . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_variable ( shape = (), initializer = 'zeros' , name = 'true_positives' ) def update_state ( self , y_true , y_pred , sample_weight = None ): y_true = ops . cast ( y_true , \"bool\" ) y_pred = ops . cast ( y_pred , \"bool\" ) values = ops . logical_and ( ops . equal ( y_true , True ), ops . equal ( y_pred , True )) values = ops . cast ( values , self . dtype ) if sample_weight is not None : sample_weight = ops . cast ( sample_weight , self . dtype ) sample_weight = ops . broadcast_to ( sample_weight , ops . shape ( values ) ) values = ops . multiply ( values , sample_weight ) self . true_positives . assign ( self . true_positives + ops . sum ( values )) def result ( self ): return self . true_positives\nclass BinaryTruePositives ( Metric ): def __init__ ( self , name = 'binary_true_positives' , ** kwargs ): super () . __init__ ( name = name , ** kwargs ) self . true_positives = self . add_variable ( shape = (), initializer = 'zeros' , name = 'true_positives' ) def update_state ( self , y_true , y_pred , sample_weight = None ): y_true = ops . cast ( y_true , \"bool\" ) y_pred = ops . cast ( y_pred , \"bool\" ) values = ops . logical_and ( ops . equal ( y_true , True ), ops . equal ( y_pred , True )) values = ops . cast ( values , self . dtype ) if sample_weight is not None : sample_weight = ops . cast ( sample_weight , self . dtype ) sample_weight = ops . broadcast_to ( sample_weight , ops . shape ( values ) ) values = ops . multiply ( values , sample_weight ) self . true_positives . assign ( self . true_positives + ops . sum ( values )) def result ( self ): return self . true_positives\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( * args , ** kwargs )\nupdate_state ( * args , ** kwargs )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredLogarithmicError",
    "content": "Computes the mean squared logarithmic error between y_true & y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . MeanSquaredLogarithmicError ( reduction = 'sum_over_batch_size' , name = 'mean_squared_logarithmic_error' )\ntf . keras . losses . MeanSquaredLogarithmicError ( reduction = 'sum_over_batch_size' , name = 'mean_squared_logarithmic_error' )\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )))\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )))\nArgs\nArgs\nreduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/LayoutMap",
    "content": "A dict-like object that maps string to TensorLayout instances.\nTensorLayout\ntf . keras . distribution . LayoutMap ( device_mesh = None )\ntf . keras . distribution . LayoutMap ( device_mesh = None )\nLayoutMap uses a string as key and a TensorLayout as value. There is a\nbehavior difference between a normal Python dict and this class. The string\nkey will be treated as a regex when retrieving the value. See the docstring\nof get for more details.\nLayoutMap\nTensorLayout\nget\nSee below for a usage example. You can define the naming schema\nof the TensorLayout , and then retrieve the corresponding TensorLayout instance.\nTensorLayout\nTensorLayout\nIn the normal case, the key to query is usually the variable.path , which\nis the idenifier of the variable.\nvariable.path\nAs shortcut, tuple or list of axis names are also allowed when inserting\nas value, and will be converted to TensorLayout .\nTensorLayout\nlayout_map = LayoutMap ( device_mesh = None ) layout_map [ 'dense.*kernel' ] = ( None , 'model' ) # layout_2d layout_map [ 'dense.*bias' ] = ( 'model' ,) # layout_1d layout_map [ 'conv2d.*kernel' ] = TensorLayout (( None , None , None , 'model' )) layout_map [ 'conv2d.*bias' ] = TensorLayout (( 'model' ,)) # layout_1d layout_1 = layout_map [ 'dense_1.kernel' ] # layout_1 == layout_2d layout_2 = layout_map [ 'dense_1.bias' ] # layout_2 == layout_1d layout_3 = layout_map [ 'dense_2.kernel' ] # layout_3 == layout_2d layout_4 = layout_map [ 'dense_2.bias' ] # layout_4 == layout_1d layout_5 = layout_map [ 'my_model/conv2d_123/kernel' ] # layout_5 == layout_4d layout_6 = layout_map [ 'my_model/conv2d_123/bias' ] # layout_6 == layout_1d layout_7 = layout_map [ 'my_model/conv3d_1/kernel' ] # layout_7 == None layout_8 = layout_map [ 'my_model/conv3d_1/bias' ] # layout_8 == None\nlayout_map = LayoutMap ( device_mesh = None ) layout_map [ 'dense.*kernel' ] = ( None , 'model' ) # layout_2d layout_map [ 'dense.*bias' ] = ( 'model' ,) # layout_1d layout_map [ 'conv2d.*kernel' ] = TensorLayout (( None , None , None , 'model' )) layout_map [ 'conv2d.*bias' ] = TensorLayout (( 'model' ,)) # layout_1d layout_1 = layout_map [ 'dense_1.kernel' ] # layout_1 == layout_2d layout_2 = layout_map [ 'dense_1.bias' ] # layout_2 == layout_1d layout_3 = layout_map [ 'dense_2.kernel' ] # layout_3 == layout_2d layout_4 = layout_map [ 'dense_2.bias' ] # layout_4 == layout_1d layout_5 = layout_map [ 'my_model/conv2d_123/kernel' ] # layout_5 == layout_4d layout_6 = layout_map [ 'my_model/conv2d_123/bias' ] # layout_6 == layout_1d layout_7 = layout_map [ 'my_model/conv3d_1/kernel' ] # layout_7 == None layout_8 = layout_map [ 'my_model/conv3d_1/bias' ] # layout_8 == None\nArgs\nArgs\ndevice_mesh An optional DeviceMesh that can be used to populate the TensorLayout.device_mesh if TensorLayout.device_mesh is not set.\ndevice_mesh\nDeviceMesh\nTensorLayout.device_mesh\nTensorLayout.device_mesh\nAttributes\nAttributes\ndevice_mesh\ndevice_mesh\nMethods\nclear\nclear\nclear ()\nclear ()\nD.clear() -> None.  Remove all items from D.\nget\nget\nget ( key , default = None )\nget ( key , default = None )\nRetrieves the corresponding layout by the string key.\nWhen there isn't an exact match, all the existing keys in the layout map\nwill be treated as a regex and map against the input key again. When\nthere are multiple matches for the regex, an ValueError will be\nraised. Returns None if there isn't any match found.\nValueError\nNone\nArgs\nkey String key to query a layout.\nkey\nReturns Corresponding layout based on the query.\nitems\nitems\nitems ()\nitems ()\nD.items() -> a set-like object providing a view on D's items\nkeys\nkeys\nkeys ()\nkeys ()\nD.keys() -> a set-like object providing a view on D's keys\npop\npop\npop ( key , default = __marker )\npop ( key , default = __marker )\nD.pop(k[,d]) -> v, remove specified key and return the corresponding value.\nIf key is not found, d is returned if given, otherwise KeyError is raised.\npopitem\npopitem\npopitem ()\npopitem ()\nD.popitem() -> (k, v), remove and return some (key, value) pair as a 2-tuple; but raise KeyError if D is empty.\nsetdefault\nsetdefault\nsetdefault ( key , default = None )\nsetdefault ( key , default = None )\nD.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\nupdate\nupdate\nupdate ( other , / , ** kwds )\nupdate ( other , / , ** kwds )\nD.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\nIf E present and has a .keys() method, does:     for k in E: D[k] = E[k]\nIf E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\nIn either case, this is followed by: for k, v in F.items(): D[k] = v\nvalues\nvalues\nvalues ()\nvalues ()\nD.values() -> an object providing a view on D's values\n__contains__\n__contains__\n__contains__ ( key )\n__contains__ ( key )\n__eq__\n__eq__\n__eq__ ( other )\n__eq__ ( other )\nReturn self==value.\n__getitem__\n__getitem__\nView source\n__getitem__ ( key )\n__getitem__ ( key )\nRetrieves the corresponding layout by the string key.\nWhen there isn't an exact match, all the existing keys in the layout map\nwill be treated as a regex and map against the input key again. When\nthere are multiple matches for the regex, an ValueError will be\nraised. Returns None if there isn't any match found.\nValueError\nNone\nArgs\nkey String key to query a layout.\nkey\nReturns Corresponding layout based on the query.\n__iter__\n__iter__\nView source\n__iter__ ()\n__iter__ ()\n__len__\n__len__\nView source\n__len__ ()\n__len__ ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/get_uid",
    "content": "Associates a string prefix with an integer counter.\ntf . keras . backend . get_uid ( prefix = '' )\ntf . keras . backend . get_uid ( prefix = '' )\nArgs\nArgs\nprefix String prefix to index.\nprefix\nReturns Unique integer ID.\nReturns\nget_uid ( 'dense' ) 1 get_uid ( 'dense' ) 2\nget_uid ( 'dense' )\n1\nget_uid ( 'dense' )\n2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/OneHotMeanIoU",
    "content": "Computes mean Intersection-Over-Union metric for one-hot encoded labels.\nInherits From: MeanIoU , IoU , Metric\nMeanIoU\nIoU\nMetric\ntf . keras . metrics . OneHotMeanIoU ( num_classes , name = None , dtype = None , ignore_class = None , sparse_y_pred = False , axis =- 1 )\ntf . keras . metrics . OneHotMeanIoU ( num_classes , name = None , dtype = None , ignore_class = None , sparse_y_pred = False , axis =- 1 )\niou = true_positives / ( true_positives + false_positives + false_negatives )\niou = true_positives / ( true_positives + false_positives + false_negatives )\nIntersection-Over-Union is a common evaluation metric for semantic image\nsegmentation.\nTo compute IoUs, the predictions are accumulated in a confusion matrix,\nweighted by sample_weight and the metric is then calculated from it.\nsample_weight\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nThis class can be used to compute the mean IoU for multi-class\nclassification tasks where the labels are one-hot encoded (the last axis\nshould have one dimension per class). Note that the predictions should also\nhave the same shape. To compute the mean IoU, first the labels and\npredictions are converted back into integer format by taking the argmax over\nthe class axis. Then the same computation steps as for the base MeanIoU class apply.\nMeanIoU\nNote, if there is only one channel in the labels and predictions, this class\nis the same as class MeanIoU . In this case, use MeanIoU instead.\nMeanIoU\nMeanIoU\nAlso, make sure that num_classes is equal to the number of classes in the\ndata, to avoid a \"labels out of bound\" error when the confusion matrix is\ncomputed.\nnum_classes\nArgs\nArgs\nnum_classes The possible number of labels the prediction task can have. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. ignore_class Optional integer. The ID of a class to be ignored during\nmetric computation. This is useful, for example, in segmentation\nproblems featuring a \"void\" class (commonly -1 or 255) in\nsegmentation maps. By default ( ignore_class=None ), all classes are\nconsidered. sparse_y_pred Whether predictions are encoded using natural numbers or\nprobability distribution vectors. If False , the argmax function will be used to determine each sample's most likely\nassociated label. axis (Optional) The dimension containing the logits. Defaults to -1 .\nnum_classes\nname\ndtype\nignore_class\nignore_class=None\nsparse_y_pred\nFalse\nargmax\naxis\n-1\ny_true = np . array ([[ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 1 , 0 , 0 ]]) y_pred = np . array ([[ 0.2 , 0.3 , 0.5 ], [ 0.1 , 0.2 , 0.7 ], [ 0.5 , 0.3 , 0.1 ], [ 0.1 , 0.4 , 0.5 ]]) sample_weight = [ 0.1 , 0.2 , 0.3 , 0.4 ] m = keras . metrics . OneHotMeanIoU ( num_classes = 3 ) m . update_state ( y_true = y_true , y_pred = y_pred , sample_weight = sample_weight ) # cm = [[0, 0, 0.2+0.4], #       [0.3, 0, 0], #       [0, 0, 0.1]] # sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1] # true_positives = [0, 0, 0.1] # single_iou = true_positives / (sum_row + sum_col - true_positives)) # mean_iou = (0 + 0 + 0.1 / (0.7 + 0.1 - 0.1)) / 3 m . result () 0.048\ny_true = np . array ([[ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 1 , 0 , 0 ]])\ny_pred = np . array ([[ 0.2 , 0.3 , 0.5 ], [ 0.1 , 0.2 , 0.7 ], [ 0.5 , 0.3 , 0.1 ],\n[ 0.1 , 0.4 , 0.5 ]])\nsample_weight = [ 0.1 , 0.2 , 0.3 , 0.4 ]\nm = keras . metrics . OneHotMeanIoU ( num_classes = 3 )\nm . update_state (\ny_true = y_true , y_pred = y_pred , sample_weight = sample_weight )\n# cm = [[0, 0, 0.2+0.4],\n#       [0.3, 0, 0],\n#       [0, 0, 0.1]]\n# sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1]\n# true_positives = [0, 0, 0.1]\n# single_iou = true_positives / (sum_row + sum_col - true_positives))\n# mean_iou = (0 + 0 + 0.1 / (0.7 + 0.1 - 0.1)) / 3\nm . result ()\n0.048\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . OneHotMeanIoU ( num_classes = 3 )])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . OneHotMeanIoU ( num_classes = 3 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the intersection-over-union via the confusion matrix.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same as y_true ,\nand must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/flatten",
    "content": "DEPRECATED.\ntf . keras . backend . flatten ( x )\ntf . keras . backend . flatten ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_image_data_format",
    "content": "Set the value of the image data format convention.\nMain aliases tf.keras.config.set_image_data_format\ntf.keras.config.set_image_data_format\ntf.keras.config.set_image_data_format\ntf . keras . backend . set_image_data_format ( data_format )\ntf . keras . backend . set_image_data_format ( data_format )\nArgs\nArgs\ndata_format string. 'channels_first' or 'channels_last' .\ndata_format\n'channels_first'\n'channels_last'\nkeras . config . image_data_format () 'channels_last'\nkeras . config . image_data_format ()\n'channels_last'\nkeras . config . set_image_data_format ( 'channels_first' ) keras . config . image_data_format () 'channels_first'\nkeras . config . set_image_data_format ( 'channels_first' )\nkeras . config . image_data_format ()\n'channels_first'\n# Set it back to `'channels_last'` keras . config . set_image_data_format ( 'channels_last' )\n# Set it back to `'channels_last'`\nkeras . config . set_image_data_format ( 'channels_last' )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/export",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass ExportArchive : ExportArchive is used to write SavedModel artifacts (e.g. for inference).\nclass ExportArchive"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nMobileNetV2(...) : Instantiates the MobileNetV2 architecture.\nMobileNetV2(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/distribution",
    "content": "Retrieve the current distribution from global context.\ntf . keras . distribution . distribution ()\ntf . keras . distribution . distribution ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3D",
    "content": "3D convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution3D\ntf.keras.layers.Convolution3D\ntf.keras.layers.Convolution3D\ntf . keras . layers . Conv3D ( filters , kernel_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ), groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv3D ( filters , kernel_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ), groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If use_bias is True, a bias vector is created and added to the\noutputs. Finally, if activation is not None , it is applied to the\noutputs as well.\nuse_bias\nactivation\nNone\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 3 integer, specifying the size of the\nconvolution window. strides int or tuple/list of 3 integer, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" . dilation_rate int or tuple/list of 3 integers, specifying the dilation\nrate to use for dilated convolution. groups A positive int specifying the number of groups in which the\ninput is split along the channel axis. Each group is convolved\nseparately with filters // groups filters. The output is the\nconcatenation of all the groups results along the channel axis.\nInput channels and filters must both be divisible by groups . activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\ngroups\nfilters // groups\ngroups\nfilters\ngroups\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\nfilters)\ndata_format=\"channels_last\"\n(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\nfilters)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, filters, new_spatial_dim1, new_spatial_dim2,\nnew_spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\nnew_spatial_dim3)\nReturns A 5D tensor representing activation(conv3d(inputs, kernel) + bias) .\nReturns\nactivation(conv3d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nx = np . random . rand ( 4 , 10 , 10 , 10 , 128 ) y = keras . layers . Conv3D ( 32 , 3 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 8 , 8 , 8 , 32 )\nx = np . random . rand ( 4 , 10 , 10 , 10 , 128 )\ny = keras . layers . Conv3D ( 32 , 3 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 8 , 8 , 8 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel\nkernel\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nconvolution_op\nconvolution_op\nView source\nconvolution_op ( inputs , kernel )\nconvolution_op ( inputs , kernel )\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_value",
    "content": "DEPRECATED.\ntf . keras . backend . set_value ( x , value )\ntf . keras . backend . set_value ( x , value )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Average",
    "content": "Averages a list of inputs element-wise..\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Average ( ** kwargs )\ntf . keras . layers . Average ( ** kwargs )\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Average ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Average ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `y = keras.layers.average([x1, x2])` y = keras . layers . Average ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `y = keras.layers.average([x1, x2])`\ny = keras . layers . Average ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop",
    "content": "A preprocessing layer which crops images.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . CenterCrop ( height , width , data_format = None , ** kwargs )\ntf . keras . layers . CenterCrop ( height , width , data_format = None , ** kwargs )\nThis layers crops the central portion of the images to a target size. If an\nimage is smaller than the target size, it will be resized and cropped\nso as to return the largest possible window in the image that matches\nthe target aspect ratio.\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ).\n[0., 1.)\n[0, 255]\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format,\nor (..., channels, height, width) , in \"channels_first\" format.\n(..., height, width, channels)\n\"channels_last\"\n(..., channels, height, width)\n\"channels_first\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., target_height, target_width, channels) ,\nor (..., channels, target_height, target_width) ,\nin \"channels_first\" format.\n(..., target_height, target_width, channels)\n(..., channels, target_height, target_width)\n\"channels_first\"\nIf the input height/width is even and the target height/width is odd (or\ninversely), the input image is left-padded by 1 pixel.\ntf.data\nArgs\nArgs\nheight Integer, the height of the output shape. width Integer, the width of the output shape. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\nheight\nwidth\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . mobilenet_v2 . preprocess_input ( x , data_format = None )\ntf . keras . applications . mobilenet_v2 . preprocess_input ( x , data_format = None )\nUsed in the notebooks\nAdversarial example using FGSM\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model",
    "content": "Saves a model as a .keras file.\n.keras\ntf . keras . models . save_model ( model , filepath , overwrite = True , ** kwargs )\ntf . keras . models . save_model ( model , filepath , overwrite = True , ** kwargs )\nUsed in the notebooks\nTrain and serve a TensorFlow model with TensorFlow Serving\nArgs\nArgs\nmodel Keras model instance to be saved. filepath str or pathlib.Path object. Path where to save the model. overwrite Whether we should overwrite any existing model at the target\nlocation, or instead ask the user via an interactive prompt.\nmodel\nfilepath\nstr\npathlib.Path\noverwrite\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nmodel = keras . Sequential ( [ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax (), ], ) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = keras . random . uniform (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nNote that model.save() is an alias for keras.saving.save_model() .\nmodel.save()\nkeras.saving.save_model()\nThe saved .keras file contains:\n.keras\nThe model's configuration (architecture)\nThe model's weights\nThe model's optimizer's state (if any)\nThus models can be reinstantiated in the exact same state."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/rgb_to_grayscale",
    "content": "Convert RGB images to grayscale.\ntf . keras . ops . image . rgb_to_grayscale ( image , data_format = 'channels_last' )\ntf . keras . ops . image . rgb_to_grayscale ( image , data_format = 'channels_last' )\nThis function converts RGB images to grayscale images. It supports both\n3D and 4D tensors, where the last dimension represents channels.\nArgs\nArgs\nimage Input RGB image or batch of RGB images. Must be a 3D tensor\nwith shape (height, width, channels) or a 4D tensor with shape (batch, height, width, channels) . data_format A string specifying the data format of the input tensor.\nIt can be either \"channels_last\" or \"channels_first\" . \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) , while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) .\nDefaults to \"channels_last\" .\nimage\n(height, width, channels)\n(batch, height, width, channels)\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\n\"channels_last\"\nReturns Grayscale image or batch of grayscale images.\nReturns\nimport numpy as np from keras.src import ops x = np . random . random (( 2 , 4 , 4 , 3 )) y = ops . image . rgb_to_grayscale ( x ) y . shape ( 2 , 4 , 4 , 1 )\nimport numpy as np\nfrom keras.src import ops\nx = np . random . random (( 2 , 4 , 4 , 3 ))\ny = ops . image . rgb_to_grayscale ( x )\ny . shape\n( 2 , 4 , 4 , 1 )\nx = np . random . random (( 4 , 4 , 3 )) # Single RGB image y = ops . image . rgb_to_grayscale ( x ) y . shape ( 4 , 4 , 1 )\nx = np . random . random (( 4 , 4 , 3 )) # Single RGB image\ny = ops . image . rgb_to_grayscale ( x )\ny . shape\n( 4 , 4 , 1 )\nx = np . random . random (( 2 , 3 , 4 , 4 )) y = ops . image . rgb_to_grayscale ( x , data_format = \"channels_first\" ) y . shape ( 2 , 1 , 4 , 4 )\nx = np . random . random (( 2 , 3 , 4 , 4 ))\ny = ops . image . rgb_to_grayscale ( x , data_format = \"channels_first\" )\ny . shape\n( 2 , 1 , 4 , 4 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/backend",
    "content": "Publicly accessible method for determining the current backend.\nMain aliases tf.keras.config.backend\ntf.keras.config.backend\ntf.keras.config.backend\ntf . keras . backend . backend ()\ntf . keras . backend . backend ()\nReturns String, the name of the backend Keras is currently using. One of \"tensorflow\" , \"torch\" , or \"jax\" .\nReturns\n\"tensorflow\"\n\"torch\"\n\"jax\"\nkeras . config . backend () 'tensorflow'\nkeras . config . backend ()\n'tensorflow'"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/Tversky",
    "content": "Computes the Tversky loss value between y_true and y_pred .\ny_true\ny_pred\nInherits From: Loss\nLoss\ntf . keras . losses . Tversky ( alpha = 0.5 , beta = 0.5 , reduction = 'sum_over_batch_size' , name = 'tversky' )\ntf . keras . losses . Tversky ( alpha = 0.5 , beta = 0.5 , reduction = 'sum_over_batch_size' , name = 'tversky' )\nThis loss function is weighted by the alpha and beta coefficients\nthat penalize false positives and false negatives.\nWith alpha=0.5 and beta=0.5 , the loss value becomes equivalent to\nDice Loss.\nalpha=0.5\nbeta=0.5\nArgs\nArgs\ny_true tensor of true targets. y_pred tensor of predicted targets. alpha coefficient controlling incidence of false positives. beta coefficient controlling incidence of false negatives.\ny_true\ny_pred\nalpha\nbeta\nReturns Tversky loss value.\nReturns\nSalehi et al., 2017\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log2",
    "content": "Base-2 logarithm of x , element-wise.\nx\nMain aliases tf.keras.ops.numpy.log2\ntf.keras.ops.numpy.log2\ntf.keras.ops.numpy.log2\ntf . keras . ops . log2 ( x )\ntf . keras . ops . log2 ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise base-2 logarithm of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ones_like",
    "content": "Return a tensor of ones with the same shape and type of x .\nx\nMain aliases tf.keras.ops.numpy.ones_like\ntf.keras.ops.numpy.ones_like\ntf.keras.ops.numpy.ones_like\ntf . keras . ops . ones_like ( x , dtype = None )\ntf . keras . ops . ones_like ( x , dtype = None )\nArgs\nArgs\nx Input tensor. dtype Overrides the data type of the result.\nx\ndtype\nReturns A tensor of ones with the same shape and type as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay",
    "content": "A LearningRateSchedule that uses a cosine decay with optional warmup.\nLearningRateSchedule\nInherits From: LearningRateSchedule\nLearningRateSchedule\ntf . keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps , alpha = 0.0 , name = 'CosineDecay' , warmup_target = None , warmup_steps = 0 )\ntf . keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps , alpha = 0.0 , name = 'CosineDecay' , warmup_target = None , warmup_steps = 0 )\nSee Loshchilov & Hutter, ICLR2016 ,\nSGDR: Stochastic Gradient Descent with Warm Restarts.\nFor the idea of a linear warmup of our learning rate,\nsee Goyal et al. .\nWhen we begin training a model, we often want an initial increase in our\nlearning rate followed by a decay. If warmup_target is an int, this\nschedule applies a linear increase per optimizer step to our learning rate\nfrom initial_learning_rate to warmup_target for a duration of warmup_steps . Afterwards, it applies a cosine decay function taking our\nlearning rate from warmup_target to alpha for a duration of decay_steps . If warmup_target is None we skip warmup and our decay\nwill take our learning rate from initial_learning_rate to alpha .\nIt requires a step value to  compute the learning rate. You can\njust pass a backend variable that you increment at each training step.\nwarmup_target\ninitial_learning_rate\nwarmup_target\nwarmup_steps\nwarmup_target\nalpha\ndecay_steps\nwarmup_target\ninitial_learning_rate\nalpha\nstep\nThe schedule is a 1-arg callable that produces a warmup followed by a\ndecayed learning rate when passed the current optimizer step. This can be\nuseful for changing the learning rate value across different invocations of\noptimizer functions.\nOur warmup is computed as:\ndef warmup_learning_rate ( step ): completed_fraction = step / warmup_steps total_delta = target_warmup - initial_learning_rate return completed_fraction * total_delta\ndef warmup_learning_rate ( step ): completed_fraction = step / warmup_steps total_delta = target_warmup - initial_learning_rate return completed_fraction * total_delta\nAnd our decay is computed as:\nif warmup_target is None : initial_decay_lr = initial_learning_rate else : initial_decay_lr = warmup_target def decayed_learning_rate ( step ): step = min ( step , decay_steps ) cosine_decay = 0.5 * ( 1 + cos ( pi * step / decay_steps )) decayed = ( 1 - alpha ) * cosine_decay + alpha return initial_decay_lr * decayed\nif warmup_target is None : initial_decay_lr = initial_learning_rate else : initial_decay_lr = warmup_target def decayed_learning_rate ( step ): step = min ( step , decay_steps ) cosine_decay = 0.5 * ( 1 + cos ( pi * step / decay_steps )) decayed = ( 1 - alpha ) * cosine_decay + alpha return initial_decay_lr * decayed\nExample usage without warmup:\ndecay_steps = 1000 initial_learning_rate = 0.1 lr_decayed_fn = keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps )\ndecay_steps = 1000 initial_learning_rate = 0.1 lr_decayed_fn = keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps )\nExample usage with warmup:\ndecay_steps = 1000 initial_learning_rate = 0 warmup_steps = 1000 target_learning_rate = 0.1 lr_warmup_decayed_fn = keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps , warmup_target = target_learning_rate , warmup_steps = warmup_steps )\ndecay_steps = 1000 initial_learning_rate = 0 warmup_steps = 1000 target_learning_rate = 0.1 lr_warmup_decayed_fn = keras . optimizers . schedules . CosineDecay ( initial_learning_rate , decay_steps , warmup_target = target_learning_rate , warmup_steps = warmup_steps )\nYou can pass this schedule directly into a keras.optimizers.Optimizer as the learning rate. The learning rate schedule is also serializable and\ndeserializable using keras.optimizers.schedules.serialize and keras.optimizers.schedules.deserialize .\nkeras.optimizers.Optimizer\nkeras.optimizers.schedules.serialize\nkeras.optimizers.schedules.deserialize\nArgs\nArgs\ninitial_learning_rate A Python float. The initial learning rate. decay_steps A Python int. Number of steps to decay over. alpha A Python float. Minimum learning rate value for decay as a\nfraction of initial_learning_rate . name String. Optional name of the operation.  Defaults to \"CosineDecay\" . warmup_target A Python float. The target learning rate for our\nwarmup phase. Will cast to the initial_learning_rate datatype.\nSetting to None will skip warmup and begins decay phase from initial_learning_rate . Otherwise scheduler will warmup from initial_learning_rate to warmup_target . warmup_steps A Python int. Number of steps to warmup over.\ninitial_learning_rate\ndecay_steps\nalpha\ninitial_learning_rate\nname\n\"CosineDecay\"\nwarmup_target\ninitial_learning_rate\nNone\ninitial_learning_rate\ninitial_learning_rate\nwarmup_target\nwarmup_steps\nReturns A 1-arg callable learning rate schedule that takes the current optimizer\nstep and outputs the decayed learning rate, a scalar tensor of the\nsame type as initial_learning_rate .\nReturns\ninitial_learning_rate\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a LearningRateSchedule from its config.\nLearningRateSchedule\nArgs\nconfig Output of get_config() .\nconfig\nget_config()\nReturns A LearningRateSchedule instance.\nLearningRateSchedule\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( step )\n__call__ ( step )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/Constraint",
    "content": "Base class for weight constraints.\nA Constraint instance works like a stateless function.\nUsers who subclass this\nclass should override the __call__() method, which takes a single\nweight parameter and return a projected version of that parameter\n(e.g. normalized or clipped). Constraints can be used with various Keras\nlayers via the kernel_constraint or bias_constraint arguments.\nConstraint\n__call__()\nkernel_constraint\nbias_constraint\nHere's a simple example of a non-negative weight constraint:\nclass NonNegative ( keras . constraints . Constraint ): def __call__ ( self , w ): return w * ops . cast ( ops . greater_equal ( w , 0. ), dtype = w . dtype )\nclass NonNegative ( keras . constraints . Constraint ):\ndef __call__ ( self , w ):\nreturn w * ops . cast ( ops . greater_equal ( w , 0. ), dtype = w . dtype )\nweight = ops . convert_to_tensor (( - 1.0 , 1.0 )) NonNegative ()( weight ) [ 0. , 1. ]\nweight = ops . convert_to_tensor (( - 1.0 , 1.0 ))\nNonNegative ()( weight )\n[ 0. , 1. ]\nkeras . layers . Dense ( 4 , kernel_constraint = NonNegative ())\nkeras . layers . Dense ( 4 , kernel_constraint = NonNegative ())\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a weight constraint from a configuration dictionary.\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns A keras.constraints.Constraint instance.\nkeras.constraints.Constraint\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns a Python dict of the object config.\nA constraint config is a Python dictionary (JSON-serializable) that can\nbe used to reinstantiate the same object.\nReturns Python dict containing the configuration of the constraint object.\n__call__\n__call__\nView source\n__call__ ( w )\n__call__ ( w )\nApplies the constraint to the input weight variable.\nBy default, the inputs weight variable is not modified.\nUsers should override this method to implement their own projection\nfunction.\nArgs\nw Input weight variable.\nw\nReturns Projected variable (by default, returns unmodified inputs)."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/legacy",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Adagrad\nclass Adagrad\nclass Adam\nclass Adam\nclass Ftrl\nclass Ftrl\nclass Optimizer\nclass Optimizer\nclass RMSprop\nclass RMSprop\nclass SGD\nclass SGD"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/disable_traceback_filtering",
    "content": "Turn off traceback filtering.\ntf . keras . config . disable_traceback_filtering ()\ntf . keras . config . disable_traceback_filtering ()\nRaw Keras tracebacks (also known as stack traces)\ninvolve many internal frames, which can be\nchallenging to read through, while not being actionable for end users.\nBy default, Keras filters internal frames in most exceptions that it\nraises, to keep traceback short, readable, and focused on what's\nactionable for you (your own code).\nSee also keras.config.enable_traceback_filtering() and keras.config.is_traceback_filtering_enabled() .\nkeras.config.enable_traceback_filtering()\nkeras.config.is_traceback_filtering_enabled()\nIf you have previously disabled traceback filtering via keras.config.disable_traceback_filtering() , you can re-enable it via keras.config.enable_traceback_filtering() .\nkeras.config.disable_traceback_filtering()\nkeras.config.enable_traceback_filtering()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RecallAtPrecision",
    "content": "Computes best recall where precision is >= specified value.\nInherits From: Metric\nMetric\ntf . keras . metrics . RecallAtPrecision ( precision , num_thresholds = 200 , class_id = None , name = None , dtype = None )\ntf . keras . metrics . RecallAtPrecision ( precision , num_thresholds = 200 , class_id = None , name = None , dtype = None )\nFor a given score-label-distribution the required precision might not\nbe achievable, in this case 0.0 is returned as recall.\nThis metric creates four local variables, true_positives , true_negatives , false_positives and false_negatives that are used to\ncompute the recall at the given precision. The threshold for the given\nprecision value is computed and used to evaluate the corresponding recall.\ntrue_positives\ntrue_negatives\nfalse_positives\nfalse_negatives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nIf class_id is specified, we calculate precision by considering only the\nentries in the batch for which class_id is above the threshold\npredictions, and computing the fraction of them for which class_id is\nindeed a correct label.\nclass_id\nclass_id\nclass_id\nArgs\nArgs\nprecision A scalar value in range [0, 1] . num_thresholds (Optional) Defaults to 200. The number of thresholds\nto use for matching the given precision. class_id (Optional) Integer class ID for which we want binary metrics.\nThis must be in the half-open interval [0, num_classes) , where num_classes is the last dimension of predictions. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nprecision\n[0, 1]\nnum_thresholds\nclass_id\n[0, num_classes)\nnum_classes\nname\ndtype\nm = keras . metrics . RecallAtPrecision ( 0.8 ) m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ]) m . result () 0.5\nm = keras . metrics . RecallAtPrecision ( 0.8 )\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ])\nm . result ()\n0.5\nm . reset_state () m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ], sample_weight = [ 1 , 0 , 0 , 1 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ],\nsample_weight = [ 1 , 0 , 0 , 1 ])\nm . result ()\n1.0\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . RecallAtPrecision ( precision = 0.8 )])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . RecallAtPrecision ( precision = 0.8 )])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model",
    "content": "Clone a Functional or Sequential Model instance.\nModel\ntf . keras . models . clone_model ( model , input_tensors = None , clone_function = None , call_function = None , recursive = False , ** kwargs )\ntf . keras . models . clone_model ( model , input_tensors = None , clone_function = None , call_function = None , recursive = False , ** kwargs )\nUsed in the notebooks\nScalable model compression\nFederated Learning for Text Generation\nModel cloning is similar to calling a model on new inputs,\nexcept that it creates new layers (and thus new weights) instead\nof sharing the weights of the existing layers.\nNote that clone_model will not preserve the uniqueness of shared objects within the\nmodel (e.g. a single variable attached to two distinct layers will be\nrestored as two separate variables).\nclone_model\nArgs\nArgs\nmodel Instance of Model (could be a Functional model or a Sequential model). input_tensors optional list of input tensors or InputLayer objects\nto build the model upon. If not provided,\nnew Input objects will be created. clone_function Callable with signature fn(layer) to be used to clone each layer in the target\nmodel (except Input instances). It takes as argument the\nlayer instance to be cloned, and returns the corresponding layer\ninstance to be used in the model copy. If unspecified, this callable\ndefaults to the following serialization/deserialization function: lambda layer: layer.__class__.from_config(layer.get_config()) .\nBy passing a custom callable, you can customize your copy of the\nmodel, e.g. by wrapping certain layers of interest (you might want\nto replace all LSTM instances with equivalent Bidirectional(LSTM(...)) instances, for example).\nDefaults to None . call_function Callable with signature fn(layer, *args, **kwargs) to be used to call each\ncloned layer and a set of inputs. It takes the layer instance,\nthe call arguments and keyword arguments, and returns the\ncall outputs. If unspecified, this callable defaults to\nthe regular __call__() method: def fn(layer, *args, **kwargs): return layer(*args, **kwargs) .\nBy passing a custom callable, you can insert new layers before or\nafter a given layer. Note: this argument can only be used with\nFunctional models. recursive Boolean. Whether to recursively clone any Sequential\nor Functional models encountered in the original\nSequential/Functional model. If False ,\nthen inner models are cloned by calling clone_function() .\nIf True , then inner models are cloned by calling clone_model() with the same clone_function , call_function , and recursive arguments. Note that in this case, call_function will not be propagated to any Sequential model\n(since it is not applicable to Sequential models).\nmodel\nModel\ninput_tensors\nInput\nclone_function\nfn(layer)\nInput\nlambda layer: layer.__class__.from_config(layer.get_config())\nLSTM\nBidirectional(LSTM(...))\nNone\ncall_function\nfn(layer, *args, **kwargs)\n__call__()\ndef fn(layer, *args, **kwargs): return layer(*args, **kwargs)\nrecursive\nFalse\nclone_function()\nTrue\nclone_model()\nclone_function\ncall_function\nrecursive\ncall_function\nReturns An instance of Model reproducing the behavior\nof the original model, on top of new inputs tensors,\nusing newly instantiated weights. The cloned model may behave\ndifferently from the original model if a custom clone_function or call_function modifies a layer or layer call.\nReturns\nModel\nclone_function\ncall_function\n# Create a test Sequential model. model = keras . Sequential ([ keras . layers . Input ( shape = ( 728 ,)), keras . layers . Dense ( 32 , activation = 'relu' ), keras . layers . Dense ( 1 , activation = 'sigmoid' ), ]) # Create a copy of the test model (with freshly initialized weights). new_model = clone_model ( model )\n# Create a test Sequential model. model = keras . Sequential ([ keras . layers . Input ( shape = ( 728 ,)), keras . layers . Dense ( 32 , activation = 'relu' ), keras . layers . Dense ( 1 , activation = 'sigmoid' ), ]) # Create a copy of the test model (with freshly initialized weights). new_model = clone_model ( model )\nUsing a clone_function to make a model deterministic by setting the\nrandom seed everywhere:\nclone_function\ndef clone_function ( layer ): config = layer . get_config () if \"seed\" in config : config [ \"seed\" ] = 1337 return layer . __class__ . from_config ( config ) new_model = clone_model ( model )\ndef clone_function ( layer ): config = layer . get_config () if \"seed\" in config : config [ \"seed\" ] = 1337 return layer . __class__ . from_config ( config ) new_model = clone_model ( model )\nUsing a call_function to add a Dropout layer after each Dense layer\n(without recreating new layers):\ncall_function\nDropout\nDense\ndef call_function ( layer , * args , ** kwargs ): out = layer ( * args , ** kwargs ) if isinstance ( layer , keras . layers . Dense ): out = keras . layers . Dropout ( 0.5 )( out ) return out new_model = clone_model ( model , clone_function = lambda x : x , # Reuse the same layers. call_function = call_function , )\ndef call_function ( layer , * args , ** kwargs ): out = layer ( * args , ** kwargs ) if isinstance ( layer , keras . layers . Dense ): out = keras . layers . Dropout ( 0.5 )( out ) return out new_model = clone_model ( model , clone_function = lambda x : x , # Reuse the same layers. call_function = call_function , )\nNote that subclassed models cannot be cloned by default,\nsince their internal layer structure is not known.\nTo achieve equivalent functionality\nas clone_model in the case of a subclassed model, simply make sure\nthat the model class implements get_config() (and optionally from_config() ), and call:\nclone_model\nget_config()\nfrom_config()\nnew_model = model . __class__ . from_config ( model . get_config ())\nnew_model = model . __class__ . from_config ( model . get_config ())\nIn the case of a subclassed model, you cannot using a custom clone_function .\nclone_function"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy",
    "content": "Computes the crossentropy loss between the labels and predictions.\nInherits From: Loss\nLoss\ntf . keras . losses . SparseCategoricalCrossentropy ( from_logits = False , ignore_class = None , reduction = 'sum_over_batch_size' , name = 'sparse_categorical_crossentropy' )\ntf . keras . losses . SparseCategoricalCrossentropy ( from_logits = False , ignore_class = None , reduction = 'sum_over_batch_size' , name = 'sparse_categorical_crossentropy' )\nUsed in the notebooks\nEffective Tensorflow 2\nMigrate early stopping\nMigrate the fault tolerance mechanism\nUse TPUs\ntf.data: Build TensorFlow input pipelines\nLoad text\nDistributed training with Keras\nImage segmentation\nSave and load a model using a distribution strategy\nImage classification\nUse this crossentropy loss function when there are two or more label\nclasses.  We expect labels to be provided as integers. If you want to\nprovide labels using one-hot representation, please use CategoricalCrossentropy loss.  There should be # classes floating point\nvalues per feature for y_pred and a single floating point value per\nfeature for y_true .\none-hot\nCategoricalCrossentropy\n# classes\ny_pred\ny_true\nIn the snippet below, there is a single floating point value per example for y_true and num_classes floating pointing values per example for y_pred . The shape of y_true is [batch_size] and the shape of y_pred is [batch_size, num_classes] .\ny_true\nnum_classes\ny_pred\ny_true\n[batch_size]\ny_pred\n[batch_size, num_classes]\nArgs\nArgs\nfrom_logits Whether y_pred is expected to be a logits tensor. By\ndefault, we assume that y_pred encodes a probability distribution. reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nfrom_logits\ny_pred\ny_pred\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\ny_true = [ 1 , 2 ] y_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]] # Using 'auto'/'sum_over_batch_size' reduction type. scce = keras . losses . SparseCategoricalCrossentropy () scce ( y_true , y_pred ) 1.177\ny_true = [ 1 , 2 ]\ny_pred = [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]\n# Using 'auto'/'sum_over_batch_size' reduction type.\nscce = keras . losses . SparseCategoricalCrossentropy ()\nscce ( y_true , y_pred )\n1.177\n# Calling with 'sample_weight'. scce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ])) 0.814\n# Calling with 'sample_weight'.\nscce ( y_true , y_pred , sample_weight = np . array ([ 0.3 , 0.7 ]))\n0.814\n# Using 'sum' reduction type. scce = keras . losses . SparseCategoricalCrossentropy ( reduction = \"sum\" ) scce ( y_true , y_pred ) 2.354\n# Using 'sum' reduction type.\nscce = keras . losses . SparseCategoricalCrossentropy (\nreduction = \"sum\" )\nscce ( y_true , y_pred )\n2.354\n# Using 'none' reduction type. scce = keras . losses . SparseCategoricalCrossentropy ( reduction = None ) scce ( y_true , y_pred ) array ([ 0.0513 , 2.303 ], dtype = float32 )\n# Using 'none' reduction type.\nscce = keras . losses . SparseCategoricalCrossentropy (\nreduction = None )\nscce ( y_true , y_pred )\narray ([ 0.0513 , 2.303 ], dtype = float32 )\nUsage with the compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = keras . losses . SparseCategoricalCrossentropy ())\nmodel . compile ( optimizer = 'sgd' , loss = keras . losses . SparseCategoricalCrossentropy ())\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/normal",
    "content": "Draw random samples from a normal (Gaussian) distribution.\ntf . keras . random . normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\ntf . keras . random . normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\nArgs\nArgs\nshape The shape of the random values to generate. mean Float, defaults to 0. Mean of the random values to generate. stddev Float, defaults to 1. Standard deviation of the random values\nto generate. dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ). seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nmean\nstddev\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/array_to_img",
    "content": "Converts a 3D NumPy array to a PIL Image instance.\nMain aliases tf.keras.preprocessing.image.array_to_img\ntf.keras.preprocessing.image.array_to_img\ntf.keras.preprocessing.image.array_to_img\ntf . keras . utils . array_to_img ( x , data_format = None , scale = True , dtype = None )\ntf . keras . utils . array_to_img ( x , data_format = None , scale = True , dtype = None )\nUsed in the notebooks\nImage segmentation\nSemantic Segmentation with Model Garden\nAdversarial regularization for image classification\nfrom PIL import Image img = np . random . random ( size = ( 100 , 100 , 3 )) pil_img = keras . utils . array_to_img ( img )\nfrom PIL import Image img = np . random . random ( size = ( 100 , 100 , 3 )) pil_img = keras . utils . array_to_img ( img )\nArgs\nArgs\nx Input data, in any form that can be converted to a NumPy array. data_format Image data format, can be either \"channels_first\" or \"channels_last\" . Defaults to None , in which case the global\nsetting keras.backend.image_data_format() is used (unless you\nchanged it, it defaults to \"channels_last\" ). scale Whether to rescale the image such that minimum and maximum values\nare 0 and 255 respectively. Defaults to True . dtype Dtype to use. None means the global setting keras.backend.floatx() is used (unless you changed it, it\ndefaults to \"float32\" ). Defaults to None .\nx\ndata_format\n\"channels_first\"\n\"channels_last\"\nNone\nkeras.backend.image_data_format()\n\"channels_last\"\nscale\nTrue\ndtype\nNone\nkeras.backend.floatx()\n\"float32\"\nNone\nReturns A PIL Image instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nResNet50(...) : Instantiates the ResNet50 architecture.\nResNet50(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/in_top_k",
    "content": "Checks if the targets are in the top-k predictions.\ntf . keras . ops . in_top_k ( targets , predictions , k )\ntf . keras . ops . in_top_k ( targets , predictions , k )\nArgs\nArgs\ntargets A tensor of true labels. predictions A tensor of predicted labels. k An integer representing the number of predictions to consider.\ntargets\npredictions\nk\nReturns A boolean tensor of the same shape as targets , where each element\nindicates whether the corresponding target is in the top-k predictions.\nReturns\ntargets\ntargets = keras . ops . convert_to_tensor ([ 2 , 5 , 3 ]) predictions = keras . ops . convert_to_tensor ( [[ 0.1 , 0.4 , 0.6 , 0.9 , 0.5 ], [ 0.1 , 0.7 , 0.9 , 0.8 , 0.3 ], [ 0.1 , 0.6 , 0.9 , 0.9 , 0.5 ]]) in_top_k ( targets , predictions , k = 3 ) array ([ True False True ], shape = ( 3 ,), dtype = bool )\ntargets = keras . ops . convert_to_tensor ([ 2 , 5 , 3 ])\npredictions = keras . ops . convert_to_tensor (\n[[ 0.1 , 0.4 , 0.6 , 0.9 , 0.5 ],\n[ 0.1 , 0.7 , 0.9 , 0.8 , 0.3 ],\n[ 0.1 , 0.6 , 0.9 , 0.9 , 0.5 ]])\nin_top_k ( targets , predictions , k = 3 )\narray ([ True False True ], shape = ( 3 ,), dtype = bool )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/greater_equal",
    "content": "Return the truth value of x1 >= x2 element-wise.\nx1 >= x2\nMain aliases tf.keras.ops.numpy.greater_equal\ntf.keras.ops.numpy.greater_equal\ntf.keras.ops.numpy.greater_equal\ntf . keras . ops . greater_equal ( x1 , x2 )\ntf . keras . ops . greater_equal ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise comparison of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nMobileNet(...) : Instantiates the MobileNet architecture.\nMobileNet(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\nMain aliases tf.keras.applications.resnet50.preprocess_input\ntf.keras.applications.resnet50.preprocess_input\ntf.keras.applications.resnet50.preprocess_input\ntf . keras . applications . resnet . preprocess_input ( x , data_format = None )\ntf . keras . applications . resnet . preprocess_input ( x , data_format = None )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe images are converted from RGB to BGR, then each color channel is\nzero-centered with respect to the ImageNet dataset, without scaling.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/matmul",
    "content": "Matrix product of two tensors.\nMain aliases tf.keras.ops.numpy.matmul\ntf.keras.ops.numpy.matmul\ntf.keras.ops.numpy.matmul\ntf . keras . ops . matmul ( x1 , x2 )\ntf . keras . ops . matmul ( x1 , x2 )\nIf both tensors are 1-dimensional, the dot product (scalar) is returned.\nIf either tensor is N-D, N > 2, it is treated as a stack of matrices\nresiding in the last two indexes and broadcast accordingly.\nIf the first tensor is 1-D, it is promoted to a matrix by prepending\na 1 to its dimensions. After matrix multiplication the prepended\n1 is removed.\nIf the second tensor is 1-D, it is promoted to a matrix by appending a 1\nto its dimensions. After matrix multiplication the appended 1 is removed.\nArgs\nArgs\nx1 First tensor. x2 Second tensor.\nx1\nx2\nReturns Output tensor, matrix product of the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv1D",
    "content": "1D separable convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.SeparableConvolution1D\ntf.keras.layers.SeparableConvolution1D\ntf.keras.layers.SeparableConvolution1D\ntf . keras . layers . SeparableConv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , depth_multiplier = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , pointwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , pointwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , pointwise_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . SeparableConv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , depth_multiplier = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , pointwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , pointwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , pointwise_constraint = None , bias_constraint = None , ** kwargs )\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf use_bias is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.\nuse_bias\nArgs\nArgs\nfilters int, the dimensionality of the output space (i.e. the number\nof filters in the pointwise convolution). kernel_size int or tuple/list of 1 integers, specifying the size of the\ndepthwise convolution window. strides int or tuple/list of 1 integers, specifying the stride length\nof the depthwise convolution. If only one int is specified, the same\nstride size will be used for all dimensions. strides > 1 is\nincompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated convolution. If only one int is specified,\nthe same dilation rate will be used for all dimensions. depth_multiplier The number of depthwise convolution output channels\nfor each input channel. The total number of depthwise convolution\noutput channels will be equal to input_channel * depth_multiplier . activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. depthwise_initializer An initializer for the depthwise convolution\nkernel. If None, then the default initializer ( \"glorot_uniform\" )\nwill be used. pointwise_initializer An initializer for the pointwise convolution\nkernel. If None, then the default initializer ( \"glorot_uniform\" )\nwill be used. bias_initializer An initializer for the bias vector. If None, the\ndefault initializer ('\"zeros\"') will be used. depthwise_regularizer Optional regularizer for the depthwise\nconvolution kernel. pointwise_regularizer Optional regularizer for the pointwise\nconvolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. depthwise_constraint Optional projection function to be applied to the\ndepthwise kernel after being updated by an Optimizer (e.g. used\nfor norm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). pointwise_constraint Optional projection function to be applied to the\npointwise kernel after being updated by an Optimizer . bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\ndepth_multiplier\ninput_channel * depth_multiplier\nactivation\nNone\nuse_bias\nTrue\ndepthwise_initializer\n\"glorot_uniform\"\npointwise_initializer\n\"glorot_uniform\"\nbias_initializer\ndepthwise_regularizer\npointwise_regularizer\nbias_regularizer\nactivity_regularizer\ndepthwise_constraint\nOptimizer\npointwise_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, steps, channels)\ndata_format=\"channels_last\"\n(batch_shape, steps, channels)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, channels, steps)\ndata_format=\"channels_first\"\n(batch_shape, channels, steps)\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, new_steps, filters)\ndata_format=\"channels_last\"\n(batch_shape, new_steps, filters)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, filters, new_steps)\ndata_format=\"channels_first\"\n(batch_shape, filters, new_steps)\nReturns A 3D tensor representing activation(separable_conv1d(inputs, kernel) + bias) .\nReturns\nactivation(separable_conv1d(inputs, kernel) + bias)\nx = np . random . rand ( 4 , 10 , 12 ) y = keras . layers . SeparableConv1D ( 3 , 4 , 3 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 4 , 4 )\nx = np . random . rand ( 4 , 10 , 12 )\ny = keras . layers . SeparableConv1D ( 3 , 4 , 3 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 4 , 4 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/solve_triangular",
    "content": "Solves a linear system of equations given by a x = b .\na x = b\nMain aliases tf.keras.ops.linalg.solve_triangular\ntf.keras.ops.linalg.solve_triangular\ntf.keras.ops.linalg.solve_triangular\ntf . keras . ops . solve_triangular ( a , b , lower = False )\ntf . keras . ops . solve_triangular ( a , b , lower = False )\nArgs\nArgs\na A tensor of shape (..., M, M) representing the coefficients matrix. b A tensor of shape (..., M) or (..., M, N) represeting the\nright-hand side or \"dependent variable\" matrix.\na\n(..., M, M)\nb\n(..., M)\n(..., M, N)\nReturns A tensor of shape (..., M) or (..., M, N) representing the solution\nof the linear system. Returned shape is identical to b .\nReturns\n(..., M)\n(..., M, N)\nb"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nlegacy module: DO NOT EDIT.\nlegacy\nClasses\nclass CustomObjectScope : Exposes custom classes/functions to Keras deserialization internals.\nclass CustomObjectScope\nclass FeatureSpace : One-stop utility for preprocessing and encoding structured data.\nclass FeatureSpace\nclass Progbar : Displays a progress bar.\nclass Progbar\nclass PyDataset : Base class for defining a parallel dataset using Python code.\nclass PyDataset\nclass Sequence : Base class for defining a parallel dataset using Python code.\nclass Sequence\nclass custom_object_scope : Exposes custom classes/functions to Keras deserialization internals.\nclass custom_object_scope\nFunctions\narray_to_img(...) : Converts a 3D NumPy array to a PIL Image instance.\narray_to_img(...)\naudio_dataset_from_directory(...) : Generates a tf.data.Dataset from audio files in a directory.\naudio_dataset_from_directory(...)\ntf.data.Dataset\nclear_session(...) : Resets all state generated by Keras.\nclear_session(...)\ndeserialize_keras_object(...) : Retrieve the object by deserializing the config dict.\ndeserialize_keras_object(...)\ndisable_interactive_logging(...) : Turn off interactive logging.\ndisable_interactive_logging(...)\nenable_interactive_logging(...) : Turn on interactive logging.\nenable_interactive_logging(...)\nget_custom_objects(...) : Retrieves a live reference to the global dictionary of custom objects.\nget_custom_objects(...)\nget_file(...) : Downloads a file from a URL if it not already in the cache.\nget_file(...)\nget_registered_name(...) : Returns the name registered to an object within the Keras framework.\nget_registered_name(...)\nget_registered_object(...) : Returns the class associated with name if it is registered with Keras.\nget_registered_object(...)\nname\nget_source_inputs(...) : Returns the list of input tensors necessary to compute tensor .\nget_source_inputs(...)\ntensor\nimage_dataset_from_directory(...) : Generates a tf.data.Dataset from image files in a directory.\nimage_dataset_from_directory(...)\ntf.data.Dataset\nimg_to_array(...) : Converts a PIL Image instance to a NumPy array.\nimg_to_array(...)\nis_interactive_logging_enabled(...) : Check if interactive logging is enabled.\nis_interactive_logging_enabled(...)\nis_keras_tensor(...) : Returns whether x is a Keras tensor.\nis_keras_tensor(...)\nx\nload_img(...) : Loads an image into PIL format.\nload_img(...)\nmodel_to_dot(...) : Convert a Keras model to dot format.\nmodel_to_dot(...)\nnormalize(...) : Normalizes an array.\nnormalize(...)\npack_x_y_sample_weight(...) : Packs user-provided data into a tuple.\npack_x_y_sample_weight(...)\npad_sequences(...) : Pads sequences to the same length.\npad_sequences(...)\nplot_model(...) : Converts a Keras model to dot format and save to a file.\nplot_model(...)\nregister_keras_serializable(...) : Registers an object with the Keras serialization framework.\nregister_keras_serializable(...)\nsave_img(...) : Saves an image stored as a NumPy array to a path or file object.\nsave_img(...)\nserialize_keras_object(...) : Retrieve the config dict by serializing the Keras object.\nserialize_keras_object(...)\nset_random_seed(...) : Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).\nset_random_seed(...)\nsplit_dataset(...) : Splits a dataset into a left half and a right half (e.g. train / test).\nsplit_dataset(...)\nstandardize_dtype(...)\nstandardize_dtype(...)\ntext_dataset_from_directory(...) : Generates a tf.data.Dataset from text files in a directory.\ntext_dataset_from_directory(...)\ntf.data.Dataset\ntimeseries_dataset_from_array(...) : Creates a dataset of sliding windows over a timeseries provided as array.\ntimeseries_dataset_from_array(...)\nto_categorical(...) : Converts a class vector (integers) to binary class matrix.\nto_categorical(...)\nunpack_x_y_sample_weight(...) : Unpacks user-provided data tuple.\nunpack_x_y_sample_weight(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy",
    "content": "Computes the cross-entropy loss between true labels and predicted labels.\nInherits From: Loss\nLoss\ntf . keras . losses . BinaryCrossentropy ( from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'binary_crossentropy' )\ntf . keras . losses . BinaryCrossentropy ( from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'binary_crossentropy' )\nUsed in the notebooks\nDistributed training with TensorFlow\nEstimators\nMigrate `tf.feature_column`s to Keras preprocessing layers\nUsing Counterfactual Logit Pairing with Keras\nLoad a pandas DataFrame\nTransfer learning and fine-tuning\nBasic text classification\nParameter server training with ParameterServerStrategy\nCycleGAN\nUse this cross-entropy loss for binary (0 or 1) classification applications.\nThe loss function requires the following inputs:\ny_true (true label): This is either 0 or 1.\ny_true\ny_pred (predicted value): This is the model's prediction, i.e, a single\nfloating-point value which either represents a logit , (i.e, value in [-inf, inf]\nwhen from_logits=True ) or a probability (i.e, value in [0., 1.] when from_logits=False ).\ny_pred\nfrom_logits=True\nfrom_logits=False\nArgs\nArgs\nfrom_logits Whether to interpret y_pred as a tensor of logit values. By default, we\nassume that y_pred is probabilities (i.e., values in [0, 1]). label_smoothing Float in range [0, 1]. When 0, no smoothing occurs.\nWhen > 0, we compute the loss between the predicted labels\nand a smoothed version of the true labels, where the smoothing\nsqueezes the labels towards 0.5. Larger values of label_smoothing correspond to heavier smoothing. axis The axis along which to compute crossentropy (the features axis).\nDefaults to -1 . reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\nfrom_logits\ny_pred\ny_pred\nlabel_smoothing\nlabel_smoothing\naxis\n-1\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nRecommended Usage: (set from_logits=True )\nfrom_logits=True\nWith compile() API:\ncompile()\nmodel . compile ( loss = keras . losses . BinaryCrossentropy ( from_logits = True ), ... )\nmodel . compile ( loss = keras . losses . BinaryCrossentropy ( from_logits = True ), ... )\nAs a standalone function:\n# Example 1: (batch_size = 1, number of samples = 4) y_true = [ 0 , 1 , 0 , 0 ] y_pred = [ - 18.6 , 0.51 , 2.94 , - 12.8 ] bce = keras . losses . BinaryCrossentropy ( from_logits = True ) bce ( y_true , y_pred ) 0.865\n# Example 1: (batch_size = 1, number of samples = 4)\ny_true = [ 0 , 1 , 0 , 0 ]\ny_pred = [ - 18.6 , 0.51 , 2.94 , - 12.8 ]\nbce = keras . losses . BinaryCrossentropy ( from_logits = True )\nbce ( y_true , y_pred )\n0.865\n# Example 2: (batch_size = 2, number of samples = 4) y_true = [[ 0 , 1 ], [ 0 , 0 ]] y_pred = [[ - 18.6 , 0.51 ], [ 2.94 , - 12.8 ]] # Using default 'auto'/'sum_over_batch_size' reduction type. bce = keras . losses . BinaryCrossentropy ( from_logits = True ) bce ( y_true , y_pred ) 0.865 # Using 'sample_weight' attribute bce ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ]) 0.243 # Using 'sum' reduction` type. bce = keras . losses . BinaryCrossentropy ( from_logits = True , reduction = \"sum\" ) bce ( y_true , y_pred ) 1.730 # Using 'none' reduction type. bce = keras . losses . BinaryCrossentropy ( from_logits = True , reduction = None ) bce ( y_true , y_pred ) array ([ 0.235 , 1.496 ], dtype = float32 )\n# Example 2: (batch_size = 2, number of samples = 4)\ny_true = [[ 0 , 1 ], [ 0 , 0 ]]\ny_pred = [[ - 18.6 , 0.51 ], [ 2.94 , - 12.8 ]]\n# Using default 'auto'/'sum_over_batch_size' reduction type.\nbce = keras . losses . BinaryCrossentropy ( from_logits = True )\nbce ( y_true , y_pred )\n0.865\n# Using 'sample_weight' attribute\nbce ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ])\n0.243\n# Using 'sum' reduction` type.\nbce = keras . losses . BinaryCrossentropy ( from_logits = True ,\nreduction = \"sum\" )\nbce ( y_true , y_pred )\n1.730\n# Using 'none' reduction type.\nbce = keras . losses . BinaryCrossentropy ( from_logits = True ,\nreduction = None )\nbce ( y_true , y_pred )\narray ([ 0.235 , 1.496 ], dtype = float32 )\nDefault Usage: (set from_logits=False )\nfrom_logits=False\n# Make the following updates to the above \"Recommended Usage\" section # 1. Set `from_logits=False` keras . losses . BinaryCrossentropy () # OR ...('from_logits=False') # 2. Update `y_pred` to use probabilities instead of logits y_pred = [ 0.6 , 0.3 , 0.2 , 0.8 ] # OR [[0.6, 0.3], [0.2, 0.8]]\n# Make the following updates to the above \"Recommended Usage\" section\n# 1. Set `from_logits=False`\nkeras . losses . BinaryCrossentropy () # OR ...('from_logits=False')\n# 2. Update `y_pred` to use probabilities instead of logits\ny_pred = [ 0.6 , 0.3 , 0.2 , 0.8 ] # OR [[0.6, 0.3], [0.2, 0.8]]\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model",
    "content": "Loads a model saved via model.save() .\nmodel.save()\ntf . keras . models . load_model ( filepath , custom_objects = None , compile = True , safe_mode = True )\ntf . keras . models . load_model ( filepath , custom_objects = None , compile = True , safe_mode = True )\nUsed in the notebooks\nIntroduction to modules, layers, and models\nMigrate `tf.feature_column`s to Keras preprocessing layers\nMigrate the SavedModel workflow\nMigrating your TFLite code to TF2\nMulti-GPU and distributed training\nSave and load a model using a distribution strategy\nSave and load models\nDistributed training with Keras\nMulti-worker training with Keras\nTransfer learning with TensorFlow Hub\nArgs\nArgs\nfilepath str or pathlib.Path object, path to the saved model file. custom_objects Optional dictionary mapping names\n(strings) to custom classes or functions to be\nconsidered during deserialization. compile Boolean, whether to compile the model after loading. safe_mode Boolean, whether to disallow unsafe lambda deserialization.\nWhen safe_mode=False , loading an object has the potential to\ntrigger arbitrary code execution. This argument is only\napplicable to the Keras v3 model format. Defaults to True .\nfilepath\nstr\npathlib.Path\ncustom_objects\ncompile\nsafe_mode\nlambda\nsafe_mode=False\nTrue\nReturns A Keras model instance. If the original model was compiled,\nand the argument compile=True is set, then the returned model\nwill be compiled. Otherwise, the model will be left uncompiled.\nReturns\ncompile=True\nmodel = keras . Sequential ([ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax ()]) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = np . random . random (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nmodel = keras . Sequential ([ keras . layers . Dense ( 5 , input_shape = ( 3 ,)), keras . layers . Softmax ()]) model . save ( \"model.keras\" ) loaded_model = keras . saving . load_model ( \"model.keras\" ) x = np . random . random (( 10 , 3 )) assert np . allclose ( model . predict ( x ), loaded_model . predict ( x ))\nNote that the model variables may have different name values\n( var.name property, e.g. \"dense_1/kernel:0\" ) after being reloaded.\nIt is recommended that you use layer attributes to\naccess specific variables, e.g. model.get_layer(\"dense_1\").kernel .\nvar.name\n\"dense_1/kernel:0\"\nmodel.get_layer(\"dense_1\").kernel"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM",
    "content": "Long Short-Term Memory layer - Hochreiter 1997.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . LSTM ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , use_cudnn = 'auto' , ** kwargs )\ntf . keras . layers . LSTM ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , use_cudnn = 'auto' , ** kwargs )\nUsed in the notebooks\nRagged tensors\nTime series forecasting\nGenerate music with an RNN\nText classification with an RNN\nLoad metrics from Prometheus server\nGraph regularization for sentiment classification using synthesized graphs\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\nThe requirements to use the cuDNN implementation are:\nactivation == tanh\nactivation\ntanh\nrecurrent_activation == sigmoid\nrecurrent_activation\nsigmoid\ndropout == 0 and recurrent_dropout == 0\ndropout\nrecurrent_dropout\nunroll is False\nunroll\nFalse\nuse_bias is True\nuse_bias\nTrue\nInputs, if use masking, are strictly right-padded.\nEager execution is enabled in the outermost context.\ninputs = np . random . random (( 32 , 10 , 8 )) lstm = keras . layers . LSTM ( 4 ) output = lstm ( inputs ) output . shape ( 32 , 4 ) lstm = keras . layers . LSTM ( 4 , return_sequences = True , return_state = True ) whole_seq_output , final_memory_state , final_carry_state = lstm ( inputs ) whole_seq_output . shape ( 32 , 10 , 4 ) final_memory_state . shape ( 32 , 4 ) final_carry_state . shape ( 32 , 4 )\ninputs = np . random . random (( 32 , 10 , 8 ))\nlstm = keras . layers . LSTM ( 4 )\noutput = lstm ( inputs )\noutput . shape\n( 32 , 4 )\nlstm = keras . layers . LSTM (\n4 , return_sequences = True , return_state = True )\nwhole_seq_output , final_memory_state , final_carry_state = lstm ( inputs )\nwhole_seq_output . shape\n( 32 , 10 , 4 )\nfinal_memory_state . shape\n( 32 , 4 )\nfinal_carry_state . shape\n( 32 , 4 )\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use.\nDefault: hyperbolic tangent ( tanh ).\nIf you pass None , no activation is applied\n(ie. \"linear\" activation: a(x) = x ). recurrent_activation Activation function to use\nfor the recurrent step.\nDefault: sigmoid ( sigmoid ).\nIf you pass None , no activation is applied\n(ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer\nshould use a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent\nstate. Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . unit_forget_bias Boolean (default True ). If True ,\nadd 1 to the bias of the forget gate at initialization.\nSetting it to True will also force bias_initializer=\"zeros\" .\nThis is recommended in Jozefowicz et al. kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . activity_regularizer Regularizer function applied to the output of the\nlayer (its \"activation\"). Default: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. Default: 0. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. Default: 0. seed Random seed for dropout. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state in addition\nto the output. Default: False . go_backwards Boolean (default: False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default: False ). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default False).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences. use_cudnn Whether to use a cuDNN-backed implementation. \"auto\" will\nattempt to use cuDNN when feasible, and will fallback to the\ndefault implementation if not.\nunits\nactivation\ntanh\nNone\na(x) = x\nrecurrent_activation\nsigmoid\nNone\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nunit_forget_bias\nTrue\nTrue\nTrue\nbias_initializer=\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nactivity_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nseed\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nFalse\nTrue\nunroll\nTrue\nuse_cudnn\n\"auto\"\nCall arguments\nCall arguments\ninputs A 3D tensor, with shape (batch, timesteps, feature) . mask Binary tensor of shape (samples, timesteps) indicating whether\na given timestep should be masked  (optional).\nAn individual True entry indicates that the corresponding timestep\nshould be utilized, while a False entry indicates that the\ncorresponding timestep should be ignored. Defaults to None . training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. This argument is passed to the\ncell when calling it. This is only relevant if dropout or recurrent_dropout is used  (optional). Defaults to None . initial_state List of initial state tensors to be passed to the first\ncall of the cell (optional, None causes creation\nof zero-filled initial state tensors). Defaults to None .\ninputs\n(batch, timesteps, feature)\nmask\n(samples, timesteps)\nTrue\nFalse\nNone\ntraining\ndropout\nrecurrent_dropout\nNone\ninitial_state\nNone\nNone\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndropout\ndropout\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. recurrent_activation\nrecurrent_activation\nrecurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nunit_forget_bias\nunit_forget_bias\nunits\nunits\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/var",
    "content": "DEPRECATED.\ntf . keras . backend . var ( x , axis = None , keepdims = False )\ntf . keras . backend . var ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/lu_factor",
    "content": "Computes the lower-upper decomposition of a square matrix.\nMain aliases tf.keras.ops.linalg.lu_factor\ntf.keras.ops.linalg.lu_factor\ntf.keras.ops.linalg.lu_factor\ntf . keras . ops . lu_factor ( x )\ntf . keras . ops . lu_factor ( x )\nArgs\nArgs\nx A tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tuple of two tensors: a tensor of shape (..., M, M) containing the\nlower and upper triangular matrices and a tensor of shape (..., M) containing the pivots.\nReturns\n(..., M, M)\n(..., M)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/OneHotIoU",
    "content": "Computes the Intersection-Over-Union metric for one-hot encoded labels.\nInherits From: IoU , Metric\nIoU\nMetric\ntf . keras . metrics . OneHotIoU ( num_classes , target_class_ids , name = None , dtype = None , ignore_class = None , sparse_y_pred = False , axis =- 1 )\ntf . keras . metrics . OneHotIoU ( num_classes , target_class_ids , name = None , dtype = None , ignore_class = None , sparse_y_pred = False , axis =- 1 )\niou = true_positives / ( true_positives + false_positives + false_negatives )\niou = true_positives / ( true_positives + false_positives + false_negatives )\nIntersection-Over-Union is a common evaluation metric for semantic image\nsegmentation.\nTo compute IoUs, the predictions are accumulated in a confusion matrix,\nweighted by sample_weight and the metric is then calculated from it.\nsample_weight\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nThis class can be used to compute IoU for multi-class classification tasks\nwhere the labels are one-hot encoded (the last axis should have one\ndimension per class). Note that the predictions should also have the same\nshape. To compute the IoU, first the labels and predictions are converted\nback into integer format by taking the argmax over the class axis. Then the\nsame computation steps as for the base IoU class apply.\nIoU\nNote, if there is only one channel in the labels and predictions, this class\nis the same as class IoU . In this case, use IoU instead.\nIoU\nIoU\nAlso, make sure that num_classes is equal to the number of classes in the\ndata, to avoid a \"labels out of bound\" error when the confusion matrix is\ncomputed.\nnum_classes\nArgs\nArgs\nnum_classes The possible number of labels the prediction task can have. target_class_ids A tuple or list of target class ids for which the\nmetric is returned. To compute IoU for a specific class, a list\n(or tuple) of a single id value should be provided. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. ignore_class Optional integer. The ID of a class to be ignored during\nmetric computation. This is useful, for example, in segmentation\nproblems featuring a \"void\" class (commonly -1 or 255) in\nsegmentation maps. By default ( ignore_class=None ), all classes are\nconsidered. sparse_y_pred Whether predictions are encoded using integers or\ndense floating point vectors. If False , the argmax function\nis used to determine each sample's most likely associated label. axis (Optional) The dimension containing the logits. Defaults to -1 .\nnum_classes\ntarget_class_ids\nname\ndtype\nignore_class\nignore_class=None\nsparse_y_pred\nFalse\nargmax\naxis\n-1\ny_true = np . array ([[ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 1 , 0 , 0 ]]) y_pred = np . array ([[ 0.2 , 0.3 , 0.5 ], [ 0.1 , 0.2 , 0.7 ], [ 0.5 , 0.3 , 0.1 ], [ 0.1 , 0.4 , 0.5 ]]) sample_weight = [ 0.1 , 0.2 , 0.3 , 0.4 ] m = keras . metrics . OneHotIoU ( num_classes = 3 , target_class_ids = [ 0 , 2 ]) m . update_state ( y_true = y_true , y_pred = y_pred , sample_weight = sample_weight ) # cm = [[0, 0, 0.2+0.4], #       [0.3, 0, 0], #       [0, 0, 0.1]] # sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1] # true_positives = [0, 0, 0.1] # single_iou = true_positives / (sum_row + sum_col - true_positives)) # mean_iou = (0 / (0.3 + 0.6 - 0) + 0.1 / (0.7 + 0.1 - 0.1)) / 2 m . result () 0.071\ny_true = np . array ([[ 0 , 0 , 1 ], [ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 1 , 0 , 0 ]])\ny_pred = np . array ([[ 0.2 , 0.3 , 0.5 ], [ 0.1 , 0.2 , 0.7 ], [ 0.5 , 0.3 , 0.1 ],\n[ 0.1 , 0.4 , 0.5 ]])\nsample_weight = [ 0.1 , 0.2 , 0.3 , 0.4 ]\nm = keras . metrics . OneHotIoU ( num_classes = 3 , target_class_ids = [ 0 , 2 ])\nm . update_state (\ny_true = y_true , y_pred = y_pred , sample_weight = sample_weight )\n# cm = [[0, 0, 0.2+0.4],\n#       [0.3, 0, 0],\n#       [0, 0, 0.1]]\n# sum_row = [0.3, 0, 0.7], sum_col = [0.6, 0.3, 0.1]\n# true_positives = [0, 0, 0.1]\n# single_iou = true_positives / (sum_row + sum_col - true_positives))\n# mean_iou = (0 / (0.3 + 0.6 - 0) + 0.1 / (0.7 + 0.1 - 0.1)) / 2\nm . result ()\n0.071\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . OneHotIoU ( num_classes = 3 , target_class_id = [ 1 ] )] )\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . OneHotIoU ( num_classes = 3 , target_class_id = [ 1 ] )] )\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the intersection-over-union via the confusion matrix.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same as y_true ,\nand must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/zeros",
    "content": "Return a new tensor of given shape and type, filled with zeros.\nMain aliases tf.keras.ops.numpy.zeros\ntf.keras.ops.numpy.zeros\ntf.keras.ops.numpy.zeros\ntf . keras . ops . zeros ( shape , dtype = None )\ntf . keras . ops . zeros ( shape , dtype = None )\nArgs\nArgs\nshape Shape of the new tensor. dtype Desired data type of the tensor.\nshape\ndtype\nReturns Tensor of zeros with the given shape and dtype.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/update_add",
    "content": "DEPRECATED.\ntf . keras . backend . update_add ( x , increment )\ntf . keras . backend . update_add ( x , increment )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . imagenet_utils . preprocess_input ( x , data_format = None , mode = 'caffe' )\ntf . keras . applications . imagenet_utils . preprocess_input ( x , data_format = None , mode = 'caffe' )\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs x: A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used.\ndata_format: Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\"). mode One of \"caffe\", \"tf\" or \"torch\".\nArgs\nnumpy.array\nnumpy.copy(x)\nkeras.backend.image_data_format()\nmode\ncaffe: will convert the images from RGB to BGR,\nthen will zero-center each color channel with\nrespect to the ImageNet dataset,\nwithout scaling.\ntf: will scale pixels between -1 and 1,\nsample-wise.\ntorch: will scale pixels between 0 and 1 and then\nwill normalize each channel with respect to the\nImageNet dataset.\nDefaults to \"caffe\" . Defaults to None .\ntorch: will scale pixels between 0 and 1 and then\nwill normalize each channel with respect to the\nImageNet dataset.\nDefaults to \"caffe\" .\n\"caffe\"\nDefaults to None .\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nRaises\nRaises\nValueError In case of unknown mode or data_format argument.\nValueError\nmode\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/softsign",
    "content": "Softsign activation function.\nMain aliases tf.keras.ops.nn.softsign\ntf.keras.ops.nn.softsign\ntf.keras.ops.nn.softsign\ntf . keras . ops . softsign ( x )\ntf . keras . ops . softsign ( x )\nIt is defined as f(x) = x / (abs(x) + 1) .\nf(x) = x / (abs(x) + 1)\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 0.100 , - 10.0 , 1.0 , 0.0 , 100.0 ]) keras . ops . softsign ( x ) Array ([ - 0.09090909 , - 0.90909094 , 0.5 , 0.0 , 0.990099 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 0.100 , - 10.0 , 1.0 , 0.0 , 100.0 ])\nkeras . ops . softsign ( x )\nArray ([ - 0.09090909 , - 0.90909094 , 0.5 , 0.0 , 0.990099 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/is_int_dtype",
    "content": "tf . keras . backend . is_int_dtype ( dtype )\ntf . keras . backend . is_int_dtype ( dtype )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/repeat",
    "content": "DEPRECATED.\ntf . keras . backend . repeat ( x , n )\ntf . keras . backend . repeat ( x , n )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sparse_categorical_crossentropy",
    "content": "Computes sparse categorical cross-entropy loss.\nMain aliases tf.keras.ops.nn.sparse_categorical_crossentropy\ntf.keras.ops.nn.sparse_categorical_crossentropy\ntf.keras.ops.nn.sparse_categorical_crossentropy\ntf . keras . ops . sparse_categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )\ntf . keras . ops . sparse_categorical_crossentropy ( target , output , from_logits = False , axis =- 1 )\nThe sparse categorical cross-entropy loss is similar to categorical\ncross-entropy, but it is used when the target tensor contains integer\nclass labels instead of one-hot encoded vectors. It measures the\ndissimilarity between the target and output probabilities or logits.\nArgs\nArgs\ntarget The target tensor representing the true class labels as\nintegers. Its shape should match the shape of the output tensor except for the last dimension. output The output tensor representing the predicted probabilities\nor logits.\nIts shape should match the shape of the target tensor except\nfor the last dimension. from_logits (optional) Whether output is a tensor of logits\nor probabilities.\nSet it to True if output represents logits; otherwise,\nset it to False if output represents probabilities.\nDefaults to False . axis (optional) The axis along which the sparse categorical\ncross-entropy is computed.\nDefaults to -1 , which corresponds to the last dimension\nof the tensors.\ntarget\noutput\noutput\ntarget\nfrom_logits\noutput\nTrue\noutput\nFalse\noutput\nFalse\naxis\n-1\nReturns Integer tensor: The computed sparse categorical cross-entropy\nloss between target and output .\nReturns\ntarget\noutput\ntarget = keras . ops . convert_to_tensor ([ 0 , 1 , 2 ], dtype = int32 ) output = keras . ops . convert_to_tensor ( [[ 0.9 , 0.05 , 0.05 ], [ 0.1 , 0.8 , 0.1 ], [ 0.2 , 0.3 , 0.5 ]]) sparse_categorical_crossentropy ( target , output ) array ([ 0.10536056 0.22314355 0.6931472 ], shape = ( 3 ,), dtype = float32 )\ntarget = keras . ops . convert_to_tensor ([ 0 , 1 , 2 ], dtype = int32 )\noutput = keras . ops . convert_to_tensor (\n[[ 0.9 , 0.05 , 0.05 ],\n[ 0.1 , 0.8 , 0.1 ],\n[ 0.2 , 0.3 , 0.5 ]])\nsparse_categorical_crossentropy ( target , output )\narray ([ 0.10536056 0.22314355 0.6931472 ], shape = ( 3 ,), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/prod",
    "content": "DEPRECATED.\ntf . keras . backend . prod ( x , axis = None , keepdims = False )\ntf . keras . backend . prod ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/moments",
    "content": "Calculates the mean and variance of x .\nx\nMain aliases tf.keras.ops.nn.moments\ntf.keras.ops.nn.moments\ntf.keras.ops.nn.moments\ntf . keras . ops . moments ( x , axes , keepdims = False , synchronized = False )\ntf . keras . ops . moments ( x , axes , keepdims = False , synchronized = False )\nThe mean and variance are calculated by aggregating the contents of x across axes . If x is 1-D and axes = [0] this is just the mean and\nvariance of a vector.\nx\naxes\nx\naxes = [0]\nArgs\nArgs\nx Input tensor. axes A list of axes which to compute mean and variance. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one. synchronized Only applicable with the TensorFlow backend.\nIf True , synchronizes the global batch statistics (mean and\nvariance) across all devices at each training step in a\ndistributed training strategy. If False , each replica uses its own\nlocal batch statistics.\nx\naxes\nkeepdims\nTrue\nsynchronized\nTrue\nFalse\nReturns A tuple containing two tensors - mean and variance.\nReturns\nx = keras . ops . convert_to_tensor ([ 0 , 1 , 2 , 3 , 100 ], dtype = \"float32\" ) keras . ops . moments ( x , axes = [ 0 ]) ( array ( 21.2 , dtype = float32 ), array ( 1553.3601 , dtype = float32 ))\nx = keras . ops . convert_to_tensor ([ 0 , 1 , 2 , 3 , 100 ], dtype = \"float32\" )\nkeras . ops . moments ( x , axes = [ 0 ])\n( array ( 21.2 , dtype = float32 ), array ( 1553.3601 , dtype = float32 ))"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/negative",
    "content": "Numerical negative, element-wise.\nMain aliases tf.keras.ops.numpy.negative\ntf.keras.ops.numpy.negative\ntf.keras.ops.numpy.negative\ntf . keras . ops . negative ( x )\ntf . keras . ops . negative ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, y = -x .\nReturns\ny = -x"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Variable",
    "content": "Represents a backend-agnostic variable in Keras.\nCompat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Variable\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Variable\ntf.compat.v1.keras.Variable\ntf . keras . Variable ( initializer , shape = None , dtype = None , trainable = True , autocast = True , aggregation = 'mean' , name = None )\ntf . keras . Variable ( initializer , shape = None , dtype = None , trainable = True , autocast = True , aggregation = 'mean' , name = None )\nA Variable acts as a container for state. It holds a tensor value and can\nbe updated. With the JAX backend, variables are used to implement\n\"functionalization\", the pattern of lifting stateful operations out of\na piece of computation to turn it into a stateless function.\nVariable\nArgs\nArgs\ninitializer Initial value or callable for initialization.\nIf a callable is used, it should take the arguments shape and dtype . shape Optional. Tuple for the variable's shape.\nRequired if initializer is a callable. dtype Optional. Data type of the variable. Defaults to the global float\ndtype type ( \"float32\" if never configured). trainable Optional. Boolean indicating if variable is trainable.\nDefaults to True . name Optional. A unique name for the variable. Automatically generated\nif not set.\ninitializer\nshape\ndtype\nshape\ninitializer\ndtype\n\"float32\"\ntrainable\nTrue\nname\nInitializing a Variable with a NumPy array:\nVariable\nimport numpy as np import keras initial_array = np . ones (( 3 , 3 )) variable_from_array = keras . Variable ( initializer = initial_array )\nimport numpy as np import keras initial_array = np . ones (( 3 , 3 )) variable_from_array = keras . Variable ( initializer = initial_array )\nUsing a Keras initializer to create a Variable :\nVariable\nfrom keras.src.initializers import Ones variable_from_initializer = keras . Variable ( initializer = Ones (), shape = ( 3 , 3 ), dtype = \"float32\" )\nfrom keras.src.initializers import Ones variable_from_initializer = keras . Variable ( initializer = Ones (), shape = ( 3 , 3 ), dtype = \"float32\" )\nUpdating the value of a Variable :\nVariable\nnew_value = np . zeros (( 3 , 3 ), dtype = \"float32\" ) variable_from_array . assign ( new_value )\nnew_value = np . zeros (( 3 , 3 ), dtype = \"float32\" ) variable_from_array . assign ( new_value )\nMarking a Variable as non-trainable:\nVariable\nnon_trainable_variable = keras . Variable ( initializer = np . ones (( 3 , 3 ), dtype = \"float32\" ), trainable = False )\nnon_trainable_variable = keras . Variable ( initializer = np . ones (( 3 , 3 ), dtype = \"float32\" ), trainable = False )\nAttributes\nAttributes\nname The name of the variable (string). path The path of the variable within the Keras model or layer (string). dtype The data type of the variable (string). shape The shape of the variable (tuple of integers). ndim The number of dimensions of the variable (integer). trainable Whether the variable is trainable (boolean). value The current value of the variable (NumPy array or tensor). aggregation\nname\npath\ndtype\nshape\nndim\ntrainable\nvalue\naggregation\nconstraint\nconstraint\nhandle\nhandle\noverwrite_with_gradient Whether this variable should be overwritten by the gradient.\noverwrite_with_gradient\nThis property is designed for a special case where we want to overwrite\nthe variable directly with its computed gradient. For example, in float8\ntraining, new scale and amax_history are computed as gradients, and\nwe want to overwrite them directly instead of following the typical\nprocedure such as gradient descent with a learning rate, gradient\nclipping and weight decaying. regularizer\nscale\namax_history\nregularizer\nMethods\nassign\nassign\nView source\nassign ( value )\nassign ( value )\nassign_add\nassign_add\nView source\nassign_add ( value )\nassign_add ( value )\nassign_sub\nassign_sub\nView source\nassign_sub ( value )\nassign_sub ( value )\nnumpy\nnumpy\nView source\nnumpy ()\nnumpy ()\n__abs__\n__abs__\nView source\n__abs__ ()\n__abs__ ()\n__add__\n__add__\nView source\n__add__ ( other )\n__add__ ( other )\n__and__\n__and__\nView source\n__and__ ( other )\n__and__ ( other )\n__array__\n__array__\nView source\n__array__ ( dtype = None )\n__array__ ( dtype = None )\n__bool__\n__bool__\nView source\n__bool__ ()\n__bool__ ()\n__eq__\n__eq__\nView source\n__eq__ ( other )\n__eq__ ( other )\nReturn self==value.\n__floordiv__\n__floordiv__\nView source\n__floordiv__ ( other )\n__floordiv__ ( other )\n__ge__\n__ge__\nView source\n__ge__ ( other )\n__ge__ ( other )\nReturn self>=value.\n__getitem__\n__getitem__\nView source\n__getitem__ ( idx )\n__getitem__ ( idx )\n__gt__\n__gt__\nView source\n__gt__ ( other )\n__gt__ ( other )\nReturn self>value.\n__invert__\n__invert__\nView source\n__invert__ ()\n__invert__ ()\n__le__\n__le__\nView source\n__le__ ( other )\n__le__ ( other )\nReturn self<=value.\n__lt__\n__lt__\nView source\n__lt__ ( other )\n__lt__ ( other )\nReturn self<value.\n__matmul__\n__matmul__\nView source\n__matmul__ ( other )\n__matmul__ ( other )\n__mod__\n__mod__\nView source\n__mod__ ( other )\n__mod__ ( other )\n__mul__\n__mul__\nView source\n__mul__ ( other )\n__mul__ ( other )\n__ne__\n__ne__\nView source\n__ne__ ( other )\n__ne__ ( other )\nReturn self!=value.\n__neg__\n__neg__\nView source\n__neg__ ()\n__neg__ ()\n__or__\n__or__\nView source\n__or__ ( other )\n__or__ ( other )\n__pos__\n__pos__\nView source\n__pos__ ()\n__pos__ ()\n__pow__\n__pow__\nView source\n__pow__ ( other )\n__pow__ ( other )\n__radd__\n__radd__\nView source\n__radd__ ( other )\n__radd__ ( other )\n__rand__\n__rand__\nView source\n__rand__ ( other )\n__rand__ ( other )\n__rfloordiv__\n__rfloordiv__\nView source\n__rfloordiv__ ( other )\n__rfloordiv__ ( other )\n__rmatmul__\n__rmatmul__\nView source\n__rmatmul__ ( other )\n__rmatmul__ ( other )\n__rmod__\n__rmod__\nView source\n__rmod__ ( other )\n__rmod__ ( other )\n__rmul__\n__rmul__\nView source\n__rmul__ ( other )\n__rmul__ ( other )\n__ror__\n__ror__\nView source\n__ror__ ( other )\n__ror__ ( other )\n__rpow__\n__rpow__\nView source\n__rpow__ ( other )\n__rpow__ ( other )\n__rsub__\n__rsub__\nView source\n__rsub__ ( other )\n__rsub__ ( other )\n__rtruediv__\n__rtruediv__\nView source\n__rtruediv__ ( other )\n__rtruediv__ ( other )\n__rxor__\n__rxor__\nView source\n__rxor__ ( other )\n__rxor__ ( other )\n__sub__\n__sub__\nView source\n__sub__ ( other )\n__sub__ ( other )\n__truediv__\n__truediv__\nView source\n__truediv__ ( other )\n__truediv__ ( other )\n__xor__\n__xor__\nView source\n__xor__ ( other )\n__xor__ ( other )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/map_fn",
    "content": "DEPRECATED.\ntf . keras . backend . map_fn ( fn , elems , name = None , dtype = None )\ntf . keras . backend . map_fn ( fn , elems , name = None , dtype = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the Fashion-MNIST dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_shift",
    "content": "DEPRECATED.\ntf . keras . preprocessing . image . random_shift ( x , wrg , hrg , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )\ntf . keras . preprocessing . image . random_shift ( x , wrg , hrg , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , interpolation_order = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError",
    "content": "Computes root mean squared error metric between y_true and y_pred .\ny_true\ny_pred\nInherits From: Mean , Metric\nMean\nMetric\ntf . keras . metrics . RootMeanSquaredError ( name = 'root_mean_squared_error' , dtype = None )\ntf . keras . metrics . RootMeanSquaredError ( name = 'root_mean_squared_error' , dtype = None )\nUsed in the notebooks\nRecommending movies: ranking\nDeep & Cross Network (DCN)\nListwise ranking\nMulti-task recommenders\nUsing TensorFlow Recommenders with TFX\nloss = sqrt ( mean (( y_pred - y_true ) ** 2 ))\nloss = sqrt ( mean (( y_pred - y_true ) ** 2 ))\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . RootMeanSquaredError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.5\nm = keras . metrics . RootMeanSquaredError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.5\nm . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 0.70710677\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.70710677\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . RootMeanSquaredError ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . RootMeanSquaredError ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates root mean squared error statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a Tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\nDefaults to 1 .\ny_true\ny_pred\nsample_weight\nTensor\ny_true\ny_true\n1\nReturns Update op.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/beta",
    "content": "Draw samples from a Beta distribution.\ntf . keras . random . beta ( shape , alpha , beta , dtype = None , seed = None )\ntf . keras . random . beta ( shape , alpha , beta , dtype = None , seed = None )\nThe values are drawm from a Beta distribution parametrized\nby alpha and beta.\nArgs\nArgs\nshape The shape of the random values to generate. alpha Float or an array of floats representing the first\nparameter alpha. Must be broadcastable with beta and shape . beta Float or an array of floats representing the second\nparameter beta. Must be broadcastable with alpha and shape . dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ). seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nalpha\nbeta\nshape\nbeta\nalpha\nshape\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/batch_normalization",
    "content": "DEPRECATED.\ntf . keras . backend . batch_normalization ( x , mean , var , beta , gamma , axis =- 1 , epsilon = 0.001 )\ntf . keras . backend . batch_normalization ( x , mean , var , beta , gamma , axis =- 1 , epsilon = 0.001 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/F1Score",
    "content": "Computes F-1 Score.\nInherits From: FBetaScore , Metric\nFBetaScore\nMetric\ntf . keras . metrics . F1Score ( average = None , threshold = None , name = 'f1_score' , dtype = None )\ntf . keras . metrics . F1Score ( average = None , threshold = None , name = 'f1_score' , dtype = None )\nf1_score = 2 * ( precision * recall ) / ( precision + recall )\nf1_score = 2 * ( precision * recall ) / ( precision + recall )\nThis is the harmonic mean of precision and recall.\nIts output range is [0, 1] . It works for both multi-class\nand multi-label classification.\n[0, 1]\nArgs\nArgs\naverage Type of averaging to be performed on data.\nAcceptable values are None , \"micro\" , \"macro\" and \"weighted\" . Defaults to None .\nIf None , no averaging is performed and result() will return\nthe score for each class.\nIf \"micro\" , compute metrics globally by counting the total\ntrue positives, false negatives and false positives.\nIf \"macro\" , compute metrics for each label,\nand return their unweighted mean.\nThis does not take label imbalance into account.\nIf \"weighted\" , compute metrics for each label,\nand return their average weighted by support\n(the number of true instances for each label).\nThis alters \"macro\" to account for label imbalance.\nIt can result in an score that is not between precision and recall. threshold Elements of y_pred greater than threshold are\nconverted to be 1, and the rest 0. If threshold is None , the argmax of y_pred is converted to 1, and the rest to 0. name Optional. String name of the metric instance. dtype Optional. Data type of the metric result.\naverage\nNone\n\"micro\"\n\"macro\"\n\"weighted\"\nNone\nNone\nresult()\n\"micro\"\n\"macro\"\n\"weighted\"\n\"macro\"\nthreshold\ny_pred\nthreshold\nthreshold\nNone\ny_pred\nname\ndtype\nReturns F-1 Score: float.\nReturns\nmetric = keras . metrics . F1Score ( threshold = 0.5 ) y_true = np . array ([[ 1 , 1 , 1 ], [ 1 , 0 , 0 ], [ 1 , 1 , 0 ]], np . int32 ) y_pred = np . array ([[ 0.2 , 0.6 , 0.7 ], [ 0.2 , 0.6 , 0.6 ], [ 0.6 , 0.8 , 0.0 ]], np . float32 ) metric . update_state ( y_true , y_pred ) result = metric . result () array ([ 0.5 , 0.8 , 0.6666667 ], dtype = float32 )\nmetric = keras . metrics . F1Score ( threshold = 0.5 )\ny_true = np . array ([[ 1 , 1 , 1 ],\n[ 1 , 0 , 0 ],\n[ 1 , 1 , 0 ]], np . int32 )\ny_pred = np . array ([[ 0.2 , 0.6 , 0.7 ],\n[ 0.2 , 0.6 , 0.6 ],\n[ 0.6 , 0.8 , 0.0 ]], np . float32 )\nmetric . update_state ( y_true , y_pred )\nresult = metric . result ()\narray ([ 0.5 , 0.8 , 0.6666667 ], dtype = float32 )\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU",
    "content": "Gated Recurrent Unit - Cho et al. 2014.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . GRU ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , reset_after = True , use_cudnn = 'auto' , ** kwargs )\ntf . keras . layers . GRU ( units , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , unroll = False , reset_after = True , use_cudnn = 'auto' , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nTransfer learning for video classification with MoViNet\nNeural machine translation with attention\nRecommending movies: retrieval using a sequential model\nText generation with an RNN\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\nThe requirements to use the cuDNN implementation are:\nactivation == tanh\nactivation\ntanh\nrecurrent_activation == sigmoid\nrecurrent_activation\nsigmoid\ndropout == 0 and recurrent_dropout == 0\ndropout\nrecurrent_dropout\nunroll is False\nunroll\nFalse\nuse_bias is True\nuse_bias\nTrue\nreset_after is True\nreset_after\nTrue\nInputs, if use masking, are strictly right-padded.\nEager execution is enabled in the outermost context.\nThere are two variants of the GRU implementation. The default one is based\non v3 and has reset gate applied to\nhidden state before matrix multiplication. The other one is based on original and has the order reversed.\nThe second variant is compatible with CuDNNGRU (GPU-only) and allows\ninference on CPU. Thus it has separate biases for kernel and recurrent_kernel . To use this variant, set reset_after=True and recurrent_activation='sigmoid' .\nkernel\nrecurrent_kernel\nreset_after=True\nrecurrent_activation='sigmoid'\ninputs = np . random . random (( 32 , 10 , 8 )) gru = keras . layers . GRU ( 4 ) output = gru ( inputs ) output . shape ( 32 , 4 ) gru = keras . layers . GRU ( 4 , return_sequences = True , return_state = True ) whole_sequence_output , final_state = gru ( inputs ) whole_sequence_output . shape ( 32 , 10 , 4 ) final_state . shape ( 32 , 4 )\ninputs = np . random . random (( 32 , 10 , 8 ))\ngru = keras . layers . GRU ( 4 )\noutput = gru ( inputs )\noutput . shape\n( 32 , 4 )\ngru = keras . layers . GRU ( 4 , return_sequences = True , return_state = True )\nwhole_sequence_output , final_state = gru ( inputs )\nwhole_sequence_output . shape\n( 32 , 10 , 4 )\nfinal_state . shape\n( 32 , 4 )\nArgs\nArgs\nunits Positive integer, dimensionality of the output space. activation Activation function to use.\nDefault: hyperbolic tangent ( tanh ).\nIf you pass None , no activation is applied\n(ie. \"linear\" activation: a(x) = x ). recurrent_activation Activation function to use\nfor the recurrent step.\nDefault: sigmoid ( sigmoid ).\nIf you pass None , no activation is applied\n(ie. \"linear\" activation: a(x) = x ). use_bias Boolean, (default True ), whether the layer\nshould use a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. Default: \"glorot_uniform\" . recurrent_initializer Initializer for the recurrent_kernel weights matrix, used for the linear transformation of the recurrent\nstate. Default: \"orthogonal\" . bias_initializer Initializer for the bias vector. Default: \"zeros\" . kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. Default: None . recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. Default: None . bias_regularizer Regularizer function applied to the bias vector.\nDefault: None . activity_regularizer Regularizer function applied to the output of the\nlayer (its \"activation\"). Default: None . kernel_constraint Constraint function applied to the kernel weights\nmatrix. Default: None . recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. Default: None . bias_constraint Constraint function applied to the bias vector.\nDefault: None . dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. Default: 0. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. Default: 0. seed Random seed for dropout. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state in addition\nto the output. Default: False . go_backwards Boolean (default False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default: False ). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default: False ).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences. reset_after GRU convention (whether to apply reset gate after or\nbefore matrix multiplication). False is \"before\" , True is \"after\" (default and cuDNN compatible). use_cudnn Whether to use a cuDNN-backed implementation. \"auto\" will\nattempt to use cuDNN when feasible, and will fallback to the\ndefault implementation if not.\nunits\nactivation\ntanh\nNone\na(x) = x\nrecurrent_activation\nsigmoid\nNone\na(x) = x\nuse_bias\nTrue\nkernel_initializer\nkernel\n\"glorot_uniform\"\nrecurrent_initializer\nrecurrent_kernel\n\"orthogonal\"\nbias_initializer\n\"zeros\"\nkernel_regularizer\nkernel\nNone\nrecurrent_regularizer\nrecurrent_kernel\nNone\nbias_regularizer\nNone\nactivity_regularizer\nNone\nkernel_constraint\nkernel\nNone\nrecurrent_constraint\nrecurrent_kernel\nNone\nbias_constraint\nNone\ndropout\nrecurrent_dropout\nseed\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nFalse\nTrue\nunroll\nFalse\nTrue\nreset_after\nFalse\n\"before\"\nTrue\n\"after\"\nuse_cudnn\n\"auto\"\nCall arguments\nCall arguments\ninputs A 3D tensor, with shape (batch, timesteps, feature) . mask Binary tensor of shape (samples, timesteps) indicating whether\na given timestep should be masked  (optional).\nAn individual True entry indicates that the corresponding timestep\nshould be utilized, while a False entry indicates that the\ncorresponding timestep should be ignored. Defaults to None . training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode. This argument is passed to the\ncell when calling it. This is only relevant if dropout or recurrent_dropout is used  (optional). Defaults to None . initial_state List of initial state tensors to be passed to the first\ncall of the cell (optional, None causes creation\nof zero-filled initial state tensors). Defaults to None .\ninputs\n(batch, timesteps, feature)\nmask\n(samples, timesteps)\nTrue\nFalse\nNone\ntraining\ndropout\nrecurrent_dropout\nNone\ninitial_state\nNone\nNone\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndropout\ndropout\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. recurrent_activation\nrecurrent_activation\nrecurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nreset_after\nreset_after\nunits\nunits\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/isnan",
    "content": "Test element-wise for NaN and return result as a boolean tensor.\nMain aliases tf.keras.ops.numpy.isnan\ntf.keras.ops.numpy.isnan\ntf.keras.ops.numpy.isnan\ntf . keras . ops . isnan ( x )\ntf . keras . ops . isnan ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output boolean tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/get_item",
    "content": "Return x[key] .\nx[key]\nMain aliases tf.keras.ops.numpy.get_item\ntf.keras.ops.numpy.get_item\ntf.keras.ops.numpy.get_item\ntf . keras . ops . get_item ( x , key )\ntf . keras . ops . get_item ( x , key )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/TensorLayout",
    "content": "A layout to apply to a tensor.\ntf . keras . distribution . TensorLayout ( axes , device_mesh = None )\ntf . keras . distribution . TensorLayout ( axes , device_mesh = None )\nThis API is aligned with jax.sharding.NamedSharding and tf.dtensor.Layout .\njax.sharding.NamedSharding\ntf.dtensor.Layout\nSee more details in jax.sharding.NamedSharding and tf.dtensor.Layout .\nArgs\nArgs\naxes tuple of strings that should map to the axis_names in\na DeviceMesh . For any dimensions that doesn't need any sharding,\nA None can be used a placeholder. device_mesh Optional DeviceMesh that will be used to create\nthe layout. The actual mapping of tensor to physical device\nis not known until the mesh is specified.\naxes\naxis_names\nDeviceMesh\nNone\ndevice_mesh\nDeviceMesh\nAttributes\nAttributes\naxes\naxes\ndevice_mesh\ndevice_mesh"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass Activation : Applies an activation function to an output.\nclass Activation\nclass ActivityRegularization : Layer that applies an update to the cost function based input activity.\nclass ActivityRegularization\nclass Add : Performs elementwise addition operation.\nclass Add\nclass AdditiveAttention : Additive attention layer, a.k.a. Bahdanau-style attention.\nclass AdditiveAttention\nclass AlphaDropout : DEPRECATED.\nclass AlphaDropout\nclass Attention : Dot-product attention layer, a.k.a. Luong-style attention.\nclass Attention\nclass Average : Averages a list of inputs element-wise..\nclass Average\nclass AveragePooling1D : Average pooling for temporal data.\nclass AveragePooling1D\nclass AveragePooling2D : Average pooling operation for 2D spatial data.\nclass AveragePooling2D\nclass AveragePooling3D : Average pooling operation for 3D data (spatial or spatio-temporal).\nclass AveragePooling3D\nclass AvgPool1D : Average pooling for temporal data.\nclass AvgPool1D\nclass AvgPool2D : Average pooling operation for 2D spatial data.\nclass AvgPool2D\nclass AvgPool3D : Average pooling operation for 3D data (spatial or spatio-temporal).\nclass AvgPool3D\nclass BatchNormalization : Layer that normalizes its inputs.\nclass BatchNormalization\nclass Bidirectional : Bidirectional wrapper for RNNs.\nclass Bidirectional\nclass CategoryEncoding : A preprocessing layer which encodes integer features.\nclass CategoryEncoding\nclass CenterCrop : A preprocessing layer which crops images.\nclass CenterCrop\nclass Concatenate : Concatenates a list of inputs.\nclass Concatenate\nclass Conv1D : 1D convolution layer (e.g. temporal convolution).\nclass Conv1D\nclass Conv1DTranspose : 1D transposed convolution layer.\nclass Conv1DTranspose\nclass Conv2D : 2D convolution layer.\nclass Conv2D\nclass Conv2DTranspose : 2D transposed convolution layer.\nclass Conv2DTranspose\nclass Conv3D : 3D convolution layer.\nclass Conv3D\nclass Conv3DTranspose : 3D transposed convolution layer.\nclass Conv3DTranspose\nclass ConvLSTM1D : 1D Convolutional LSTM.\nclass ConvLSTM1D\nclass ConvLSTM2D : 2D Convolutional LSTM.\nclass ConvLSTM2D\nclass ConvLSTM3D : 3D Convolutional LSTM.\nclass ConvLSTM3D\nclass Convolution1D : 1D convolution layer (e.g. temporal convolution).\nclass Convolution1D\nclass Convolution1DTranspose : 1D transposed convolution layer.\nclass Convolution1DTranspose\nclass Convolution2D : 2D convolution layer.\nclass Convolution2D\nclass Convolution2DTranspose : 2D transposed convolution layer.\nclass Convolution2DTranspose\nclass Convolution3D : 3D convolution layer.\nclass Convolution3D\nclass Convolution3DTranspose : 3D transposed convolution layer.\nclass Convolution3DTranspose\nclass Cropping1D : Cropping layer for 1D input (e.g. temporal sequence).\nclass Cropping1D\nclass Cropping2D : Cropping layer for 2D input (e.g. picture).\nclass Cropping2D\nclass Cropping3D : Cropping layer for 3D data (e.g. spatial or spatio-temporal).\nclass Cropping3D\nclass Dense : Just your regular densely-connected NN layer.\nclass Dense\nclass DepthwiseConv1D : 1D depthwise convolution layer.\nclass DepthwiseConv1D\nclass DepthwiseConv2D : 2D depthwise convolution layer.\nclass DepthwiseConv2D\nclass Discretization : A preprocessing layer which buckets continuous features by ranges.\nclass Discretization\nclass Dot : Computes element-wise dot product of two tensors.\nclass Dot\nclass Dropout : Applies dropout to the input.\nclass Dropout\nclass ELU : Applies an Exponential Linear Unit function to an output.\nclass ELU\nclass EinsumDense : A layer that uses einsum as the backing computation.\nclass EinsumDense\neinsum\nclass Embedding : Turns positive integers (indexes) into dense vectors of fixed size.\nclass Embedding\nclass Flatten : Flattens the input. Does not affect the batch size.\nclass Flatten\nclass FlaxLayer : Keras Layer that wraps a Flax module.\nclass FlaxLayer\nclass GRU : Gated Recurrent Unit - Cho et al. 2014.\nclass GRU\nclass GRUCell : Cell class for the GRU layer.\nclass GRUCell\nclass GaussianDropout : Apply multiplicative 1-centered Gaussian noise.\nclass GaussianDropout\nclass GaussianNoise : Apply additive zero-centered Gaussian noise.\nclass GaussianNoise\nclass GlobalAveragePooling1D : Global average pooling operation for temporal data.\nclass GlobalAveragePooling1D\nclass GlobalAveragePooling2D : Global average pooling operation for 2D data.\nclass GlobalAveragePooling2D\nclass GlobalAveragePooling3D : Global average pooling operation for 3D data.\nclass GlobalAveragePooling3D\nclass GlobalAvgPool1D : Global average pooling operation for temporal data.\nclass GlobalAvgPool1D\nclass GlobalAvgPool2D : Global average pooling operation for 2D data.\nclass GlobalAvgPool2D\nclass GlobalAvgPool3D : Global average pooling operation for 3D data.\nclass GlobalAvgPool3D\nclass GlobalMaxPool1D : Global max pooling operation for temporal data.\nclass GlobalMaxPool1D\nclass GlobalMaxPool2D : Global max pooling operation for 2D data.\nclass GlobalMaxPool2D\nclass GlobalMaxPool3D : Global max pooling operation for 3D data.\nclass GlobalMaxPool3D\nclass GlobalMaxPooling1D : Global max pooling operation for temporal data.\nclass GlobalMaxPooling1D\nclass GlobalMaxPooling2D : Global max pooling operation for 2D data.\nclass GlobalMaxPooling2D\nclass GlobalMaxPooling3D : Global max pooling operation for 3D data.\nclass GlobalMaxPooling3D\nclass GroupNormalization : Group normalization layer.\nclass GroupNormalization\nclass GroupQueryAttention : Grouped Query Attention layer.\nclass GroupQueryAttention\nclass HashedCrossing : A preprocessing layer which crosses features using the \"hashing trick\".\nclass HashedCrossing\nclass Hashing : A preprocessing layer which hashes and bins categorical features.\nclass Hashing\nclass Identity : Identity layer.\nclass Identity\nclass InputLayer : This is the class from which all layers inherit.\nclass InputLayer\nclass InputSpec : Specifies the rank, dtype and shape of every input to a layer.\nclass InputSpec\nclass IntegerLookup : A preprocessing layer that maps integers to (possibly encoded) indices.\nclass IntegerLookup\nclass JaxLayer : Keras Layer that wraps a JAX model.\nclass JaxLayer\nclass LSTM : Long Short-Term Memory layer - Hochreiter 1997.\nclass LSTM\nclass LSTMCell : Cell class for the LSTM layer.\nclass LSTMCell\nclass Lambda : Wraps arbitrary expressions as a Layer object.\nclass Lambda\nLayer\nclass Layer : This is the class from which all layers inherit.\nclass Layer\nclass LayerNormalization : Layer normalization layer (Ba et al., 2016).\nclass LayerNormalization\nclass LeakyReLU : Leaky version of a Rectified Linear Unit activation layer.\nclass LeakyReLU\nclass Masking : Masks a sequence by using a mask value to skip timesteps.\nclass Masking\nclass MaxPool1D : Max pooling operation for 1D temporal data.\nclass MaxPool1D\nclass MaxPool2D : Max pooling operation for 2D spatial data.\nclass MaxPool2D\nclass MaxPool3D : Max pooling operation for 3D data (spatial or spatio-temporal).\nclass MaxPool3D\nclass MaxPooling1D : Max pooling operation for 1D temporal data.\nclass MaxPooling1D\nclass MaxPooling2D : Max pooling operation for 2D spatial data.\nclass MaxPooling2D\nclass MaxPooling3D : Max pooling operation for 3D data (spatial or spatio-temporal).\nclass MaxPooling3D\nclass Maximum : Computes element-wise maximum on a list of inputs.\nclass Maximum\nclass MelSpectrogram : A preprocessing layer to convert raw audio signals to Mel spectrograms.\nclass MelSpectrogram\nclass Minimum : Computes elementwise minimum on a list of inputs.\nclass Minimum\nclass MultiHeadAttention : MultiHeadAttention layer.\nclass MultiHeadAttention\nclass Multiply : Performs elementwise multiplication.\nclass Multiply\nclass Normalization : A preprocessing layer that normalizes continuous features.\nclass Normalization\nclass PReLU : Parametric Rectified Linear Unit activation layer.\nclass PReLU\nclass Permute : Permutes the dimensions of the input according to a given pattern.\nclass Permute\nclass RNN : Base class for recurrent layers.\nclass RNN\nclass RandomBrightness : A preprocessing layer which randomly adjusts brightness during training.\nclass RandomBrightness\nclass RandomContrast : A preprocessing layer which randomly adjusts contrast during training.\nclass RandomContrast\nclass RandomCrop : A preprocessing layer which randomly crops images during training.\nclass RandomCrop\nclass RandomFlip : A preprocessing layer which randomly flips images during training.\nclass RandomFlip\nclass RandomHeight : DEPRECATED.\nclass RandomHeight\nclass RandomRotation : A preprocessing layer which randomly rotates images during training.\nclass RandomRotation\nclass RandomTranslation : A preprocessing layer which randomly translates images during training.\nclass RandomTranslation\nclass RandomWidth : DEPRECATED.\nclass RandomWidth\nclass RandomZoom : A preprocessing layer which randomly zooms images during training.\nclass RandomZoom\nclass ReLU : Rectified Linear Unit activation function layer.\nclass ReLU\nclass RepeatVector : Repeats the input n times.\nclass RepeatVector\nclass Rescaling : A preprocessing layer which rescales input values to a new range.\nclass Rescaling\nclass Reshape : Layer that reshapes inputs into the given shape.\nclass Reshape\nclass Resizing : A preprocessing layer which resizes images.\nclass Resizing\nclass SeparableConv1D : 1D separable convolution layer.\nclass SeparableConv1D\nclass SeparableConv2D : 2D separable convolution layer.\nclass SeparableConv2D\nclass SeparableConvolution1D : 1D separable convolution layer.\nclass SeparableConvolution1D\nclass SeparableConvolution2D : 2D separable convolution layer.\nclass SeparableConvolution2D\nclass SimpleRNN : Fully-connected RNN where the output is to be fed back as the new input.\nclass SimpleRNN\nclass SimpleRNNCell : Cell class for SimpleRNN.\nclass SimpleRNNCell\nclass Softmax : Softmax activation layer.\nclass Softmax\nclass SpatialDropout1D : Spatial 1D version of Dropout.\nclass SpatialDropout1D\nclass SpatialDropout2D : Spatial 2D version of Dropout.\nclass SpatialDropout2D\nclass SpatialDropout3D : Spatial 3D version of Dropout.\nclass SpatialDropout3D\nclass SpectralNormalization : Performs spectral normalization on the weights of a target layer.\nclass SpectralNormalization\nclass StackedRNNCells : Wrapper allowing a stack of RNN cells to behave as a single cell.\nclass StackedRNNCells\nclass StringLookup : A preprocessing layer that maps strings to (possibly encoded) indices.\nclass StringLookup\nclass Subtract : Performs elementwise subtraction.\nclass Subtract\nclass TFSMLayer : Reload a Keras model/layer that was saved via SavedModel / ExportArchive.\nclass TFSMLayer\nclass TextVectorization : A preprocessing layer which maps text features to integer sequences.\nclass TextVectorization\nclass ThresholdedReLU : DEPRECATED.\nclass ThresholdedReLU\nclass TimeDistributed : This wrapper allows to apply a layer to every temporal slice of an input.\nclass TimeDistributed\nclass TorchModuleWrapper : Torch module wrapper layer.\nclass TorchModuleWrapper\nclass UnitNormalization : Unit normalization layer.\nclass UnitNormalization\nclass UpSampling1D : Upsampling layer for 1D inputs.\nclass UpSampling1D\nclass UpSampling2D : Upsampling layer for 2D inputs.\nclass UpSampling2D\nclass UpSampling3D : Upsampling layer for 3D inputs.\nclass UpSampling3D\nclass Wrapper : Abstract wrapper base class.\nclass Wrapper\nclass ZeroPadding1D : Zero-padding layer for 1D input (e.g. temporal sequence).\nclass ZeroPadding1D\nclass ZeroPadding2D : Zero-padding layer for 2D input (e.g. picture).\nclass ZeroPadding2D\nclass ZeroPadding3D : Zero-padding layer for 3D data (spatial or spatio-temporal).\nclass ZeroPadding3D\nFunctions\nInput(...) : Used to instantiate a Keras tensor.\nInput(...)\nadd(...) : Functional interface to the keras.layers.Add layer.\nadd(...)\nkeras.layers.Add\naverage(...) : Functional interface to the keras.layers.Average layer.\naverage(...)\nkeras.layers.Average\nconcatenate(...) : Functional interface to the Concatenate layer.\nconcatenate(...)\nConcatenate\ndeserialize(...) : Returns a Keras layer object via its configuration.\ndeserialize(...)\ndot(...) : Functional interface to the Dot layer.\ndot(...)\nDot\nmaximum(...) : Functional interface to the keras.layers.Maximum layer.\nmaximum(...)\nkeras.layers.Maximum\nminimum(...) : Functional interface to the keras.layers.Minimum layer.\nminimum(...)\nkeras.layers.Minimum\nmultiply(...) : Functional interface to the keras.layers.Multiply layer.\nmultiply(...)\nkeras.layers.Multiply\nserialize(...) : Returns the layer configuration as a Python dict.\nserialize(...)\nsubtract(...) : Functional interface to the keras.layers.Subtract layer.\nsubtract(...)\nkeras.layers.Subtract"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/real",
    "content": "Return the real part of the complex argument.\nMain aliases tf.keras.ops.numpy.real\ntf.keras.ops.numpy.real\ntf.keras.ops.numpy.real\ntf . keras . ops . real ( x )\ntf . keras . ops . real ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns The real component of the complex argument.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization",
    "content": "Layer that normalizes its inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . BatchNormalization ( axis =- 1 , momentum = 0.99 , epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , moving_mean_initializer = 'zeros' , moving_variance_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , synchronized = False , ** kwargs )\ntf . keras . layers . BatchNormalization ( axis =- 1 , momentum = 0.99 , epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , moving_mean_initializer = 'zeros' , moving_variance_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , synchronized = False , ** kwargs )\nUsed in the notebooks\nEffective Tensorflow 2\nAdvanced automatic differentiation\nPruning for on-device inference w/ XNNPACK\nSparse weights using structural pruning\nCustom layers\nDeep Convolutional Generative Adversarial Network\npix2pix: Image-to-image translation with a conditional GAN\nDistributed training with DTensors\nBatch normalization applies a transformation that maintains the mean output\nclose to 0 and the output standard deviation close to 1.\nImportantly, batch normalization works differently during training and\nduring inference.\nDuring training (i.e. when using fit() or when calling the layer/model\nwith the argument training=True ), the layer normalizes its output using\nthe mean and standard deviation of the current batch of inputs. That is to\nsay, for each channel being normalized, the layer returns gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta , where:\nfit()\ntraining=True\ngamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta\nepsilon is small constant (configurable as part of the constructor\narguments)\nepsilon\ngamma is a learned scaling factor (initialized as 1), which\ncan be disabled by passing scale=False to the constructor.\ngamma\nscale=False\nbeta is a learned offset factor (initialized as 0), which\ncan be disabled by passing center=False to the constructor.\nbeta\ncenter=False\nDuring inference (i.e. when using evaluate() or predict() or when\ncalling the layer/model with the argument training=False (which is the\ndefault), the layer normalizes its output using a moving average of the\nmean and standard deviation of the batches it has seen during training. That\nis to say, it returns gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta .\nevaluate()\npredict()\ntraining=False\ngamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta\nself.moving_mean and self.moving_var are non-trainable variables that\nare updated each time the layer in called in training mode, as such:\nself.moving_mean\nself.moving_var\nmoving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\nmoving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\nmoving_var = moving_var * momentum + var(batch) * (1 - momentum)\nmoving_var = moving_var * momentum + var(batch) * (1 - momentum)\nAs such, the layer will only normalize its inputs during inference after having been trained on data that has similar statistics as the\ninference data .\nArgs\nArgs\naxis Integer, the axis that should be normalized\n(typically the features axis). For instance, after a Conv2D layer\nwith data_format=\"channels_first\" , use axis=1 . momentum Momentum for the moving average. epsilon Small float added to variance to avoid dividing by zero. center If True , add offset of beta to normalized tensor.\nIf False , beta is ignored. scale If True , multiply by gamma . If False , gamma is not used.\nWhen the next layer is linear this can be disabled\nsince the scaling will be done by the next layer. beta_initializer Initializer for the beta weight. gamma_initializer Initializer for the gamma weight. moving_mean_initializer Initializer for the moving mean. moving_variance_initializer Initializer for the moving variance. beta_regularizer Optional regularizer for the beta weight. gamma_regularizer Optional regularizer for the gamma weight. beta_constraint Optional constraint for the beta weight. gamma_constraint Optional constraint for the gamma weight. synchronized Only applicable with the TensorFlow backend.\nIf True , synchronizes the global batch statistics (mean and\nvariance) for the layer across all devices at each training step\nin a distributed training strategy.\nIf False , each replica uses its own local batch statistics. **kwargs Base layer keyword arguments (e.g. name and dtype ).\naxis\nConv2D\ndata_format=\"channels_first\"\naxis=1\nmomentum\nepsilon\ncenter\nTrue\nbeta\nFalse\nbeta\nscale\nTrue\ngamma\nFalse\ngamma\nbeta_initializer\ngamma_initializer\nmoving_mean_initializer\nmoving_variance_initializer\nbeta_regularizer\ngamma_regularizer\nbeta_constraint\ngamma_constraint\nsynchronized\nTrue\nFalse\n**kwargs\nname\ndtype\nCall arguments\nCall arguments\ninputs Input tensor (of any rank). training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode.\ninputs\ntraining\ntraining=True : The layer will normalize its inputs using\nthe mean and variance of the current batch of inputs.\ntraining=True\ntraining=False : The layer will normalize its inputs using\nthe mean and variance of its moving statistics, learned during\ntraining. mask Binary tensor of shape broadcastable to inputs tensor, with True values indicating the positions for which mean and variance\nshould be computed. Masked elements of the current inputs are not\ntaken into account for mean and variance computation during\ntraining. Any prior unmasked element values will be taken into\naccount until their momentum expires.\ntraining=False\nmask\ninputs\nTrue\nIoffe and Szegedy, 2015 .\nAbout setting layer.trainable = False on a BatchNormalization layer:\nlayer.trainable = False\nBatchNormalization\nThe meaning of setting layer.trainable = False is to freeze the layer,\ni.e. its internal state will not change during training:\nits trainable weights will not be updated\nduring fit() or train_on_batch() , and its state updates will not be run.\nlayer.trainable = False\nfit()\ntrain_on_batch()\nUsually, this does not necessarily mean that the layer is run in inference\nmode (which is normally controlled by the training argument that can\nbe passed when calling a layer). \"Frozen state\" and \"inference mode\"\nare two separate concepts.\ntraining\nHowever, in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be\nsubsequently run in inference mode (meaning that it will use\nthe moving mean and the moving variance to normalize the current batch,\nrather than using the mean and variance of the current batch).\nBatchNormalization\ntrainable = False\nSetting trainable on an model containing other layers will recursively\nset the trainable value of all inner layers.\ntrainable\ntrainable\nIf the value of the trainable attribute is changed after calling compile() on a model, the new value doesn't take effect for this model\nuntil compile() is called again.\ntrainable\ncompile()\ncompile()\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy",
    "content": "Calculates how often predictions match binary labels.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . BinaryAccuracy ( name = 'binary_accuracy' , dtype = None , threshold = 0.5 )\ntf . keras . metrics . BinaryAccuracy ( name = 'binary_accuracy' , dtype = None , threshold = 0.5 )\nUsed in the notebooks\nTransfer learning and fine-tuning\nClassification on imbalanced data\nTensorFlow Constrained Optimization Example Using CelebA Dataset\nTFX Keras Component Tutorial\nThis metric creates two local variables, total and count that are used\nto compute the frequency with which y_pred matches y_true . This\nfrequency is ultimately returned as binary accuracy : an idempotent\noperation that simply divides total by count .\ntotal\ncount\ny_pred\ny_true\nbinary accuracy\ntotal\ncount\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. threshold (Optional) Float representing the threshold for deciding\nwhether prediction values are 1 or 0.\nname\ndtype\nthreshold\nm = keras . metrics . BinaryAccuracy () m . update_state ([[ 1 ], [ 1 ], [ 0 ], [ 0 ]], [[ 0.98 ], [ 1 ], [ 0 ], [ 0.6 ]]) m . result () 0.75\nm = keras . metrics . BinaryAccuracy ()\nm . update_state ([[ 1 ], [ 1 ], [ 0 ], [ 0 ]], [[ 0.98 ], [ 1 ], [ 0 ], [ 0.6 ]])\nm . result ()\n0.75\nm . reset_state () m . update_state ([[ 1 ], [ 1 ], [ 0 ], [ 0 ]], [[ 0.98 ], [ 1 ], [ 0 ], [ 0.6 ]], sample_weight = [ 1 , 0 , 0 , 1 ]) m . result () 0.5\nm . reset_state ()\nm . update_state ([[ 1 ], [ 1 ], [ 0 ], [ 0 ]], [[ 0.98 ], [ 1 ], [ 0 ], [ 0.6 ]],\nsample_weight = [ 1 , 0 , 0 , 1 ])\nm . result ()\n0.5\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . BinaryAccuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . BinaryAccuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/exp",
    "content": "DEPRECATED.\ntf . keras . backend . exp ( x )\ntf . keras . backend . exp ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/dot",
    "content": "Functional interface to the Dot layer.\nDot\ntf . keras . layers . dot ( inputs , axes =- 1 , ** kwargs )\ntf . keras . layers . dot ( inputs , axes =- 1 , ** kwargs )\nArgs\nArgs\ninputs A list of input tensors (at least 2). axes Integer or tuple of integers,\naxis or axes along which to take the dot product. normalize Whether to L2-normalize samples along the\ndot product axis before taking the dot product.\nIf set to True , then the output of the dot product\nis the cosine proximity between the two samples. **kwargs Standard layer keyword arguments.\ninputs\naxes\nnormalize\nTrue\n**kwargs\nReturns A tensor, the dot product of the samples from the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/swapaxes",
    "content": "Interchange two axes of a tensor.\nMain aliases tf.keras.ops.numpy.swapaxes\ntf.keras.ops.numpy.swapaxes\ntf.keras.ops.numpy.swapaxes\ntf . keras . ops . swapaxes ( x , axis1 , axis2 )\ntf . keras . ops . swapaxes ( x , axis1 , axis2 )\nArgs\nArgs\nx Input tensor. axis1 First axis. axis2 Second axis.\nx\naxis1\naxis2\nReturns A tensor with the axes swapped.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/one_hot",
    "content": "DEPRECATED.\ntf . keras . backend . one_hot ( indices , num_classes )\ntf . keras . backend . one_hot ( indices , num_classes )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard",
    "content": "Enable visualizations for TensorBoard.\nInherits From: Callback\nCallback\ntf . keras . callbacks . TensorBoard ( log_dir = 'logs' , histogram_freq = 0 , write_graph = True , write_images = False , write_steps_per_second = False , update_freq = 'epoch' , profile_batch = 0 , embeddings_freq = 0 , embeddings_metadata = None )\ntf . keras . callbacks . TensorBoard ( log_dir = 'logs' , histogram_freq = 0 , write_graph = True , write_images = False , write_steps_per_second = False , update_freq = 'epoch' , profile_batch = 0 , embeddings_freq = 0 , embeddings_metadata = None )\nUsed in the notebooks\nMigrate TensorBoard: TensorFlow's visualization toolkit\nDistributed training with Keras\nParameter server training with ParameterServerStrategy\nTransfer learning with TensorFlow Hub\nOverfit and underfit\nTensorBoard Scalars: Logging training metrics in Keras\nTensorBoard is a visualization tool provided with TensorFlow. A TensorFlow\ninstallation is required to use this callback.\nThis callback logs events for TensorBoard, including:\nMetrics summary plots\nTraining graph visualization\nWeight histograms\nSampled profiling\nWhen used in model.evaluate() or regular validation\nin addition to epoch summaries, there will be a summary that records\nevaluation metrics vs model.optimizer.iterations written. The metric names\nwill be prepended with evaluation , with model.optimizer.iterations being\nthe step in the visualized TensorBoard.\nmodel.evaluate()\nmodel.optimizer.iterations\nevaluation\nmodel.optimizer.iterations\nIf you have installed TensorFlow with pip, you should be able\nto launch TensorBoard from the command line:\ntensorboard -- logdir = path_to_your_logs\ntensorboard -- logdir = path_to_your_logs\nYou can find more information about TensorBoard here .\nArgs\nArgs\nlog_dir the path of the directory where to save the log files to be\nparsed by TensorBoard. e.g., log_dir = os.path.join(working_dir, 'logs') .\nThis directory should not be reused by any other callbacks. histogram_freq frequency (in epochs) at which to compute\nweight histograms for the layers of the model. If set to 0,\nhistograms won't be computed. Validation data (or split) must be\nspecified for histogram visualizations. write_graph (Not supported at this time)\nWhether to visualize the graph in TensorBoard.\nNote that the log file can become quite large\nwhen write_graph is set to True . write_images whether to write model weights to visualize as image in\nTensorBoard. write_steps_per_second whether to log the training steps per second\ninto TensorBoard. This supports both epoch and batch frequency\nlogging. update_freq \"batch\" or \"epoch\" or integer. When using \"epoch\" ,\nwrites the losses and metrics to TensorBoard after every epoch.\nIf using an integer, let's say 1000 , all metrics and losses\n(including custom ones added by Model.compile ) will be logged to\nTensorBoard every 1000 batches. \"batch\" is a synonym for 1,\nmeaning that they will be written every batch.\nNote however that writing too frequently to TensorBoard can slow\ndown your training, especially when used with distribution\nstrategies as it will incur additional synchronization overhead.\nBatch-level summary writing is also available via train_step override. Please see TensorBoard Scalars tutorial # noqa: E501\nfor more details. profile_batch (Not supported at this time)\nProfile the batch(es) to sample compute characteristics.\nprofile_batch must be a non-negative integer or a tuple of integers.\nA pair of positive integers signify a range of batches to profile.\nBy default, profiling is disabled. embeddings_freq frequency (in epochs) at which embedding layers will be\nvisualized. If set to 0, embeddings won't be visualized. embeddings_metadata Dictionary which maps embedding layer names to the\nfilename of a file in which to save metadata for the embedding layer.\nIn case the same metadata file is to be\nused for all embedding layers, a single filename can be passed.\nlog_dir\nlog_dir = os.path.join(working_dir, 'logs')\nhistogram_freq\nwrite_graph\nwrite_graph\nTrue\nwrite_images\nwrite_steps_per_second\nupdate_freq\n\"batch\"\n\"epoch\"\n\"epoch\"\n1000\nModel.compile\n\"batch\"\ntrain_step\nprofile_batch\nembeddings_freq\nembeddings_metadata\ntensorboard_callback = keras . callbacks . TensorBoard ( log_dir = \"./logs\" ) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ]) # Then run the tensorboard command to view the visualizations.\ntensorboard_callback = keras . callbacks . TensorBoard ( log_dir = \"./logs\" ) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ]) # Then run the tensorboard command to view the visualizations.\nCustom batch-level summaries in a subclassed Model:\nclass MyModel ( keras . Model ): def build ( self , _ ): self . dense = keras . layers . Dense ( 10 ) def call ( self , x ): outputs = self . dense ( x ) tf . summary . histogram ( 'outputs' , outputs ) return outputs model = MyModel () model . compile ( 'sgd' , 'mse' ) # Make sure to set `update_freq=N` to log a batch-level summary every N # batches.  In addition to any `tf.summary` contained in `model.call()`, # metrics added in `Model.compile` will be logged every N batches. tb_callback = keras . callbacks . TensorBoard ( './logs' , update_freq = 1 ) model . fit ( x_train , y_train , callbacks = [ tb_callback ])\nclass MyModel ( keras . Model ): def build ( self , _ ): self . dense = keras . layers . Dense ( 10 ) def call ( self , x ): outputs = self . dense ( x ) tf . summary . histogram ( 'outputs' , outputs ) return outputs model = MyModel () model . compile ( 'sgd' , 'mse' ) # Make sure to set `update_freq=N` to log a batch-level summary every N # batches.  In addition to any `tf.summary` contained in `model.call()`, # metrics added in `Model.compile` will be logged every N batches. tb_callback = keras . callbacks . TensorBoard ( './logs' , update_freq = 1 ) model . fit ( x_train , y_train , callbacks = [ tb_callback ])\nCustom batch-level summaries in a Functional API Model:\ndef my_summary ( x ): tf . summary . histogram ( 'x' , x ) return x inputs = keras . Input ( 10 ) x = keras . layers . Dense ( 10 )( inputs ) outputs = keras . layers . Lambda ( my_summary )( x ) model = keras . Model ( inputs , outputs ) model . compile ( 'sgd' , 'mse' ) # Make sure to set `update_freq=N` to log a batch-level summary every N # batches. In addition to any `tf.summary` contained in `Model.call`, # metrics added in `Model.compile` will be logged every N batches. tb_callback = keras . callbacks . TensorBoard ( './logs' , update_freq = 1 ) model . fit ( x_train , y_train , callbacks = [ tb_callback ])\ndef my_summary ( x ): tf . summary . histogram ( 'x' , x ) return x inputs = keras . Input ( 10 ) x = keras . layers . Dense ( 10 )( inputs ) outputs = keras . layers . Lambda ( my_summary )( x ) model = keras . Model ( inputs , outputs ) model . compile ( 'sgd' , 'mse' ) # Make sure to set `update_freq=N` to log a batch-level summary every N # batches. In addition to any `tf.summary` contained in `Model.call`, # metrics added in `Model.compile` will be logged every N batches. tb_callback = keras . callbacks . TensorBoard ( './logs' , update_freq = 1 ) model . fit ( x_train , y_train , callbacks = [ tb_callback ])\n# Profile a single batch, e.g. the 5th batch. tensorboard_callback = keras . callbacks . TensorBoard ( log_dir = './logs' , profile_batch = 5 ) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ]) # Profile a range of batches, e.g. from 10 to 20. tensorboard_callback = keras . callbacks . TensorBoard ( log_dir = './logs' , profile_batch = ( 10 , 20 )) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ])\n# Profile a single batch, e.g. the 5th batch. tensorboard_callback = keras . callbacks . TensorBoard ( log_dir = './logs' , profile_batch = 5 ) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ]) # Profile a range of batches, e.g. from 10 to 20. tensorboard_callback = keras . callbacks . TensorBoard ( log_dir = './logs' , profile_batch = ( 10 , 20 )) model . fit ( x_train , y_train , epochs = 2 , callbacks = [ tensorboard_callback ])\nAttributes\nAttributes\nmodel\nmodel\nsummary\nsummary\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nRuns metrics and histogram summaries at epoch end.\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nSets Keras model and writes graph if specified.\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/epsilon",
    "content": "Return the value of the fuzz factor used in numeric expressions.\nMain aliases tf.keras.config.epsilon\ntf.keras.config.epsilon\ntf.keras.config.epsilon\ntf . keras . backend . epsilon ()\ntf . keras . backend . epsilon ()\nReturns A float.\nReturns\nkeras . config . epsilon () 1e-07\nkeras . config . epsilon ()\n1e-07"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D",
    "content": "1D convolution layer (e.g. temporal convolution).\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution1D\ntf.keras.layers.Convolution1D\ntf.keras.layers.Convolution1D\ntf . keras . layers . Conv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv1D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nUsed in the notebooks\nUsing Counterfactual Logit Pairing with Keras\nTime series forecasting\nLoad text\nWiki Talk Comments Toxicity Prediction\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If use_bias is True, a bias vector is created and added to the\noutputs. Finally, if activation is not None , it is applied to the\noutputs as well.\nuse_bias\nactivation\nNone\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 1 integer, specifying the size of the\nconvolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, \"valid\" , \"same\" or \"causal\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. \"causal\" results in causal(dilated) convolutions, e.g. output[t] does not depend on input[t+1:] . Useful when modeling temporal data\nwhere the model should not violate the temporal order.\nSee WaveNet: A Generative Model for Raw Audio, section2.1 . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated convolution. groups A positive int specifying the number of groups in which the\ninput is split along the channel axis. Each group is convolved\nseparately with filters // groups filters. The output is the\nconcatenation of all the groups results along the channel axis.\nInput channels and filters must both be divisible by groups . activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"causal\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\n\"causal\"\noutput[t]\ninput[t+1:]\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\ngroups\nfilters // groups\ngroups\nfilters\ngroups\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, steps, channels)\ndata_format=\"channels_last\"\n(batch_shape, steps, channels)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, channels, steps)\ndata_format=\"channels_first\"\n(batch_shape, channels, steps)\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, new_steps, filters)\ndata_format=\"channels_last\"\n(batch_shape, new_steps, filters)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, filters, new_steps)\ndata_format=\"channels_first\"\n(batch_shape, filters, new_steps)\nReturns A 3D tensor representing activation(conv1d(inputs, kernel) + bias) .\nReturns\nactivation(conv1d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\n# The inputs are 128-length vectors with 10 timesteps, and the # batch size is 4. x = np . random . rand ( 4 , 10 , 128 ) y = keras . layers . Conv1D ( 32 , 3 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 8 , 32 )\n# The inputs are 128-length vectors with 10 timesteps, and the\n# batch size is 4.\nx = np . random . rand ( 4 , 10 , 128 )\ny = keras . layers . Conv1D ( 32 , 3 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 8 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel\nkernel\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nconvolution_op\nconvolution_op\nView source\nconvolution_op ( inputs , kernel )\nconvolution_op ( inputs , kernel )\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/irfft",
    "content": "Inverse real-valued Fast Fourier transform along the last axis.\ntf . keras . ops . irfft ( x , fft_length = None )\ntf . keras . ops . irfft ( x , fft_length = None )\nComputes the inverse 1D Discrete Fourier Transform of a real-valued signal\nover the inner-most dimension of input.\nThe inner-most dimension of the input is assumed to be the result of RFFT:\nthe fft_length / 2 + 1 unique components of the DFT of a real-valued\nsignal. If fft_length is not provided, it is computed from the size of the\ninner-most dimension of the input (fft_length = 2 * (inner - 1)) . If the\nFFT length used to compute is odd, it should be provided since it cannot\nbe inferred properly.\nfft_length / 2 + 1\nfft_length\n(fft_length = 2 * (inner - 1))\nAlong the axis IRFFT is computed on, if fft_length / 2 + 1 is smaller than\nthe corresponding dimension of the input, the dimension is cropped. If it is\nlarger, the dimension is padded with zeros.\nfft_length / 2 + 1\nArgs\nArgs\nx Tuple of the real and imaginary parts of the input tensor. Both\ntensors in the tuple should be of floating type. fft_length An integer representing the number of the fft length. If not\nspecified, it is inferred from the length of the last axis of x .\nDefaults to None .\nx\nfft_length\nx\nNone\nReturns A tensor containing the inverse real-valued Fast Fourier Transform\nalong the last axis of x .\nReturns\nx\nreal = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ]) imag = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ]) irfft (( real , imag )) array ([ 0.66666667 , - 0.9106836 , 0.24401694 ])\nreal = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nimag = keras . ops . convert_to_tensor ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nirfft (( real , imag ))\narray ([ 0.66666667 , - 0.9106836 , 0.24401694 ])\nirfft ( rfft ( real , 5 ), 5 ) array ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])\nirfft ( rfft ( real , 5 ), 5 )\narray ([ 0.0 , 1.0 , 2.0 , 3.0 , 4.0 ])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/square",
    "content": "Return the element-wise square of the input.\nMain aliases tf.keras.ops.numpy.square\ntf.keras.ops.numpy.square\ntf.keras.ops.numpy.square\ntf . keras . ops . square ( x )\ntf . keras . ops . square ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, the square of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/version",
    "content": "Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.version\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.version\ntf.compat.v1.keras.version\ntf . keras . version ()\ntf . keras . version ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean",
    "content": "Compute the (weighted) mean of the given values.\nInherits From: Metric\nMetric\ntf . keras . metrics . Mean ( name = 'mean' , dtype = None )\ntf . keras . metrics . Mean ( name = 'mean' , dtype = None )\nUsed in the notebooks\nEffective Tensorflow 2\nMixed precision\nUse TPUs\nTensorFlow 2 quickstart for experts\nCustom training: walkthrough\nCustom training with tf.distribute.Strategy\nConvolutional Variational Autoencoder\nTraining with Orbit\nFor example, if values is [1, 3, 5, 7] then the mean is 4.\nIf sample_weight was specified as [1, 1, 0, 0] then the mean would be 2.\n[1, 3, 5, 7]\nsample_weight\n[1, 1, 0, 0]\nThis metric creates two variables, total and count .\nThe mean value returned is simply total divided by count .\ntotal\ncount\ntotal\ncount\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = Mean () m . update_state ([ 1 , 3 , 5 , 7 ]) m . result () 4.0\nm = Mean ()\nm . update_state ([ 1 , 3 , 5 , 7 ])\nm . result ()\n4.0\nm . reset_state () m . update_state ([ 1 , 3 , 5 , 7 ], sample_weight = [ 1 , 1 , 0 , 0 ]) m . result () 2.0\nm . reset_state ()\nm . update_state ([ 1 , 3 , 5 , 7 ], sample_weight = [ 1 , 1 , 0 , 0 ])\nm . result ()\n2.0\n< ! -- Tabular view -- >\n < table class = \"responsive fixed orange\" >\n< colgroup><col width = \"214px\" >< col >< / colgroup >\n< tr><th colspan = \"2\" >< h2 class = \"add-link\" > Attributes < / h2 >< / th >< / tr >\n\n< tr >\n< td > ` dtype ` < a id = \"dtype\" >< / a >\n< / td >\n< td >\n\n< / td >\n< / tr><tr> < td > ` variables ` < a id = \"variables\" >< / a >\n< / td >\n< td >\n\n< / td >\n< / tr >\n< / table > ## Methods < h3 id = \"add_variable\" >< code>add_variable < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L186-L202\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>add_variable ( shape , initializer , dtype = None , aggregation = & #x27;sum&#x27;, name=None ) < / code >< / pre >\n\n\n\n\n< h3 id = \"add_weight\" >< code>add_weight < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L204-L208\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>add_weight ( shape = (), initializer = None , dtype = None , name = None ) < / code >< / pre >\n\n\n\n\n< h3 id = \"from_config\" >< code>from_config < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L226-L228\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code > @classmethod < / code >\n< code>from_config ( config ) < / code >< / pre >\n\n\n\n\n< h3 id = \"get_config\" >< code>get_config < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L222-L224\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>get_config () < / code >< / pre > Return the serializable config of the metric . < h3 id = \"reset_state\" >< code>reset_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L150-L152\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>reset_state () < / code >< / pre > Reset all of the metric state variables . This function is called between epochs / steps , when a metric is evaluated during training . < h3 id = \"result\" >< code>result < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L154-L157\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>result () < / code >< / pre > Compute the current metric value . < ! -- Tabular view -- >\n < table class = \"responsive fixed orange\" >\n< colgroup><col width = \"214px\" >< col >< / colgroup >\n< tr><th colspan = \"2\" > Returns < / th >< / tr >\n< tr class = \"alt\" >\n< td colspan = \"2\" > A scalar tensor , or a dictionary of scalar tensors . < / td >\n< / tr >\n\n< / table >\n\n\n\n< h3 id = \"stateless_reset_state\" >< code>stateless_reset_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L164-L177\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_reset_state () < / code >< / pre >\n\n\n\n\n< h3 id = \"stateless_result\" >< code>stateless_result < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L148-L162\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_result ( metric_variables ) < / code >< / pre >\n\n\n\n\n< h3 id = \"stateless_update_state\" >< code>stateless_update_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L115-L138\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_update_state ( metric_variables , * args , ** kwargs ) < / code >< / pre >\n\n\n\n\n< h3 id = \"update_state\" >< code>update_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L137-L148\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>update_state ( values , sample_weight = None ) < / code >< / pre > Accumulate statistics for the metric . < h3 id = \"__call__\" >< code>__call__ < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L217-L220\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>__call__ ( * args , ** kwargs ) < / code >< / pre > Call self as a function .\n< ! -- Tabular view -- >\n < table class = \"responsive fixed orange\" >\n< colgroup><col width = \"214px\" >< col >< / colgroup >\n< tr><th colspan = \"2\" >< h2 class = \"add-link\" > Attributes < / h2 >< / th >< / tr >\n\n< tr >\n< td > ` dtype ` < a id = \"dtype\" >< / a >\n< / td >\n< td >\n\n< / td >\n< / tr><tr> < td > ` variables ` < a id = \"variables\" >< / a >\n< / td >\n< td >\n\n< / td >\n< / tr >\n< / table > ## Methods < h3 id = \"add_variable\" >< code>add_variable < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L186-L202\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>add_variable ( shape , initializer , dtype = None , aggregation = & #x27;sum&#x27;, name=None ) < / code >< / pre >\n\n\n\n\n< h3 id = \"add_weight\" >< code>add_weight < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L204-L208\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>add_weight ( shape = (), initializer = None , dtype = None , name = None ) < / code >< / pre >\n\n\n\n\n< h3 id = \"from_config\" >< code>from_config < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L226-L228\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code > @classmethod < / code >\n< code>from_config ( config ) < / code >< / pre >\n\n\n\n\n< h3 id = \"get_config\" >< code>get_config < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L222-L224\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>get_config () < / code >< / pre > Return the serializable config of the metric . < h3 id = \"reset_state\" >< code>reset_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L150-L152\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>reset_state () < / code >< / pre > Reset all of the metric state variables . This function is called between epochs / steps , when a metric is evaluated during training . < h3 id = \"result\" >< code>result < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L154-L157\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>result () < / code >< / pre > Compute the current metric value . < ! -- Tabular view -- >\n < table class = \"responsive fixed orange\" >\n< colgroup><col width = \"214px\" >< col >< / colgroup >\n< tr><th colspan = \"2\" > Returns < / th >< / tr >\n< tr class = \"alt\" >\n< td colspan = \"2\" > A scalar tensor , or a dictionary of scalar tensors . < / td >\n< / tr >\n\n< / table >\n\n\n\n< h3 id = \"stateless_reset_state\" >< code>stateless_reset_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L164-L177\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_reset_state () < / code >< / pre >\n\n\n\n\n< h3 id = \"stateless_result\" >< code>stateless_result < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L148-L162\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_result ( metric_variables ) < / code >< / pre >\n\n\n\n\n< h3 id = \"stateless_update_state\" >< code>stateless_update_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L115-L138\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>stateless_update_state ( metric_variables , * args , ** kwargs ) < / code >< / pre >\n\n\n\n\n< h3 id = \"update_state\" >< code>update_state < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/reduction_metrics.py#L137-L148\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>update_state ( values , sample_weight = None ) < / code >< / pre > Accumulate statistics for the metric . < h3 id = \"__call__\" >< code>__call__ < / code >< / h3 >\n\n< a target = \"_blank\" class = \"external\" href = \"https://github.com/keras-team/keras/tree/v3.3.3/keras/src/metrics/metric.py#L217-L220\" > View source < / a >\n\n< pre class = \"devsite-click-to-copy prettyprint lang-py tfo-signature-link\" >\n< code>__call__ ( * args , ** kwargs ) < / code >< / pre > Call self as a function ."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD",
    "content": "Gradient descent (with momentum) optimizer.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'SGD' , ** kwargs )\ntf . keras . optimizers . SGD ( learning_rate = 0.01 , momentum = 0.0 , nesterov = False , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'SGD' , ** kwargs )\nUsed in the notebooks\nBasic training loops\nTensorFlow basics\nDistributed training with TensorFlow\nUse a GPU\nMigrate the fault tolerance mechanism\nCustom training: walkthrough\nMulti-worker training with Keras\nTFF for Federated Learning Research: Model and Update Compression\nFederated Learning for Image Classification\nFederated Reconstruction for Matrix Factorization\nUpdate rule for parameter w with gradient g when momentum is 0:\nw\ng\nmomentum\nw = w - learning_rate * g\nw = w - learning_rate * g\nUpdate rule when momentum is larger than 0:\nmomentum\nvelocity = momentum * velocity - learning_rate * g w = w + velocity\nvelocity = momentum * velocity - learning_rate * g w = w + velocity\nWhen nesterov=True , this rule becomes:\nnesterov=True\nvelocity = momentum * velocity - learning_rate * g w = w + momentum * velocity - learning_rate * g\nvelocity = momentum * velocity - learning_rate * g w = w + momentum * velocity - learning_rate * g\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.01 . momentum float hyperparameter >= 0 that accelerates gradient descent in\nthe relevant direction and dampens oscillations. 0 is vanilla\ngradient descent. Defaults to 0.0 . nesterov boolean. Whether to apply Nesterov momentum.\nDefaults to False . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.01\nmomentum\n0.0\nnesterov\nFalse\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( variables )\nbuild ( variables )\nInitialize optimizer variables.\nSGD optimizer has one variable momentums , only set if self.momentum is not 0.\nmomentums\nself.momentum\nArgs\nvar_list list of model variables to build SGD variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/meshgrid",
    "content": "Creates grids of coordinates from coordinate vectors.\nMain aliases tf.keras.ops.numpy.meshgrid\ntf.keras.ops.numpy.meshgrid\ntf.keras.ops.numpy.meshgrid\ntf . keras . ops . meshgrid ( * x , indexing = 'xy' )\ntf . keras . ops . meshgrid ( * x , indexing = 'xy' )\nGiven N 1-D tensors T0, T1, ..., TN-1 as inputs with corresponding\nlengths S0, S1, ..., SN-1 , this creates an N N-dimensional tensors G0, G1, ..., GN-1 each with shape (S0, ..., SN-1) where the output Gi is constructed by expanding Ti to the result shape.\nN\nT0, T1, ..., TN-1\nS0, S1, ..., SN-1\nN\nG0, G1, ..., GN-1\n(S0, ..., SN-1)\nGi\nTi\nArgs\nArgs\nx 1-D tensors representing the coordinates of a grid. indexing \"xy\" or \"ij\" . \"xy\" is cartesian; \"ij\" is matrix\nindexing of output. Defaults to \"xy\" .\nx\nindexing\n\"xy\"\n\"ij\"\n\"ij\"\n\"xy\"\nReturns Sequence of N tensors.\nReturns\nfrom keras.src import ops x = ops . array ([ 1 , 2 , 3 ]) y = ops . array ([ 4 , 5 , 6 ])\nfrom keras.src import ops\nx = ops . array ([ 1 , 2 , 3 ])\ny = ops . array ([ 4 , 5 , 6 ])\ngrid_x , grid_y = ops . meshgrid ( x , y , indexing = \"ij\" ) grid_x array ([[ 1 , 1 , 1 ], [ 2 , 2 , 2 ], [ 3 , 3 , 3 ]]) grid_y array ([[ 4 , 5 , 6 ], [ 4 , 5 , 6 ], [ 4 , 5 , 6 ]])\ngrid_x , grid_y = ops . meshgrid ( x , y , indexing = \"ij\" )\ngrid_x\narray ([[ 1 , 1 , 1 ],\n[ 2 , 2 , 2 ],\n[ 3 , 3 , 3 ]])\ngrid_y\narray ([[ 4 , 5 , 6 ],\n[ 4 , 5 , 6 ],\n[ 4 , 5 , 6 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MAE",
    "content": "Computes the mean absolute error between labels and predictions.\nMain aliases tf.keras.losses.mae , tf.keras.metrics.MAE , tf.keras.metrics.mae\ntf.keras.losses.mae , tf.keras.metrics.MAE , tf.keras.metrics.mae\ntf.keras.losses.mae\ntf.keras.metrics.MAE\ntf.keras.metrics.mae\ntf . keras . losses . MAE ( y_true , y_pred )\ntf . keras . losses . MAE ( y_true , y_pred )\nUsed in the notebooks\nIntro to Autoencoders\nloss = mean ( abs ( y_true - y_pred ), axis =- 1 )\nloss = mean ( abs ( y_true - y_pred ), axis =- 1 )\nArgs\nArgs\ny_true Ground truth values with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Mean absolute error values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . mean_absolute_error ( y_true , y_pred )\ny_true = np . random . randint ( 0 , 2 , size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . mean_absolute_error ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cholesky",
    "content": "Computes the Cholesky decomposition of a positive semi-definite matrix.\nMain aliases tf.keras.ops.linalg.cholesky\ntf.keras.ops.linalg.cholesky\ntf.keras.ops.linalg.cholesky\ntf . keras . ops . cholesky ( x )\ntf . keras . ops . cholesky ( x )\nArgs\nArgs\nx Input tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tensor of shape (..., M, M) representing the lower triangular\nCholesky factor of x .\nReturns\n(..., M, M)\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory",
    "content": "Generates a tf.data.Dataset from image files in a directory.\ntf.data.Dataset\nMain aliases tf.keras.utils.image_dataset_from_directory\ntf.keras.utils.image_dataset_from_directory\ntf.keras.utils.image_dataset_from_directory\ntf . keras . preprocessing . image_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , color_mode = 'rgb' , batch_size = 32 , image_size = ( 256 , 256 ), shuffle = True , seed = None , validation_split = None , subset = None , interpolation = 'bilinear' , follow_links = False , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , data_format = None , verbose = True )\ntf . keras . preprocessing . image_dataset_from_directory ( directory , labels = 'inferred' , label_mode = 'int' , class_names = None , color_mode = 'rgb' , batch_size = 32 , image_size = ( 256 , 256 ), shuffle = True , seed = None , validation_split = None , subset = None , interpolation = 'bilinear' , follow_links = False , crop_to_aspect_ratio = False , pad_to_aspect_ratio = False , data_format = None , verbose = True )\nUsed in the notebooks\nImage classification\nTransfer learning and fine-tuning\nTransfer learning with TensorFlow Hub\nLoad and preprocess images\nRetraining an Image Classifier\nIf your directory structure is:\nmain_directory / ... class_a / ...... a_image_1 . jpg ...... a_image_2 . jpg ... class_b / ...... b_image_1 . jpg ...... b_image_2 . jpg\nmain_directory / ... class_a / ...... a_image_1 . jpg ...... a_image_2 . jpg ... class_b / ...... b_image_1 . jpg ...... b_image_2 . jpg\nThen calling image_dataset_from_directory(main_directory,\nlabels='inferred') will return a tf.data.Dataset that yields batches of\nimages from the subdirectories class_a and class_b , together with labels\n0 and 1 (0 corresponding to class_a and 1 corresponding to class_b ).\nimage_dataset_from_directory(main_directory,\nlabels='inferred')\ntf.data.Dataset\nclass_a\nclass_b\nclass_a\nclass_b\nSupported image formats: .jpeg , .jpg , .png , .bmp , .gif .\nAnimated gifs are truncated to the first frame.\n.jpeg\n.jpg\n.png\n.bmp\n.gif\nArgs\nArgs\ndirectory Directory where the data is located.\nIf labels is \"inferred\" , it should contain\nsubdirectories, each containing images for a class.\nOtherwise, the directory structure is ignored. labels Either \"inferred\" (labels are generated from the directory structure), None (no labels),\nor a list/tuple of integer labels of the same size as the number of\nimage files found in the directory. Labels should be sorted\naccording to the alphanumeric order of the image file paths\n(obtained via os.walk(directory) in Python). label_mode String describing the encoding of labels . Options are:\ndirectory\nlabels\n\"inferred\"\nlabels\n\"inferred\"\nNone\nos.walk(directory)\nlabel_mode\nlabels\n\"int\" : means that the labels are encoded as integers\n(e.g. for sparse_categorical_crossentropy loss).\n\"int\"\nsparse_categorical_crossentropy\n\"categorical\" means that the labels are\nencoded as a categorical vector\n(e.g. for categorical_crossentropy loss).\n\"categorical\"\ncategorical_crossentropy\n\"binary\" means that the labels (there can be only 2)\nare encoded as float32 scalars with values 0 or 1\n(e.g. for binary_crossentropy ).\n\"binary\"\nfloat32\nbinary_crossentropy\nNone (no labels). class_names Only valid if labels is \"inferred\" .\nThis is the explicit list of class names\n(must match names of subdirectories). Used to control the order\nof the classes (otherwise alphanumerical order is used). color_mode One of \"grayscale\" , \"rgb\" , \"rgba\" .\nDefaults to \"rgb\" . Whether the images will be converted to\nhave 1, 3, or 4 channels. batch_size Size of the batches of data. Defaults to 32.\nIf None , the data will not be batched\n(the dataset will yield individual samples). image_size Size to resize images to after they are read from disk,\nspecified as (height, width) . Defaults to (256, 256) .\nSince the pipeline processes batches of images that must all have\nthe same size, this must be provided. shuffle Whether to shuffle the data. Defaults to True .\nIf set to False , sorts the data in alphanumeric order. seed Optional random seed for shuffling and transformations. validation_split Optional float between 0 and 1,\nfraction of data to reserve for validation. subset Subset of the data to return.\nOne of \"training\" , \"validation\" , or \"both\" .\nOnly used if validation_split is set.\nWhen subset=\"both\" , the utility returns a tuple of two datasets\n(the training and validation datasets respectively). interpolation String, the interpolation method used when\nresizing images. Defaults to \"bilinear\" .\nSupports \"bilinear\" , \"nearest\" , \"bicubic\" , \"area\" , \"lanczos3\" , \"lanczos5\" , \"gaussian\" , \"mitchellcubic\" . follow_links Whether to visit subdirectories pointed to by symlinks.\nDefaults to False . crop_to_aspect_ratio If True , resize the images without aspect\nratio distortion. When the original aspect ratio differs from the\ntarget aspect ratio, the output image will be cropped so as to\nreturn the largest possible window in the image\n(of size image_size ) that matches the target aspect ratio. By\ndefault ( crop_to_aspect_ratio=False ), aspect ratio may not be\npreserved. pad_to_aspect_ratio If True , resize the images without aspect\nratio distortion. When the original aspect ratio differs from the\ntarget aspect ratio, the output image will be padded so as to\nreturn the largest possible window in the image\n(of size image_size ) that matches the target aspect ratio. By\ndefault ( pad_to_aspect_ratio=False ), aspect ratio may not be\npreserved. data_format If None uses keras.config.image_data_format()\notherwise either 'channel_last' or 'channel_first'. verbose Whether to display number information on classes and\nnumber of files found. Defaults to True .\nNone\nclass_names\nlabels\n\"inferred\"\ncolor_mode\n\"grayscale\"\n\"rgb\"\n\"rgba\"\n\"rgb\"\nbatch_size\nNone\nimage_size\n(height, width)\n(256, 256)\nshuffle\nTrue\nFalse\nseed\nvalidation_split\nsubset\n\"training\"\n\"validation\"\n\"both\"\nvalidation_split\nsubset=\"both\"\ninterpolation\n\"bilinear\"\n\"bilinear\"\n\"nearest\"\n\"bicubic\"\n\"area\"\n\"lanczos3\"\n\"lanczos5\"\n\"gaussian\"\n\"mitchellcubic\"\nfollow_links\nFalse\ncrop_to_aspect_ratio\nTrue\nimage_size\ncrop_to_aspect_ratio=False\npad_to_aspect_ratio\nTrue\nimage_size\npad_to_aspect_ratio=False\ndata_format\nverbose\nTrue\nReturns\nReturns\nA tf.data.Dataset object.\ntf.data.Dataset\nIf label_mode is None , it yields float32 tensors of shape (batch_size, image_size[0], image_size[1], num_channels) ,\nencoding images (see below for rules regarding num_channels ).\nlabel_mode\nNone\nfloat32\n(batch_size, image_size[0], image_size[1], num_channels)\nnum_channels\nOtherwise, it yields a tuple (images, labels) , where images has\nshape (batch_size, image_size[0], image_size[1], num_channels) ,\nand labels follows the format described below.\n(images, labels)\nimages\n(batch_size, image_size[0], image_size[1], num_channels)\nlabels\nRules regarding labels format:\nif label_mode is \"int\" , the labels are an int32 tensor of shape (batch_size,) .\nlabel_mode\n\"int\"\nint32\n(batch_size,)\nif label_mode is \"binary\" , the labels are a float32 tensor of\n1s and 0s of shape (batch_size, 1) .\nlabel_mode\n\"binary\"\nfloat32\n(batch_size, 1)\nif label_mode is \"categorical\" , the labels are a float32 tensor\nof shape (batch_size, num_classes) , representing a one-hot\nencoding of the class index.\nlabel_mode\n\"categorical\"\nfloat32\n(batch_size, num_classes)\nRules regarding number of channels in the yielded images:\nif color_mode is \"grayscale\" ,\nthere's 1 channel in the image tensors.\ncolor_mode\n\"grayscale\"\nif color_mode is \"rgb\" ,\nthere are 3 channels in the image tensors.\ncolor_mode\n\"rgb\"\nif color_mode is \"rgba\" ,\nthere are 4 channels in the image tensors.\ncolor_mode\n\"rgba\""
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/softplus",
    "content": "Softplus activation function.\nMain aliases tf.keras.ops.nn.softplus\ntf.keras.ops.nn.softplus\ntf.keras.ops.nn.softplus\ntf . keras . ops . softplus ( x )\ntf . keras . ops . softplus ( x )\nIt is defined as f(x) = log(exp(x) + 1) , where log is the natural\nlogarithm and exp is the exponential function.\nf(x) = log(exp(x) + 1)\nlog\nexp\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 0.555 , 0.0 , 0.555 ]) keras . ops . softplus ( x ) array ([ 0.45366603 , 0.6931472 , 1.008666 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 0.555 , 0.0 , 0.555 ])\nkeras . ops . softplus ( x )\narray ([ 0.45366603 , 0.6931472 , 1.008666 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/get",
    "content": "Retrieves a Keras loss as a function / Loss class instance.\nfunction\nLoss\ntf . keras . losses . get ( identifier )\ntf . keras . losses . get ( identifier )\nThe identifier may be the string name of a loss function or Loss class.\nidentifier\nLoss\nloss = losses . get ( \"categorical_crossentropy\" ) type ( loss ) < class ' function ' > loss = losses . get ( \"CategoricalCrossentropy\" ) type ( loss ) < class '... CategoricalCrossentropy ' >\nloss = losses . get ( \"categorical_crossentropy\" )\ntype ( loss )\n< class ' function ' >\nloss = losses . get ( \"CategoricalCrossentropy\" )\ntype ( loss )\n< class '... CategoricalCrossentropy ' >\nYou can also specify config of the loss to this function by passing dict\ncontaining class_name and config as an identifier. Also note that the class_name must map to a Loss class\nconfig\nclass_name\nconfig\nclass_name\nLoss\nidentifier = { \"class_name\" : \"CategoricalCrossentropy\" , \"config\" : { \"from_logits\" : True } } loss = losses . get ( identifier ) type ( loss ) < class '... CategoricalCrossentropy ' >\nidentifier = { \"class_name\" : \"CategoricalCrossentropy\" ,\n\"config\" : { \"from_logits\" : True } }\nloss = losses . get ( identifier )\ntype ( loss )\n< class '... CategoricalCrossentropy ' >\nArgs\nArgs\nidentifier A loss identifier. One of None or string name of a loss\nfunction/class or loss configuration dictionary or a loss function\nor a loss class instance.\nidentifier\nReturns A Keras loss as a function / Loss class instance.\nReturns\nfunction\nLoss"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional",
    "content": "Bidirectional wrapper for RNNs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Bidirectional ( layer , merge_mode = 'concat' , weights = None , backward_layer = None , ** kwargs )\ntf . keras . layers . Bidirectional ( layer , merge_mode = 'concat' , weights = None , backward_layer = None , ** kwargs )\nUsed in the notebooks\nText classification with an RNN\nGraph regularization for sentiment classification using synthesized graphs\nNeural machine translation with attention\nArgs\nArgs\nlayer keras.layers.RNN instance, such as keras.layers.LSTM or keras.layers.GRU .\nIt could also be a keras.layers.Layer instance\nthat meets the following criteria:\nlayer\nkeras.layers.RNN\nkeras.layers.LSTM\nkeras.layers.GRU\nkeras.layers.Layer\nBe a sequence-processing layer (accepts 3D+ inputs).\nHave a go_backwards , return_sequences and return_state attribute (with the same semantics as for the RNN class).\ngo_backwards\nreturn_sequences\nreturn_state\nRNN\nHave an input_spec attribute.\ninput_spec\nImplement serialization via get_config() and from_config() .\nNote that the recommended way to create new RNN layers is to write a\ncustom RNN cell and use it with keras.layers.RNN , instead of\nsubclassing keras.layers.Layer directly.\nWhen return_sequences is True , the output of the masked\ntimestep will be zero regardless of the layer's original zero_output_for_mask value. merge_mode Mode by which outputs of the forward and backward RNNs\nwill be combined. One of {\"sum\", \"mul\", \"concat\", \"ave\", None} .\nIf None , the outputs will not be combined,\nthey will be returned as a list. Defaults to \"concat\" . backward_layer Optional keras.layers.RNN ,\nor keras.layers.Layer instance to be used to handle\nbackwards input processing.\nIf backward_layer is not provided, the layer instance passed\nas the layer argument will be used to generate the backward layer\nautomatically.\nNote that the provided backward_layer layer should have properties\nmatching those of the layer argument, in particular\nit should have the same values for stateful , return_states , return_sequences , etc. In addition, backward_layer and layer should have different go_backwards argument values.\nA ValueError will be raised if these requirements are not met.\nget_config()\nfrom_config()\nkeras.layers.RNN\nkeras.layers.Layer\nreturn_sequences\nTrue\nzero_output_for_mask\nmerge_mode\n{\"sum\", \"mul\", \"concat\", \"ave\", None}\nNone\n\"concat\"\nbackward_layer\nkeras.layers.RNN\nkeras.layers.Layer\nbackward_layer\nlayer\nbackward_layer\nlayer\nstateful\nreturn_states\nreturn_sequences\nbackward_layer\nlayer\ngo_backwards\nValueError\nCall arguments The call arguments for this layer are the same as those of the\nwrapped RNN layer. Beware that when passing the initial_state argument during the call of this layer, the first half in the\nlist of elements in the initial_state list will be passed to\nthe forward RNN call and the last half in the list of elements\nwill be passed to the backward RNN call.\nCall arguments\ninitial_state\ninitial_state\nBidirectional\nBidirectional\nmodel = Sequential ([ Input ( shape = ( 5 , 10 )), Bidirectional ( LSTM ( 10 , return_sequences = True ), Bidirectional ( LSTM ( 10 )), Dense ( 5 , activation = \"softmax\" ), ]) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'rmsprop' ) # With custom backward layer forward_layer = LSTM ( 10 , return_sequences = True ) backward_layer = LSTM ( 10 , activation = 'relu' , return_sequences = True , go_backwards = True ) model = Sequential ([ Input ( shape = ( 5 , 10 )), Bidirectional ( forward_layer , backward_layer = backward_layer ), Dense ( 5 , activation = \"softmax\" ), ]) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'rmsprop' )\nmodel = Sequential ([ Input ( shape = ( 5 , 10 )), Bidirectional ( LSTM ( 10 , return_sequences = True ), Bidirectional ( LSTM ( 10 )), Dense ( 5 , activation = \"softmax\" ), ]) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'rmsprop' ) # With custom backward layer forward_layer = LSTM ( 10 , return_sequences = True ) backward_layer = LSTM ( 10 , activation = 'relu' , return_sequences = True , go_backwards = True ) model = Sequential ([ Input ( shape = ( 5 , 10 )), Bidirectional ( forward_layer , backward_layer = backward_layer ), Dense ( 5 , activation = \"softmax\" ), ]) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'rmsprop' )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. states\nstates\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryFocalCrossentropy",
    "content": "Computes focal cross-entropy loss between true labels and predictions.\nInherits From: Loss\nLoss\ntf . keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'binary_focal_crossentropy' )\ntf . keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = False , alpha = 0.25 , gamma = 2.0 , from_logits = False , label_smoothing = 0.0 , axis =- 1 , reduction = 'sum_over_batch_size' , name = 'binary_focal_crossentropy' )\nBinary cross-entropy loss is often used for binary (0 or 1) classification\ntasks. The loss function requires the following inputs:\ny_true (true label): This is either 0 or 1.\ny_true\ny_pred (predicted value): This is the model's prediction, i.e, a single\nfloating-point value which either represents a logit , (i.e, value in [-inf, inf]\nwhen from_logits=True ) or a probability (i.e, value in [0., 1.] when from_logits=False ).\ny_pred\nfrom_logits=True\n[0., 1.]\nfrom_logits=False\nAccording to Lin et al., 2018 , it\nhelps to apply a \"focal factor\" to down-weight easy examples and focus more\non hard examples. By default, the focal tensor is computed as follows:\nfocal_factor = (1 - output) ** gamma for class 1 focal_factor = output ** gamma for class 0\nwhere gamma is a focusing parameter. When gamma=0 , this function is\nequivalent to the binary crossentropy loss.\nfocal_factor = (1 - output) ** gamma\nfocal_factor = output ** gamma\ngamma\ngamma=0\nArgs\nArgs\napply_class_balancing A bool, whether to apply weight balancing on the\nbinary classes 0 and 1. alpha A weight balancing factor for class 1, default is 0.25 as\nmentioned in reference Lin et al., 2018 .  The weight for class 0 is 1.0 - alpha . gamma A focusing parameter used to compute the focal factor, default is 2.0 as mentioned in the reference Lin et al., 2018 . from_logits Whether to interpret y_pred as a tensor of logit values. By default, we\nassume that y_pred are probabilities (i.e., values in [0, 1] ). label_smoothing Float in [0, 1] . When 0 , no smoothing occurs.\nWhen > 0 , we compute the loss between the predicted labels\nand a smoothed version of the true labels, where the smoothing\nsqueezes the labels towards 0.5 .\nLarger values of label_smoothing correspond to heavier smoothing. axis The axis along which to compute crossentropy (the features axis).\nDefaults to -1 . reduction Type of reduction to apply to the loss. In almost all cases\nthis should be \"sum_over_batch_size\" .\nSupported options are \"sum\" , \"sum_over_batch_size\" or None . name Optional name for the loss instance.\napply_class_balancing\nalpha\n0.25\n1.0 - alpha\ngamma\n2.0\nfrom_logits\ny_pred\ny_pred\n[0, 1]\nlabel_smoothing\n[0, 1]\n0\n0\n0.5\nlabel_smoothing\naxis\n-1\nreduction\n\"sum_over_batch_size\"\n\"sum\"\n\"sum_over_batch_size\"\nNone\nname\nWith the compile() API:\ncompile()\nmodel . compile ( loss = keras . losses . BinaryFocalCrossentropy ( gamma = 2.0 , from_logits = True ), ... )\nmodel . compile ( loss = keras . losses . BinaryFocalCrossentropy ( gamma = 2.0 , from_logits = True ), ... )\nAs a standalone function:\n# Example 1: (batch_size = 1, number of samples = 4) y_true = [ 0 , 1 , 0 , 0 ] y_pred = [ - 18.6 , 0.51 , 2.94 , - 12.8 ] loss = keras . losses . BinaryFocalCrossentropy ( gamma = 2 , from_logits = True ) loss ( y_true , y_pred ) 0.691\n# Example 1: (batch_size = 1, number of samples = 4)\ny_true = [ 0 , 1 , 0 , 0 ]\ny_pred = [ - 18.6 , 0.51 , 2.94 , - 12.8 ]\nloss = keras . losses . BinaryFocalCrossentropy (\ngamma = 2 , from_logits = True )\nloss ( y_true , y_pred )\n0.691\n# Apply class weight loss = keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = True , gamma = 2 , from_logits = True ) loss ( y_true , y_pred ) 0.51\n# Apply class weight\nloss = keras . losses . BinaryFocalCrossentropy (\napply_class_balancing = True , gamma = 2 , from_logits = True )\nloss ( y_true , y_pred )\n0.51\n# Example 2: (batch_size = 2, number of samples = 4) y_true = [[ 0 , 1 ], [ 0 , 0 ]] y_pred = [[ - 18.6 , 0.51 ], [ 2.94 , - 12.8 ]] # Using default 'auto'/'sum_over_batch_size' reduction type. loss = keras . losses . BinaryFocalCrossentropy ( gamma = 3 , from_logits = True ) loss ( y_true , y_pred ) 0.647\n# Example 2: (batch_size = 2, number of samples = 4)\ny_true = [[ 0 , 1 ], [ 0 , 0 ]]\ny_pred = [[ - 18.6 , 0.51 ], [ 2.94 , - 12.8 ]]\n# Using default 'auto'/'sum_over_batch_size' reduction type.\nloss = keras . losses . BinaryFocalCrossentropy (\ngamma = 3 , from_logits = True )\nloss ( y_true , y_pred )\n0.647\n# Apply class weight loss = keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = True , gamma = 3 , from_logits = True ) loss ( y_true , y_pred ) 0.482\n# Apply class weight\nloss = keras . losses . BinaryFocalCrossentropy (\napply_class_balancing = True , gamma = 3 , from_logits = True )\nloss ( y_true , y_pred )\n0.482\n# Using 'sample_weight' attribute with focal effect loss = keras . losses . BinaryFocalCrossentropy ( gamma = 3 , from_logits = True ) loss ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ]) 0.133\n# Using 'sample_weight' attribute with focal effect\nloss = keras . losses . BinaryFocalCrossentropy (\ngamma = 3 , from_logits = True )\nloss ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ])\n0.133\n# Apply class weight loss = keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = True , gamma = 3 , from_logits = True ) loss ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ]) 0.097\n# Apply class weight\nloss = keras . losses . BinaryFocalCrossentropy (\napply_class_balancing = True , gamma = 3 , from_logits = True )\nloss ( y_true , y_pred , sample_weight = [ 0.8 , 0.2 ])\n0.097\n# Using 'sum' reduction` type. loss = keras . losses . BinaryFocalCrossentropy ( gamma = 4 , from_logits = True , reduction = \"sum\" ) loss ( y_true , y_pred ) 1.222\n# Using 'sum' reduction` type.\nloss = keras . losses . BinaryFocalCrossentropy (\ngamma = 4 , from_logits = True ,\nreduction = \"sum\" )\nloss ( y_true , y_pred )\n1.222\n# Apply class weight loss = keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = True , gamma = 4 , from_logits = True , reduction = \"sum\" ) loss ( y_true , y_pred ) 0.914\n# Apply class weight\nloss = keras . losses . BinaryFocalCrossentropy (\napply_class_balancing = True , gamma = 4 , from_logits = True ,\nreduction = \"sum\" )\nloss ( y_true , y_pred )\n0.914\n# Using 'none' reduction type. loss = keras . losses . BinaryFocalCrossentropy ( gamma = 5 , from_logits = True , reduction = None ) loss ( y_true , y_pred ) array ([ 0.0017 1.1561 ], dtype = float32 )\n# Using 'none' reduction type.\nloss = keras . losses . BinaryFocalCrossentropy (\ngamma = 5 , from_logits = True ,\nreduction = None )\nloss ( y_true , y_pred )\narray ([ 0.0017 1.1561 ], dtype = float32 )\n# Apply class weight loss = keras . losses . BinaryFocalCrossentropy ( apply_class_balancing = True , gamma = 5 , from_logits = True , reduction = None ) loss ( y_true , y_pred ) array ([ 0.0004 0.8670 ], dtype = float32 )\n# Apply class weight\nloss = keras . losses . BinaryFocalCrossentropy (\napply_class_balancing = True , gamma = 5 , from_logits = True ,\nreduction = None )\nloss ( y_true , y_pred )\narray ([ 0.0004 0.8670 ], dtype = float32 )\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/assert_same_structure",
    "content": "Asserts that two structures are nested in the same way.\ntf . keras . tree . assert_same_structure ( a , b , check_types = True )\ntf . keras . tree . assert_same_structure ( a , b , check_types = True )\nNote that namedtuples with identical name and fields will not be considered\nas same structures even check_types=False .\ncheck_types=False\nkeras . tree . assert_same_structure ([( 0 , 1 )], [( 2 , 3 )])\nkeras . tree . assert_same_structure ([( 0 , 1 )], [( 2 , 3 )])\nFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ]) AlsoFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ]) keras . tree . assert_same_structure ( Foo ( 0 , 1 ), Foo ( 2 , 3 )) keras . tree . assert_same_structure ( Foo ( 0 , 1 ), AlsoFoo ( 2 , 3 )) Traceback ( most recent call last ): ValueError : ` a ` and ` b ` don 't have the same structure.\nFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ])\nAlsoFoo = collections . namedtuple ( 'Foo' , [ 'a' , 'b' ])\nkeras . tree . assert_same_structure ( Foo ( 0 , 1 ), Foo ( 2 , 3 ))\nkeras . tree . assert_same_structure ( Foo ( 0 , 1 ), AlsoFoo ( 2 , 3 ))\nTraceback ( most recent call last ):\nValueError : ` a ` and ` b ` don 't have the same structure.\nArgs\nArgs\na an arbitrarily nested structure. b an arbitrarily nested structure. check_types if True (default) types of leaves are checked as well.\na\nb\ncheck_types\nTrue"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/log",
    "content": "DEPRECATED.\ntf . keras . backend . log ( x )\ntf . keras . backend . log ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . inception_v3 . preprocess_input ( x , data_format = None )\ntf . keras . applications . inception_v3 . preprocess_input ( x , data_format = None )\nUsed in the notebooks\nDeepDream\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/serialize",
    "content": "Serializes loss function or Loss instance.\nLoss\ntf . keras . losses . serialize ( loss )\ntf . keras . losses . serialize ( loss )\nArgs\nArgs\nloss A Keras Loss instance or a loss function.\nloss\nLoss\nReturns Loss configuration dictionary.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sinh",
    "content": "Hyperbolic sine, element-wise.\nMain aliases tf.keras.ops.numpy.sinh\ntf.keras.ops.numpy.sinh\ntf.keras.ops.numpy.sinh\ntf . keras . ops . sinh ( x )\ntf . keras . ops . sinh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization",
    "content": "A preprocessing layer that normalizes continuous features.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Normalization ( axis =- 1 , mean = None , variance = None , invert = False , ** kwargs )\ntf . keras . layers . Normalization ( axis =- 1 , mean = None , variance = None , invert = False , ** kwargs )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nWorking with preprocessing layers\nLoad a pandas DataFrame\nBasic regression: Predict fuel efficiency\nLoad CSV data\nSimple audio recognition: Recognizing keywords\nClassify structured data using Keras preprocessing layers\nThis layer will shift and scale inputs into a distribution centered around\n0 with standard deviation 1. It accomplishes this by precomputing the mean\nand variance of the data, and calling (input - mean) / sqrt(var) at\nruntime.\n(input - mean) / sqrt(var)\nThe mean and variance values for the layer must be either supplied on\nconstruction or learned via adapt() . adapt() will compute the mean and\nvariance of the data and store them as the layer's weights. adapt() should\nbe called before fit() , evaluate() , or predict() .\nadapt()\nadapt()\nadapt()\nfit()\nevaluate()\npredict()\nArgs\nArgs\naxis Integer, tuple of integers, or None. The axis or axes that should\nhave a separate mean and variance for each index in the shape.\nFor example, if shape is (None, 5) and axis=1 , the layer will\ntrack 5 separate mean and variance values for the last axis.\nIf axis is set to None , the layer will normalize\nall elements in the input by a scalar mean and variance.\nWhen -1 , the last axis of the input is assumed to be a\nfeature dimension and is normalized per index.\nNote that in the specific case of batched scalar inputs where\nthe only axis is the batch axis, the default will normalize\neach index in the batch separately.\nIn this case, consider passing axis=None . Defaults to -1 . mean The mean value(s) to use during normalization. The passed value(s)\nwill be broadcast to the shape of the kept axes above;\nif the value(s) cannot be broadcast, an error will be raised when\nthis layer's build() method is called. variance The variance value(s) to use during normalization. The passed\nvalue(s) will be broadcast to the shape of the kept axes above;\nif the value(s) cannot be broadcast, an error will be raised when\nthis layer's build() method is called. invert If True , this layer will apply the inverse transformation\nto its inputs: it would turn a normalized input back into its\noriginal form.\naxis\n(None, 5)\naxis=1\naxis\nNone\n-1\naxis=None\n-1\nmean\nbuild()\nvariance\nbuild()\ninvert\nTrue\nCalculate a global mean and variance by analyzing the dataset in adapt() .\nadapt()\nadapt_data = np . array ([ 1. , 2. , 3. , 4. , 5. ], dtype = 'float32' ) input_data = np . array ([ 1. , 2. , 3. ], dtype = 'float32' ) layer = keras . layers . Normalization ( axis = None ) layer . adapt ( adapt_data ) layer ( input_data ) array ([ - 1.4142135 , - 0.70710677 , 0. ], dtype = float32 )\nadapt_data = np . array ([ 1. , 2. , 3. , 4. , 5. ], dtype = 'float32' )\ninput_data = np . array ([ 1. , 2. , 3. ], dtype = 'float32' )\nlayer = keras . layers . Normalization ( axis = None )\nlayer . adapt ( adapt_data )\nlayer ( input_data )\narray ([ - 1.4142135 , - 0.70710677 , 0. ], dtype = float32 )\nCalculate a mean and variance for each index on the last axis.\nadapt_data = np . array ([[ 0. , 7. , 4. ], [ 2. , 9. , 6. ], [ 0. , 7. , 4. ], [ 2. , 9. , 6. ]], dtype = 'float32' ) input_data = np . array ([[ 0. , 7. , 4. ]], dtype = 'float32' ) layer = keras . layers . Normalization ( axis =- 1 ) layer . adapt ( adapt_data ) layer ( input_data ) array ([ - 1. , - 1. , - 1. ], dtype = float32 )\nadapt_data = np . array ([[ 0. , 7. , 4. ],\n[ 2. , 9. , 6. ],\n[ 0. , 7. , 4. ],\n[ 2. , 9. , 6. ]], dtype = 'float32' )\ninput_data = np . array ([[ 0. , 7. , 4. ]], dtype = 'float32' )\nlayer = keras . layers . Normalization ( axis =- 1 )\nlayer . adapt ( adapt_data )\nlayer ( input_data )\narray ([ - 1. , - 1. , - 1. ], dtype = float32 )\nPass the mean and variance directly.\ninput_data = np . array ([[ 1. ], [ 2. ], [ 3. ]], dtype = 'float32' ) layer = keras . layers . Normalization ( mean = 3. , variance = 2. ) layer ( input_data ) array ([[ - 1.4142135 ], [ - 0.70710677 ], [ 0. ]], dtype = float32 )\ninput_data = np . array ([[ 1. ], [ 2. ], [ 3. ]], dtype = 'float32' )\nlayer = keras . layers . Normalization ( mean = 3. , variance = 2. )\nlayer ( input_data )\narray ([[ - 1.4142135 ],\n[ - 0.70710677 ],\n[ 0. ]], dtype = float32 )\nUse the layer to de-normalize inputs (after adapting the layer).\nadapt_data = np . array ([[ 0. , 7. , 4. ], [ 2. , 9. , 6. ], [ 0. , 7. , 4. ], [ 2. , 9. , 6. ]], dtype = 'float32' ) input_data = np . array ([[ 1. , 2. , 3. ]], dtype = 'float32' ) layer = keras . layers . Normalization ( axis =- 1 , invert = True ) layer . adapt ( adapt_data ) layer ( input_data ) array ([ 2. , 10. , 8. ], dtype = float32 )\nadapt_data = np . array ([[ 0. , 7. , 4. ],\n[ 2. , 9. , 6. ],\n[ 0. , 7. , 4. ],\n[ 2. , 9. , 6. ]], dtype = 'float32' )\ninput_data = np . array ([[ 1. , 2. , 3. ]], dtype = 'float32' )\nlayer = keras . layers . Normalization ( axis =- 1 , invert = True )\nlayer . adapt ( adapt_data )\nlayer ( input_data )\narray ([ 2. , 10. , 8. ], dtype = float32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( data )\nadapt ( data )\nComputes the mean and variance of values in a dataset.\nCalling adapt() on a Normalization layer is an alternative to\npassing in mean and variance arguments during layer construction. A Normalization layer should always either be adapted over a dataset or\npassed mean and variance .\nadapt()\nNormalization\nmean\nvariance\nNormalization\nmean\nvariance\nDuring adapt() , the layer will compute a mean and variance separately for each position in each axis specified by the axis argument. To calculate a single mean and variance over the input\ndata, simply pass axis=None to the layer.\nadapt()\nmean\nvariance\naxis\nmean\nvariance\naxis=None\nArg\ndata The data to train on. It can be passed either as a tf.data.Dataset , as a NumPy array, or as a backend-native\neager tensor.\nIf a dataset, it must be batched . Keras will assume that the\ndata is batched, and if that assumption doesn't hold, the mean\nand variance may be incorrectly computed.\ndata\ntf.data.Dataset\nfinalize_state\nfinalize_state\nView source\nfinalize_state ()\nfinalize_state ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup",
    "content": "A preprocessing layer that maps integers to (possibly encoded) indices.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . IntegerLookup ( max_tokens = None , num_oov_indices = 1 , mask_token = None , oov_token =- 1 , vocabulary = None , vocabulary_dtype = 'int64' , idf_weights = None , invert = False , output_mode = 'int' , sparse = False , pad_to_max_tokens = False , name = None , ** kwargs )\ntf . keras . layers . IntegerLookup ( max_tokens = None , num_oov_indices = 1 , mask_token = None , oov_token =- 1 , vocabulary = None , vocabulary_dtype = 'int64' , idf_weights = None , invert = False , output_mode = 'int' , sparse = False , pad_to_max_tokens = False , name = None , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nLoad a pandas DataFrame\nClassify structured data using Keras preprocessing layers\nDeep & Cross Network (DCN)\nThis layer maps a set of arbitrary integer input tokens into indexed integer\noutput via a table-based vocabulary lookup. The layer's output indices will\nbe contiguously arranged up to the maximum vocab size, even if the input\ntokens are non-continguous or unbounded. The layer supports multiple options\nfor encoding the output via output_mode , and has optional support for\nout-of-vocabulary (OOV) tokens and masking.\noutput_mode\nThe vocabulary for the layer must be either supplied on construction or\nlearned via adapt() . During adapt() , the layer will analyze a data set,\ndetermine the frequency of individual integer tokens, and create a\nvocabulary from them. If the vocabulary is capped in size, the most frequent\ntokens will be used to create the vocabulary and all others will be treated\nas OOV.\nadapt()\nadapt()\nThere are two possible output modes for the layer.  When output_mode is \"int\" , input integers are converted to their index in the vocabulary (an\ninteger).  When output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" ,\ninput integers are encoded into an array where each dimension corresponds to\nan element in the vocabulary.\noutput_mode\n\"int\"\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nThe vocabulary can optionally contain a mask token as well as an OOV token\n(which can optionally occupy multiple indices in the vocabulary, as set\nby num_oov_indices ).\nThe position of these tokens in the vocabulary is fixed. When output_mode is \"int\" , the vocabulary will begin with the mask token at index 0,\nfollowed by OOV indices, followed by the rest of the vocabulary. When output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" the vocabulary will\nbegin with OOV indices and instances of the mask token will be dropped.\nnum_oov_indices\noutput_mode\n\"int\"\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\ntf.data\nArgs\nArgs\nmax_tokens Maximum size of the vocabulary for this layer. This should\nonly be specified when adapting the vocabulary or when setting pad_to_max_tokens=True . If None, there is no cap on the size of\nthe vocabulary. Note that this size includes the OOV\nand mask tokens. Defaults to None . num_oov_indices The number of out-of-vocabulary tokens to use.\nIf this value is more than 1, OOV inputs are modulated to\ndetermine their OOV value.\nIf this value is 0, OOV inputs will cause an error when calling\nthe layer. Defaults to 1 . mask_token An integer token that represents masked inputs. When output_mode is \"int\" , the token is included in vocabulary\nand mapped to index 0. In other output modes,\nthe token will not appear in the vocabulary and instances\nof the mask token in the input will be dropped.\nIf set to None, no mask term will be added. Defaults to None . oov_token Only used when invert is True . The token to return\nfor OOV indices. Defaults to -1 . vocabulary Optional. Either an array of integers or a string path to a\ntext file. If passing an array, can pass a tuple, list,\n1D NumPy array, or 1D tensor containing the integer vocbulary terms.\nIf passing a file path, the file should contain one line per term\nin the vocabulary. If this argument is set,\nthere is no need to adapt() the layer. vocabulary_dtype The dtype of the vocabulary terms, for example \"int64\" or \"int32\" . Defaults to \"int64\" . idf_weights Only valid when output_mode is \"tf_idf\" .\nA tuple, list, 1D NumPy array, or 1D tensor or the same length\nas the vocabulary, containing the floating point inverse document\nfrequency weights, which will be multiplied by per sample term\ncounts for the final TF-IDF weight.\nIf the vocabulary argument is set, and output_mode is \"tf_idf\" , this argument must be supplied. invert Only valid when output_mode is \"int\" .\nIf True , this layer will map indices to vocabulary items\ninstead of mapping vocabulary items to indices.\nDefaults to False . output_mode Specification for the output of the layer. Values can be \"int\" , \"one_hot\" , \"multi_hot\" , \"count\" , or \"tf_idf\" configuring the layer as follows:\nmax_tokens\npad_to_max_tokens=True\nNone\nnum_oov_indices\n1\nmask_token\noutput_mode\n\"int\"\nNone\noov_token\ninvert\nTrue\n-1\nvocabulary\nadapt()\nvocabulary_dtype\n\"int64\"\n\"int32\"\n\"int64\"\nidf_weights\noutput_mode\n\"tf_idf\"\nvocabulary\noutput_mode\n\"tf_idf\"\ninvert\noutput_mode\n\"int\"\nTrue\nFalse\noutput_mode\n\"int\"\n\"one_hot\"\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\n\"int\" : Return the vocabulary indices of the input tokens.\n\"int\"\n\"one_hot\" : Encodes each individual element in the input into an\narray the same size as the vocabulary,\ncontaining a 1 at the element index. If the last dimension\nis size 1, will encode on that dimension.\nIf the last dimension is not size 1, will append a new\ndimension for the encoded output.\n\"one_hot\"\n\"multi_hot\" : Encodes each sample in the input into a single\narray the same size as the vocabulary,\ncontaining a 1 for each vocabulary term present in the sample.\nTreats the last dimension as the sample dimension,\nif input shape is (..., sample_length) ,\noutput shape will be (..., num_tokens) .\n\"multi_hot\"\n(..., sample_length)\n(..., num_tokens)\n\"count\" : As \"multi_hot\" , but the int array contains\na count of the number of times the token at that index\nappeared in the sample.\n\"count\"\n\"multi_hot\"\n\"tf_idf\" : As \"multi_hot\" , but the TF-IDF algorithm is\napplied to find the value in each token slot.\nFor \"int\" output, any shape of input and output is supported.\nFor all other output modes, currently only output up to rank 2\nis supported. Defaults to \"int\" . pad_to_max_tokens Only applicable when output_mode is \"multi_hot\" , \"count\" , or \"tf_idf\" . If True , the output will have\nits feature axis padded to max_tokens even if the number\nof unique tokens in the vocabulary is less than max_tokens ,\nresulting in a tensor of shape (batch_size, max_tokens) regardless of vocabulary size. Defaults to False . sparse Boolean. Only applicable to \"multi_hot\" , \"count\" , and \"tf_idf\" output modes. Only supported with TensorFlow\nbackend. If True , returns a SparseTensor instead of a dense Tensor . Defaults to False .\n\"tf_idf\"\n\"multi_hot\"\n\"int\"\n\"int\"\npad_to_max_tokens\noutput_mode\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nmax_tokens\nmax_tokens\n(batch_size, max_tokens)\nFalse\nsparse\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nSparseTensor\nTensor\nFalse\nCreating a lookup layer with a known vocabulary\nThis example creates a lookup layer with a pre-existing vocabulary.\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]]) # Note OOV tokens layer = IntegerLookup ( vocabulary = vocab ) layer ( data ) array ([[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]])\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]]) # Note OOV tokens\nlayer = IntegerLookup ( vocabulary = vocab )\nlayer ( data )\narray ([[ 1 , 3 , 4 ],\n[ 4 , 0 , 2 ]])\nCreating a lookup layer with an adapted vocabulary\nThis example creates a lookup layer and generates the vocabulary by\nanalyzing the dataset.\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]]) layer = IntegerLookup () layer . adapt ( data ) layer . get_vocabulary () [ - 1 , 42 , 1138 , 1000 , 36 , 12 ]\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]])\nlayer = IntegerLookup ()\nlayer . adapt ( data )\nlayer . get_vocabulary ()\n[ - 1 , 42 , 1138 , 1000 , 36 , 12 ]\nNote that the OOV token -1 have been added to the vocabulary. The remaining\ntokens are sorted by frequency (42, which has 2 occurrences, is first) then\nby inverse sort order.\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]]) layer = IntegerLookup () layer . adapt ( data ) layer ( data ) array ([[ 5 , 2 , 1 ], [ 1 , 3 , 4 ]])\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]])\nlayer = IntegerLookup ()\nlayer . adapt ( data )\nlayer ( data )\narray ([[ 5 , 2 , 1 ],\n[ 1 , 3 , 4 ]])\nLookups with multiple OOV indices\nThis example demonstrates how to use a lookup layer with multiple OOV\nindices.  When a layer is created with more than one OOV index, any OOV\ntokens are hashed into the number of OOV buckets, distributing OOV tokens in\na deterministic fashion across the set.\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 12 , 1138 , 42 ], [ 37 , 1000 , 36 ]]) layer = IntegerLookup ( vocabulary = vocab , num_oov_indices = 2 ) layer ( data ) array ([[ 2 , 4 , 5 ], [ 1 , 0 , 3 ]])\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 12 , 1138 , 42 ], [ 37 , 1000 , 36 ]])\nlayer = IntegerLookup ( vocabulary = vocab , num_oov_indices = 2 )\nlayer ( data )\narray ([[ 2 , 4 , 5 ],\n[ 1 , 0 , 3 ]])\nNote that the output for OOV token 37 is 1, while the output for OOV token\n1000 is 0. The in-vocab terms have their output index increased by 1 from\nearlier examples (12 maps to 2, etc) in order to make space for the extra\nOOV token.\nOne-hot output\nConfigure the layer with output_mode='one_hot' . Note that the first num_oov_indices dimensions in the ont_hot encoding represent OOV values.\noutput_mode='one_hot'\nnum_oov_indices\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([ 12 , 36 , 1138 , 42 , 7 ]) # Note OOV tokens layer = IntegerLookup ( vocabulary = vocab , output_mode = 'one_hot' ) layer ( data ) array ([[ 0. , 1. , 0. , 0. , 0. ], [ 0. , 0. , 1. , 0. , 0. ], [ 0. , 0. , 0. , 1. , 0. ], [ 0. , 0. , 0. , 0. , 1. ], [ 1. , 0. , 0. , 0. , 0. ]], dtype = float32 )\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([ 12 , 36 , 1138 , 42 , 7 ]) # Note OOV tokens\nlayer = IntegerLookup ( vocabulary = vocab , output_mode = 'one_hot' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 0. , 0. ],\n[ 0. , 0. , 1. , 0. , 0. ],\n[ 0. , 0. , 0. , 1. , 0. ],\n[ 0. , 0. , 0. , 0. , 1. ],\n[ 1. , 0. , 0. , 0. , 0. ]], dtype = float32 )\nMulti-hot output\nConfigure the layer with output_mode='multi_hot' . Note that the first num_oov_indices dimensions in the multi_hot encoding represent OOV tokens\noutput_mode='multi_hot'\nnum_oov_indices\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 12 , 1138 , 42 , 42 ], [ 42 , 7 , 36 , 7 ]]) # Note OOV tokens layer = IntegerLookup ( vocabulary = vocab , output_mode = 'multi_hot' ) layer ( data ) array ([[ 0. , 1. , 0. , 1. , 1. ], [ 1. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 12 , 1138 , 42 , 42 ],\n[ 42 , 7 , 36 , 7 ]]) # Note OOV tokens\nlayer = IntegerLookup ( vocabulary = vocab , output_mode = 'multi_hot' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 1. , 1. ],\n[ 1. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nToken count output\nConfigure the layer with output_mode='count' . As with multi_hot output,\nthe first num_oov_indices dimensions in the output represent OOV tokens.\noutput_mode='count'\nnum_oov_indices\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 12 , 1138 , 42 , 42 ], [ 42 , 7 , 36 , 7 ]]) # Note OOV tokens layer = IntegerLookup ( vocabulary = vocab , output_mode = 'count' ) layer ( data ) array ([[ 0. , 1. , 0. , 1. , 2. ], [ 2. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 12 , 1138 , 42 , 42 ],\n[ 42 , 7 , 36 , 7 ]]) # Note OOV tokens\nlayer = IntegerLookup ( vocabulary = vocab , output_mode = 'count' )\nlayer ( data )\narray ([[ 0. , 1. , 0. , 1. , 2. ],\n[ 2. , 0. , 1. , 0. , 1. ]], dtype = float32 )\nTF-IDF output\nConfigure the layer with output_mode='tf_idf' . As with multi_hot output,\nthe first num_oov_indices dimensions in the output represent OOV tokens.\noutput_mode='tf_idf'\nnum_oov_indices\nEach token bin will output token_count * idf_weight , where the idf weights\nare the inverse document frequency weights per token. These should be\nprovided along with the vocabulary. Note that the idf_weight for OOV\ntokens will default to the average of all idf weights passed in.\ntoken_count * idf_weight\nidf_weight\nvocab = [ 12 , 36 , 1138 , 42 ] idf_weights = [ 0.25 , 0.75 , 0.6 , 0.4 ] data = np . array ([[ 12 , 1138 , 42 , 42 ], [ 42 , 7 , 36 , 7 ]]) # Note OOV tokens layer = IntegerLookup ( output_mode = 'tf_idf' , vocabulary = vocab , idf_weights = idf_weights ) layer ( data ) array ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ], [ 1.0 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nvocab = [ 12 , 36 , 1138 , 42 ]\nidf_weights = [ 0.25 , 0.75 , 0.6 , 0.4 ]\ndata = np . array ([[ 12 , 1138 , 42 , 42 ],\n[ 42 , 7 , 36 , 7 ]]) # Note OOV tokens\nlayer = IntegerLookup (\noutput_mode = 'tf_idf' , vocabulary = vocab , idf_weights = idf_weights )\nlayer ( data )\narray ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ],\n[ 1.0 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nTo specify the idf weights for oov tokens, you will need to pass the entire\nvocabulary including the leading oov token.\nvocab = [ - 1 , 12 , 36 , 1138 , 42 ] idf_weights = [ 0.9 , 0.25 , 0.75 , 0.6 , 0.4 ] data = np . array ([[ 12 , 1138 , 42 , 42 ], [ 42 , 7 , 36 , 7 ]]) # Note OOV tokens layer = IntegerLookup ( output_mode = 'tf_idf' , vocabulary = vocab , idf_weights = idf_weights ) layer ( data ) array ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ], [ 1.8 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nvocab = [ - 1 , 12 , 36 , 1138 , 42 ]\nidf_weights = [ 0.9 , 0.25 , 0.75 , 0.6 , 0.4 ]\ndata = np . array ([[ 12 , 1138 , 42 , 42 ],\n[ 42 , 7 , 36 , 7 ]]) # Note OOV tokens\nlayer = IntegerLookup (\noutput_mode = 'tf_idf' , vocabulary = vocab , idf_weights = idf_weights )\nlayer ( data )\narray ([[ 0. , 0.25 , 0. , 0.6 , 0.8 ],\n[ 1.8 , 0. , 0.75 , 0. , 0.4 ]], dtype = float32 )\nWhen adapting the layer in \"tf_idf\" mode, each input sample will\nbe considered a document, and IDF weight per token will be\ncalculated as: log(1 + num_documents / (1 + token_document_count)) .\n\"tf_idf\"\nlog(1 + num_documents / (1 + token_document_count))\nInverse lookup\nThis example demonstrates how to map indices to tokens using this layer.\n(You can also use adapt() with inverse=True , but for simplicity we'll\npass the vocab in this example.)\nadapt()\ninverse=True\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]]) layer = IntegerLookup ( vocabulary = vocab , invert = True ) layer ( data ) array ([[ 12 , 1138 , 42 ], [ 42 , - 1 , 36 ]])\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 1 , 3 , 4 ], [ 4 , 0 , 2 ]])\nlayer = IntegerLookup ( vocabulary = vocab , invert = True )\nlayer ( data )\narray ([[ 12 , 1138 , 42 ],\n[ 42 , - 1 , 36 ]])\nNote that the first index correspond to the oov token by default.\nForward and inverse lookup pairs\nThis example demonstrates how to use the vocabulary of a standard lookup\nlayer to create an inverse lookup layer.\nvocab = [ 12 , 36 , 1138 , 42 ] data = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]]) layer = IntegerLookup ( vocabulary = vocab ) i_layer = IntegerLookup ( vocabulary = layer . get_vocabulary (), invert = True ) int_data = layer ( data ) i_layer ( int_data ) array ([[ 12 , 1138 , 42 ], [ 42 , - 1 , 36 ]])\nvocab = [ 12 , 36 , 1138 , 42 ]\ndata = np . array ([[ 12 , 1138 , 42 ], [ 42 , 1000 , 36 ]])\nlayer = IntegerLookup ( vocabulary = vocab )\ni_layer = IntegerLookup (\nvocabulary = layer . get_vocabulary (), invert = True )\nint_data = layer ( data )\ni_layer ( int_data )\narray ([[ 12 , 1138 , 42 ],\n[ 42 , - 1 , 36 ]])\nIn this example, the input token 1000 resulted in an output of -1, since\n1000 was not in the vocabulary - it got represented as an OOV, and all OOV\ntokens are returned as -1 in the inverse layer. Also, note that for the\ninverse to work, you must have already set the forward layer vocabulary\neither directly or via adapt() before calling get_vocabulary() .\nadapt()\nget_vocabulary()\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( data , steps = None )\nadapt ( data , steps = None )\nComputes a vocabulary of integer terms from tokens in a dataset.\nCalling adapt() on an IntegerLookup layer is an alternative to\npassing in a precomputed vocabulary  on construction via the vocabulary argument.  An IntegerLookup layer should always be either\nadapted over a dataset or supplied with a vocabulary.\nadapt()\nIntegerLookup\nvocabulary\nIntegerLookup\nDuring adapt() , the layer will build a vocabulary of all integer\ntokens seen in the dataset, sorted by occurrence count, with ties broken\nby sort order of the tokens (high to low). At the end of adapt() , if max_tokens is set, the vocabulary will be truncated to max_tokens size. For example, adapting a layer with max_tokens=1000 will compute\nthe 1000 most frequent tokens occurring in the input dataset. If output_mode='tf-idf' , adapt() will also learn the document\nfrequencies of each token in the input dataset.\nadapt()\nadapt()\nmax_tokens\nmax_tokens\nmax_tokens=1000\noutput_mode='tf-idf'\nadapt()\nArguments\ndata The data to train on. It can be passed either as a\nbatched tf.data.Dataset , as a list of integers,\nor as a NumPy array. steps Integer or None .\nTotal number of steps (batches of samples) to process.\nIf data is a tf.data.Dataset , and steps is None , adapt() will run until the input dataset is exhausted.\nWhen passing an infinitely\nrepeating dataset, you must specify the steps argument. This\nargument is not supported with array inputs or list inputs.\ndata\ntf.data.Dataset\nsteps\nNone\ndata\ntf.data.Dataset\nsteps\nNone\nadapt()\nsteps\nfinalize_state\nfinalize_state\nView source\nfinalize_state ()\nfinalize_state ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_vocabulary\nget_vocabulary\nView source\nget_vocabulary ( include_special_tokens = True )\nget_vocabulary ( include_special_tokens = True )\nReturns the current vocabulary of the layer.\nArgs\ninclude_special_tokens If True , the returned vocabulary\nwill include mask and OOV tokens,\nand a term's index in the vocabulary\nwill equal the term's index when calling the layer.\nIf False , the returned vocabulary will not include\nany mask or OOV tokens.\ninclude_special_tokens\nTrue\nFalse\nload_assets\nload_assets\nView source\nload_assets ( dir_path )\nload_assets ( dir_path )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nsave_assets\nsave_assets\nView source\nsave_assets ( dir_path )\nsave_assets ( dir_path )\nset_vocabulary\nset_vocabulary\nView source\nset_vocabulary ( vocabulary , idf_weights = None )\nset_vocabulary ( vocabulary , idf_weights = None )\nSets vocabulary (and optionally document frequency) for this layer.\nThis method sets the vocabulary and idf weights for this layer directly,\ninstead of analyzing a dataset through adapt . It should be used\nwhenever the vocab (and optionally document frequency) information is\nalready known.  If vocabulary data is already present in the layer, this\nmethod will replace it.\nadapt\nArgs\nvocabulary Either an array or a string path to a text file.\nIf passing an array, can pass a tuple, list,\n1D numpy array, or 1D tensor containing the vocbulary terms.\nIf passing a file path, the file should contain one line\nper term in the vocabulary. idf_weights A tuple, list, 1D numpy array, or 1D tensor\nof inverse document frequency weights with equal\nlength to vocabulary. Must be set if output_mode is \"tf_idf\" . Should not be set otherwise.\nvocabulary\nidf_weights\noutput_mode\n\"tf_idf\"\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( data )\nupdate_state ( data )\nvocabulary_size\nvocabulary_size\nView source\nvocabulary_size ()\nvocabulary_size ()\nGets the current size of the layer's vocabulary.\nReturns The integer size of the vocabulary, including optional mask and oov\nindices."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/l2_normalize",
    "content": "DEPRECATED.\ntf . keras . backend . l2_normalize ( x , axis = None )\ntf . keras . backend . l2_normalize ( x , axis = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adamax",
    "content": "Optimizer that implements the Adamax algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Adamax ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adamax' , ** kwargs )\ntf . keras . optimizers . Adamax ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adamax' , ** kwargs )\nAdamax, a variant of Adam based on the infinity norm, is a first-order\ngradient-based optimization method. Due to its capability of adjusting the\nlearning rate based on data characteristics, it is suited to learn\ntime-variant process, e.g., speech data with dynamically changed noise\nconditions. Default parameters follow those provided in the paper (see\nreferences below).\nm = 0 # Initialize initial 1st moment vector u = 0 # Initialize the exponentially weighted infinity norm t = 0 # Initialize timestep\nm = 0 # Initialize initial 1st moment vector u = 0 # Initialize the exponentially weighted infinity norm t = 0 # Initialize timestep\nThe update rule for parameter w with gradient g is described at the end\nof section 7.1 of the paper (see the referenece section):\nw\ng\nt += 1 m = beta1 * m + ( 1 - beta ) * g u = max ( beta2 * u , abs ( g )) current_lr = learning_rate / ( 1 - beta1 ** t ) w = w - current_lr * m / ( u + epsilon )\nt += 1 m = beta1 * m + ( 1 - beta ) * g u = max ( beta2 * u , abs ( g )) current_lr = learning_rate / ( 1 - beta1 ** t ) w = w - current_lr * m / ( u + epsilon )\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_1 A float value or a constant float tensor. The exponential decay\nrate for the 1st moment estimates. beta_2 A float value or a constant float tensor. The exponential decay\nrate for the exponentially weighted infinity norm. epsilon A small constant for numerical stability.\nname: String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_1\nbeta_2\nepsilon\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nKingma et al., 2014\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nAdamax optimizer has 2 types of variables: momentums (denoted as m),\nexponentially weighted infinity norm (denoted as u).\nArgs\nvar_list list of model variables to build Adamax variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/dice",
    "content": "Computes the Dice loss value between y_true and y_pred .\ny_true\ny_pred\ntf . keras . losses . dice ( y_true , y_pred )\ntf . keras . losses . dice ( y_true , y_pred )\nloss = 1 - ( 2 * sum ( y_true * y_pred )) / ( sum ( y_true ) + sum ( y_pred ))\nloss = 1 - ( 2 * sum ( y_true * y_pred )) / ( sum ( y_true ) + sum ( y_pred ))\nArgs\nArgs\ny_true tensor of true targets. y_pred tensor of predicted targets.\ny_true\ny_pred\nReturns Dice loss value.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/unstack",
    "content": "Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\ntf . keras . ops . unstack ( x , num = None , axis = 0 )\ntf . keras . ops . unstack ( x , num = None , axis = 0 )\nArgs\nArgs\nx The input tensor. num The length of the dimension axis. Automatically inferred\nif None . axis The axis along which to unpack.\nx\nnum\nNone\naxis\nReturns A list of tensors unpacked along the given axis.\nReturns\nx = keras . ops . array ([[ 1 , 2 ], [ 3 , 4 ]]) keras . ops . unstack ( x , axis = 0 ) [ array ([ 1 , 2 ]), array ([ 3 , 4 ])]\nx = keras . ops . array ([[ 1 , 2 ], [ 3 , 4 ]])\nkeras . ops . unstack ( x , axis = 0 )\n[ array ([ 1 , 2 ]), array ([ 3 , 4 ])]"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies/deserialize",
    "content": "Deserializes a serialized DTypePolicy instance.\nDTypePolicy\ntf . keras . dtype_policies . deserialize ( config , custom_objects = None )\ntf . keras . dtype_policies . deserialize ( config , custom_objects = None )\nArgs\nArgs\nconfig DTypePolicy configuration. custom_objects Optional dictionary mapping names (strings) to custom\nobjects (classes and functions) to be considered during\ndeserialization.\nconfig\nDTypePolicy\ncustom_objects\nReturns A Keras DTypePolicy instance.\nReturns\nDTypePolicy"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sum",
    "content": "Sum of a tensor over the given axes.\nMain aliases tf.keras.ops.numpy.sum\ntf.keras.ops.numpy.sum\ntf.keras.ops.numpy.sum\ntf . keras . ops . sum ( x , axis = None , keepdims = False )\ntf . keras . ops . sum ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which the sum is computed. The default is to\ncompute the sum of the flattened tensor. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one.\nx\naxis\nkeepdims\nTrue\nReturns Output tensor containing the sum.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/var",
    "content": "Compute the variance along the specified axes.\nMain aliases tf.keras.ops.numpy.var\ntf.keras.ops.numpy.var\ntf.keras.ops.numpy.var\ntf . keras . ops . var ( x , axis = None , keepdims = False )\ntf . keras . ops . var ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which the variance is computed. The default\nis to compute the variance of the flattened tensor. keepdims If this is set to True , the axes which are reduced are left\nin the result as dimensions with size one.\nx\naxis\nkeepdims\nTrue\nReturns Output tensor containing the variance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/hashing_trick",
    "content": "DEPRECATED.\ntf . keras . preprocessing . text . hashing_trick ( text , n , hash_function = None , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , analyzer = None )\ntf . keras . preprocessing . text . hashing_trick ( text , n , hash_function = None , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , analyzer = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding",
    "content": "A preprocessing layer which encodes integer features.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . CategoryEncoding ( num_tokens = None , output_mode = 'multi_hot' , sparse = False , ** kwargs )\ntf . keras . layers . CategoryEncoding ( num_tokens = None , output_mode = 'multi_hot' , sparse = False , ** kwargs )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nWorking with preprocessing layers\nLoad CSV data\nClassify structured data using Keras preprocessing layers\nThis layer provides options for condensing data into a categorical encoding\nwhen the total number of tokens are known in advance. It accepts integer\nvalues as inputs, and it outputs a dense or sparse representation of those\ninputs. For integer inputs where the total number of tokens is not known,\nuse keras.layers.IntegerLookup instead.\nkeras.layers.IntegerLookup\ntf.data\nOne-hot encoding data\nlayer = keras . layers . CategoryEncoding ( num_tokens = 4 , output_mode = \"one_hot\" ) layer ([ 3 , 2 , 0 , 1 ]) array ([[ 0. , 0. , 0. , 1. ], [ 0. , 0. , 1. , 0. ], [ 1. , 0. , 0. , 0. ], [ 0. , 1. , 0. , 0. ]] >\nlayer = keras . layers . CategoryEncoding (\nnum_tokens = 4 , output_mode = \"one_hot\" )\nlayer ([ 3 , 2 , 0 , 1 ])\narray ([[ 0. , 0. , 0. , 1. ],\n[ 0. , 0. , 1. , 0. ],\n[ 1. , 0. , 0. , 0. ],\n[ 0. , 1. , 0. , 0. ]] >\nMulti-hot encoding data\nlayer = keras . layers . CategoryEncoding ( num_tokens = 4 , output_mode = \"multi_hot\" ) layer ([[ 0 , 1 ], [ 0 , 0 ], [ 1 , 2 ], [ 3 , 1 ]]) array ([[ 1. , 1. , 0. , 0. ], [ 1. , 0. , 0. , 0. ], [ 0. , 1. , 1. , 0. ], [ 0. , 1. , 0. , 1. ]] >\nlayer = keras . layers . CategoryEncoding (\nnum_tokens = 4 , output_mode = \"multi_hot\" )\nlayer ([[ 0 , 1 ], [ 0 , 0 ], [ 1 , 2 ], [ 3 , 1 ]])\narray ([[ 1. , 1. , 0. , 0. ],\n[ 1. , 0. , 0. , 0. ],\n[ 0. , 1. , 1. , 0. ],\n[ 0. , 1. , 0. , 1. ]] >\nUsing weighted inputs in \"count\" mode\n\"count\"\nlayer = keras . layers . CategoryEncoding ( num_tokens = 4 , output_mode = \"count\" ) count_weights = np . array ([[ .1 , .2 ], [ .1 , .1 ], [ .2 , .3 ], [ .4 , .2 ]]) layer ([[ 0 , 1 ], [ 0 , 0 ], [ 1 , 2 ], [ 3 , 1 ]], count_weights = count_weights ) array ([[ 0.1 , 0.2 , 0. , 0. ], [ 0.2 , 0. , 0. , 0. ], [ 0. , 0.2 , 0.3 , 0. ], [ 0. , 0.2 , 0. , 0.4 ]] >\nlayer = keras . layers . CategoryEncoding (\nnum_tokens = 4 , output_mode = \"count\" )\ncount_weights = np . array ([[ .1 , .2 ], [ .1 , .1 ], [ .2 , .3 ], [ .4 , .2 ]])\nlayer ([[ 0 , 1 ], [ 0 , 0 ], [ 1 , 2 ], [ 3 , 1 ]], count_weights = count_weights )\narray ([[ 0.1 , 0.2 , 0. , 0. ],\n[ 0.2 , 0. , 0. , 0. ],\n[ 0. , 0.2 , 0.3 , 0. ],\n[ 0. , 0.2 , 0. , 0.4 ]] >\nArgs\nArgs\nnum_tokens The total number of tokens the layer should support. All\ninputs to the layer must integers in the range 0 <= value <\nnum_tokens , or an error will be thrown. output_mode Specification for the output of the layer.\nValues can be \"one_hot\" , \"multi_hot\" or \"count\" ,\nconfiguring the layer as follows:\nnum_tokens\n0 <= value <\nnum_tokens\noutput_mode\n\"one_hot\"\n\"multi_hot\"\n\"count\"\n- ` \"one_hot\" ` : Encodes each individual element in the input into an array of ` num_tokens ` size , containing a 1 at the element index . If the last dimension is size 1 , will encode on that dimension . If the last dimension is not size 1 , will append a new dimension for the encoded output . - ` \"multi_hot\" ` : Encodes each sample in the input into a single array of ` num_tokens ` size , containing a 1 for each vocabulary term present in the sample . Treats the last dimension as the sample dimension , if input shape is ` ( ... , sample_length ) ` , output shape will be ` ( ... , num_tokens ) ` . - ` \"count\" ` : Like ` \"multi_hot\" ` , but the int array contains a count of the number of times the token at that index appeared in the sample .\n- ` \"one_hot\" ` : Encodes each individual element in the input into an array of ` num_tokens ` size , containing a 1 at the element index . If the last dimension is size 1 , will encode on that dimension . If the last dimension is not size 1 , will append a new dimension for the encoded output . - ` \"multi_hot\" ` : Encodes each sample in the input into a single array of ` num_tokens ` size , containing a 1 for each vocabulary term present in the sample . Treats the last dimension as the sample dimension , if input shape is ` ( ... , sample_length ) ` , output shape will be ` ( ... , num_tokens ) ` . - ` \"count\" ` : Like ` \"multi_hot\" ` , but the int array contains a count of the number of times the token at that index appeared in the sample .\nFor all output modes, currently only output up to rank 2 is\nsupported.\nDefaults to \"multi_hot\" . sparse Whether to return a sparse tensor; for backends that support\nsparse tensors.\n\"multi_hot\"\nsparse\nCall arguments\nCall arguments\ninputs A 1D or 2D tensor of integer inputs. count_weights A tensor in the same shape as inputs indicating the\nweight for each sample value when summing up in count mode.\nNot used in \"multi_hot\" or \"one_hot\" modes.\ninputs\ncount_weights\ninputs\ncount\n\"multi_hot\"\n\"one_hot\"\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logical_or",
    "content": "Computes the element-wise logical OR of the given input tensors.\nMain aliases tf.keras.ops.numpy.logical_or\ntf.keras.ops.numpy.logical_or\ntf.keras.ops.numpy.logical_or\ntf . keras . ops . logical_or ( x1 , x2 )\ntf . keras . ops . logical_or ( x1 , x2 )\nZeros are treated as False and non-zeros are treated as True .\nFalse\nTrue\nArgs\nArgs\nx1 Input tensor. x2 Input tensor.\nx1\nx2\nReturns Output tensor, element-wise logical OR of the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/load_img",
    "content": "Loads an image into PIL format.\nMain aliases tf.keras.preprocessing.image.load_img\ntf.keras.preprocessing.image.load_img\ntf.keras.preprocessing.image.load_img\ntf . keras . utils . load_img ( path , color_mode = 'rgb' , target_size = None , interpolation = 'nearest' , keep_aspect_ratio = False )\ntf . keras . utils . load_img ( path , color_mode = 'rgb' , target_size = None , interpolation = 'nearest' , keep_aspect_ratio = False )\nUsed in the notebooks\nUsing the SavedModel format\nImage classification\nimage = keras . utils . load_img ( image_path ) input_arr = keras . utils . img_to_array ( image ) input_arr = np . array ([ input_arr ]) # Convert single image to a batch. predictions = model . predict ( input_arr )\nimage = keras . utils . load_img ( image_path ) input_arr = keras . utils . img_to_array ( image ) input_arr = np . array ([ input_arr ]) # Convert single image to a batch. predictions = model . predict ( input_arr )\nArgs\nArgs\npath Path to image file. color_mode One of \"grayscale\" , \"rgb\" , \"rgba\" . Default: \"rgb\" .\nThe desired image format. target_size Either None (default to original size) or tuple of ints (img_height, img_width) . interpolation Interpolation method used to resample the image if the\ntarget size is different from that of the loaded image. Supported\nmethods are \"nearest\" , \"bilinear\" , and \"bicubic\" .\nIf PIL version 1.1.3 or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0 or newer is installed, \"box\" and \"hamming\" are also\nsupported. By default, \"nearest\" is used. keep_aspect_ratio Boolean, whether to resize images to a target\nsize without aspect ratio distortion. The image is cropped in\nthe center with target aspect ratio before resizing.\npath\ncolor_mode\n\"grayscale\"\n\"rgb\"\n\"rgba\"\n\"rgb\"\ntarget_size\nNone\n(img_height, img_width)\ninterpolation\n\"nearest\"\n\"bilinear\"\n\"bicubic\"\n\"lanczos\"\n\"box\"\n\"hamming\"\n\"nearest\"\nkeep_aspect_ratio\nReturns A PIL Image instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Orthogonal",
    "content": "Initializer that generates an orthogonal matrix.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.OrthogonalInitializer , tf.keras.initializers.orthogonal\ntf.keras.initializers.OrthogonalInitializer , tf.keras.initializers.orthogonal\ntf.keras.initializers.OrthogonalInitializer\ntf.keras.initializers.orthogonal\ntf . keras . initializers . Orthogonal ( gain = 1.0 , seed = None )\ntf . keras . initializers . Orthogonal ( gain = 1.0 , seed = None )\nIf the shape of the tensor to initialize is two-dimensional, it is\ninitialized with an orthogonal matrix obtained from the QR decomposition of\na matrix of random numbers drawn from a normal distribution. If the matrix\nhas fewer rows than columns then the output will have orthogonal rows.\nOtherwise, the output will have orthogonal columns.\nIf the shape of the tensor to initialize is more than two-dimensional,\na matrix of shape (shape[0] * ... * shape[n - 2], shape[n - 1]) is initialized, where n is the length of the shape vector.\nThe matrix is subsequently reshaped to give a tensor of the desired shape.\n(shape[0] * ... * shape[n - 2], shape[n - 1])\nn\n# Standalone usage: initializer = keras . initializers . Orthogonal () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = keras . initializers . Orthogonal ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = keras . initializers . Orthogonal () layer = keras . layers . Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = keras . initializers . Orthogonal ()\nlayer = keras . layers . Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\ngain Multiplicative factor to apply to the orthogonal matrix. seed A Python integer. Used to make the behavior of the initializer\ndeterministic.\ngain\nseed\nSaxe et al., 2014\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking",
    "content": "Masks a sequence by using a mask value to skip timesteps.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Masking ( mask_value = 0.0 , ** kwargs )\ntf . keras . layers . Masking ( mask_value = 0.0 , ** kwargs )\nFor each timestep in the input tensor (dimension #1 in the tensor),\nif all values in the input tensor at that timestep\nare equal to mask_value , then the timestep will be masked (skipped)\nin all downstream layers (as long as they support masking).\nmask_value\nIf any downstream layer does not support masking yet receives such\nan input mask, an exception will be raised.\nConsider a NumPy data array x of shape (samples, timesteps, features) ,\nto be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\nlack data for these timesteps. You can:\nx\n(samples, timesteps, features)\nSet x[:, 3, :] = 0. and x[:, 5, :] = 0.\nx[:, 3, :] = 0.\nx[:, 5, :] = 0.\nInsert a Masking layer with mask_value=0. before the LSTM layer:\nMasking\nmask_value=0.\nsamples , timesteps , features = 32 , 10 , 8 inputs = np . random . random ([ samples , timesteps , features ]) . astype ( np . float32 ) inputs [:, 3 , :] = 0. inputs [:, 5 , :] = 0. model = keras . models . Sequential () model . add ( keras . layers . Masking ( mask_value = 0. ) model . add ( keras . layers . LSTM ( 32 )) output = model ( inputs ) # The time step 3 and 5 will be skipped from LSTM calculation.\nsamples , timesteps , features = 32 , 10 , 8 inputs = np . random . random ([ samples , timesteps , features ]) . astype ( np . float32 ) inputs [:, 3 , :] = 0. inputs [:, 5 , :] = 0. model = keras . models . Sequential () model . add ( keras . layers . Masking ( mask_value = 0. ) model . add ( keras . layers . LSTM ( 32 )) output = model ( inputs ) # The time step 3 and 5 will be skipped from LSTM calculation.\nFalse\nTrue\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_resnet_v2",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nInceptionResNetV2(...) : Instantiates the Inception-ResNet v2 architecture.\nInceptionResNetV2(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . vgg16 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . vgg16 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/softsign",
    "content": "Softsign activation function.\ntf . keras . activations . softsign ( x )\ntf . keras . activations . softsign ( x )\nSoftsign is defined as: softsign(x) = x / (abs(x) + 1) .\nsoftsign(x) = x / (abs(x) + 1)\nArgs\nArgs\nx Input tensor.\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nNASNetLarge(...) : Instantiates a NASNet model in ImageNet mode.\nNASNetLarge(...)\nNASNetMobile(...) : Instantiates a Mobile NASNet model in ImageNet mode.\nNASNetMobile(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : Preprocesses a tensor or Numpy array encoding a batch of images.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom",
    "content": "A preprocessing layer which randomly zooms images during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomZoom ( height_factor , width_factor = None , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , data_format = None , ** kwargs )\ntf . keras . layers . RandomZoom ( height_factor , width_factor = None , fill_mode = 'reflect' , interpolation = 'bilinear' , seed = None , fill_value = 0.0 , data_format = None , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nImage classification\nRetraining an Image Classifier\nThis layer will randomly zoom in or out on each axis of an image\nindependently, filling empty space according to fill_mode .\nfill_mode\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\n[0., 1.)\n[0, 255]\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format,\nor (..., channels, height, width) , in \"channels_first\" format.\n(..., height, width, channels)\n\"channels_last\"\n(..., channels, height, width)\n\"channels_first\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., target_height, target_width, channels) ,\nor (..., channels, target_height, target_width) ,\nin \"channels_first\" format.\n(..., target_height, target_width, channels)\n(..., channels, target_height, target_width)\n\"channels_first\"\ntf.data\nArgs\nArgs\nheight_factor a float represented as fraction of value, or a tuple of\nsize 2 representing lower and upper bound for zooming vertically.\nWhen represented as a single float, this value is used for both the\nupper and lower bound. A positive value means zooming out, while a\nnegative value means zooming in. For instance, height_factor=(0.2, 0.3) result in an output zoomed out by a\nrandom amount in the range [+20%, +30%] . height_factor=(-0.3, -0.2) result in an output zoomed in by a\nrandom amount in the range [+20%, +30%] . width_factor a float represented as fraction of value, or a tuple of\nsize 2 representing lower and upper bound for zooming horizontally.\nWhen represented as a single float, this value is used for both the\nupper and lower bound. For instance, width_factor=(0.2, 0.3) result in an output zooming out between 20% to 30%. width_factor=(-0.3, -0.2) result in an output zooming in between\n20% to 30%. None means i.e., zooming vertical and horizontal\ndirections by preserving the aspect ratio. Defaults to None . fill_mode Points outside the boundaries of the input are filled\naccording to the given mode. Available methods are \"constant\" , \"nearest\" , \"wrap\" and \"reflect\" . Defaults to \"constant\" .\nheight_factor\nheight_factor=(0.2, 0.3)\n[+20%, +30%]\nheight_factor=(-0.3, -0.2)\n[+20%, +30%]\nwidth_factor\nwidth_factor=(0.2, 0.3)\nwidth_factor=(-0.3, -0.2)\nNone\nNone\nfill_mode\n\"constant\"\n\"nearest\"\n\"wrap\"\n\"reflect\"\n\"constant\"\n\"reflect\" : (d c b a | a b c d | d c b a) The input is extended by reflecting about the edge of the last\npixel.\n\"reflect\"\n(d c b a | a b c d | d c b a)\n\"constant\" : (k k k k | a b c d | k k k k) The input is extended by filling all values beyond\nthe edge with the same constant value k specified by fill_value .\n\"constant\"\n(k k k k | a b c d | k k k k)\nfill_value\n\"wrap\" : (a b c d | a b c d | a b c d) The input is extended by wrapping around to the opposite edge.\n\"wrap\"\n(a b c d | a b c d | a b c d)\n\"nearest\" : (a a a a | a b c d | d d d d) The input is extended by the nearest pixel.\nNote that when using torch backend, \"reflect\" is redirected to \"mirror\" (c d c b | a b c d | c b a b) because torch does not\nsupport \"reflect\" .\nNote that torch backend does not support \"wrap\" . interpolation Interpolation mode. Supported values: \"nearest\" , \"bilinear\" . seed Integer. Used to create a random seed. fill_value a float that represents the value to be filled outside\nthe boundaries when fill_mode=\"constant\" . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . **kwargs Base layer keyword arguments, such as name and dtype .\n\"nearest\"\n(a a a a | a b c d | d d d d)\n\"reflect\"\n\"mirror\"\n(c d c b | a b c d | c b a b)\n\"reflect\"\n\"wrap\"\ninterpolation\n\"nearest\"\n\"bilinear\"\nseed\nfill_value\nfill_mode=\"constant\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\n**kwargs\nname\ndtype\ninput_img = np . random . random (( 32 , 224 , 224 , 3 )) layer = keras . layers . RandomZoom ( .5 , .2 ) out_img = layer ( input_img )\ninput_img = np . random . random (( 32 , 224 , 224 , 3 ))\nlayer = keras . layers . RandomZoom ( .5 , .2 )\nout_img = layer ( input_img )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip",
    "content": "A preprocessing layer which randomly flips images during training.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RandomFlip ( mode = HORIZONTAL_AND_VERTICAL , seed = None , ** kwargs )\ntf . keras . layers . RandomFlip ( mode = HORIZONTAL_AND_VERTICAL , seed = None , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nImage segmentation\nImage classification\nData augmentation\nTransfer learning and fine-tuning\nRetraining an Image Classifier\nThis layer will flip the images horizontally and or vertically based on the mode attribute. During inference time, the output will be identical to\ninput. Call the layer with training=True to flip the input.\nInput pixel values can be of any range (e.g. [0., 1.) or [0, 255] ) and\nof integer or floating point dtype.\nBy default, the layer will output floats.\nmode\ntraining=True\n[0., 1.)\n[0, 255]\ntf.data\nInput shape\nInput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format.\n(..., height, width, channels)\n\"channels_last\"\nOutput shape\nOutput shape\n3D unbatched) or 4D (batched) tensor with shape\n3D\nunbatched) or 4D (batched) tensor with shape\n(..., height, width, channels) , in \"channels_last\" format.\n(..., height, width, channels)\n\"channels_last\"\nArgs\nArgs\nmode String indicating which flip mode to use. Can be \"horizontal\" , \"vertical\" , or \"horizontal_and_vertical\" . \"horizontal\" is a\nleft-right flip and \"vertical\" is a top-bottom flip. Defaults to \"horizontal_and_vertical\" seed Integer. Used to create a random seed. **kwargs Base layer keyword arguments, such as name and dtype .\nmode\n\"horizontal\"\n\"vertical\"\n\"horizontal_and_vertical\"\n\"horizontal\"\n\"vertical\"\n\"horizontal_and_vertical\"\nseed\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/Progbar",
    "content": "Displays a progress bar.\ntf . keras . utils . Progbar ( target , width = 20 , verbose = 1 , interval = 0.05 , stateful_metrics = None , unit_name = 'step' )\ntf . keras . utils . Progbar ( target , width = 20 , verbose = 1 , interval = 0.05 , stateful_metrics = None , unit_name = 'step' )\nUsed in the notebooks\nDistributed training with DTensors\nUsing DTensors with Keras\nArgs\nArgs\ntarget Total number of steps expected, None if unknown. width Progress bar width on screen. verbose Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose) stateful_metrics Iterable of string names of metrics that should not be averaged over time. Metrics in this list will be displayed as-is.\nAll others will be averaged by the progbar before display. interval Minimum visual progress update interval (in seconds). unit_name Display name for step counts (usually \"step\" or \"sample\").\ntarget\nwidth\nverbose\nstateful_metrics\ninterval\nunit_name\nMethods\nadd\nadd\nView source\nadd ( n , values = None )\nadd ( n , values = None )\nupdate\nupdate\nView source\nupdate ( current , values = None , finalize = None )\nupdate ( current , values = None , finalize = None )\nUpdates the progress bar.\nArgs\ncurrent Index of current step. values List of tuples: (name, value_for_last_step) . If name is\nin stateful_metrics , value_for_last_step will be displayed\nas-is. Else, an average of the metric over time will be\ndisplayed. finalize Whether this is the last update for the progress bar. If None , defaults to current >= self.target .\ncurrent\nvalues\n(name, value_for_last_step)\nname\nstateful_metrics\nvalue_for_last_step\nfinalize\nNone\ncurrent >= self.target"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TrueNegatives",
    "content": "Calculates the number of true negatives.\nInherits From: Metric\nMetric\ntf . keras . metrics . TrueNegatives ( thresholds = None , name = None , dtype = None )\ntf . keras . metrics . TrueNegatives ( thresholds = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nIf sample_weight is given, calculates the sum of the weights of\ntrue negatives. This metric creates one local variable, accumulator that is used to keep track of the number of true negatives.\nsample_weight\naccumulator\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nthresholds (Optional) Defaults to 0.5 . A float value, or a Python\nlist/tuple of float threshold values in [0, 1] . A threshold is\ncompared with prediction values to determine the truth value of\npredictions (i.e., above the threshold is True , below is False ).\nIf used with a loss function that sets from_logits=True (i.e. no\nsigmoid applied to predictions), thresholds should be set to 0.\nOne metric value is generated for each threshold value. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n0.5\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nname\ndtype\nm = keras . metrics . TrueNegatives () m . update_state ([ 0 , 1 , 0 , 0 ], [ 1 , 1 , 0 , 0 ]) m . result () 2.0\nm = keras . metrics . TrueNegatives ()\nm . update_state ([ 0 , 1 , 0 , 0 ], [ 1 , 1 , 0 , 0 ])\nm . result ()\n2.0\nm . reset_state () m . update_state ([ 0 , 1 , 0 , 0 ], [ 1 , 1 , 0 , 0 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 0 , 0 ], [ 1 , 1 , 0 , 0 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the metric statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/transpose",
    "content": "Returns a tensor with axes transposed.\naxes\nMain aliases tf.keras.ops.numpy.transpose\ntf.keras.ops.numpy.transpose\ntf.keras.ops.numpy.transpose\ntf . keras . ops . transpose ( x , axes = None )\ntf . keras . ops . transpose ( x , axes = None )\nArgs\nArgs\nx Input tensor. axes Sequence of integers. Permutation of the dimensions of x .\nBy default, the order of the axes are reversed.\nx\naxes\nx\nReturns x with its axes permuted.\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/serialize",
    "content": "Serializes a LearningRateSchedule into a JSON-compatible dict.\nLearningRateSchedule\ntf . keras . optimizers . schedules . serialize ( learning_rate_schedule )\ntf . keras . optimizers . schedules . serialize ( learning_rate_schedule )\nArgs\nArgs\nlearning_rate_schedule The LearningRateSchedule object to serialize.\nlearning_rate_schedule\nLearningRateSchedule\nReturns A JSON-serializable dict representing the object's config.\nReturns\nlr_schedule = keras . optimizers . schedules . ExponentialDecay ( 0.1 , decay_steps = 100000 , decay_rate = 0.96 , staircase = True ) keras . optimizers . schedules . serialize ( lr_schedule ) { 'module' : 'keras.optimizers.schedules' , 'class_name' : 'ExponentialDecay' , 'config' : { ... }, 'registered_name' : None }\nlr_schedule = keras . optimizers . schedules . ExponentialDecay (\n0.1 , decay_steps = 100000 , decay_rate = 0.96 , staircase = True )\nkeras . optimizers . schedules . serialize ( lr_schedule )\n{ 'module' : 'keras.optimizers.schedules' ,\n'class_name' : 'ExponentialDecay' , 'config' : { ... },\n'registered_name' : None }"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D",
    "content": "Zero-padding layer for 2D input (e.g. picture).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ZeroPadding2D ( padding = ( 1 , 1 ), data_format = None , ** kwargs )\ntf . keras . layers . ZeroPadding2D ( padding = ( 1 , 1 ), data_format = None , ** kwargs )\nUsed in the notebooks\nPruning for on-device inference w/ XNNPACK\npix2pix: Image-to-image translation with a conditional GAN\nThis layer can add rows and columns of zeros at the top, bottom, left and\nright side of an image tensor.\ninput_shape = ( 1 , 1 , 2 , 2 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) x [[[[ 0 1 ] [ 2 3 ]]]] y = keras . layers . ZeroPadding2D ( padding = 1 )( x ) y [[[[ 0 0 ] [ 0 0 ] [ 0 0 ] [ 0 0 ]] [[ 0 0 ] [ 0 1 ] [ 2 3 ] [ 0 0 ]] [[ 0 0 ] [ 0 0 ] [ 0 0 ] [ 0 0 ]]]]\ninput_shape = ( 1 , 1 , 2 , 2 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\nx\n[[[[ 0 1 ]\n[ 2 3 ]]]]\ny = keras . layers . ZeroPadding2D ( padding = 1 )( x )\ny\n[[[[ 0 0 ]\n[ 0 0 ]\n[ 0 0 ]\n[ 0 0 ]]\n[[ 0 0 ]\n[ 0 1 ]\n[ 2 3 ]\n[ 0 0 ]]\n[[ 0 0 ]\n[ 0 0 ]\n[ 0 0 ]\n[ 0 0 ]]]]\nArgs\nArgs\npadding Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\npadding\nIf int: the same symmetric padding is applied to height and width.\nIf tuple of 2 ints: interpreted as two different symmetric padding\nvalues for height and width: (symmetric_height_pad, symmetric_width_pad) .\n(symmetric_height_pad, symmetric_width_pad)\nIf tuple of 2 tuples of 2 ints: interpreted as ((top_pad, bottom_pad), (left_pad, right_pad)) . data_format A string, one of \"channels_last\" (default) or \"channels_first\" . The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, height, width) .\nWhen unspecified, uses image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json (if exists). Defaults to \"channels_last\" .\n((top_pad, bottom_pad), (left_pad, right_pad))\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, height, width, channels)\n\"channels_first\"\n(batch_size, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nInput shape 4D tensor with shape:\nInput shape\nIf data_format is \"channels_last\" : (batch_size, height, width, channels)\ndata_format\n\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, height, width)\ndata_format\n\"channels_first\"\n(batch_size, channels, height, width)\nOutput shape 4D tensor with shape:\nOutput shape\nIf data_format is \"channels_last\" : (batch_size, padded_height, padded_width, channels)\ndata_format\n\"channels_last\"\n(batch_size, padded_height, padded_width, channels)\nIf data_format is \"channels_first\" : (batch_size, channels, padded_height, padded_width)\ndata_format\n\"channels_first\"\n(batch_size, channels, padded_height, padded_width)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention",
    "content": "Dot-product attention layer, a.k.a. Luong-style attention.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Attention ( use_scale = False , score_mode = 'dot' , dropout = 0.0 , seed = None , ** kwargs )\ntf . keras . layers . Attention ( use_scale = False , score_mode = 'dot' , dropout = 0.0 , seed = None , ** kwargs )\nInputs are a list with 2 or 3 elements:\nA query tensor of shape (batch_size, Tq, dim) .\nquery\n(batch_size, Tq, dim)\nA value tensor of shape (batch_size, Tv, dim) .\nvalue\n(batch_size, Tv, dim)\nA optional key tensor of shape (batch_size, Tv, dim) . If none\nsupplied, value will be used as a key .\nkey\n(batch_size, Tv, dim)\nvalue\nkey\nThe calculation follows the steps:\nCalculate attention scores using query and key with shape (batch_size, Tq, Tv) .\nquery\nkey\n(batch_size, Tq, Tv)\nUse scores to calculate a softmax distribution with shape (batch_size, Tq, Tv) .\n(batch_size, Tq, Tv)\nUse the softmax distribution to create a linear combination of value with shape (batch_size, Tq, dim) .\nvalue\n(batch_size, Tq, dim)\nArgs\nArgs\nuse_scale If True , will create a scalar variable to scale the\nattention scores. dropout Float between 0 and 1. Fraction of the units to drop for the\nattention scores. Defaults to 0.0 . seed A Python integer to use as random seed incase of dropout . score_mode Function to use to compute attention scores, one of {\"dot\", \"concat\"} . \"dot\" refers to the dot product between the\nquery and key vectors. \"concat\" refers to the hyperbolic tangent\nof the concatenation of the query and key vectors.\nuse_scale\nTrue\ndropout\n0.0\nseed\ndropout\nscore_mode\n{\"dot\", \"concat\"}\n\"dot\"\n\"concat\"\nquery\nkey\nCall Args\nCall Args\ninputs List of the following tensors:\ninputs\nquery : Query tensor of shape (batch_size, Tq, dim) .\nquery\n(batch_size, Tq, dim)\nvalue : Value tensor of shape (batch_size, Tv, dim) .\nvalue\n(batch_size, Tv, dim)\nkey : Optional key tensor of shape (batch_size, Tv, dim) . If\nnot given, will use value for both key and value , which is\nthe most common case. mask List of the following tensors:\nkey\n(batch_size, Tv, dim)\nvalue\nkey\nvalue\nmask\nquery_mask : A boolean mask tensor of shape (batch_size, Tq) .\nIf given, the output will be zero at the positions where mask==False .\nquery_mask\n(batch_size, Tq)\nmask==False\nvalue_mask : A boolean mask tensor of shape (batch_size, Tv) .\nIf given, will apply the mask such that values at positions\n where mask==False do not contribute to the result. return_attention_scores bool, it True , returns the attention scores\n(after masking and softmax) as an additional output argument. training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (no dropout). use_causal_mask Boolean. Set to True for decoder self-attention. Adds\na mask such that position i cannot attend to positions j > i .\nThis prevents the flow of information from the future towards the\npast. Defaults to False .\nvalue_mask\n(batch_size, Tv)\nmask==False\nreturn_attention_scores\nTrue\ntraining\nuse_causal_mask\nTrue\ni\nj > i\nFalse\nOutput Attention outputs of shape (batch_size, Tq, dim) .\n(Optional) Attention scores after masking and softmax with shape (batch_size, Tq, Tv) .\nOutput\n(batch_size, Tq, dim)\n(batch_size, Tq, Tv)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/silu",
    "content": "Swish (or Silu) activation function.\nMain aliases tf.keras.activations.swish\ntf.keras.activations.swish\ntf.keras.activations.swish\ntf . keras . activations . silu ( x )\ntf . keras . activations . silu ( x )\nIt is defined as: swish(x) = x * sigmoid(x) .\nswish(x) = x * sigmoid(x)\nThe Swish (or Silu) activation function is a smooth,\nnon-monotonic function that is unbounded above and\nbounded below.\nArgs\nArgs\nx Input tensor.\nx\nRamachandran et al., 2017"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/transpose",
    "content": "DEPRECATED.\ntf . keras . backend . transpose ( x )\ntf . keras . backend . transpose ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/relu",
    "content": "Rectified linear unit activation function.\nMain aliases tf.keras.ops.nn.relu\ntf.keras.ops.nn.relu\ntf.keras.ops.nn.relu\ntf . keras . ops . relu ( x )\ntf . keras . ops . relu ( x )\nIt is defined as f(x) = max(0, x) .\nf(x) = max(0, x)\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx1 = keras . ops . convert_to_tensor ([ - 1.0 , 0.0 , 1.0 , 0.2 ]) keras . ops . relu ( x1 ) array ([ 0.0 , 0.0 , 1.0 , 0.2 ], dtype = float32 )\nx1 = keras . ops . convert_to_tensor ([ - 1.0 , 0.0 , 1.0 , 0.2 ])\nkeras . ops . relu ( x1 )\narray ([ 0.0 , 0.0 , 1.0 , 0.2 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Initializer",
    "content": "Initializer base class: all Keras initializers inherit from this class.\nMain aliases tf.keras.initializers.Initializer Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Initializer\ntf.keras.initializers.Initializer\ntf.keras.initializers.Initializer\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Initializer\ntf.compat.v1.keras.Initializer\nInitializers should implement a __call__() method with the following\nsignature:\n__call__()\ndef __call__ ( self , shape , dtype = None , ** kwargs ): # returns a tensor of shape `shape` and dtype `dtype` # containing values drawn from a distribution of your choice.\ndef __call__ ( self , shape , dtype = None , ** kwargs ): # returns a tensor of shape `shape` and dtype `dtype` # containing values drawn from a distribution of your choice.\nOptionally, you an also implement the method get_config() and the class\nmethod from_config in order to support serialization -- just like with\nany Keras object.\nget_config()\nfrom_config\nHere's a simple example: a random normal initializer.\nclass ExampleRandomNormal ( Initializer ): def __init__ ( self , mean , stddev ): self . mean = mean self . stddev = stddev def __call__ ( self , shape , dtype = None , ** kwargs ): return keras . random . normal ( shape , mean = self . mean , stddev = self . stddev , dtype = dtype ) def get_config ( self ): # To support serialization return { \"mean\" : self . mean , \"stddev\" : self . stddev }\nclass ExampleRandomNormal ( Initializer ): def __init__ ( self , mean , stddev ): self . mean = mean self . stddev = stddev def __call__ ( self , shape , dtype = None , ** kwargs ): return keras . random . normal ( shape , mean = self . mean , stddev = self . stddev , dtype = dtype ) def get_config ( self ): # To support serialization return { \"mean\" : self . mean , \"stddev\" : self . stddev }\nNote that we don't have to implement from_config() in the example above\nsince the constructor arguments of the class the keys in the config returned\nby get_config() are the same. In this case, the default from_config() works fine.\nfrom_config()\nget_config()\nfrom_config()\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cos",
    "content": "Cosine, element-wise.\nMain aliases tf.keras.ops.numpy.cos\ntf.keras.ops.numpy.cos\ntf.keras.ops.numpy.cos\ntf . keras . ops . cos ( x )\ntf . keras . ops . cos ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns The corresponding cosine values.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB7",
    "content": "Instantiates the EfficientNetB7 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB7\ntf.keras.applications.efficientnet.EfficientNetB7\ntf.keras.applications.efficientnet.EfficientNetB7\ntf . keras . applications . EfficientNetB7 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB7 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/TorchModuleWrapper",
    "content": "Torch module wrapper layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . TorchModuleWrapper ( module , name = None , ** kwargs )\ntf . keras . layers . TorchModuleWrapper ( module , name = None , ** kwargs )\nTorchModuleWrapper is a wrapper class that can turn any torch.nn.Module into a Keras layer, in particular by making its\nparameters trackable by Keras.\nTorchModuleWrapper\ntorch.nn.Module\nArgs\nArgs\nmodule torch.nn.Module instance. If it's a LazyModule instance, then its parameters must be initialized before\npassing the instance to TorchModuleWrapper (e.g. by calling\nit once). name The name of the layer (string).\nmodule\ntorch.nn.Module\nLazyModule\nTorchModuleWrapper\nname\nHere's an example of how the TorchModuleWrapper can be used with vanilla\nPyTorch modules.\nTorchModuleWrapper\nimport torch.nn as nn import torch.nn.functional as F import keras from keras.src.layers import TorchModuleWrapper class Classifier ( keras . Model ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) # Wrap `torch.nn.Module`s with `TorchModuleWrapper` # if they contain parameters self . conv1 = TorchModuleWrapper ( nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = ( 3 , 3 )) ) self . conv2 = TorchModuleWrapper ( nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = ( 3 , 3 )) ) self . pool = nn . MaxPool2d ( kernel_size = ( 2 , 2 )) self . flatten = nn . Flatten () self . dropout = nn . Dropout ( p = 0.5 ) self . fc = TorchModuleWrapper ( nn . Linear ( 1600 , 10 )) def call ( self , inputs ): x = F . relu ( self . conv1 ( inputs )) x = self . pool ( x ) x = F . relu ( self . conv2 ( x )) x = self . pool ( x ) x = self . flatten ( x ) x = self . dropout ( x ) x = self . fc ( x ) return F . softmax ( x , dim = 1 ) model = Classifier () model . build (( 1 , 28 , 28 )) print ( \"Output shape:\" , model ( torch . ones ( 1 , 1 , 28 , 28 ) . to ( \"cuda\" )) . shape ) model . compile ( loss = \"sparse_categorical_crossentropy\" , optimizer = \"adam\" , metrics = [ \"accuracy\" ] ) model . fit ( train_loader , epochs = 5 )\nimport torch.nn as nn import torch.nn.functional as F import keras from keras.src.layers import TorchModuleWrapper class Classifier ( keras . Model ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) # Wrap `torch.nn.Module`s with `TorchModuleWrapper` # if they contain parameters self . conv1 = TorchModuleWrapper ( nn . Conv2d ( in_channels = 1 , out_channels = 32 , kernel_size = ( 3 , 3 )) ) self . conv2 = TorchModuleWrapper ( nn . Conv2d ( in_channels = 32 , out_channels = 64 , kernel_size = ( 3 , 3 )) ) self . pool = nn . MaxPool2d ( kernel_size = ( 2 , 2 )) self . flatten = nn . Flatten () self . dropout = nn . Dropout ( p = 0.5 ) self . fc = TorchModuleWrapper ( nn . Linear ( 1600 , 10 )) def call ( self , inputs ): x = F . relu ( self . conv1 ( inputs )) x = self . pool ( x ) x = F . relu ( self . conv2 ( x )) x = self . pool ( x ) x = self . flatten ( x ) x = self . dropout ( x ) x = self . fc ( x ) return F . softmax ( x , dim = 1 ) model = Classifier () model . build (( 1 , 28 , 28 )) print ( \"Output shape:\" , model ( torch . ones ( 1 , 1 , 28 , 28 ) . to ( \"cuda\" )) . shape ) model . compile ( loss = \"sparse_categorical_crossentropy\" , optimizer = \"adam\" , metrics = [ \"accuracy\" ] ) model . fit ( train_loader , epochs = 5 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nparameters\nparameters\nView source\nparameters ( recurse = True )\nparameters ( recurse = True )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/absolute",
    "content": "Compute the absolute value element-wise.\nMain aliases tf.keras.ops.numpy.absolute\ntf.keras.ops.numpy.absolute\ntf.keras.ops.numpy.absolute\ntf . keras . ops . absolute ( x )\ntf . keras . ops . absolute ( x )\nkeras.ops.abs is a shorthand for this function.\nkeras.ops.abs\nArgs\nArgs\nx Input tensor.\nx\nReturns An array containing the absolute value of each element in x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 1.2 , 1.2 ]) keras . ops . absolute ( x ) array ([ 1.2 , 1.2 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 1.2 , 1.2 ])\nkeras . ops . absolute ( x )\narray ([ 1.2 , 1.2 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling1D",
    "content": "Upsampling layer for 1D inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . UpSampling1D ( size = 2 , ** kwargs )\ntf . keras . layers . UpSampling1D ( size = 2 , ** kwargs )\nRepeats each temporal step size times along the time axis.\nsize\ninput_shape = ( 2 , 2 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) x [[[ 0 1 2 ] [ 3 4 5 ]] [[ 6 7 8 ] [ 9 10 11 ]]] y = keras . layers . UpSampling1D ( size = 2 )( x ) y [[[ 0. 1. 2. ] [ 0. 1. 2. ] [ 3. 4. 5. ] [ 3. 4. 5. ]]\ninput_shape = ( 2 , 2 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\nx\n[[[ 0 1 2 ]\n[ 3 4 5 ]]\n[[ 6 7 8 ]\n[ 9 10 11 ]]]\ny = keras . layers . UpSampling1D ( size = 2 )( x )\ny\n[[[ 0. 1. 2. ]\n[ 0. 1. 2. ]\n[ 3. 4. 5. ]\n[ 3. 4. 5. ]]\n[[ 6.  7.  8.]\n  [ 6.  7.  8.]\n  [ 9. 10. 11.]\n  [ 9. 10. 11.]]]\nArgs\nArgs\nsize Integer. Upsampling factor.\nsize\nInput shape 3D tensor with shape: (batch_size, steps, features) .\nInput shape\n(batch_size, steps, features)\nOutput shape 3D tensor with shape: (batch_size, upsampled_steps, features) .\nOutput shape\n(batch_size, upsampled_steps, features)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/disable_interactive_logging",
    "content": "Turn off interactive logging.\nMain aliases tf.keras.utils.disable_interactive_logging\ntf.keras.utils.disable_interactive_logging\ntf.keras.utils.disable_interactive_logging\ntf . keras . config . disable_interactive_logging ()\ntf . keras . config . disable_interactive_logging ()\nWhen interactive logging is disabled, Keras sends logs to absl.logging .\nThis is the best option when using Keras in a non-interactive\nway, such as running a training or inference job on a server.\nabsl.logging"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\nMain aliases tf.keras.applications.resnet50.decode_predictions\ntf.keras.applications.resnet50.decode_predictions\ntf.keras.applications.resnet50.decode_predictions\ntf . keras . applications . resnet . decode_predictions ( preds , top = 5 )\ntf . keras . applications . resnet . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/power",
    "content": "First tensor elements raised to powers from second tensor, element-wise.\nMain aliases tf.keras.ops.numpy.power\ntf.keras.ops.numpy.power\ntf.keras.ops.numpy.power\ntf . keras . ops . power ( x1 , x2 )\ntf . keras . ops . power ( x1 , x2 )\nArgs\nArgs\nx1 The bases. x2 The exponents.\nx1\nx2\nReturns Output tensor, the bases in x1 raised to the exponents in x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/psnr",
    "content": "Peak Signal-to-Noise Ratio (PSNR) function.\nMain aliases tf.keras.ops.nn.psnr\ntf.keras.ops.nn.psnr\ntf.keras.ops.nn.psnr\ntf . keras . ops . psnr ( x1 , x2 , max_val )\ntf . keras . ops . psnr ( x1 , x2 , max_val )\nThis function computes the Peak Signal-to-Noise Ratio between two signals, x1 and x2 . PSNR is a measure of the quality of a reconstructed signal.\nThe higher the PSNR, the closer the reconstructed signal is to the original\nsignal. Note that it can become negative when the signal power is\nsmaller that the noise power.\nx1\nx2\nArgs\nArgs\nx1 The first input signal. x2 The second input signal. Must have the same shape as x1 . max_val The maximum possible value in the signals.\nx1\nx2\nx1\nmax_val\nReturns\nReturns\nfloat The PSNR value between x1 and x2 .\nfloat\nx1\nx2\nx1 = keras . random . normal (( 2 , 4 , 4 , 3 )) x2 = keras . random . normal (( 2 , 4 , 4 , 3 )) max_val = 1.0 keras . ops . nn . psnr ( x1 , x2 , max_val ) - 3.1697404\nx1 = keras . random . normal (( 2 , 4 , 4 , 3 ))\nx2 = keras . random . normal (( 2 , 4 , 4 , 3 ))\nmax_val = 1.0\nkeras . ops . nn . psnr ( x1 , x2 , max_val )\n- 3.1697404"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_channel_shift",
    "content": "Performs a channel shift.\ntf . keras . preprocessing . image . apply_channel_shift ( x , intensity , channel_axis = 0 )\ntf . keras . preprocessing . image . apply_channel_shift ( x , intensity , channel_axis = 0 )\nDEPRECATED.\nArgs\nArgs\nx Input tensor. Must be 3D. intensity Transformation intensity. channel_axis Index of axis for channels in the input tensor.\nx\nintensity\nchannel_axis\nReturns Numpy image tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TruePositives",
    "content": "Calculates the number of true positives.\nInherits From: Metric\nMetric\ntf . keras . metrics . TruePositives ( thresholds = None , name = None , dtype = None )\ntf . keras . metrics . TruePositives ( thresholds = None , name = None , dtype = None )\nUsed in the notebooks\nClassification on imbalanced data\nIf sample_weight is given, calculates the sum of the weights of\ntrue positives. This metric creates one local variable, true_positives that is used to keep track of the number of true positives.\nsample_weight\ntrue_positives\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nthresholds (Optional) Defaults to 0.5 . A float value, or a Python\nlist/tuple of float threshold values in [0, 1] . A threshold is\ncompared with prediction values to determine the truth value of\npredictions (i.e., above the threshold is True , below is False ).\nIf used with a loss function that sets from_logits=True (i.e. no\nsigmoid applied to predictions), thresholds should be set to 0.\nOne metric value is generated for each threshold value. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nthresholds\n0.5\n[0, 1]\nTrue\nFalse\nfrom_logits=True\nthresholds\nname\ndtype\nm = keras . metrics . TruePositives () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ]) m . result () 2.0\nm = keras . metrics . TruePositives ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ])\nm . result ()\n2.0\nm . reset_state () m . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 1 , 1 , 1 ], [ 1 , 0 , 1 , 1 ], sample_weight = [ 0 , 0 , 1 , 0 ])\nm . result ()\n1.0\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates the metric statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Defaults to 1 .\nCan be a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true .\ny_true\ny_pred\nsample_weight\n1\ny_true\ny_true\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/california_housing/load_data",
    "content": "Loads the California Housing dataset.\ntf . keras . datasets . california_housing . load_data ( version = 'large' , path = 'california_housing.npz' , test_split = 0.2 , seed = 113 )\ntf . keras . datasets . california_housing . load_data ( version = 'large' , path = 'california_housing.npz' , test_split = 0.2 , seed = 113 )\nThis dataset was obtained from the StatLib repository .\nIt's a continuous regression dataset with 20,640 samples with\n8 features each.\nThe target variable is a scalar: the median house value\nfor California districts, in dollars.\nThe 8 input features are the following:\nMedInc: median income in block group\nHouseAge: median house age in block group\nAveRooms: average number of rooms per household\nAveBedrms: average number of bedrooms per household\nPopulation: block group population\nAveOccup: average number of household members\nLatitude: block group latitude\nLongitude: block group longitude\nThis dataset was derived from the 1990 U.S. census, using one row\nper census block group. A block group is the smallest geographical\nunit for which the U.S. Census Bureau publishes sample data\n(a block group typically has a population of 600 to 3,000 people).\nA household is a group of people residing within a home.\nSince the average number of rooms and bedrooms in this dataset are\nprovided per household, these columns may take surprisingly large\nvalues for block groups with few households and many empty houses,\nsuch as vacation resorts.\nArgs\nArgs\nversion \"small\" or \"large\" . The small version\ncontains 600 samples, the large version contains\n20,640 samples. The purpose of the small version is\nto serve as an approximate replacement for the\ndeprecated boston_housing dataset. path path where to cache the dataset locally\n(relative to ~/.keras/datasets ). test_split fraction of the data to reserve as test set. seed Random seed for shuffling the data\nbefore computing the test split.\nversion\n\"small\"\n\"large\"\nboston_housing\npath\n~/.keras/datasets\ntest_split\nseed\nReturns Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test) .\nReturns\n(x_train, y_train), (x_test, y_test)\nx_train , x_test : numpy arrays with shape (num_samples, 8) containing either the training samples (for x_train ),\n  or test samples (for y_train ).\nx_train\nx_test\n(num_samples, 8)\nx_train\ny_train\ny_train , y_test : numpy arrays of shape (num_samples,) containing the target scalars. The targets are float scalars\n    typically between 25,000 and 500,000 that represent\n    the home prices in dollars.\ny_train\ny_test\n(num_samples,)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log",
    "content": "Natural logarithm, element-wise.\nMain aliases tf.keras.ops.numpy.log\ntf.keras.ops.numpy.log\ntf.keras.ops.numpy.log\ntf . keras . ops . log ( x )\ntf . keras . ops . log ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise natural logarithm of x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU",
    "content": "Leaky version of a Rectified Linear Unit activation layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . LeakyReLU ( negative_slope = 0.3 , ** kwargs )\ntf . keras . layers . LeakyReLU ( negative_slope = 0.3 , ** kwargs )\nUsed in the notebooks\nCustomizing what happens in `fit()`\nDeep Convolutional Generative Adversarial Network\npix2pix: Image-to-image translation with a conditional GAN\nThis layer allows a small gradient when the unit is not active.\nf ( x ) = alpha * x if x < 0 f ( x ) = x if x > = 0\nf ( x ) = alpha * x if x < 0 f ( x ) = x if x > = 0\nleaky_relu_layer = LeakyReLU ( negative_slope = 0.5 ) input = np . array ([ - 10 , - 5 , 0.0 , 5 , 10 ]) result = leaky_relu_layer ( input ) # result = [-5. , -2.5,  0. ,  5. , 10.]\nleaky_relu_layer = LeakyReLU ( negative_slope = 0.5 ) input = np . array ([ - 10 , - 5 , 0.0 , 5 , 10 ]) result = leaky_relu_layer ( input ) # result = [-5. , -2.5,  0. ,  5. , 10.]\nArgs\nArgs\nnegative_slope Float >= 0.0. Negative slope coefficient.\nDefaults to 0.3 . **kwargs Base layer keyword arguments, such as name and dtype .\nnegative_slope\n0.3\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/legacy/Adagrad",
    "content": "Main aliases tf.keras.optimizers.legacy.Adam , tf.keras.optimizers.legacy.Ftrl , tf.keras.optimizers.legacy.Optimizer , tf.keras.optimizers.legacy.RMSprop , tf.keras.optimizers.legacy.SGD\ntf.keras.optimizers.legacy.Adam , tf.keras.optimizers.legacy.Ftrl , tf.keras.optimizers.legacy.Optimizer , tf.keras.optimizers.legacy.RMSprop , tf.keras.optimizers.legacy.SGD\ntf.keras.optimizers.legacy.Adam\ntf.keras.optimizers.legacy.Ftrl\ntf.keras.optimizers.legacy.Optimizer\ntf.keras.optimizers.legacy.RMSprop\ntf.keras.optimizers.legacy.SGD\ntf . keras . optimizers . legacy . Adagrad ( * args , ** kwargs )\ntf . keras . optimizers . legacy . Adagrad ( * args , ** kwargs )\nUsed in the notebooks\nMigration examples: Canned Estimators\nDebug a TensorFlow 2 migrated training pipeline\nMigrate multi-worker CPU/GPU training\nParameter server training with ParameterServerStrategy\nUncertainty-aware Deep Learning with SNGP\nTensorFlow Constrained Optimization Example Using CelebA Dataset\nIntroduction to Fairness Indicators"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform",
    "content": "Applies an affine transformation specified by the parameters given.\ntf . keras . preprocessing . image . apply_affine_transform ( x , theta = 0 , tx = 0 , ty = 0 , shear = 0 , zx = 1 , zy = 1 , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , order = 1 )\ntf . keras . preprocessing . image . apply_affine_transform ( x , theta = 0 , tx = 0 , ty = 0 , shear = 0 , zx = 1 , zy = 1 , row_axis = 1 , col_axis = 2 , channel_axis = 0 , fill_mode = 'nearest' , cval = 0.0 , order = 1 )\nDEPRECATED."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/log1p",
    "content": "Returns the natural logarithm of one plus the x , element-wise.\nx\nMain aliases tf.keras.ops.numpy.log1p\ntf.keras.ops.numpy.log1p\ntf.keras.ops.numpy.log1p\ntf . keras . ops . log1p ( x )\ntf . keras . ops . log1p ( x )\nCalculates log(1 + x) .\nlog(1 + x)\nArgs\nArgs\nx Input tensor.\nx\nReturns Output tensor, element-wise natural logarithm of 1 + x .\nReturns\n1 + x"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/logcosh",
    "content": "Logarithm of the hyperbolic cosine of the prediction error.\nMain aliases tf.keras.metrics.logcosh\ntf.keras.metrics.logcosh\ntf.keras.metrics.logcosh\ntf . keras . losses . logcosh ( y_true , y_pred )\ntf . keras . losses . logcosh ( y_true , y_pred )\nloss = mean ( log ( cosh ( y_pred - y_true )), axis =- 1 )\nloss = mean ( log ( cosh ( y_pred - y_true )), axis =- 1 )\nNote that log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x . This means that 'logcosh' works\nmostly like the mean squared error, but will not be so strongly affected by\nthe occasional wildly incorrect prediction.\nlog(cosh(x))\n(x ** 2) / 2\nx\nabs(x) - log(2)\nx\ny_true = [[ 0. , 1. ], [ 0. , 0. ]] y_pred = [[ 1. , 1. ], [ 0. , 0. ]] loss = keras . losses . log_cosh ( y_true , y_pred ) 0.108\ny_true = [[ 0. , 1. ], [ 0. , 0. ]]\ny_pred = [[ 1. , 1. ], [ 0. , 0. ]]\nloss = keras . losses . log_cosh ( y_true , y_pred )\n0.108\nArgs\nArgs\ny_true Ground truth values with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Logcosh error values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanSquaredLogarithmicError",
    "content": "Computes mean squared logarithmic error between y_true and y_pred .\ny_true\ny_pred\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . MeanSquaredLogarithmicError ( name = 'mean_squared_logarithmic_error' , dtype = None )\ntf . keras . metrics . MeanSquaredLogarithmicError ( name = 'mean_squared_logarithmic_error' , dtype = None )\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )))\nloss = mean ( square ( log ( y_true + 1 ) - log ( y_pred + 1 )))\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . MeanSquaredLogarithmicError () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]]) m . result () 0.12011322 m . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]], sample_weight = [ 1 , 0 ]) m . result () 0.24022643\nm = keras . metrics . MeanSquaredLogarithmicError ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]])\nm . result ()\n0.12011322\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 1 , 1 ], [ 0 , 0 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.24022643\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanSquaredLogarithmicError ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . MeanSquaredLogarithmicError ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/update_sub",
    "content": "DEPRECATED.\ntf . keras . backend . update_sub ( x , decrement )\ntf . keras . backend . update_sub ( x , decrement )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/floor_divide",
    "content": "Returns the largest integer smaller or equal to the division of inputs.\nMain aliases tf.keras.ops.numpy.floor_divide\ntf.keras.ops.numpy.floor_divide\ntf.keras.ops.numpy.floor_divide\ntf . keras . ops . floor_divide ( x1 , x2 )\ntf . keras . ops . floor_divide ( x1 , x2 )\nArgs\nArgs\nx1 Numerator. x2 Denominator.\nx1\nx2\nReturns Output tensor, y = floor(x1/x2)\nReturns\ny = floor(x1/x2)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/logical_and",
    "content": "Computes the element-wise logical AND of the given input tensors.\nMain aliases tf.keras.ops.numpy.logical_and\ntf.keras.ops.numpy.logical_and\ntf.keras.ops.numpy.logical_and\ntf . keras . ops . logical_and ( x1 , x2 )\ntf . keras . ops . logical_and ( x1 , x2 )\nZeros are treated as False and non-zeros are treated as True .\nFalse\nTrue\nArgs\nArgs\nx1 Input tensor. x2 Input tensor.\nx1\nx2\nReturns Output tensor, element-wise logical AND of the inputs.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalCrossentropy",
    "content": "Computes the crossentropy metric between the labels and predictions.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . SparseCategoricalCrossentropy ( name = 'sparse_categorical_crossentropy' , dtype = None , from_logits = False , axis =- 1 )\ntf . keras . metrics . SparseCategoricalCrossentropy ( name = 'sparse_categorical_crossentropy' , dtype = None , from_logits = False , axis =- 1 )\nUsed in the notebooks\nMigrate early stopping\nWorking with tff's ClientData.\nUse this crossentropy metric when there are two or more label classes.\nIt expects labels to be provided as integers. If you want to provide labels\nthat are one-hot encoded, please use the CategoricalCrossentropy metric instead.\nCategoricalCrossentropy\nThere should be num_classes floating point values per feature for y_pred and a single floating point value per feature for y_true .\nnum_classes\ny_pred\ny_true\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. from_logits (Optional) Whether output is expected\nto be a logits tensor. By default, we consider that output\nencodes a probability distribution. axis (Optional) Defaults to -1 .\nThe dimension along which entropy is computed.\nname\ndtype\nfrom_logits\naxis\n-1\n# y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]] # logits = log(y_pred) # softmax = exp(logits) / sum(exp(logits), axis=-1) # softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]] # xent = -sum(y * log(softmax), 1) # log(softmax) = [[-2.9957, -0.0513, -16.1181], #                [-2.3026, -0.2231, -2.3026]] # y_true * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]] # xent = [0.0513, 2.3026] # Reduced xent = (0.0513 + 2.3026) / 2 m = keras . metrics . SparseCategoricalCrossentropy () m . update_state ([ 1 , 2 ], [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]]) m . result () 1.1769392\n# y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n# logits = log(y_pred)\n# softmax = exp(logits) / sum(exp(logits), axis=-1)\n# softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n# xent = -sum(y * log(softmax), 1)\n# log(softmax) = [[-2.9957, -0.0513, -16.1181],\n#                [-2.3026, -0.2231, -2.3026]]\n# y_true * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n# xent = [0.0513, 2.3026]\n# Reduced xent = (0.0513 + 2.3026) / 2\nm = keras . metrics . SparseCategoricalCrossentropy ()\nm . update_state ([ 1 , 2 ],\n[[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]])\nm . result ()\n1.1769392\nm . reset_state () m . update_state ([ 1 , 2 ], [[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]], sample_weight = np . array ([ 0.3 , 0.7 ])) m . result () 1.6271976\nm . reset_state ()\nm . update_state ([ 1 , 2 ],\n[[ 0.05 , 0.95 , 0 ], [ 0.1 , 0.8 , 0.1 ]],\nsample_weight = np . array ([ 0.3 , 0.7 ]))\nm . result ()\n1.6271976\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . SparseCategoricalCrossentropy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . SparseCategoricalCrossentropy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/sin",
    "content": "Trigonometric sine, element-wise.\nMain aliases tf.keras.ops.numpy.sin\ntf.keras.ops.numpy.sin\ntf.keras.ops.numpy.sin\ntf . keras . ops . sin ( x )\ntf . keras . ops . sin ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_brightness",
    "content": "Performs a random brightness shift.\ntf . keras . preprocessing . image . random_brightness ( x , brightness_range , scale = True )\ntf . keras . preprocessing . image . random_brightness ( x , brightness_range , scale = True )\nDEPRECATED.\nArgs\nArgs\nx Input tensor. Must be 3D. brightness_range Tuple of floats; brightness range. scale Whether to rescale the image such that minimum and maximum values\nare 0 and 255 respectively. Default: True.\nx\nbrightness_range\nscale\nReturns Numpy image tensor.\nReturns\nRaises ValueError if brightness_range isn't a tuple.\nRaises\nbrightness_range"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nget_label_names(...) : Returns labels as a list of strings with indices matching training data.\nget_label_names(...)\nget_word_index(...) : Retrieves a dict mapping words to their index in the Reuters dataset.\nget_word_index(...)\nload_data(...) : Loads the Reuters newswire classification dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/relu",
    "content": "DEPRECATED.\ntf . keras . backend . relu ( x , alpha = 0.0 , max_value = None , threshold = 0.0 )\ntf . keras . backend . relu ( x , alpha = 0.0 , max_value = None , threshold = 0.0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/erf",
    "content": "Computes the error function of x , element-wise.\nx\ntf . keras . ops . erf ( x )\ntf . keras . ops . erf ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same dtype as x .\nReturns\nx\nx = np . array ([ - 3.0 , - 2.0 , - 1.0 , 0.0 , 1.0 ]) keras . ops . erf ( x ) array ([ - 0.99998 , - 0.99532 , - 0.842701 , 0. , 0.842701 ], dtype = float32 )\nx = np . array ([ - 3.0 , - 2.0 , - 1.0 , 0.0 , 1.0 ])\nkeras . ops . erf ( x )\narray ([ - 0.99998 , - 0.99532 , - 0.842701 , 0. , 0.842701 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet101V2",
    "content": "Instantiates the ResNet101V2 architecture.\nMain aliases tf.keras.applications.resnet_v2.ResNet101V2\ntf.keras.applications.resnet_v2.ResNet101V2\ntf.keras.applications.resnet_v2.ResNet101V2\ntf . keras . applications . ResNet101V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . ResNet101V2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nIdentity Mappings in Deep Residual Networks (CVPR 2016)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.resnet_v2.preprocess_input\nresnet_v2.preprocess_input\nArgs\nArgs\ninclude_top whether to include the fully-connected\nlayer at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights\nfile to be loaded. input_tensor optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format). It should have exactly 3\ninputs channels, and width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction when include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be the 4D tensor\n    output of the last convolutional block.\nNone\navg means that global average pooling will be applied to the output\n    of the last convolutional block, and thus the output of the\n    model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes optional number of classes to classify images into, only to be\nspecified if include_top is True , and if no weights argument is\nspecified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/std",
    "content": "DEPRECATED.\ntf . keras . backend . std ( x , axis = None , keepdims = False )\ntf . keras . backend . std ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/isclose",
    "content": "Return whether two tensors are element-wise almost equal.\nMain aliases tf.keras.ops.numpy.isclose\ntf.keras.ops.numpy.isclose\ntf.keras.ops.numpy.isclose\ntf . keras . ops . isclose ( x1 , x2 )\ntf . keras . ops . isclose ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output boolean tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/img_to_array",
    "content": "Converts a PIL Image instance to a NumPy array.\nMain aliases tf.keras.preprocessing.image.img_to_array\ntf.keras.preprocessing.image.img_to_array\ntf.keras.preprocessing.image.img_to_array\ntf . keras . utils . img_to_array ( img , data_format = None , dtype = None )\ntf . keras . utils . img_to_array ( img , data_format = None , dtype = None )\nUsed in the notebooks\nUsing the SavedModel format\nDeepDream\nImage classification\nfrom PIL import Image img_data = np . random . random ( size = ( 100 , 100 , 3 )) img = keras . utils . array_to_img ( img_data ) array = keras . utils . image . img_to_array ( img )\nfrom PIL import Image img_data = np . random . random ( size = ( 100 , 100 , 3 )) img = keras . utils . array_to_img ( img_data ) array = keras . utils . image . img_to_array ( img )\nArgs\nArgs\nimg Input PIL Image instance. data_format Image data format, can be either \"channels_first\" or \"channels_last\" . Defaults to None , in which case the global\nsetting keras.backend.image_data_format() is used (unless you\nchanged it, it defaults to \"channels_last\" ). dtype Dtype to use. None means the global setting keras.backend.floatx() is used (unless you changed it, it\ndefaults to \"float32\" ).\nimg\ndata_format\n\"channels_first\"\n\"channels_last\"\nNone\nkeras.backend.image_data_format()\n\"channels_last\"\ndtype\nNone\nkeras.backend.floatx()\n\"float32\"\nReturns A 3D NumPy array.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger",
    "content": "Callback that streams epoch results to a CSV file.\nInherits From: Callback\nCallback\ntf . keras . callbacks . CSVLogger ( filename , separator = ',' , append = False )\ntf . keras . callbacks . CSVLogger ( filename , separator = ',' , append = False )\nSupports all values that can be represented as a string,\nincluding 1D iterables such as np.ndarray .\nnp.ndarray\nArgs\nArgs\nfilename Filename of the CSV file, e.g. 'run/log.csv' . separator String used to separate elements in the CSV file. append Boolean. True: append if file exists (useful for continuing\ntraining). False: overwrite existing file.\nfilename\n'run/log.csv'\nseparator\nappend\ncsv_logger = CSVLogger ( 'training.log' ) model . fit ( X_train , Y_train , callbacks = [ csv_logger ])\ncsv_logger = CSVLogger ( 'training.log' ) model . fit ( X_train , Y_train , callbacks = [ csv_logger ])\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector",
    "content": "Repeats the input n times.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . RepeatVector ( n , ** kwargs )\ntf . keras . layers . RepeatVector ( n , ** kwargs )\nx = keras . Input ( shape = ( 32 ,)) y = keras . layers . RepeatVector ( 3 )( x ) y . shape ( None , 3 , 32 )\nx = keras . Input ( shape = ( 32 ,))\ny = keras . layers . RepeatVector ( 3 )( x )\ny . shape\n( None , 3 , 32 )\nArgs\nArgs\nn Integer, repetition factor.\nn\nInput shape 2D tensor with shape (batch_size, features) .\nInput shape\n(batch_size, features)\nOutput shape 3D tensor with shape (batch_size, n, features) .\nOutput shape\n(batch_size, n, features)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/constant",
    "content": "DEPRECATED.\ntf . keras . backend . constant ( value , dtype = None , shape = None , name = None )\ntf . keras . backend . constant ( value , dtype = None , shape = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2",
    "content": "Instantiates the MobileNetV2 architecture.\nMain aliases tf.keras.applications.mobilenet_v2.MobileNetV2\ntf.keras.applications.mobilenet_v2.MobileNetV2\ntf.keras.applications.mobilenet_v2.MobileNetV2\ntf . keras . applications . MobileNetV2 ( input_shape = None , alpha = 1.0 , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . MobileNetV2 ( input_shape = None , alpha = 1.0 , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nUsed in the notebooks\nEstimators\nAdversarial example using FGSM\nImage segmentation\nTransfer learning and fine-tuning\nMobileNetV2 is very similar to the original MobileNet,\nexcept that it uses inverted residual blocks with\nbottlenecking features. It has a drastically lower\nparameter count than the original MobileNet.\nMobileNets support any input size greater\nthan 32 x 32, with larger image sizes\noffering better performance.\nMobileNetV2: Inverted Residuals and Linear Bottlenecks (CVPR 2018)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nkeras.applications.mobilenet_v2.preprocess_input\nmobilenet_v2.preprocess_input\nArgs\nArgs\ninput_shape Optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with \"channels_last\" data format) or (3, 224, 224) (with \"channels_first\" data format).\nIt should have exactly 3 inputs channels, and width and\nheight should be no smaller than 32. E.g. (200, 200, 3) would\nbe one valid value. Defaults to None . input_shape will be ignored if the input_tensor is provided. alpha Controls the width of the network. This is known as the width\nmultiplier in the MobileNet paper.\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\n\"channels_last\"\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\nNone\ninput_shape\ninput_tensor\nalpha\nIf alpha < 1.0 , proportionally decreases the number\nof filters in each layer.\nalpha < 1.0\nIf alpha > 1.0 , proportionally increases the number\nof filters in each layer.\nalpha > 1.0\nIf alpha == 1 , default number of filters from the paper\nare used at each layer. Defaults to 1.0 . include_top Boolean, whether to include the fully-connected layer\nat the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet), or the path to the weights file\nto be loaded. Defaults to \"imagenet\" . input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. input_tensor is useful\nfor sharing inputs between multiple different networks.\nDefaults to None . pooling Optional pooling mode for feature extraction when include_top is False .\nalpha == 1\n1.0\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_tensor\nNone\npooling\ninclude_top\nFalse\nNone (default) means that the output of the model will be\nthe 4D tensor output of the last convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will be applied. classes Optional number of classes to classify images into,\nonly to be specified if include_top is True , and if\nno weights argument is specified. Defaults to 1000 . classifier_activation A str or callable. The activation function\nto use on the \"top\" layer. Ignored unless include_top=True .\nSet classifier_activation=None to return the logits of the \"top\"\nlayer. When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet/preprocess_input",
    "content": "Preprocesses a tensor or Numpy array encoding a batch of images.\ntf . keras . applications . mobilenet . preprocess_input ( x , data_format = None )\ntf . keras . applications . mobilenet . preprocess_input ( x , data_format = None )\nUsed in the notebooks\nUsing the SavedModel format\nUsage example with applications.MobileNet :\napplications.MobileNet\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\ni = keras . layers . Input ([ None , None , 3 ], dtype = \"uint8\" ) x = ops . cast ( i , \"float32\" ) x = keras . applications . mobilenet . preprocess_input ( x ) core = keras . applications . MobileNet () x = core ( x ) model = keras . Model ( inputs = [ i ], outputs = [ x ]) result = model ( image )\nArgs\nArgs\nx A floating point numpy.array or a backend-native tensor,\n    3D or 4D with 3 color\n    channels, with values in the range [0, 255].\n    The preprocessed data are written over the input data\nif the data types are compatible. To avoid this\nbehaviour, numpy.copy(x) can be used. data_format Optional data format of the image tensor/array. None, means\nthe global setting keras.backend.image_data_format() is used\n(unless you changed it, it uses \"channels_last\").\nDefaults to None .\nx\nnumpy.array\nnumpy.copy(x)\ndata_format\nkeras.backend.image_data_format()\nNone\nReturns Preprocessed array with type float32 .\nReturns\nfloat32\nThe inputs pixel values are scaled between -1 and 1, sample-wise.\nRaises\nRaises\nValueError In case of unknown data_format argument.\nValueError\ndata_format"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/LogCosh",
    "content": "Computes the logarithm of the hyperbolic cosine of the prediction error.\nInherits From: Loss\nLoss\ntf . keras . losses . LogCosh ( reduction = 'sum_over_batch_size' , name = 'log_cosh' )\ntf . keras . losses . LogCosh ( reduction = 'sum_over_batch_size' , name = 'log_cosh' )\nerror = y_pred - y_true logcosh = mean ( log (( exp ( error ) + exp ( - error )) / 2 ), axis =- 1 ) `\nerror = y_pred - y_true logcosh = mean ( log (( exp ( error ) + exp ( - error )) / 2 ), axis =- 1 ) `\nwhere x is the error y_pred - y_true .\ny_pred - y_true\nArgs\nArgs\nreduction Type of reduction to apply to loss. Options are \"sum\" , \"sum_over_batch_size\" or None . Defaults to \"sum_over_batch_size\" . name Optional name for the instance.\nreduction\n\"sum\"\n\"sum_over_batch_size\"\nNone\n\"sum_over_batch_size\"\nname\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/selu",
    "content": "Scaled Exponential Linear Unit (SELU).\ntf . keras . activations . selu ( x )\ntf . keras . activations . selu ( x )\nThe Scaled Exponential Linear Unit (SELU) activation function is defined as:\nscale * x if x > 0\nscale * x\nx > 0\nscale * alpha * (exp(x) - 1) if x < 0\nscale * alpha * (exp(x) - 1)\nx < 0\nwhere alpha and scale are pre-defined constants\n( alpha=1.67326324 and scale=1.05070098 ).\nalpha\nscale\nalpha=1.67326324\nscale=1.05070098\nBasically, the SELU activation function multiplies scale (> 1) with the\noutput of the keras.activations.elu function to ensure a slope larger\nthan one for positive inputs.\nscale\nkeras.activations.elu\nThe values of alpha and scale are\nchosen so that the mean and variance of the inputs are preserved\nbetween two consecutive layers as long as the weights are initialized\ncorrectly (see keras.initializers.LecunNormal initializer)\nand the number of input units is \"large enough\"\n(see reference paper for more information).\nalpha\nscale\nkeras.initializers.LecunNormal\nArgs\nArgs\nx Input tensor.\nx\nTo be used together with the keras.initializers.LecunNormal initializer.\nkeras.initializers.LecunNormal\nTo be used together with the dropout variant keras.layers.AlphaDropout (rather than regular dropout).\nkeras.layers.AlphaDropout\nKlambauer et al., 2017"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/all",
    "content": "DEPRECATED.\ntf . keras . backend . all ( x , axis = None , keepdims = False )\ntf . keras . backend . all ( x , axis = None , keepdims = False )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/maximum",
    "content": "DEPRECATED.\ntf . keras . backend . maximum ( x , y )\ntf . keras . backend . maximum ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D",
    "content": "2D convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution2D\ntf.keras.layers.Convolution2D\ntf.keras.layers.Convolution2D\ntf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv2D ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), groups = 1 , activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nUsed in the notebooks\nUse TF1.x models in TF2 workflows\nEffective Tensorflow 2\nUse TPUs\nBetter performance with tf.function\nPruning for on-device inference w/ XNNPACK\nCustom layers\nImage classification\nData augmentation\nIntro to Autoencoders\npix2pix: Image-to-image translation with a conditional GAN\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If use_bias is True, a bias vector is created and added to the\noutputs. Finally, if activation is not None , it is applied to the\noutputs as well.\nuse_bias\nactivation\nNone\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 2 integer, specifying the size of the\nconvolution window. strides int or tuple/list of 2 integer, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 2 integers, specifying the dilation\nrate to use for dilated convolution. groups A positive int specifying the number of groups in which the\ninput is split along the channel axis. Each group is convolved\nseparately with filters // groups filters. The output is the\nconcatenation of all the groups results along the channel axis.\nInput channels and filters must both be divisible by groups . activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, height, width, channels)\n\"channels_first\"\n(batch_size, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\ngroups\nfilters // groups\ngroups\nfilters\ngroups\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, height, width, channels)\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, channels, height, width)\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, new_height, new_width, filters)\ndata_format=\"channels_last\"\n(batch_size, new_height, new_width, filters)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, filters, new_height, new_width)\ndata_format=\"channels_first\"\n(batch_size, filters, new_height, new_width)\nReturns A 4D tensor representing activation(conv2d(inputs, kernel) + bias) .\nReturns\nactivation(conv2d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nx = np . random . rand ( 4 , 10 , 10 , 128 ) y = keras . layers . Conv2D ( 32 , 3 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 8 , 8 , 32 )\nx = np . random . rand ( 4 , 10 , 10 , 128 )\ny = keras . layers . Conv2D ( 32 , 3 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 8 , 8 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel\nkernel\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nconvolution_op\nconvolution_op\nView source\nconvolution_op ( inputs , kernel )\nconvolution_op ( inputs , kernel )\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/VarianceScaling",
    "content": "Initializer that adapts its scale to the shape of its input tensors.\nInherits From: Initializer\nInitializer\nMain aliases tf.keras.initializers.variance_scaling\ntf.keras.initializers.variance_scaling\ntf.keras.initializers.variance_scaling\ntf . keras . initializers . VarianceScaling ( scale = 1.0 , mode = 'fan_in' , distribution = 'truncated_normal' , seed = None )\ntf . keras . initializers . VarianceScaling ( scale = 1.0 , mode = 'fan_in' , distribution = 'truncated_normal' , seed = None )\nUsed in the notebooks\nTrain a Deep Q Network with TF-Agents\nNetworks\nWith distribution=\"truncated_normal\" or \"untruncated_normal\" , samples are\ndrawn from a truncated/untruncated normal distribution with a mean of zero\nand a standard deviation (after truncation, if used) stddev = sqrt(scale /\nn) , where n is:\ndistribution=\"truncated_normal\" or \"untruncated_normal\"\nstddev = sqrt(scale /\nn)\nn\nnumber of input units in the weight tensor, if mode=\"fan_in\"\nmode=\"fan_in\"\nnumber of output units, if mode=\"fan_out\"\nmode=\"fan_out\"\naverage of the numbers of input and output units, if mode=\"fan_avg\"\nmode=\"fan_avg\"\nWith distribution=\"uniform\" , samples are drawn from a uniform distribution\nwithin [-limit, limit] , where limit = sqrt(3 * scale / n) .\ndistribution=\"uniform\"\n[-limit, limit]\nlimit = sqrt(3 * scale / n)\n# Standalone usage: initializer = VarianceScaling ( scale = 0.1 , mode = 'fan_in' , distribution = 'uniform' ) values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = VarianceScaling (\nscale = 0.1 , mode = 'fan_in' , distribution = 'uniform' )\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = VarianceScaling ( scale = 0.1 , mode = 'fan_in' , distribution = 'uniform' ) layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = VarianceScaling (\nscale = 0.1 , mode = 'fan_in' , distribution = 'uniform' )\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nscale Scaling factor (positive float). mode One of \"fan_in\" , \"fan_out\" , \"fan_avg\" . distribution Random distribution to use.\nOne of \"truncated_normal\" , \"untruncated_normal\" , or \"uniform\" . seed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nscale\nmode\n\"fan_in\"\n\"fan_out\"\n\"fan_avg\"\ndistribution\n\"truncated_normal\"\n\"untruncated_normal\"\n\"uniform\"\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling3D",
    "content": "Global average pooling operation for 3D data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalAvgPool3D\ntf.keras.layers.GlobalAvgPool3D\ntf.keras.layers.GlobalAvgPool3D\ntf . keras . layers . GlobalAveragePooling3D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalAveragePooling3D ( data_format = None , keepdims = False , ** kwargs )\nUsed in the notebooks\nLoad video data\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\nspatial dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nIf data_format='channels_last' :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format='channels_last'\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format='channels_first' :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format='channels_first'\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf keepdims=False :\n2D tensor with shape (batch_size, channels) .\nkeepdims=False\n(batch_size, channels)\nIf keepdims=True : If data_format=\"channels_last\" :\n5D tensor with shape (batch_size, 1, 1, 1, channels) If data_format=\"channels_first\" :\n5D tensor with shape (batch_size, channels, 1, 1, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n5D tensor with shape (batch_size, 1, 1, 1, channels)\ndata_format=\"channels_last\"\n(batch_size, 1, 1, 1, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape (batch_size, channels, 1, 1, 1)\ndata_format=\"channels_first\"\n(batch_size, channels, 1, 1, 1)\nx = np . random . rand ( 2 , 4 , 5 , 4 , 3 ) y = keras . layers . GlobalAveragePooling3D ()( x ) y . shape ( 2 , 3 )\nx = np . random . rand ( 2 , 4 , 5 , 4 , 3 )\ny = keras . layers . GlobalAveragePooling3D ()( x )\ny . shape\n( 2 , 3 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/conv2d_transpose",
    "content": "DEPRECATED.\ntf . keras . backend . conv2d_transpose ( x , kernel , output_shape , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )\ntf . keras . backend . conv2d_transpose ( x , kernel , output_shape , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization",
    "content": "Group normalization layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . GroupNormalization ( groups = 32 , axis =- 1 , epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , ** kwargs )\ntf . keras . layers . GroupNormalization ( groups = 32 , axis =- 1 , epsilon = 0.001 , center = True , scale = True , beta_initializer = 'zeros' , gamma_initializer = 'ones' , beta_regularizer = None , gamma_regularizer = None , beta_constraint = None , gamma_constraint = None , ** kwargs )\nGroup Normalization divides the channels into groups and computes\nwithin each group the mean and variance for normalization.\nEmpirically, its accuracy is more stable than batch norm in a wide\nrange of small batch sizes, if learning rate is adjusted linearly\nwith batch sizes.\nRelation to Layer Normalization:\nIf the number of groups is set to 1, then this operation becomes nearly\nidentical to Layer Normalization (see Layer Normalization docs for details).\nRelation to Instance Normalization:\nIf the number of groups is set to the input dimension (number of groups is\nequal to number of channels), then this operation becomes identical to\nInstance Normalization. You can achieve this via groups=-1 .\ngroups=-1\nArgs\nArgs\ngroups Integer, the number of groups for Group Normalization. Can be in\nthe range [1, N] where N is the input dimension. The input\ndimension must be divisible by the number of groups.\nDefaults to 32. axis Integer or List/Tuple. The axis or axes to normalize across.\nTypically, this is the features axis/axes. The left-out axes are\ntypically the batch axis/axes. -1 is the last dimension in the\ninput. Defaults to -1 . epsilon Small float added to variance to avoid dividing by zero.\nDefaults to 1e-3. center If True , add offset of beta to normalized tensor.\nIf False , beta is ignored. Defaults to True . scale If True , multiply by gamma . If False , gamma is not used.\nWhen the next layer is linear (also e.g. relu ), this can be\ndisabled since the scaling will be done by the next layer.\nDefaults to True . beta_initializer Initializer for the beta weight. Defaults to zeros. gamma_initializer Initializer for the gamma weight. Defaults to ones. beta_regularizer Optional regularizer for the beta weight. None by\ndefault. gamma_regularizer Optional regularizer for the gamma weight. None by\ndefault. beta_constraint Optional constraint for the beta weight.\nNone by default. gamma_constraint Optional constraint for the gamma weight. None by\ndefault.  Input shape: Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples\naxis) when using this layer as the first layer in a model.\nOutput shape: Same shape as input. **kwargs Base layer keyword arguments (e.g. name and dtype ).\ngroups\n[1, N]\naxis\n-1\nepsilon\ncenter\nTrue\nbeta\nFalse\nbeta\nTrue\nscale\nTrue\ngamma\nFalse\ngamma\nrelu\nTrue\nbeta_initializer\ngamma_initializer\nbeta_regularizer\ngamma_regularizer\nbeta_constraint\ngamma_constraint\ninput_shape\n**kwargs\nname\ndtype\nYuxin Wu & Kaiming He, 2018\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16",
    "content": "Instantiates the VGG16 model.\nMain aliases tf.keras.applications.vgg16.VGG16\ntf.keras.applications.vgg16.VGG16\ntf.keras.applications.vgg16.VGG16\ntf . keras . applications . VGG16 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . VGG16 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nVery Deep Convolutional Networks for Large-Scale Image Recognition (ICLR 2015)\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nThe default input size for this model is 224x224.\nkeras.applications.vgg16.preprocess_input\nvgg16.preprocess_input\nArgs\nArgs\ninclude_top whether to include the 3 fully-connected\nlayers at the top of the network. weights one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with \"channels_first\" data format).\nIt should have exactly 3 input channels,\nand width and height should be no smaller than 32.\nE.g. (200, 200, 3) would be one valid value. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninclude_top\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\nFalse\n(224, 224, 3)\nchannels_last\n(3, 224, 224)\n\"channels_first\"\n(200, 200, 3)\npooling\ninclude_top\nFalse\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\"\nlayer.  When loading pretrained weights, classifier_activation can only be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/softplus",
    "content": "DEPRECATED.\ntf . keras . backend . softplus ( x )\ntf . keras . backend . softplus ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/hinge",
    "content": "Computes the hinge loss between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.metrics.hinge\ntf.keras.metrics.hinge\ntf.keras.metrics.hinge\ntf . keras . losses . hinge ( y_true , y_pred )\ntf . keras . losses . hinge ( y_true , y_pred )\nloss = mean ( maximum ( 1 - y_true * y_pred , 0 ), axis =- 1 )\nloss = mean ( maximum ( 1 - y_true * y_pred , 0 ), axis =- 1 )\nArgs\nArgs\ny_true The ground truth values. y_true values are expected to be -1\nor 1. If binary (0 or 1) labels are provided they will be converted\nto -1 or 1 with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Hinge loss values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . choice ([ - 1 , 1 ], size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . hinge ( y_true , y_pred )\ny_true = np . random . choice ([ - 1 , 1 ], size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . hinge ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cross",
    "content": "Returns the cross product of two (arrays of) vectors.\nMain aliases tf.keras.ops.numpy.cross\ntf.keras.ops.numpy.cross\ntf.keras.ops.numpy.cross\ntf . keras . ops . cross ( x1 , x2 , axisa =- 1 , axisb =- 1 , axisc =- 1 , axis = None )\ntf . keras . ops . cross ( x1 , x2 , axisa =- 1 , axisb =- 1 , axisc =- 1 , axis = None )\nThe cross product of x1 and x2 in R^3 is a vector\nperpendicular to both x1 and x2 . If x1 and x2 are arrays of\nvectors, the vectors are defined by the last axis of x1 and x2 by default, and these axes can have dimensions 2 or 3.\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nWhere the dimension of either x1 or x2 is 2, the third component of\nthe input vector is assumed to be zero and the cross product calculated\naccordingly.\nx1\nx2\nIn cases where both input vectors have dimension 2, the z-component of\nthe cross product is returned.\nArgs\nArgs\nx1 Components of the first vector(s). x2 Components of the second vector(s). axisa Axis of x1 that defines the vector(s). Defaults to -1 . axisb Axis of x2 that defines the vector(s). Defaults to -1 . axisc Axis of the result containing the cross product vector(s).\nIgnored if both input vectors have dimension 2, as the return is\nscalar. By default, the last axis. axis If defined, the axis of x1 , x2 and the result that\ndefines the vector(s) and cross product(s). Overrides axisa , axisb and axisc .\nx1\nx2\naxisa\nx1\n-1\naxisb\nx2\n-1\naxisc\naxis\nx1\nx2\naxisa\naxisb\naxisc\nNote Torch backend does not support two dimensional vectors, or the\narguments axisa , axisb and axisc . Use axis instead.\nNote\naxisa\naxisb\naxisc\naxis\nReturns Vector cross product(s).\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/less",
    "content": "Return the truth value of x1 < x2 element-wise.\nx1 < x2\nMain aliases tf.keras.ops.numpy.less\ntf.keras.ops.numpy.less\ntf.keras.ops.numpy.less\ntf . keras . ops . less ( x1 , x2 )\ntf . keras . ops . less ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise comparison of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/truncated_normal",
    "content": "Draw samples from a truncated normal distribution.\ntf . keras . random . truncated_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\ntf . keras . random . truncated_normal ( shape , mean = 0.0 , stddev = 1.0 , dtype = None , seed = None )\nThe values are drawn from a normal distribution with specified mean and\nstandard deviation, discarding and re-drawing any samples that are more\nthan two standard deviations from the mean.\nArgs\nArgs\nshape The shape of the random values to generate. mean Float, defaults to 0. Mean of the random values to generate. stddev Float, defaults to 1. Standard deviation of the random values\nto generate. dtype Optional dtype of the tensor. Only floating point types are\nsupported. If not specified, keras.config.floatx() is used,\nwhich defaults to float32 unless you configured it otherwise (via keras.config.set_floatx(float_dtype) ) seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nshape\nmean\nstddev\ndtype\nkeras.config.floatx()\nfloat32\nkeras.config.set_floatx(float_dtype)\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/silu",
    "content": "Sigmoid Linear Unit (SiLU) activation function, also known as Swish.\nMain aliases tf.keras.ops.nn.silu , tf.keras.ops.nn.swish , tf.keras.ops.swish\ntf.keras.ops.nn.silu , tf.keras.ops.nn.swish , tf.keras.ops.swish\ntf.keras.ops.nn.silu\ntf.keras.ops.nn.swish\ntf.keras.ops.swish\ntf . keras . ops . silu ( x )\ntf . keras . ops . silu ( x )\nThe SiLU activation function is computed by the sigmoid function multiplied\nby its input. It is defined as f(x) = x * sigmoid(x) .\nf(x) = x * sigmoid(x)\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 6.0 , 1.0 , 0.0 , 1.0 , 6.0 ]) keras . ops . sigmoid ( x ) array ([ 0.00247262 , 0.7310586 , 0.5 , 0.7310586 , 0.9975274 ], dtype = float32 ) keras . ops . silu ( x ) array ([ - 0.0148357 , 0.7310586 , 0.0 , 0.7310586 , 5.9851646 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 6.0 , 1.0 , 0.0 , 1.0 , 6.0 ])\nkeras . ops . sigmoid ( x )\narray ([ 0.00247262 , 0.7310586 , 0.5 , 0.7310586 , 0.9975274 ], dtype = float32 )\nkeras . ops . silu ( x )\narray ([ - 0.0148357 , 0.7310586 , 0.0 , 0.7310586 , 5.9851646 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/PyDataset",
    "content": "Base class for defining a parallel dataset using Python code.\nMain aliases tf.keras.utils.Sequence\ntf.keras.utils.Sequence\ntf.keras.utils.Sequence\ntf . keras . utils . PyDataset ( workers = 1 , use_multiprocessing = False , max_queue_size = 10 )\ntf . keras . utils . PyDataset ( workers = 1 , use_multiprocessing = False , max_queue_size = 10 )\nEvery PyDataset must implement the __getitem__() and the __len__() methods. If you want to modify your dataset between epochs,\nyou may additionally implement on_epoch_end() .\nThe __getitem__() method should return a complete batch\n(not a single sample), and the __len__ method should return\nthe number of batches in the dataset (rather than the number of samples).\nPyDataset\n__getitem__()\n__len__()\non_epoch_end()\n__getitem__()\n__len__\nArgs\nArgs\nworkers Number of workers to use in multithreading or\nmultiprocessing. use_multiprocessing Whether to use Python multiprocessing for\nparallelism. Setting this to True means that your\ndataset will be replicated in multiple forked processes.\nThis is necessary to gain compute-level (rather than I/O level)\nbenefits from parallelism. However it can only be set to True if your dataset can be safely pickled. max_queue_size Maximum number of batches to keep in the queue\nwhen iterating over the dataset in a multithreaded or\nmultipricessed setting.\nReduce this value to reduce the CPU memory consumption of\nyour dataset. Defaults to 10.\nworkers\nuse_multiprocessing\nTrue\nTrue\nmax_queue_size\nPyDataset is a safer way to do multiprocessing.\nThis structure guarantees that the model will only train\nonce on each sample per epoch, which is not the case\nwith Python generators.\nPyDataset\nThe arguments workers , use_multiprocessing , and max_queue_size exist to configure how fit() uses parallelism to iterate\nover the dataset. They are not being used by the PyDataset class\ndirectly. When you are manually iterating over a PyDataset ,\nno parallelism is applied.\nworkers\nuse_multiprocessing\nmax_queue_size\nfit()\nPyDataset\nPyDataset\nfrom skimage.io import imread from skimage.transform import resize import numpy as np import math # Here, `x_set` is list of path to the images # and `y_set` are the associated classes. class CIFAR10PyDataset ( keras . utils . PyDataset ): def __init__ ( self , x_set , y_set , batch_size , ** kwargs ): super () . __init__ ( ** kwargs ) self . x , self . y = x_set , y_set self . batch_size = batch_size def __len__ ( self ): # Return number of batches. return math . ceil ( len ( self . x ) / self . batch_size ) def __getitem__ ( self , idx ): # Return x, y for batch idx. low = idx * self . batch_size # Cap upper bound at array length; the last batch may be smaller # if the total number of items is not a multiple of batch size. high = min ( low + self . batch_size , len ( self . x )) batch_x = self . x [ low : high ] batch_y = self . y [ low : high ] return np . array ([ resize ( imread ( file_name ), ( 200 , 200 )) for file_name in batch_x ]), np . array ( batch_y )\nfrom skimage.io import imread from skimage.transform import resize import numpy as np import math # Here, `x_set` is list of path to the images # and `y_set` are the associated classes. class CIFAR10PyDataset ( keras . utils . PyDataset ): def __init__ ( self , x_set , y_set , batch_size , ** kwargs ): super () . __init__ ( ** kwargs ) self . x , self . y = x_set , y_set self . batch_size = batch_size def __len__ ( self ): # Return number of batches. return math . ceil ( len ( self . x ) / self . batch_size ) def __getitem__ ( self , idx ): # Return x, y for batch idx. low = idx * self . batch_size # Cap upper bound at array length; the last batch may be smaller # if the total number of items is not a multiple of batch size. high = min ( low + self . batch_size , len ( self . x )) batch_x = self . x [ low : high ] batch_y = self . y [ low : high ] return np . array ([ resize ( imread ( file_name ), ( 200 , 200 )) for file_name in batch_x ]), np . array ( batch_y )\nAttributes\nAttributes\nmax_queue_size\nmax_queue_size\nnum_batches Number of batches in the PyDataset. use_multiprocessing\nnum_batches\nuse_multiprocessing\nworkers\nworkers\nMethods\non_epoch_end\non_epoch_end\nView source\non_epoch_end ()\non_epoch_end ()\nMethod called at the end of every epoch.\n__getitem__\n__getitem__\nView source\n__getitem__ ( index )\n__getitem__ ( index )\nGets batch at position index .\nindex\nArgs\nindex position of the batch in the PyDataset.\nindex\nReturns A batch"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/result_type",
    "content": "Returns the type from applying the Keras type promotion rules.\ntf . keras . backend . result_type ( * dtypes )\ntf . keras . backend . result_type ( * dtypes )\nIn general, each argument is first parsed by backend.standardize_dtype ,\nand the resulting dtype is determined by the least upper bound of the type\npromotion lattice.\nbackend.standardize_dtype\njnp.result_type\nArgs\nArgs\ndtypes Input dtypes.\ndtypes\nReturns The result dtype.\nReturns\nx = keras . ops . ones (( 1 ,), dtype = \"bfloat16\" ) keras . backend . result_type ( x . dtype , int ) \"bfloat16\"\nx = keras . ops . ones (( 1 ,), dtype = \"bfloat16\" )\nkeras . backend . result_type ( x . dtype , int )\n\"bfloat16\"\nx = keras . ops . ones (( 1 ,), dtype = \"int32\" ) y = keras . ops . ones (( 1 ,), dtype = \"float32\" ) keras . backend . result_type ( x . dtype , y . dtype ) \"float32\"\nx = keras . ops . ones (( 1 ,), dtype = \"int32\" )\ny = keras . ops . ones (( 1 ,), dtype = \"float32\" )\nkeras . backend . result_type ( x . dtype , y . dtype )\n\"float32\""
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MelSpectrogram",
    "content": "A preprocessing layer to convert raw audio signals to Mel spectrograms.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . MelSpectrogram ( fft_length = 2048 , sequence_stride = 512 , sequence_length = None , window = 'hann' , sampling_rate = 16000 , num_mel_bins = 128 , min_freq = 20.0 , max_freq = None , power_to_db = True , top_db = 80.0 , mag_exp = 2.0 , min_power = 1e-10 , ref_power = 1.0 , ** kwargs )\ntf . keras . layers . MelSpectrogram ( fft_length = 2048 , sequence_stride = 512 , sequence_length = None , window = 'hann' , sampling_rate = 16000 , num_mel_bins = 128 , min_freq = 20.0 , max_freq = None , power_to_db = True , top_db = 80.0 , mag_exp = 2.0 , min_power = 1e-10 , ref_power = 1.0 , ** kwargs )\nThis layer takes float32 / float64 single or batched audio signal as\ninputs and computes the Mel spectrogram using Short-Time Fourier Transform\nand Mel scaling. The input should be a 1D (unbatched) or 2D (batched) tensor\nrepresenting audio signals. The output will be a 2D or 3D tensor\nrepresenting Mel spectrograms.\nfloat32\nfloat64\nA spectrogram is an image-like representation that shows the frequency\nspectrum of a signal over time. It uses x-axis to represent time, y-axis to\nrepresent frequency, and each pixel to represent intensity.\nMel spectrograms are a special type of spectrogram that use the mel scale,\nwhich approximates how humans perceive sound. They are commonly used in\nspeech and music processing tasks like speech recognition, speaker\nidentification, and music genre classification.\nSpectrogram ,\nMel scale .\nUnbatched audio signal\nlayer = keras . layers . MelSpectrogram ( num_mel_bins = 64 , sampling_rate = 8000 , sequence_stride = 256 , fft_length = 2048 ) layer ( keras . random . uniform ( shape = ( 16000 ,))) . shape ( 64 , 63 )\nlayer = keras . layers . MelSpectrogram ( num_mel_bins = 64 ,\nsampling_rate = 8000 ,\nsequence_stride = 256 ,\nfft_length = 2048 )\nlayer ( keras . random . uniform ( shape = ( 16000 ,))) . shape\n( 64 , 63 )\nBatched audio signal\nlayer = keras . layers . MelSpectrogram ( num_mel_bins = 80 , sampling_rate = 8000 , sequence_stride = 128 , fft_length = 2048 ) layer ( keras . random . uniform ( shape = ( 2 , 16000 ))) . shape ( 2 , 80 , 125 )\nlayer = keras . layers . MelSpectrogram ( num_mel_bins = 80 ,\nsampling_rate = 8000 ,\nsequence_stride = 128 ,\nfft_length = 2048 )\nlayer ( keras . random . uniform ( shape = ( 2 , 16000 ))) . shape\n( 2 , 80 , 125 )\nInput shape 1D (unbatched) or 2D (batched) tensor with shape: (..., samples) .\nInput shape\n(..., samples)\nOutput shape 2D (unbatched) or 3D (batched) tensor with\nshape: (..., num_mel_bins, time) .\nOutput shape\n(..., num_mel_bins, time)\nArgs\nArgs\nfft_length Integer, size of the FFT window. sequence_stride Integer, number of samples between successive STFT\ncolumns. sequence_length Integer, size of the window used for applying window to each audio frame. If None , defaults to fft_length . window String, name of the window function to use. Available values\nare \"hann\" and \"hamming\" . If window is a tensor, it will be\nused directly as the window and its length must be sequence_length . If window is None , no windowing is\nused. Defaults to \"hann\" . sampling_rate Integer, sample rate of the input signal. num_mel_bins Integer, number of mel bins to generate. min_freq Float, minimum frequency of the mel bins. max_freq Float, maximum frequency of the mel bins.\nIf None , defaults to sampling_rate / 2 . power_to_db If True, convert the power spectrogram to decibels. top_db Float, minimum negative cut-off max(10 * log10(S)) - top_db . mag_exp Float, exponent for the magnitude spectrogram.\n1 for magnitude, 2 for power, etc. Default is 2. ref_power Float, the power is scaled relative to it 10 * log10(S / ref_power) . min_power Float, minimum value for power and ref_power .\nfft_length\nsequence_stride\nsequence_length\nwindow\nNone\nfft_length\nwindow\n\"hann\"\n\"hamming\"\nwindow\nsequence_length\nwindow\nNone\n\"hann\"\nsampling_rate\nnum_mel_bins\nmin_freq\nmax_freq\nNone\nsampling_rate / 2\npower_to_db\ntop_db\nmax(10 * log10(S)) - top_db\nmag_exp\nref_power\n10 * log10(S / ref_power)\nmin_power\nref_power\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nlinear_to_mel_weight_matrix\nlinear_to_mel_weight_matrix\nView source\nlinear_to_mel_weight_matrix ( num_mel_bins = 20 , num_spectrogram_bins = 129 , sampling_rate = 8000 , lower_edge_hertz = 125.0 , upper_edge_hertz = 3800.0 , dtype = 'float32' )\nlinear_to_mel_weight_matrix ( num_mel_bins = 20 , num_spectrogram_bins = 129 , sampling_rate = 8000 , lower_edge_hertz = 125.0 , upper_edge_hertz = 3800.0 , dtype = 'float32' )\nReturns a matrix to warp linear scale spectrograms to the mel scale.\nReturns a weight matrix that can be used to re-weight a tensor\ncontaining num_spectrogram_bins linearly sampled frequency information\nfrom [0, sampling_rate / 2] into num_mel_bins frequency information\nfrom [lower_edge_hertz, upper_edge_hertz] on the mel scale.\nnum_spectrogram_bins\n[0, sampling_rate / 2]\nnum_mel_bins\n[lower_edge_hertz, upper_edge_hertz]\nThis function follows the Hidden Markov Model Toolkit (HTK) convention, defining the mel scale in\nterms of a frequency in hertz according to the following formula:\nmel(f) = 2595 * log10( 1 + f/700)\nmel(f) = 2595 * log10( 1 + f/700)\nIn the returned matrix, all the triangles (filterbanks) have a peak\nvalue of 1.0.\nFor example, the returned matrix A can be used to right-multiply a\nspectrogram S of shape [frames, num_spectrogram_bins] of linear\nscale spectrum values (e.g. STFT magnitudes) to generate a\n\"mel spectrogram\" M of shape [frames, num_mel_bins] .\nA\nS\n[frames, num_spectrogram_bins]\nM\n[frames, num_mel_bins]\n# `S` has shape [frames, num_spectrogram_bins] # `M` has shape [frames, num_mel_bins] M = keras . ops . matmul ( S , A )\n# `S` has shape [frames, num_spectrogram_bins] # `M` has shape [frames, num_mel_bins] M = keras . ops . matmul ( S , A )\nThe matrix can be used with keras.ops.tensordot to convert an\narbitrary rank Tensor of linear-scale spectral bins into the\nmel scale.\nkeras.ops.tensordot\nTensor\n# S has shape [..., num_spectrogram_bins]. # M has shape [..., num_mel_bins]. M = keras . ops . tensordot ( S , A , 1 )\n# S has shape [..., num_spectrogram_bins]. # M has shape [..., num_mel_bins]. M = keras . ops . tensordot ( S , A , 1 )\nMel scale (Wikipedia)\nArgs\nnum_mel_bins Python int. How many bands in the resulting\nmel spectrum. num_spectrogram_bins An integer Tensor . How many bins there are\nin the source spectrogram data, which is understood to be fft_size // 2 + 1 , i.e. the spectrogram only contains the\nnonredundant FFT bins. sampling_rate An integer or float Tensor . Samples per second of\nthe input signal used to create the spectrogram. Used to figure\nout the frequencies corresponding to each spectrogram bin,\nwhich dictates how they are mapped into the mel scale. lower_edge_hertz Python float. Lower bound on the frequencies to be\nincluded in the mel spectrum. This corresponds to the lower\nedge of the lowest triangular band. upper_edge_hertz Python float. The desired top edge of the highest\nfrequency band. dtype The DType of the result matrix. Must be a floating point\ntype.\nnum_mel_bins\nnum_spectrogram_bins\nTensor\nfft_size // 2 + 1\nsampling_rate\nTensor\nlower_edge_hertz\nupper_edge_hertz\ndtype\nDType\nReturns A tensor of shape [num_spectrogram_bins, num_mel_bins] .\n[num_spectrogram_bins, num_mel_bins]\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file",
    "content": "Downloads a file from a URL if it not already in the cache.\ntf . keras . utils . get_file ( fname = None , origin = None , untar = False , md5_hash = None , file_hash = None , cache_subdir = 'datasets' , hash_algorithm = 'auto' , extract = False , archive_format = 'auto' , cache_dir = None , force_download = False )\ntf . keras . utils . get_file ( fname = None , origin = None , untar = False , md5_hash = None , file_hash = None , cache_subdir = 'datasets' , hash_algorithm = 'auto' , extract = False , archive_format = 'auto' , cache_dir = None , force_download = False )\nUsed in the notebooks\ntf.data: Build TensorFlow input pipelines\nUsing the SavedModel format\nEstimators\nMigrating your TFLite code to TF2\nUsing Counterfactual Logit Pairing with Keras\nTransfer learning with TensorFlow Hub\nLoad CSV data\nTransfer learning with YAMNet for environmental sound classification\nPremade Estimators\nNeural style transfer\nBy default the file at the url origin is downloaded to the\ncache_dir ~/.keras , placed in the cache_subdir datasets ,\nand given the filename fname . The final location of a file example.txt would therefore be ~/.keras/datasets/example.txt .\nFiles in .tar , .tar.gz , .tar.bz , and .zip formats can\nalso be extracted.\norigin\n~/.keras\ndatasets\nfname\nexample.txt\n~/.keras/datasets/example.txt\n.tar\n.tar.gz\n.tar.bz\n.zip\nPassing a hash will verify the file after download. The command line\nprograms shasum and sha256sum can compute the hash.\nshasum\nsha256sum\npath_to_downloaded_file = get_file ( origin = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\" , extract = True , )\npath_to_downloaded_file = get_file ( origin = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\" , extract = True , )\nArgs\nArgs\nfname Name of the file. If an absolute path, e.g. \"/path/to/file.txt\" is specified, the file will be saved at that location.\nIf None , the name of the file at origin will be used. origin Original URL of the file. untar Deprecated in favor of extract argument.\nboolean, whether the file should be decompressed md5_hash Deprecated in favor of file_hash argument.\nmd5 hash of the file for verification file_hash The expected hash string of the file after download.\nThe sha256 and md5 hash algorithms are both supported. cache_subdir Subdirectory under the Keras cache dir where the file is\nsaved. If an absolute path, e.g. \"/path/to/folder\" is\nspecified, the file will be saved at that location. hash_algorithm Select the hash algorithm to verify the file.\noptions are \"md5' , \"sha256' , and \"auto' .\nThe default 'auto' detects the hash algorithm in use. extract True tries extracting the file as an Archive, like tar or zip. archive_format Archive format to try for extracting the file.\nOptions are \"auto' , \"tar' , \"zip' , and None . \"tar\" includes tar, tar.gz, and tar.bz files.\nThe default \"auto\" corresponds to [\"tar\", \"zip\"] .\nNone or an empty list will return no matches found. cache_dir Location to store cached files, when None it\ndefaults ether $KERAS_HOME if the KERAS_HOME environment\nvariable is set or ~/.keras/ . force_download If True , the file will always be re-downloaded\nregardless of the cache state.\nfname\n\"/path/to/file.txt\"\nNone\norigin\norigin\nuntar\nextract\nmd5_hash\nfile_hash\nfile_hash\ncache_subdir\n\"/path/to/folder\"\nhash_algorithm\n\"md5'\n\"sha256'\n\"auto'\nextract\narchive_format\n\"auto'\n\"tar'\n\"zip'\nNone\n\"tar\"\n\"auto\"\n[\"tar\", \"zip\"]\ncache_dir\n$KERAS_HOME\nKERAS_HOME\n~/.keras/\nforce_download\nTrue\nReturns Path to the downloaded file.\nReturns\n\u26a0\ufe0f Warning on malicious downloads \u26a0\ufe0f\nDownloading something from the Internet carries a risk.\nNEVER download a file/archive if you do not trust the source.\nWe recommend that you specify the file_hash argument\n(if the hash of the source file is known) to make sure that the file you\nare getting is the one you expect.\nfile_hash"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/is_sparse",
    "content": "DEPRECATED.\ntf . keras . backend . is_sparse ( tensor )\ntf . keras . backend . is_sparse ( tensor )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding1D",
    "content": "Zero-padding layer for 1D input (e.g. temporal sequence).\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ZeroPadding1D ( padding = 1 , ** kwargs )\ntf . keras . layers . ZeroPadding1D ( padding = 1 , ** kwargs )\ninput_shape = ( 2 , 2 , 3 ) x = np . arange ( np . prod ( input_shape )) . reshape ( input_shape ) x [[[ 0 1 2 ] [ 3 4 5 ]] [[ 6 7 8 ] [ 9 10 11 ]]] y = keras . layers . ZeroPadding1D ( padding = 2 )( x ) y [[[ 0 0 0 ] [ 0 0 0 ] [ 0 1 2 ] [ 3 4 5 ] [ 0 0 0 ] [ 0 0 0 ]] [[ 0 0 0 ] [ 0 0 0 ] [ 6 7 8 ] [ 9 10 11 ] [ 0 0 0 ] [ 0 0 0 ]]]\ninput_shape = ( 2 , 2 , 3 )\nx = np . arange ( np . prod ( input_shape )) . reshape ( input_shape )\nx\n[[[ 0 1 2 ]\n[ 3 4 5 ]]\n[[ 6 7 8 ]\n[ 9 10 11 ]]]\ny = keras . layers . ZeroPadding1D ( padding = 2 )( x )\ny\n[[[ 0 0 0 ]\n[ 0 0 0 ]\n[ 0 1 2 ]\n[ 3 4 5 ]\n[ 0 0 0 ]\n[ 0 0 0 ]]\n[[ 0 0 0 ]\n[ 0 0 0 ]\n[ 6 7 8 ]\n[ 9 10 11 ]\n[ 0 0 0 ]\n[ 0 0 0 ]]]\nArgs\nArgs\npadding Int, or tuple of int (length 2), or dictionary.\npadding\nIf int: how many zeros to add at the beginning and end of\nthe padding dimension (axis 1).\nIf tuple of 2 ints: how many zeros to add at the beginning and the\nend of the padding dimension ( (left_pad, right_pad) ).\n(left_pad, right_pad)\nInput shape 3D tensor with shape (batch_size, axis_to_pad, features)\nInput shape\n(batch_size, axis_to_pad, features)\nOutput shape 3D tensor with shape (batch_size, padded_axis, features)\nOutput shape\n(batch_size, padded_axis, features)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/binary_accuracy",
    "content": "tf . keras . metrics . binary_accuracy ( y_true , y_pred , threshold = 0.5 )\ntf . keras . metrics . binary_accuracy ( y_true , y_pred , threshold = 0.5 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ones_like",
    "content": "DEPRECATED.\ntf . keras . backend . ones_like ( x , dtype = None , name = None )\ntf . keras . backend . ones_like ( x , dtype = None , name = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_source_inputs",
    "content": "Returns the list of input tensors necessary to compute tensor .\ntensor\ntf . keras . utils . get_source_inputs ( tensor )\ntf . keras . utils . get_source_inputs ( tensor )\nOutput will always be a list of tensors\n(potentially with 1 element).\nArgs\nArgs\ntensor The tensor to start from.\ntensor\nReturns List of input tensors.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/not_equal",
    "content": "DEPRECATED.\ntf . keras . backend . not_equal ( x , y )\ntf . keras . backend . not_equal ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_normal_variable",
    "content": "DEPRECATED.\ntf . keras . backend . random_normal_variable ( shape , mean , scale , dtype = None , name = None , seed = None )\ntf . keras . backend . random_normal_variable ( shape , mean , scale , dtype = None , name = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/conv2d",
    "content": "DEPRECATED.\ntf . keras . backend . conv2d ( x , kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )\ntf . keras . backend . conv2d ( x , kernel , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/random_uniform_variable",
    "content": "DEPRECATED.\ntf . keras . backend . random_uniform_variable ( shape , low , high , dtype = None , name = None , seed = None )\ntf . keras . backend . random_uniform_variable ( shape , low , high , dtype = None , name = None , seed = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D",
    "content": "Average pooling operation for 2D spatial data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.AvgPool2D\ntf.keras.layers.AvgPool2D\ntf.keras.layers.AvgPool2D\ntf . keras . layers . AveragePooling2D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . AveragePooling2D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nDownsamples the input along its spatial dimensions (height and width)\nby taking the average value over an input window\n(of size defined by pool_size ) for each channel of the input.\nThe window is shifted by strides along each dimension.\npool_size\nstrides\nThe resulting output when using the \"valid\" padding option has a spatial\nshape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape >= pool_size )\n\"valid\"\noutput_shape = math.floor((input_shape - pool_size) / strides) + 1\ninput_shape >= pool_size\nThe resulting output shape when using the \"same\" padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1\n\"same\"\noutput_shape = math.floor((input_shape - 1) / strides) + 1\nArgs\nArgs\npool_size int or tuple of 2 integers, factors by which to downscale\n(dim1, dim2). If only one integer is specified, the same\nwindow length will be used for all dimensions. strides int or tuple of 2 integers, or None. Strides values. If None,\nit will default to pool_size . If only one int is specified, the\nsame stride size will be used for all dimensions. padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, height, width, channels) .\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, height, width) .\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, pooled_height, pooled_width, channels) .\ndata_format=\"channels_last\"\n(batch_size, pooled_height, pooled_width, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, pooled_height, pooled_width) .\ndata_format=\"channels_first\"\n(batch_size, channels, pooled_height, pooled_width)\nstrides=(1, 1) and padding=\"valid\" :\nstrides=(1, 1)\npadding=\"valid\"\nx = np . array ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) x = np . reshape ( x , [ 1 , 3 , 3 , 1 ]) avg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = \"valid\" ) avg_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. ],\n[ 4. , 5. , 6. ],\n[ 7. , 8. , 9. ]])\nx = np . reshape ( x , [ 1 , 3 , 3 , 1 ])\navg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 1 , 1 ), padding = \"valid\" )\navg_pool_2d ( x )\nstrides=(2, 2) and padding=\"valid\" :\nstrides=(2, 2)\npadding=\"valid\"\nx = np . array ([[ 1. , 2. , 3. , 4. ], [ 5. , 6. , 7. , 8. ], [ 9. , 10. , 11. , 12. ]]) x = np . reshape ( x , [ 1 , 3 , 4 , 1 ]) avg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = ( 2 , 2 ), padding = \"valid\" ) avg_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. , 4. ],\n[ 5. , 6. , 7. , 8. ],\n[ 9. , 10. , 11. , 12. ]])\nx = np . reshape ( x , [ 1 , 3 , 4 , 1 ])\navg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 2 , 2 ), padding = \"valid\" )\navg_pool_2d ( x )\nstride=(1, 1) and padding=\"same\" :\nstride=(1, 1)\npadding=\"same\"\nx = np . array ([[ 1. , 2. , 3. ], [ 4. , 5. , 6. ], [ 7. , 8. , 9. ]]) x = np . reshape ( x , [ 1 , 3 , 3 , 1 ]) avg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ), strides = ( 1 , 1 ), padding = \"same\" ) avg_pool_2d ( x )\nx = np . array ([[ 1. , 2. , 3. ],\n[ 4. , 5. , 6. ],\n[ 7. , 8. , 9. ]])\nx = np . reshape ( x , [ 1 , 3 , 3 , 1 ])\navg_pool_2d = keras . layers . AveragePooling2D ( pool_size = ( 2 , 2 ),\nstrides = ( 1 , 1 ), padding = \"same\" )\navg_pool_2d ( x )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . inception_v3 . decode_predictions ( preds , top = 5 )\ntf . keras . applications . inception_v3 . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/FeatureSpace",
    "content": "One-stop utility for preprocessing and encoding structured data.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . utils . FeatureSpace ( features , output_mode = 'concat' , crosses = None , crossing_dim = 32 , hashing_dim = 32 , num_discretization_bins = 32 , name = None )\ntf . keras . utils . FeatureSpace ( features , output_mode = 'concat' , crosses = None , crossing_dim = 32 , hashing_dim = 32 , num_discretization_bins = 32 , name = None )\nArguments\nArguments\nfeature_names Dict mapping the names of your features to their\ntype specification, e.g. {\"my_feature\": \"integer_categorical\"} or {\"my_feature\": FeatureSpace.integer_categorical()} .\nFor a complete list of all supported types, see\n\"Available feature types\" paragraph below. output_mode One of \"concat\" or \"dict\" . In concat mode, all\nfeatures get concatenated together into a single vector.\nIn dict mode, the FeatureSpace returns a dict of individually\nencoded features (with the same keys as the input dict keys). crosses List of features to be crossed together, e.g. crosses=[(\"feature_1\", \"feature_2\")] . The features will be\n\"crossed\" by hashing their combined value into\na fixed-length vector. crossing_dim Default vector size for hashing crossed features.\nDefaults to 32 . hashing_dim Default vector size for hashing features of type \"integer_hashed\" and \"string_hashed\" . Defaults to 32 . num_discretization_bins Default number of bins to be used for\ndiscretizing features of type \"float_discretized\" .\nDefaults to 32 .\nfeature_names\n{\"my_feature\": \"integer_categorical\"}\n{\"my_feature\": FeatureSpace.integer_categorical()}\noutput_mode\n\"concat\"\n\"dict\"\ncrosses\ncrosses=[(\"feature_1\", \"feature_2\")]\ncrossing_dim\n32\nhashing_dim\n\"integer_hashed\"\n\"string_hashed\"\n32\nnum_discretization_bins\n\"float_discretized\"\n32\nAvailable feature types:\nNote that all features can be referred to by their string name,\ne.g. \"integer_categorical\" . When using the string name, the default\nargument values are used.\n\"integer_categorical\"\n# Plain float values. FeatureSpace . float ( name = None ) # Float values to be preprocessed via featurewise standardization # (i.e. via a `keras.layers.Normalization` layer). FeatureSpace . float_normalized ( name = None ) # Float values to be preprocessed via linear rescaling # (i.e. via a `keras.layers.Rescaling` layer). FeatureSpace . float_rescaled ( scale = 1. , offset = 0. , name = None ) # Float values to be discretized. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . float_discretized ( num_bins , bin_boundaries = None , output_mode = \"one_hot\" , name = None ) # Integer values to be indexed. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . integer_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = \"one_hot\" , name = None ) # String values to be indexed. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . string_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = \"one_hot\" , name = None ) # Integer values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. FeatureSpace . integer_hashed ( num_bins , output_mode = \"one_hot\" , name = None ) # String values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. FeatureSpace . string_hashed ( num_bins , output_mode = \"one_hot\" , name = None )\n# Plain float values. FeatureSpace . float ( name = None ) # Float values to be preprocessed via featurewise standardization # (i.e. via a `keras.layers.Normalization` layer). FeatureSpace . float_normalized ( name = None ) # Float values to be preprocessed via linear rescaling # (i.e. via a `keras.layers.Rescaling` layer). FeatureSpace . float_rescaled ( scale = 1. , offset = 0. , name = None ) # Float values to be discretized. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . float_discretized ( num_bins , bin_boundaries = None , output_mode = \"one_hot\" , name = None ) # Integer values to be indexed. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . integer_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = \"one_hot\" , name = None ) # String values to be indexed. By default, the discrete # representation will then be one-hot encoded. FeatureSpace . string_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = \"one_hot\" , name = None ) # Integer values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. FeatureSpace . integer_hashed ( num_bins , output_mode = \"one_hot\" , name = None ) # String values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. FeatureSpace . string_hashed ( num_bins , output_mode = \"one_hot\" , name = None )\nBasic usage with a dict of input data:\nraw_data = { \"float_values\" : [ 0.0 , 0.1 , 0.2 , 0.3 ], \"string_values\" : [ \"zero\" , \"one\" , \"two\" , \"three\" ], \"int_values\" : [ 0 , 1 , 2 , 3 ], } dataset = tf . data . Dataset . from_tensor_slices ( raw_data ) feature_space = FeatureSpace ( features = { \"float_values\" : \"float_normalized\" , \"string_values\" : \"string_categorical\" , \"int_values\" : \"integer_categorical\" , }, crosses = [( \"string_values\" , \"int_values\" )], output_mode = \"concat\" , ) # Before you start using the FeatureSpace, # you must `adapt()` it on some data. feature_space . adapt ( dataset ) # You can call the FeatureSpace on a dict of data (batched or unbatched). output_vector = feature_space ( raw_data )\nraw_data = { \"float_values\" : [ 0.0 , 0.1 , 0.2 , 0.3 ], \"string_values\" : [ \"zero\" , \"one\" , \"two\" , \"three\" ], \"int_values\" : [ 0 , 1 , 2 , 3 ], } dataset = tf . data . Dataset . from_tensor_slices ( raw_data ) feature_space = FeatureSpace ( features = { \"float_values\" : \"float_normalized\" , \"string_values\" : \"string_categorical\" , \"int_values\" : \"integer_categorical\" , }, crosses = [( \"string_values\" , \"int_values\" )], output_mode = \"concat\" , ) # Before you start using the FeatureSpace, # you must `adapt()` it on some data. feature_space . adapt ( dataset ) # You can call the FeatureSpace on a dict of data (batched or unbatched). output_vector = feature_space ( raw_data )\nBasic usage with tf.data :\ntf.data\n# Unlabeled data preprocessed_ds = unlabeled_dataset . map ( feature_space ) # Labeled data preprocessed_ds = labeled_dataset . map ( lambda x , y : ( feature_space ( x ), y ))\n# Unlabeled data preprocessed_ds = unlabeled_dataset . map ( feature_space ) # Labeled data preprocessed_ds = labeled_dataset . map ( lambda x , y : ( feature_space ( x ), y ))\nBasic usage with the Keras Functional API:\n# Retrieve a dict Keras Input objects inputs = feature_space . get_inputs () # Retrieve the corresponding encoded Keras tensors encoded_features = feature_space . get_encoded_features () # Build a Functional model outputs = keras . layers . Dense ( 1 , activation = \"sigmoid\" )( encoded_features ) model = keras . Model ( inputs , outputs )\n# Retrieve a dict Keras Input objects inputs = feature_space . get_inputs () # Retrieve the corresponding encoded Keras tensors encoded_features = feature_space . get_encoded_features () # Build a Functional model outputs = keras . layers . Dense ( 1 , activation = \"sigmoid\" )( encoded_features ) model = keras . Model ( inputs , outputs )\nCustomizing each feature or feature cross:\nfeature_space = FeatureSpace ( features = { \"float_values\" : FeatureSpace . float_normalized (), \"string_values\" : FeatureSpace . string_categorical ( max_tokens = 10 ), \"int_values\" : FeatureSpace . integer_categorical ( max_tokens = 10 ), }, crosses = [ FeatureSpace . cross (( \"string_values\" , \"int_values\" ), crossing_dim = 32 ) ], output_mode = \"concat\" , )\nfeature_space = FeatureSpace ( features = { \"float_values\" : FeatureSpace . float_normalized (), \"string_values\" : FeatureSpace . string_categorical ( max_tokens = 10 ), \"int_values\" : FeatureSpace . integer_categorical ( max_tokens = 10 ), }, crosses = [ FeatureSpace . cross (( \"string_values\" , \"int_values\" ), crossing_dim = 32 ) ], output_mode = \"concat\" , )\nReturning a dict of integer-encoded features:\nfeature_space = FeatureSpace ( features = { \"string_values\" : FeatureSpace . string_categorical ( output_mode = \"int\" ), \"int_values\" : FeatureSpace . integer_categorical ( output_mode = \"int\" ), }, crosses = [ FeatureSpace . cross ( feature_names = ( \"string_values\" , \"int_values\" ), crossing_dim = 32 , output_mode = \"int\" , ) ], output_mode = \"dict\" , )\nfeature_space = FeatureSpace ( features = { \"string_values\" : FeatureSpace . string_categorical ( output_mode = \"int\" ), \"int_values\" : FeatureSpace . integer_categorical ( output_mode = \"int\" ), }, crosses = [ FeatureSpace . cross ( feature_names = ( \"string_values\" , \"int_values\" ), crossing_dim = 32 , output_mode = \"int\" , ) ], output_mode = \"dict\" , )\nSpecifying your own Keras preprocessing layer:\n# Let's say that one of the features is a short text paragraph that # we want to encode as a vector (one vector per paragraph) via TF-IDF. data = { \"text\" : [ \"1st string\" , \"2nd string\" , \"3rd string\" ], } # There's a Keras layer for this: TextVectorization. custom_layer = layers . TextVectorization ( output_mode = \"tf_idf\" ) # We can use FeatureSpace.feature to create a custom feature # that will use our preprocessing layer. feature_space = FeatureSpace ( features = { \"text\" : FeatureSpace . feature ( preprocessor = custom_layer , dtype = \"string\" , output_mode = \"float\" ), }, output_mode = \"concat\" , ) feature_space . adapt ( tf . data . Dataset . from_tensor_slices ( data )) output_vector = feature_space ( data )\n# Let's say that one of the features is a short text paragraph that # we want to encode as a vector (one vector per paragraph) via TF-IDF. data = { \"text\" : [ \"1st string\" , \"2nd string\" , \"3rd string\" ], } # There's a Keras layer for this: TextVectorization. custom_layer = layers . TextVectorization ( output_mode = \"tf_idf\" ) # We can use FeatureSpace.feature to create a custom feature # that will use our preprocessing layer. feature_space = FeatureSpace ( features = { \"text\" : FeatureSpace . feature ( preprocessor = custom_layer , dtype = \"string\" , output_mode = \"float\" ), }, output_mode = \"concat\" , ) feature_space . adapt ( tf . data . Dataset . from_tensor_slices ( data )) output_vector = feature_space ( data )\nRetrieving the underlying Keras preprocessing layers:\n# The preprocessing layer of each feature is available in `.preprocessors`. preprocessing_layer = feature_space . preprocessors [ \"feature1\" ] # The crossing layer of each feature cross is available in `.crossers`. # It's an instance of keras.layers.HashedCrossing. crossing_layer = feature_space . crossers [ \"feature1_X_feature2\" ]\n# The preprocessing layer of each feature is available in `.preprocessors`. preprocessing_layer = feature_space . preprocessors [ \"feature1\" ] # The crossing layer of each feature cross is available in `.crossers`. # It's an instance of keras.layers.HashedCrossing. crossing_layer = feature_space . crossers [ \"feature1_X_feature2\" ]\nSaving and reloading a FeatureSpace:\nfeature_space . save ( \"featurespace.keras\" ) reloaded_feature_space = keras . models . load_model ( \"featurespace.keras\" )\nfeature_space . save ( \"featurespace.keras\" ) reloaded_feature_space = keras . models . load_model ( \"featurespace.keras\" )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( dataset )\nadapt ( dataset )\ncross\ncross\nView source\n@classmethod cross ( feature_names , crossing_dim , output_mode = 'one_hot' )\n@classmethod\ncross ( feature_names , crossing_dim , output_mode = 'one_hot' )\nfeature\nfeature\nView source\n@classmethod feature ( dtype , preprocessor , output_mode )\n@classmethod\nfeature ( dtype , preprocessor , output_mode )\nfloat\nfloat\nView source\n@classmethod float ( name = None )\n@classmethod\nfloat ( name = None )\nfloat_discretized\nfloat_discretized\nView source\n@classmethod float_discretized ( num_bins , bin_boundaries = None , output_mode = 'one_hot' , name = None )\n@classmethod\nfloat_discretized ( num_bins , bin_boundaries = None , output_mode = 'one_hot' , name = None )\nfloat_normalized\nfloat_normalized\nView source\n@classmethod float_normalized ( name = None )\n@classmethod\nfloat_normalized ( name = None )\nfloat_rescaled\nfloat_rescaled\nView source\n@classmethod float_rescaled ( scale = 1.0 , offset = 0.0 , name = None )\n@classmethod\nfloat_rescaled ( scale = 1.0 , offset = 0.0 , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_encoded_features\nget_encoded_features\nView source\nget_encoded_features ()\nget_encoded_features ()\nget_inputs\nget_inputs\nView source\nget_inputs ()\nget_inputs ()\ninteger_categorical\ninteger_categorical\nView source\n@classmethod integer_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = 'one_hot' , name = None )\n@classmethod\ninteger_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = 'one_hot' , name = None )\ninteger_hashed\ninteger_hashed\nView source\n@classmethod integer_hashed ( num_bins , output_mode = 'one_hot' , name = None )\n@classmethod\ninteger_hashed ( num_bins , output_mode = 'one_hot' , name = None )\nsave\nsave\nView source\nsave ( filepath )\nsave ( filepath )\nSave the FeatureSpace instance to a .keras file.\nFeatureSpace\n.keras\nYou can reload it via keras.models.load_model() :\nkeras.models.load_model()\nfeature_space . save ( \"featurespace.keras\" ) reloaded_fs = keras . models . load_model ( \"featurespace.keras\" )\nfeature_space . save ( \"featurespace.keras\" ) reloaded_fs = keras . models . load_model ( \"featurespace.keras\" )\nstring_categorical\nstring_categorical\nView source\n@classmethod string_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = 'one_hot' , name = None )\n@classmethod\nstring_categorical ( max_tokens = None , num_oov_indices = 1 , output_mode = 'one_hot' , name = None )\nstring_hashed\nstring_hashed\nView source\n@classmethod string_hashed ( num_bins , output_mode = 'one_hot' , name = None )\n@classmethod\nstring_hashed ( num_bins , output_mode = 'one_hot' , name = None )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nEfficientNetB0(...) : Instantiates the EfficientNetB0 architecture.\nEfficientNetB0(...)\nEfficientNetB1(...) : Instantiates the EfficientNetB1 architecture.\nEfficientNetB1(...)\nEfficientNetB2(...) : Instantiates the EfficientNetB2 architecture.\nEfficientNetB2(...)\nEfficientNetB3(...) : Instantiates the EfficientNetB3 architecture.\nEfficientNetB3(...)\nEfficientNetB4(...) : Instantiates the EfficientNetB4 architecture.\nEfficientNetB4(...)\nEfficientNetB5(...) : Instantiates the EfficientNetB5 architecture.\nEfficientNetB5(...)\nEfficientNetB6(...) : Instantiates the EfficientNetB6 architecture.\nEfficientNetB6(...)\nEfficientNetB7(...) : Instantiates the EfficientNetB7 architecture.\nEfficientNetB7(...)\ndecode_predictions(...) : Decodes the prediction of an ImageNet model.\ndecode_predictions(...)\npreprocess_input(...) : A placeholder method for backward compatibility.\npreprocess_input(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/qr",
    "content": "Computes the QR decomposition of a tensor.\nMain aliases tf.keras.ops.linalg.qr\ntf.keras.ops.linalg.qr\ntf.keras.ops.linalg.qr\ntf . keras . ops . qr ( x , mode = 'reduced' )\ntf . keras . ops . qr ( x , mode = 'reduced' )\nArgs\nArgs\nx Input tensor of shape (..., M, N) . mode A string specifying the mode of the QR decomposition.\nx\n(..., M, N)\nmode\n'reduced': Returns the reduced QR decomposition. (default)\n'complete': Returns the complete QR decomposition.\nReturns A tuple containing two tensors. The first tensor of shape (..., M, K) is the orthogonal matrix q and the second tensor of shape (..., K, N) is the upper triangular matrix r , where K = min(M, N) .\nReturns\n(..., M, K)\nq\n(..., K, N)\nr\nK = min(M, N)\nx = keras . ops . convert_to_tensor ([[ 1. , 2. ], [ 3. , 4. ], [ 5. , 6. ]]) q , r = qr ( x ) print ( q ) array ([[ - 0.16903079 0.897085 ] [ - 0.5070925 0.2760267 ] [ - 0.8451542 - 0.34503305 ]], shape = ( 3 , 2 ), dtype = float32 )\nx = keras . ops . convert_to_tensor ([[ 1. , 2. ], [ 3. , 4. ], [ 5. , 6. ]])\nq , r = qr ( x )\nprint ( q )\narray ([[ - 0.16903079 0.897085 ]\n[ - 0.5070925 0.2760267 ]\n[ - 0.8451542 - 0.34503305 ]], shape = ( 3 , 2 ), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam",
    "content": "Optimizer that implements the Nadam algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Nadam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'nadam' , ** kwargs )\ntf . keras . optimizers . Nadam ( learning_rate = 0.001 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'nadam' , ** kwargs )\nMuch like Adam is essentially RMSprop with momentum, Nadam is Adam with\nNesterov momentum.\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_1 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 1st moment estimates.\nDefaults to 0.9 . beta_2 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 2nd moment estimates. Defaults to 0.999 . epsilon A small constant for numerical stability. This epsilon is\n\"epsilon hat\" in the Kingma and Ba paper (in the formula just before\nSection 2.1), not the epsilon in Algorithm 1 of the paper.\nDefaults to 1e-7 . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_1\n0.9\nbeta_2\n0.999\nepsilon\n1e-7\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nDozat, 2015 .\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nNadam optimizer has 2 types of variables: momentums and velocities.\nArgs\nvar_list list of model variables to build Nadam variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/MaxNorm",
    "content": "MaxNorm weight constraint.\nInherits From: Constraint\nConstraint\nMain aliases tf.keras.constraints.max_norm\ntf.keras.constraints.max_norm\ntf.keras.constraints.max_norm\ntf . keras . constraints . MaxNorm ( max_value = 2 , axis = 0 )\ntf . keras . constraints . MaxNorm ( max_value = 2 , axis = 0 )\nConstrains the weights incident to each hidden unit\nto have a norm less than or equal to a desired value.\nAlso available via the shortcut function keras.constraints.max_norm .\nkeras.constraints.max_norm\nArgs\nArgs\nmax_value the maximum norm value for the incoming weights. axis integer, axis along which to calculate weight norms.\nFor instance, in a Dense layer the weight matrix\nhas shape (input_dim, output_dim) ,\nset axis to 0 to constrain each weight vector\nof length (input_dim,) .\nIn a Conv2D layer with data_format=\"channels_last\" ,\nthe weight tensor has shape (rows, cols, input_depth, output_depth) ,\nset axis to [0, 1, 2] to constrain the weights of each filter tensor of size (rows, cols, input_depth) .\nmax_value\naxis\nDense\n(input_dim, output_dim)\naxis\n0\n(input_dim,)\nConv2D\ndata_format=\"channels_last\"\n(rows, cols, input_depth, output_depth)\naxis\n[0, 1, 2]\n(rows, cols, input_depth)\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates a weight constraint from a configuration dictionary.\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nconstraint = UnitNorm () config = constraint . get_config () constraint = UnitNorm . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns A keras.constraints.Constraint instance.\nkeras.constraints.Constraint\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns a Python dict of the object config.\nA constraint config is a Python dictionary (JSON-serializable) that can\nbe used to reinstantiate the same object.\nReturns Python dict containing the configuration of the constraint object.\n__call__\n__call__\nView source\n__call__ ( w )\n__call__ ( w )\nApplies the constraint to the input weight variable.\nBy default, the inputs weight variable is not modified.\nUsers should override this method to implement their own projection\nfunction.\nArgs\nw Input weight variable.\nw\nReturns Projected variable (by default, returns unmodified inputs)."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/dtype_policies",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass DTypePolicy : A dtype policy for a Keras layer.\nclass DTypePolicy\nclass FloatDTypePolicy : A dtype policy for a Keras layer.\nclass FloatDTypePolicy\nclass QuantizedDTypePolicy : A dtype policy for a Keras layer.\nclass QuantizedDTypePolicy\nclass QuantizedFloat8DTypePolicy : A dtype policy for a Keras layer.\nclass QuantizedFloat8DTypePolicy\nFunctions\ndeserialize(...) : Deserializes a serialized DTypePolicy instance.\ndeserialize(...)\nDTypePolicy\nget(...) : Retrieves a Keras DTypePolicy instance.\nget(...)\nDTypePolicy\nserialize(...) : Serializes DTypePolicy instance.\nserialize(...)\nDTypePolicy"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/log_softmax",
    "content": "Log-Softmax activation function.\ntf . keras . activations . log_softmax ( x , axis =- 1 )\ntf . keras . activations . log_softmax ( x , axis =- 1 )\nEach input vector is handled independently.\nThe axis argument sets which axis of the input the function\nis applied along.\naxis\nArgs\nArgs\nx Input tensor. axis Integer, axis along which the softmax is applied.\nx\naxis"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB3",
    "content": "Instantiates the EfficientNetB3 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB3\ntf.keras.applications.efficientnet.EfficientNetB3\ntf.keras.applications.efficientnet.EfficientNetB3\ntf . keras . applications . EfficientNetB3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB3 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/gelu",
    "content": "Gaussian Error Linear Unit (GELU) activation function.\nMain aliases tf.keras.ops.nn.gelu\ntf.keras.ops.nn.gelu\ntf.keras.ops.nn.gelu\ntf . keras . ops . gelu ( x , approximate = True )\ntf . keras . ops . gelu ( x , approximate = True )\nIf approximate is True , it is defined as: f(x) = 0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3)))\napproximate\nTrue\nf(x) = 0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3)))\nOr if approximate is False , it is defined as: f(x) = x * P(X <= x) = 0.5 * x * (1 + erf(x / sqrt(2))) ,\nwhere P(X) ~ N(0, 1) .\napproximate\nFalse\nf(x) = x * P(X <= x) = 0.5 * x * (1 + erf(x / sqrt(2)))\nP(X) ~ N(0, 1)\nArgs\nArgs\nx Input tensor. approximate Approximate version of GELU activation. Defaults to True .\nx\napproximate\nTrue\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_gelu = keras . ops . gelu ( x ) print ( x_gelu ) array ([ - 0.15865525 , 0. , 0.84134475 ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_gelu = keras . ops . gelu ( x )\nprint ( x_gelu )\narray ([ - 0.15865525 , 0. , 0.84134475 ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/greater",
    "content": "Return the truth value of x1 > x2 element-wise.\nx1 > x2\nMain aliases tf.keras.ops.numpy.greater\ntf.keras.ops.numpy.greater\ntf.keras.ops.numpy.greater\ntf . keras . ops . greater ( x1 , x2 )\ntf . keras . ops . greater ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise comparison of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/quantile",
    "content": "Compute the q-th quantile(s) of the data along the specified axis.\nMain aliases tf.keras.ops.numpy.quantile\ntf.keras.ops.numpy.quantile\ntf.keras.ops.numpy.quantile\ntf . keras . ops . quantile ( x , q , axis = None , method = 'linear' , keepdims = False )\ntf . keras . ops . quantile ( x , q , axis = None , method = 'linear' , keepdims = False )\nArgs\nArgs\nx Input tensor. q Probability or sequence of probabilities for the quantiles to\ncompute. Values must be between 0 and 1 inclusive. axis Axis or axes along which the quantiles are computed. Defaults to axis=None which is to compute the quantile(s) along a flattened\nversion of the array. method A string specifies the method to use for estimating the\nquantile. Available methods are \"linear\" , \"lower\" , \"higher\" , \"midpoint\" , and \"nearest\" . Defaults to \"linear\" .\nIf the desired quantile lies between two data points i < j :\nx\nq\naxis\naxis=None\nmethod\n\"linear\"\n\"lower\"\n\"higher\"\n\"midpoint\"\n\"nearest\"\n\"linear\"\ni < j\n\"linear\" : i + (j - i) * fraction , where fraction is the\nfractional part of the index surrounded by i and j .\n\"linear\"\ni + (j - i) * fraction\ni\nj\n\"lower\" : i .\n\"lower\"\ni\n\"higher\" : j .\n\"higher\"\nj\n\"midpoint\" : (i + j) / 2\n\"midpoint\"\n(i + j) / 2\n\"nearest\" : i or j , whichever is nearest. keepdims If this is set to True , the axes which are reduce\nare left in the result as dimensions with size one.\n\"nearest\"\ni\nj\nkeepdims\nTrue\nReturns The quantile(s). If q is a single probability and axis=None , then\nthe result is a scalar. If multiple probabilies levels are given, first\naxis of the result corresponds to the quantiles. The other axes are the\naxes that remain after the reduction of x .\nReturns\nq\naxis=None\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/DataParallel",
    "content": "Distribution for data parallelism.\ntf . keras . distribution . DataParallel ( device_mesh = None , devices = None )\ntf . keras . distribution . DataParallel ( device_mesh = None , devices = None )\nYou can choose to create this instance by either specifying\nthe device_mesh or devices arguments (but not both).\ndevice_mesh\ndevices\nThe device_mesh argument is expected to be a DeviceMesh instance,\nand is expected to be 1D only. In case that the mesh has multiple axes,\nthen the first axis will be treated as the data parallel dimension\n(and a warning will be raised).\ndevice_mesh\nDeviceMesh\nWhen a list of devices are provided, they will be used to construct a\n1D mesh.\ndevices\nWhen both mesh and devices are absent, then list_devices() will be used to detect any available devices and create a 1D mesh from\nthem.\nmesh\ndevices\nlist_devices()\nArgs\nArgs\ndevice_mesh Optional DeviceMesh instance. devices Optional list of devices.\ndevice_mesh\nDeviceMesh\ndevices\nAttributes\nAttributes\ndevice_mesh\ndevice_mesh\nMethods\ndistribute_dataset\ndistribute_dataset\nView source\ndistribute_dataset ( dataset )\ndistribute_dataset ( dataset )\nCreate a distributed dataset instance from the original user dataset.\nArgs\ndataset the original global dataset instance. Only tf.data.Dataset is supported at the moment.\ndataset\ntf.data.Dataset\nReturns a sharded tf.data.Dataset instance, which will produce data for\nthe current local worker/process.\ntf.data.Dataset\nget_data_layout\nget_data_layout\nView source\nget_data_layout ( data_shape )\nget_data_layout ( data_shape )\nRetrieve the TensorLayout for the input data.\nTensorLayout\nArgs\ndata_shape shape for the input data in list or tuple format.\ndata_shape\nReturns The TensorLayout for the data, which can be used by backend.distribute_value() to redistribute a input data.\nTensorLayout\nbackend.distribute_value()\nget_tensor_layout\nget_tensor_layout\nView source\nget_tensor_layout ( path )\nget_tensor_layout ( path )\nRetrieve the TensorLayout for the intermediate tensor.\nTensorLayout\nArgs\npath a string path for the corresponding tensor.\npath\nreturn:\n    The TensorLayout for the intermediate tensor, which can be used\n    by backend.relayout() to reshard the tensor. Could also return\n    None.\nTensorLayout\nbackend.relayout()\nget_variable_layout\nget_variable_layout\nView source\nget_variable_layout ( variable )\nget_variable_layout ( variable )\nRetrieve the TensorLayout for the variable.\nTensorLayout\nArgs\nvariable A KerasVariable instance.\nvariable\nKerasVariable\nreturn:\n    The TensorLayout for the variable, which can be used by backend.distribute_value() to redistribute a variable.\nTensorLayout\nbackend.distribute_value()\nscope\nscope\nView source\n@contextlib . contextmanager scope ()\n@contextlib . contextmanager\nscope ()\nContext manager to make the Distribution current.\nDistribution"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass L1 : A regularizer that applies a L1 regularization penalty.\nclass L1\nclass L1L2 : A regularizer that applies both L1 and L2 regularization penalties.\nclass L1L2\nclass L2 : A regularizer that applies a L2 regularization penalty.\nclass L2\nclass OrthogonalRegularizer : Regularizer that encourages input vectors to be orthogonal to each other.\nclass OrthogonalRegularizer\nclass Regularizer : Regularizer base class.\nclass Regularizer\nclass l1 : A regularizer that applies a L1 regularization penalty.\nclass l1\nclass l1_l2 : A regularizer that applies both L1 and L2 regularization penalties.\nclass l1_l2\nclass l2 : A regularizer that applies a L2 regularization penalty.\nclass l2\nclass orthogonal_regularizer : Regularizer that encourages input vectors to be orthogonal to each other.\nclass orthogonal_regularizer\nFunctions\ndeserialize(...) : Return a Keras regularizer object via its config.\ndeserialize(...)\nget(...) : Retrieve a Keras regularizer object via an identifier.\nget(...)\nserialize(...)\nserialize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arcsin",
    "content": "Inverse sine, element-wise.\nMain aliases tf.keras.ops.numpy.arcsin\ntf.keras.ops.numpy.arcsin\ntf.keras.ops.numpy.arcsin\ntf . keras . ops . arcsin ( x )\ntf . keras . ops . arcsin ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Tensor of the inverse sine of each element in x , in radians and in\nthe closed interval [-pi/2, pi/2] .\nReturns\nx\n[-pi/2, pi/2]\nx = keras . ops . convert_to_tensor ([ 1 , - 1 , 0 ]) keras . ops . arcsin ( x ) array ([ 1.5707964 , - 1.5707964 , 0. ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 1 , - 1 , 0 ])\nkeras . ops . arcsin ( x )\narray ([ 1.5707964 , - 1.5707964 , 0. ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/is_float_dtype",
    "content": "tf . keras . backend . is_float_dtype ( dtype )\ntf . keras . backend . is_float_dtype ( dtype )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/InputSpec",
    "content": "Specifies the rank, dtype and shape of every input to a layer.\nMain aliases tf.keras.layers.InputSpec Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.InputSpec\ntf.keras.layers.InputSpec\ntf.keras.layers.InputSpec\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.InputSpec\ntf.compat.v1.keras.InputSpec\ntf . keras . InputSpec ( dtype = None , shape = None , ndim = None , max_ndim = None , min_ndim = None , axes = None , allow_last_axis_squeeze = False , name = None )\ntf . keras . InputSpec ( dtype = None , shape = None , ndim = None , max_ndim = None , min_ndim = None , axes = None , allow_last_axis_squeeze = False , name = None )\nLayers can expose (if appropriate) an input_spec attribute:\nan instance of InputSpec , or a nested structure of InputSpec instances\n(one per input tensor). These objects enable the layer to run input\ncompatibility checks for input structure, input rank, input shape, and\ninput dtype for the first argument of Layer. call .\ninput_spec\nInputSpec\nInputSpec\nLayer. call\nA None entry in a shape is compatible with any dimension.\nNone\nArgs\nArgs\ndtype Expected dtype of the input. shape Shape tuple, expected shape of the input\n(may include None for dynamic axes).\nIncludes the batch size. ndim Integer, expected rank of the input. max_ndim Integer, maximum rank of the input. min_ndim Integer, minimum rank of the input. axes Dictionary mapping integer axes to\na specific dimension value. allow_last_axis_squeeze If True , allow inputs of rank N+1 as long\nas the last axis of the input is 1, as well as inputs of rank N-1\nas long as the last axis of the spec is 1. name Expected key corresponding to this input when passing data as\na dictionary.\ndtype\nshape\nNone\nndim\nmax_ndim\nmin_ndim\naxes\nallow_last_axis_squeeze\nTrue\nname\nclass MyLayer ( Layer ): def __init__ ( self ): super () . __init__ () # The layer will accept inputs with # shape (*, 28, 28) & (*, 28, 28, 1) # and raise an appropriate error message otherwise. self . input_spec = InputSpec ( shape = ( None , 28 , 28 , 1 ), allow_last_axis_squeeze = True )\nclass MyLayer ( Layer ): def __init__ ( self ): super () . __init__ () # The layer will accept inputs with # shape (*, 28, 28) & (*, 28, 28, 1) # and raise an appropriate error message otherwise. self . input_spec = InputSpec ( shape = ( None , 28 , 28 , 1 ), allow_last_axis_squeeze = True )\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB6",
    "content": "Instantiates the EfficientNetB6 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB6\ntf.keras.applications.efficientnet.EfficientNetB6\ntf.keras.applications.efficientnet.EfficientNetB6\ntf . keras . applications . EfficientNetB6 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB6 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/softmax",
    "content": "DEPRECATED.\ntf . keras . backend . softmax ( x , axis =- 1 )\ntf . keras . backend . softmax ( x , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling",
    "content": "A preprocessing layer which rescales input values to a new range.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Rescaling ( scale , offset = 0.0 , ** kwargs )\ntf . keras . layers . Rescaling ( scale , offset = 0.0 , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nImage classification\nLoad and preprocess images\nData augmentation\nTransfer learning and fine-tuning\nTransfer learning with TensorFlow Hub\nThis layer rescales every value of an input (often an image) by multiplying\nby scale and adding offset .\nscale\noffset\nTo rescale an input in the [0, 255] range\nto be in the [0, 1] range, you would pass scale=1./255 .\nTo rescale an input in the [0, 255] range\nto be in the [0, 1] range, you would pass scale=1./255 .\n[0, 255]\n[0, 1]\nscale=1./255\nTo rescale an input in the [0, 255] range to be in the [-1, 1] range,\nyou would pass scale=1./127.5, offset=-1 .\nTo rescale an input in the [0, 255] range to be in the [-1, 1] range,\nyou would pass scale=1./127.5, offset=-1 .\n[0, 255]\n[-1, 1]\nscale=1./127.5, offset=-1\nThe rescaling is applied both during training and inference. Inputs can be\nof integer or floating point dtype, and by default the layer will output\nfloats.\ntf.data\nArgs\nArgs\nscale Float, the scale to apply to the inputs. offset Float, the offset to apply to the inputs. **kwargs Base layer keyword arguments, such as name and dtype .\nscale\noffset\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/floatx",
    "content": "Return the default float type, as a string.\nMain aliases tf.keras.config.floatx\ntf.keras.config.floatx\ntf.keras.config.floatx\ntf . keras . backend . floatx ()\ntf . keras . backend . floatx ()\nE.g. 'bfloat16' , 'float16' , 'float32' , 'float64' .\n'bfloat16'\n'float16'\n'float32'\n'float64'\nReturns String, the current default float type.\nReturns\nkeras . config . floatx () 'float32'\nkeras . config . floatx ()\n'float32'"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/SeedGenerator",
    "content": "Generates variable seeds upon each call to a RNG-using function.\ntf . keras . random . SeedGenerator ( seed = None , name = None , ** kwargs )\ntf . keras . random . SeedGenerator ( seed = None , name = None , ** kwargs )\nIn Keras, all RNG-using methods (such as keras.random.normal() )\nare stateless, meaning that if you pass an integer seed to them\n(such as seed=42 ), they will return the same values at each call.\nIn order to get different values at each call, you must use a SeedGenerator instead as the seed argument. The SeedGenerator object is stateful.\nkeras.random.normal()\nseed=42\nSeedGenerator\nSeedGenerator\nseed_gen = keras . random . SeedGenerator ( seed = 42 ) values = keras . random . normal ( shape = ( 2 , 3 ), seed = seed_gen ) new_values = keras . random . normal ( shape = ( 2 , 3 ), seed = seed_gen )\nseed_gen = keras . random . SeedGenerator ( seed = 42 ) values = keras . random . normal ( shape = ( 2 , 3 ), seed = seed_gen ) new_values = keras . random . normal ( shape = ( 2 , 3 ), seed = seed_gen )\nclass Dropout ( keras . Layer ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) self . seed_generator = keras . random . SeedGenerator ( 1337 ) def call ( self , x , training = False ): if training : return keras . random . dropout ( x , rate = 0.5 , seed = self . seed_generator ) return x\nclass Dropout ( keras . Layer ): def __init__ ( self , ** kwargs ): super () . __init__ ( ** kwargs ) self . seed_generator = keras . random . SeedGenerator ( 1337 ) def call ( self , x , training = False ): if training : return keras . random . dropout ( x , rate = 0.5 , seed = self . seed_generator ) return x\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nnext\nnext\nView source\nnext ( ordered = True )\nnext ( ordered = True )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/amin",
    "content": "Returns the minimum of an array or minimum value along an axis.\nMain aliases tf.keras.ops.numpy.amin\ntf.keras.ops.numpy.amin\ntf.keras.ops.numpy.amin\ntf . keras . ops . amin ( x , axis = None , keepdims = False )\ntf . keras . ops . amin ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis Axis along which to compute the minimum.\nBy default ( axis=None ), find the minimum value in all the\ndimensions of the input array. keepdims If True , axes which are reduced are left in the result as\ndimensions that are broadcast to the size of the original\ninput tensor. Defaults to False .\nx\naxis\naxis=None\nkeepdims\nTrue\nFalse\nReturns An array with the minimum value. If axis=None , the result is a scalar\nvalue representing the minimum element in the entire array. If axis is\ngiven, the result is an array with the minimum values along\nthe specified axis.\nReturns\naxis=None\naxis\nx = keras . ops . convert_to_tensor ([ 1 , 3 , 5 , 2 , 3 , 6 ]) keras . ops . amin ( x ) array ( 1 , dtype = int32 )\nx = keras . ops . convert_to_tensor ([ 1 , 3 , 5 , 2 , 3 , 6 ])\nkeras . ops . amin ( x )\narray ( 1 , dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 7 , 5 , 3 ]]) keras . ops . amin ( x , axis = 0 ) array ([ 1 , 5 , 3 ], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 7 , 5 , 3 ]])\nkeras . ops . amin ( x , axis = 0 )\narray ([ 1 , 5 , 3 ], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 7 , 5 , 3 ]]) keras . ops . amin ( x , axis = 1 , keepdims = True ) array ([[ 1 ],[ 3 ]], dtype = int32 )\nx = keras . ops . convert_to_tensor ([[ 1 , 6 , 8 ], [ 7 , 5 , 3 ]])\nkeras . ops . amin ( x , axis = 1 , keepdims = True )\narray ([[ 1 ],[ 3 ]], dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization",
    "content": "A preprocessing layer which maps text features to integer sequences.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . TextVectorization ( max_tokens = None , standardize = 'lower_and_strip_punctuation' , split = 'whitespace' , ngrams = None , output_mode = 'int' , output_sequence_length = None , pad_to_max_tokens = False , vocabulary = None , idf_weights = None , sparse = False , ragged = False , encoding = 'utf-8' , name = None , ** kwargs )\ntf . keras . layers . TextVectorization ( max_tokens = None , standardize = 'lower_and_strip_punctuation' , split = 'whitespace' , ngrams = None , output_mode = 'int' , output_sequence_length = None , pad_to_max_tokens = False , vocabulary = None , idf_weights = None , sparse = False , ragged = False , encoding = 'utf-8' , name = None , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nLoad text\nDistributed training with DTensors\nBasic text classification\nUsing side features: feature preprocessing\nNeural machine translation with attention\nThis layer has basic options for managing text in a Keras model. It\ntransforms a batch of strings (one example = one string) into either a list\nof token indices (one example = 1D tensor of integer token indices) or a\ndense representation (one example = 1D tensor of float values representing\ndata about the example's tokens). This layer is meant to handle natural\nlanguage inputs. To handle simple string inputs (categorical strings or\npre-tokenized strings) see kers_core.layers.StringLookup .\nkers_core.layers.StringLookup\nThe vocabulary for the layer must be either supplied on construction or\nlearned via adapt() . When this layer is adapted, it will analyze the\ndataset, determine the frequency of individual string values, and create a\nvocabulary from them. This vocabulary can have unlimited size or be capped,\ndepending on the configuration options for this layer; if there are more\nunique values in the input than the maximum vocabulary size, the most\nfrequent terms will be used to create the vocabulary.\nadapt()\nThe processing of each example contains the following steps:\nStandardize each example (usually lowercasing + punctuation stripping)\nSplit each example into substrings (usually words)\nRecombine substrings into tokens (usually ngrams)\nIndex tokens (associate a unique int value with each token)\nTransform each example using this index, either into a vector of ints or\na dense float vector.\nSome notes on passing callables to customize splitting and normalization for\nthis layer:\nAny callable can be passed to this Layer, but if you want to serialize\nthis object you should only pass functions that are registered Keras\nserializables (see keras.saving.register_keras_serializable for more details).\nkeras.saving.register_keras_serializable\nWhen using a custom callable for standardize , the data received\nby the callable will be exactly as passed to this layer. The callable\nshould return a tensor of the same shape as the input.\nstandardize\nWhen using a custom callable for split , the data received by the\ncallable will have the 1st dimension squeezed out - instead of [[\"string to split\"], [\"another string to split\"]] , the Callable will\nsee [\"string to split\", \"another string to split\"] .\nThe callable should return a tf.Tensor of dtype string with the first dimension containing the split tokens -\nin this example, we should see something like [[\"string\", \"to\",\n\"split\"], [\"another\", \"string\", \"to\", \"split\"]] .\nsplit\n[[\"string to split\"], [\"another string to split\"]]\n[\"string to split\", \"another string to split\"]\ntf.Tensor\nstring\n[[\"string\", \"to\",\n\"split\"], [\"another\", \"string\", \"to\", \"split\"]]\ntf.data\nArgs\nArgs\nmax_tokens Maximum size of the vocabulary for this layer. This should\nonly be specified when adapting a vocabulary or when setting pad_to_max_tokens=True . Note that this vocabulary\ncontains 1 OOV token, so the effective number of tokens is (max_tokens - 1 - (1 if output_mode == \"int\" else 0)) . standardize Optional specification for standardization to apply to the\ninput text. Values can be:\nmax_tokens\npad_to_max_tokens=True\n(max_tokens - 1 - (1 if output_mode == \"int\" else 0))\nstandardize\nNone : No standardization.\nNone\n\"lower_and_strip_punctuation\" : Text will be lowercased and all\npunctuation removed.\n\"lower_and_strip_punctuation\"\n\"lower\" : Text will be lowercased.\n\"lower\"\n\"strip_punctuation\" : All punctuation will be removed.\n\"strip_punctuation\"\nCallable: Inputs will passed to the callable function,\nwhich should be standardized and returned. split Optional specification for splitting the input text.\nValues can be:\nsplit\nNone : No splitting.\nNone\n\"whitespace\" : Split on whitespace.\n\"whitespace\"\n\"character\" : Split on each unicode character.\n\"character\"\nCallable: Standardized inputs will passed to the callable\nfunction, which should be split and returned. ngrams Optional specification for ngrams to create from the\npossibly-split input text. Values can be None , an integer\nor tuple of integers; passing an integer will create ngrams\nup to that integer, and passing a tuple of integers will\ncreate ngrams for the specified values in the tuple.\nPassing None means that no ngrams will be created. output_mode Optional specification for the output of the layer.\nValues can be \"int\" , \"multi_hot\" , \"count\" or \"tf_idf\" ,\nconfiguring the layer as follows:\nngrams\nNone\nNone\noutput_mode\n\"int\"\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\n\"int\" : Outputs integer indices, one integer index per split\nstring token. When output_mode == \"int\" ,\n0 is reserved for masked locations;\nthis reduces the vocab size to max_tokens - 2 instead of max_tokens - 1 .\n\"int\"\noutput_mode == \"int\"\nmax_tokens - 2\nmax_tokens - 1\n\"multi_hot\" : Outputs a single int array per batch, of either\nvocab_size or max_tokens size, containing 1s in all elements\nwhere the token mapped to that index exists at least\nonce in the batch item.\n\"multi_hot\"\n\"count\" : Like \"multi_hot\" , but the int array contains\na count of the number of times the token at that index\nappeared in the batch item.\n\"count\"\n\"multi_hot\"\n\"tf_idf\" : Like \"multi_hot\" , but the TF-IDF algorithm\nis applied to find the value in each token slot.\nFor \"int\" output, any shape of input and output is supported.\nFor all other output modes, currently only rank 1 inputs\n(and rank 2 outputs after splitting) are supported. output_sequence_length Only valid in INT mode. If set, the output will\nhave its time dimension padded or truncated to exactly output_sequence_length values, resulting in a tensor of shape (batch_size, output_sequence_length) regardless of how many tokens\nresulted from the splitting step. Defaults to None . If ragged is True then output_sequence_length may still truncate the\noutput. pad_to_max_tokens Only valid in \"multi_hot\" , \"count\" ,\nand \"tf_idf\" modes. If True , the output will have\nits feature axis padded to max_tokens even if the number\nof unique tokens in the vocabulary is less than max_tokens ,\nresulting in a tensor of shape (batch_size, max_tokens) regardless of vocabulary size. Defaults to False . vocabulary Optional. Either an array of strings or a string path to a\ntext file. If passing an array, can pass a tuple, list,\n1D NumPy array, or 1D tensor containing the string vocabulary terms.\nIf passing a file path, the file should contain one line per term\nin the vocabulary. If this argument is set,\nthere is no need to adapt() the layer. idf_weights Only valid when output_mode is \"tf_idf\" . A tuple, list,\n1D NumPy array, or 1D tensor of the same length as the vocabulary,\ncontaining the floating point inverse document frequency weights,\nwhich will be multiplied by per sample term counts for\nthe final tf_idf weight. If the vocabulary argument is set,\nand output_mode is \"tf_idf\" , this argument must be supplied. ragged Boolean. Only applicable to \"int\" output mode.\nOnly supported with TensorFlow backend.\nIf True , returns a RaggedTensor instead of a dense Tensor ,\nwhere each sequence may have a different length\nafter string splitting. Defaults to False . sparse Boolean. Only applicable to \"multi_hot\" , \"count\" , and \"tf_idf\" output modes. Only supported with TensorFlow\nbackend. If True , returns a SparseTensor instead of a dense Tensor . Defaults to False . encoding Optional. The text encoding to use to interpret the input\nstrings. Defaults to \"utf-8\" .\n\"tf_idf\"\n\"multi_hot\"\n\"int\"\noutput_sequence_length\noutput_sequence_length\n(batch_size, output_sequence_length)\nNone\nragged\nTrue\noutput_sequence_length\npad_to_max_tokens\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nmax_tokens\nmax_tokens\n(batch_size, max_tokens)\nFalse\nvocabulary\nadapt()\nidf_weights\noutput_mode\n\"tf_idf\"\ntf_idf\nvocabulary\noutput_mode\n\"tf_idf\"\nragged\n\"int\"\nTrue\nRaggedTensor\nTensor\nFalse\nsparse\n\"multi_hot\"\n\"count\"\n\"tf_idf\"\nTrue\nSparseTensor\nTensor\nFalse\nencoding\n\"utf-8\"\nThis example instantiates a TextVectorization layer that lowercases text,\nsplits on whitespace, strips punctuation, and outputs integer vocab indices.\nTextVectorization\nmax_tokens = 5000 # Maximum vocab size. max_len = 4 # Sequence length to pad the outputs to. # Create the layer. vectorize_layer = TextVectorization ( max_tokens = max_tokens , output_mode = 'int' , output_sequence_length = max_len )\nmax_tokens = 5000 # Maximum vocab size.\nmax_len = 4 # Sequence length to pad the outputs to.\n# Create the layer.\nvectorize_layer = TextVectorization (\nmax_tokens = max_tokens ,\noutput_mode = 'int' ,\noutput_sequence_length = max_len )\n# Now that the vocab layer has been created, call `adapt` on the # list of strings to create the vocabulary. vectorize_layer . adapt ([ \"foo bar\" , \"bar baz\" , \"baz bada boom\" ])\n# Now that the vocab layer has been created, call `adapt` on the\n# list of strings to create the vocabulary.\nvectorize_layer . adapt ([ \"foo bar\" , \"bar baz\" , \"baz bada boom\" ])\n# Now, the layer can map strings to integers -- you can use an # embedding layer to map these integers to learned embeddings. input_data = [[ \"foo qux bar\" ], [ \"qux baz\" ]] vectorize_layer ( input_data ) array ([[ 4 , 1 , 3 , 0 ], [ 1 , 2 , 0 , 0 ]])\n# Now, the layer can map strings to integers -- you can use an\n# embedding layer to map these integers to learned embeddings.\ninput_data = [[ \"foo qux bar\" ], [ \"qux baz\" ]]\nvectorize_layer ( input_data )\narray ([[ 4 , 1 , 3 , 0 ],\n[ 1 , 2 , 0 , 0 ]])\nThis example instantiates a TextVectorization layer by passing a list\nof vocabulary terms to the layer's __init__() method.\nTextVectorization\n__init__()\nvocab_data = [ \"earth\" , \"wind\" , \"and\" , \"fire\" ] max_len = 4 # Sequence length to pad the outputs to. # Create the layer, passing the vocab directly. You can also pass the # vocabulary arg a path to a file containing one vocabulary word per # line. vectorize_layer = keras . layers . TextVectorization ( max_tokens = max_tokens , output_mode = 'int' , output_sequence_length = max_len , vocabulary = vocab_data )\nvocab_data = [ \"earth\" , \"wind\" , \"and\" , \"fire\" ]\nmax_len = 4 # Sequence length to pad the outputs to.\n# Create the layer, passing the vocab directly. You can also pass the\n# vocabulary arg a path to a file containing one vocabulary word per\n# line.\nvectorize_layer = keras . layers . TextVectorization (\nmax_tokens = max_tokens ,\noutput_mode = 'int' ,\noutput_sequence_length = max_len ,\nvocabulary = vocab_data )\n# Because we've passed the vocabulary directly, we don't need to adapt # the layer - the vocabulary is already set. The vocabulary contains the # padding token ('') and OOV token ('[UNK]') # as well as the passed tokens. vectorize_layer . get_vocabulary () [ '' , '[UNK]' , 'earth' , 'wind' , 'and' , 'fire' ]\n# Because we've passed the vocabulary directly, we don't need to adapt\n# the layer - the vocabulary is already set. The vocabulary contains the\n# padding token ('') and OOV token ('[UNK]')\n# as well as the passed tokens.\nvectorize_layer . get_vocabulary ()\n[ '' , '[UNK]' , 'earth' , 'wind' , 'and' , 'fire' ]\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nadapt\nadapt\nView source\nadapt ( data , batch_size = None , steps = None )\nadapt ( data , batch_size = None , steps = None )\nComputes a vocabulary of string terms from tokens in a dataset.\nCalling adapt() on a TextVectorization layer is an alternative to\npassing in a precomputed vocabulary on construction via the vocabulary argument. A TextVectorization layer should always be either adapted\nover a dataset or supplied with a vocabulary.\nadapt()\nTextVectorization\nvocabulary\nTextVectorization\nDuring adapt() , the layer will build a vocabulary of all string tokens\nseen in the dataset, sorted by occurrence count, with ties broken by\nsort order of the tokens (high to low). At the end of adapt() , if max_tokens is set, the vocabulary will be truncated to max_tokens size. For example, adapting a layer with max_tokens=1000 will compute\nthe 1000 most frequent tokens occurring in the input dataset. If output_mode='tf-idf' , adapt() will also learn the document\nfrequencies of each token in the input dataset.\nadapt()\nadapt()\nmax_tokens\nmax_tokens\nmax_tokens=1000\noutput_mode='tf-idf'\nadapt()\nArguments\ndata The data to train on. It can be passed either as a\nbatched tf.data.Dataset , as a list of strings,\nor as a NumPy array. steps Integer or None .\nTotal number of steps (batches of samples) to process.\nIf data is a tf.data.Dataset , and steps is None , adapt() will run until the input dataset is exhausted.\nWhen passing an infinitely\nrepeating dataset, you must specify the steps argument. This\nargument is not supported with array inputs or list inputs.\ndata\ntf.data.Dataset\nsteps\nNone\ndata\ntf.data.Dataset\nsteps\nNone\nadapt()\nsteps\nfinalize_state\nfinalize_state\nView source\nfinalize_state ()\nfinalize_state ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_vocabulary\nget_vocabulary\nView source\nget_vocabulary ( include_special_tokens = True )\nget_vocabulary ( include_special_tokens = True )\nReturns the current vocabulary of the layer.\nArgs\ninclude_special_tokens If True , the returned vocabulary\nwill include the padding and OOV tokens,\nand a term's index in the vocabulary will equal\nthe term's index when calling the layer. If False , the\nreturned vocabulary will not include any padding\nor OOV tokens.\ninclude_special_tokens\nTrue\nFalse\nload_assets\nload_assets\nView source\nload_assets ( dir_path )\nload_assets ( dir_path )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nsave_assets\nsave_assets\nView source\nsave_assets ( dir_path )\nsave_assets ( dir_path )\nset_vocabulary\nset_vocabulary\nView source\nset_vocabulary ( vocabulary , idf_weights = None )\nset_vocabulary ( vocabulary , idf_weights = None )\nSets vocabulary (and optionally document frequency) for this layer.\nThis method sets the vocabulary and IDF weights for this layer directly,\ninstead of analyzing a dataset through adapt() . It should be used\nwhenever the vocab (and optionally document frequency) information is\nalready known. If vocabulary data is already present in the layer, this\nmethod will replace it.\nadapt()\nArgs\nvocabulary Either an array or a string path to a text file.\nIf passing an array, can pass a tuple, list, 1D NumPy array,\nor 1D tensor containing the vocbulary terms.\nIf passing a file path, the file should contain one line\nper term in the vocabulary. idf_weights A tuple, list, 1D NumPy array, or 1D tensor of inverse\ndocument frequency weights with equal length to vocabulary.\nMust be set if output_mode is \"tf_idf\" .\nShould not be set otherwise.\nvocabulary\nidf_weights\noutput_mode\n\"tf_idf\"\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( data )\nupdate_state ( data )\nvocabulary_size\nvocabulary_size\nView source\nvocabulary_size ()\nvocabulary_size ()\nGets the current size of the layer's vocabulary.\nReturns The integer size of the vocabulary, including optional\nmask and OOV indices."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/one_hot",
    "content": "DEPRECATED.\ntf . keras . preprocessing . text . one_hot ( input_text , n , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , analyzer = None )\ntf . keras . preprocessing . text . one_hot ( input_text , n , filters = '!\"#$%&()*+,-./:;<=>?@[ \\\\ ]^_`{|}~ \\t\\n ' , lower = True , split = ' ' , analyzer = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/tree/pack_sequence_as",
    "content": "Returns a given flattened sequence packed into a given structure.\ntf . keras . tree . pack_sequence_as ( structure , flat_sequence , sequence_fn = None )\ntf . keras . tree . pack_sequence_as ( structure , flat_sequence , sequence_fn = None )\nIf structure is an atom, flat_sequence must be a single-item list; in\nthis case the return value is flat_sequence[0] .\nstructure\nflat_sequence\nflat_sequence[0]\nIf structure is or contains a dict instance, the keys will be sorted to\npack the flat sequence in deterministic order. This is true also for OrderedDict instances: their sequence order is considered. The same\nconvention is followed in flatten . This correctly repacks dicts and OrderedDicts after they have been flattened, or vice-versa.\nstructure\nOrderedDict\nflatten\nOrderedDicts\nDictionaries with non-sortable keys cannot be flattened.\nstructure = { \"key3\" : \"\" , \"key1\" : \"\" , \"key2\" : \"\" } flat_sequence = [ \"value1\" , \"value2\" , \"value3\" ] keras . tree . pack_sequence_as ( structure , flat_sequence ) { \"key3\" : \"value3\" , \"key1\" : \"value1\" , \"key2\" : \"value2\" }\nstructure = { \"key3\" : \"\" , \"key1\" : \"\" , \"key2\" : \"\" }\nflat_sequence = [ \"value1\" , \"value2\" , \"value3\" ]\nkeras . tree . pack_sequence_as ( structure , flat_sequence )\n{ \"key3\" : \"value3\" , \"key1\" : \"value1\" , \"key2\" : \"value2\" }\nstructure = (( \"a\" , \"b\" ), ( \"c\" , \"d\" , \"e\" ), \"f\" ) flat_sequence = [ 1.0 , 2.0 , 3.0 , 4.0 , 5.0 , 6.0 ] keras . tree . pack_sequence_as ( structure , flat_sequence ) (( 1.0 , 2.0 ), ( 3.0 , 4.0 , 5.0 ), 6.0 )\nstructure = (( \"a\" , \"b\" ), ( \"c\" , \"d\" , \"e\" ), \"f\" )\nflat_sequence = [ 1.0 , 2.0 , 3.0 , 4.0 , 5.0 , 6.0 ]\nkeras . tree . pack_sequence_as ( structure , flat_sequence )\n(( 1.0 , 2.0 ), ( 3.0 , 4.0 , 5.0 ), 6.0 )\nstructure = { \"key3\" : { \"c\" : ( \"alpha\" , \"beta\" ), \"a\" : ( \"gamma\" )}, \"key1\" : { \"e\" : \"val1\" , \"d\" : \"val2\" } } flat_sequence = [ \"val2\" , \"val1\" , 3.0 , 1.0 , 2.0 ] keras . tree . pack_sequence_as ( structure , flat_sequence ) { 'key3' : { 'c' : ( 1.0 , 2.0 ), 'a' : 3.0 }, 'key1' : { 'e' : 'val1' , 'd' : 'val2' } }\nstructure = { \"key3\" : { \"c\" : ( \"alpha\" , \"beta\" ), \"a\" : ( \"gamma\" )},\n\"key1\" : { \"e\" : \"val1\" , \"d\" : \"val2\" } }\nflat_sequence = [ \"val2\" , \"val1\" , 3.0 , 1.0 , 2.0 ]\nkeras . tree . pack_sequence_as ( structure , flat_sequence )\n{ 'key3' : { 'c' : ( 1.0 , 2.0 ), 'a' : 3.0 }, 'key1' : { 'e' : 'val1' , 'd' : 'val2' } }\nstructure = [ \"a\" ] flat_sequence = [ np . array ([[ 1 , 2 ], [ 3 , 4 ]])] keras . tree . pack_sequence_as ( structure , flat_sequence ) [ array ([[ 1 , 2 ], [ 3 , 4 ]])]\nstructure = [ \"a\" ]\nflat_sequence = [ np . array ([[ 1 , 2 ], [ 3 , 4 ]])]\nkeras . tree . pack_sequence_as ( structure , flat_sequence )\n[ array ([[ 1 , 2 ],\n[ 3 , 4 ]])]\nstructure = [ \"a\" ] flat_sequence = [ keras . ops . ones ([ 2 , 2 ])] keras . tree . pack_sequence_as ( structure , flat_sequence ) [ array ([[ 1. , 1. ], [ 1. , 1. ]]]\nstructure = [ \"a\" ]\nflat_sequence = [ keras . ops . ones ([ 2 , 2 ])]\nkeras . tree . pack_sequence_as ( structure , flat_sequence )\n[ array ([[ 1. , 1. ],\n[ 1. , 1. ]]]\nArgs\nArgs\nstructure Arbitrarily nested structure. flat_sequence Flat sequence to pack. sequence_fn Defaults to _sequence_like .\nstructure\nflat_sequence\nsequence_fn\n_sequence_like\nReturns flat_sequence converted to have the same recursive structure as structure .\nReturns\nflat_sequence\nstructure"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/register_keras_serializable",
    "content": "Registers an object with the Keras serialization framework.\ntf . keras . utils . register_keras_serializable ( package = 'Custom' , name = None )\ntf . keras . utils . register_keras_serializable ( package = 'Custom' , name = None )\nThis decorator injects the decorated class or function into the Keras custom\nobject dictionary, so that it can be serialized and deserialized without\nneeding an entry in the user-provided custom object dict. It also injects a\nfunction that Keras will call to get the object's serializable string key.\nNote that to be serialized and deserialized, classes must implement the get_config() method. Functions do not have this requirement.\nget_config()\nThe object will be registered under the key 'package>name' where name ,\ndefaults to the object name if not passed.\n'package>name'\nname\n# Note that `'my_package'` is used as the `package` argument here, and since # the `name` argument is not provided, `'MyDense'` is used as the `name`. @register_keras_serializable ( 'my_package' ) class MyDense ( keras . layers . Dense ): pass assert get_registered_object ( 'my_package>MyDense' ) == MyDense assert get_registered_name ( MyDense ) == 'my_package>MyDense'\n# Note that `'my_package'` is used as the `package` argument here, and since # the `name` argument is not provided, `'MyDense'` is used as the `name`. @register_keras_serializable ( 'my_package' ) class MyDense ( keras . layers . Dense ): pass assert get_registered_object ( 'my_package>MyDense' ) == MyDense assert get_registered_name ( MyDense ) == 'my_package>MyDense'\nArgs\nArgs\npackage The package that this class belongs to. This is used for the key (which is \"package>name\" ) to idenfify the class. Note that\nthis is the first argument passed into the decorator. name The name to serialize this class under in this package. If not\nprovided or None , the class' name will be used (note that this is\nthe case when the decorator is used with only one argument, which\nbecomes the package ).\npackage\nkey\n\"package>name\"\nname\nNone\npackage\nReturns A decorator that registers the decorated class with the passed names.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/in_top_k",
    "content": "DEPRECATED.\ntf . keras . backend . in_top_k ( predictions , targets , k )\ntf . keras . backend . in_top_k ( predictions , targets , k )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC",
    "content": "Approximates the AUC (Area under the curve) of the ROC or PR curves.\nInherits From: Metric\nMetric\ntf . keras . metrics . AUC ( num_thresholds = 200 , curve = 'ROC' , summation_method = 'interpolation' , name = None , dtype = None , thresholds = None , multi_label = False , num_labels = None , label_weights = None , from_logits = False )\ntf . keras . metrics . AUC ( num_thresholds = 200 , curve = 'ROC' , summation_method = 'interpolation' , name = None , dtype = None , thresholds = None , multi_label = False , num_labels = None , label_weights = None , from_logits = False )\nUsed in the notebooks\nClassification on imbalanced data\nClient-efficient large-model federated learning via `federated_select` and sparse aggregation\nThe AUC (Area under the curve) of the ROC (Receiver operating\ncharacteristic; default) or PR (Precision Recall) curves are quality\nmeasures of binary classifiers. Unlike the accuracy, and like cross-entropy\nlosses, ROC-AUC and PR-AUC evaluate all the operational points of a model.\nThis class approximates AUCs using a Riemann sum. During the metric\naccumulation phrase, predictions are accumulated within predefined buckets\nby value. The AUC is then computed by interpolating per-bucket averages.\nThese buckets define the evaluated operational points.\nThis metric creates four local variables, true_positives , true_negatives , false_positives and false_negatives that are used to\ncompute the AUC.  To discretize the AUC curve, a linearly spaced set of\nthresholds is used to compute pairs of recall and precision values. The area\nunder the ROC-curve is therefore computed using the height of the recall\nvalues by the false positive rate, while the area under the PR-curve is the\ncomputed using the height of the precision values by the recall.\ntrue_positives\ntrue_negatives\nfalse_positives\nfalse_negatives\nThis value is ultimately returned as auc , an idempotent operation that\ncomputes the area under a discretized curve of precision versus recall\nvalues (computed using the aforementioned variables). The num_thresholds variable controls the degree of discretization with larger numbers of\nthresholds more closely approximating the true AUC. The quality of the\napproximation may vary dramatically depending on num_thresholds . The thresholds parameter can be used to manually specify thresholds which\nsplit the predictions more evenly.\nauc\nnum_thresholds\nnum_thresholds\nthresholds\nFor a best approximation of the real AUC, predictions should be\ndistributed approximately uniformly in the range [0, 1] (if from_logits=False ). The quality of the AUC approximation may be poor if\nthis is not the case. Setting summation_method to 'minoring' or 'majoring'\ncan help quantify the error in the approximation by providing lower or upper\nbound estimate of the AUC.\npredictions\n[0, 1]\nfrom_logits=False\nsummation_method\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nnum_thresholds (Optional) The number of thresholds to\nuse when discretizing the roc curve. Values must be > 1.\nDefaults to 200 . curve (Optional) Specifies the name of the curve to be computed, 'ROC' (default) or 'PR' for the Precision-Recall-curve. summation_method (Optional) Specifies the Riemann summation method used.\n'interpolation' (default) applies mid-point summation scheme for ROC .  For PR-AUC, interpolates (true/false) positives but not\nthe ratio that is precision (see Davis & Goadrich 2006 for\ndetails); 'minoring' applies left summation for increasing\nintervals and right summation for decreasing intervals; 'majoring'\ndoes the opposite. name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. thresholds (Optional) A list of floating point values to use as the\nthresholds for discretizing the curve. If set, the num_thresholds parameter is ignored. Values should be in [0, 1] . Endpoint\nthresholds equal to { -epsilon , 1+epsilon } for a small positive\nepsilon value will be automatically included with these to correctly\nhandle predictions equal to exactly 0 or 1. multi_label boolean indicating whether multilabel data should be\ntreated as such, wherein AUC is computed separately for each label\nand then averaged across labels, or (when False ) if the data\nshould be flattened into a single label before AUC computation. In\nthe latter case, when multilabel data is passed to AUC, each\nlabel-prediction pair is treated as an individual data point. Should\nbe set to False for multi-class data. num_labels (Optional) The number of labels, used when multi_label is\nTrue. If num_labels is not specified, then state variables get\ncreated on the first call to update_state . label_weights (Optional) list, array, or tensor of non-negative weights\nused to compute AUCs for multilabel data. When multi_label is\nTrue, the weights are applied to the individual label AUCs when they\nare averaged to produce the multi-label AUC. When it's False, they\nare used to weight the individual label predictions in computing the\nconfusion matrix on the flattened data. Note that this is unlike class_weights in that class_weights weights the example\ndepending on the value of its label, whereas label_weights depends\nonly on the index of that label before flattening; therefore label_weights should not be used for multi-class data. from_logits boolean indicating whether the predictions ( y_pred in update_state ) are probabilities or sigmoid logits. As a rule of thumb,\nwhen using a keras loss, the from_logits constructor argument of the\nloss should match the AUC from_logits constructor argument.\nnum_thresholds\n200\ncurve\n'ROC'\n'PR'\nsummation_method\nROC\nname\ndtype\nthresholds\nnum_thresholds\n[0, 1]\n-epsilon\n1+epsilon\nmulti_label\nFalse\nFalse\nnum_labels\nmulti_label\nnum_labels\nupdate_state\nlabel_weights\nmulti_label\nclass_weights\nclass_weights\nlabel_weights\nlabel_weights\nfrom_logits\ny_pred\nupdate_state\nfrom_logits\nfrom_logits\nm = keras . metrics . AUC ( num_thresholds = 3 ) m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ]) # threshold values are [0 - 1e-7, 0.5, 1 + 1e-7] # tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2] # tp_rate = recall = [1, 0.5, 0], fp_rate = [1, 0, 0] # auc = ((((1 + 0.5) / 2) * (1 - 0)) + (((0.5 + 0) / 2) * (0 - 0))) #     = 0.75 m . result () 0.75\nm = keras . metrics . AUC ( num_thresholds = 3 )\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ])\n# threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]\n# tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]\n# tp_rate = recall = [1, 0.5, 0], fp_rate = [1, 0, 0]\n# auc = ((((1 + 0.5) / 2) * (1 - 0)) + (((0.5 + 0) / 2) * (0 - 0)))\n#     = 0.75\nm . result ()\n0.75\nm . reset_state () m . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ], sample_weight = [ 1 , 0 , 0 , 1 ]) m . result () 1.0\nm . reset_state ()\nm . update_state ([ 0 , 0 , 1 , 1 ], [ 0 , 0.5 , 0.3 , 0.9 ],\nsample_weight = [ 1 , 0 , 0 , 1 ])\nm . result ()\n1.0\nUsage with compile() API:\ncompile()\n# Reports the AUC of a model outputting a probability. model . compile ( optimizer = 'sgd' , loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . AUC ()]) # Reports the AUC of a model outputting a logit. model . compile ( optimizer = 'sgd' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . AUC ( from_logits = True )])\n# Reports the AUC of a model outputting a probability. model . compile ( optimizer = 'sgd' , loss = keras . losses . BinaryCrossentropy (), metrics = [ keras . metrics . AUC ()]) # Reports the AUC of a model outputting a logit. model . compile ( optimizer = 'sgd' , loss = keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ keras . metrics . AUC ( from_logits = True )])\nAttributes\nAttributes\ndtype\ndtype\nthresholds The thresholds used for evaluating AUC. variables\nthresholds\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\ninterpolate_pr_auc\ninterpolate_pr_auc\nView source\ninterpolate_pr_auc ()\ninterpolate_pr_auc ()\nInterpolation formula inspired by section 4 of Davis & Goadrich 2006.\nhttps://www.biostat.wisc.edu/~page/rocpr.pdf\nNote here we derive & use a closed formula not present in the paper\nas follows:\nPrecision = TP / ( TP + FP ) = TP / P\nPrecision = TP / ( TP + FP ) = TP / P\nModeling all of TP (true positive), FP (false positive) and their sum\nP = TP + FP (predicted positive) as varying linearly within each\ninterval [A, B] between successive thresholds, we get\nPrecision slope = dTP / dP = ( TP_B - TP_A ) / ( P_B - P_A ) = ( TP - TP_A ) / ( P - P_A ) Precision = ( TP_A + slope * ( P - P_A )) / P\nPrecision slope = dTP / dP = ( TP_B - TP_A ) / ( P_B - P_A ) = ( TP - TP_A ) / ( P - P_A ) Precision = ( TP_A + slope * ( P - P_A )) / P\nThe area within the interval is (slope / total_pos_weight) times\nint_A ^ B { Precision . dP } = int_A ^ B {( TP_A + slope * ( P - P_A )) * dP / P } int_A ^ B { Precision . dP } = int_A ^ B { slope * dP + intercept * dP / P }\nint_A ^ B { Precision . dP } = int_A ^ B {( TP_A + slope * ( P - P_A )) * dP / P } int_A ^ B { Precision . dP } = int_A ^ B { slope * dP + intercept * dP / P }\nwhere intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in\nint_A ^ B { Precision . dP } = TP_B - TP_A + intercept * log ( P_B / P_A )\nint_A ^ B { Precision . dP } = TP_B - TP_A + intercept * log ( P_B / P_A )\nBringing back the factor (slope / total_pos_weight) we'd put aside, we\nget\nslope * [ dTP + intercept * log ( P_B / P_A )] / total_pos_weight\nslope * [ dTP + intercept * log ( P_B / P_A )] / total_pos_weight\nwhere dTP == TP_B - TP_A.\nNote that when P_A == 0 the above calculation simplifies into\nint_A ^ B { Precision . dTP } = int_A ^ B { slope * dTP } = slope * ( TP_B - TP_A )\nint_A ^ B { Precision . dTP } = int_A ^ B { slope * dTP } = slope * ( TP_B - TP_A )\nwhich is really equivalent to imputing constant precision throughout the\nfirst bucket having >0 true positives.\nReturns\npr_auc an approximation of the area under the P-R curve.\npr_auc\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulates confusion matrix statistics.\nArgs\ny_true The ground truth values. y_pred The predicted values. sample_weight Optional weighting of each example. Can\nbe a tensor whose rank is either 0, or the same rank as y_true , and must be broadcastable to y_true . Defaults to 1 .\ny_true\ny_pred\nsample_weight\ny_true\ny_true\n1\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/device",
    "content": "Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.device\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.device\ntf.compat.v1.keras.device\ntf . keras . device ( device_name )\ntf . keras . device ( device_name )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass AUC : Approximates the AUC (Area under the curve) of the ROC or PR curves.\nclass AUC\nclass Accuracy : Calculates how often predictions equal labels.\nclass Accuracy\nclass BinaryAccuracy : Calculates how often predictions match binary labels.\nclass BinaryAccuracy\nclass BinaryCrossentropy : Computes the crossentropy metric between the labels and predictions.\nclass BinaryCrossentropy\nclass BinaryIoU : Computes the Intersection-Over-Union metric for class 0 and/or 1.\nclass BinaryIoU\nclass CategoricalAccuracy : Calculates how often predictions match one-hot labels.\nclass CategoricalAccuracy\nclass CategoricalCrossentropy : Computes the crossentropy metric between the labels and predictions.\nclass CategoricalCrossentropy\nclass CategoricalHinge : Computes the categorical hinge metric between y_true and y_pred .\nclass CategoricalHinge\ny_true\ny_pred\nclass CosineSimilarity : Computes the cosine similarity between the labels and predictions.\nclass CosineSimilarity\nclass F1Score : Computes F-1 Score.\nclass F1Score\nclass FBetaScore : Computes F-Beta score.\nclass FBetaScore\nclass FalseNegatives : Calculates the number of false negatives.\nclass FalseNegatives\nclass FalsePositives : Calculates the number of false positives.\nclass FalsePositives\nclass Hinge : Computes the hinge metric between y_true and y_pred .\nclass Hinge\ny_true\ny_pred\nclass IoU : Computes the Intersection-Over-Union metric for specific target classes.\nclass IoU\nclass KLDivergence : Computes Kullback-Leibler divergence metric between y_true and y_pred .\nclass KLDivergence\ny_true\ny_pred\nclass LogCoshError : Computes the logarithm of the hyperbolic cosine of the prediction error.\nclass LogCoshError\nclass Mean : Compute the (weighted) mean of the given values.\nclass Mean\nclass MeanAbsoluteError : Computes the mean absolute error between the labels and predictions.\nclass MeanAbsoluteError\nclass MeanAbsolutePercentageError : Computes mean absolute percentage error between y_true and y_pred .\nclass MeanAbsolutePercentageError\ny_true\ny_pred\nclass MeanIoU : Computes the mean Intersection-Over-Union metric.\nclass MeanIoU\nclass MeanMetricWrapper : Wrap a stateless metric function with the Mean metric.\nclass MeanMetricWrapper\nMean\nclass MeanSquaredError : Computes the mean squared error between y_true and y_pred .\nclass MeanSquaredError\ny_true\ny_pred\nclass MeanSquaredLogarithmicError : Computes mean squared logarithmic error between y_true and y_pred .\nclass MeanSquaredLogarithmicError\ny_true\ny_pred\nclass Metric : Encapsulates metric logic and state.\nclass Metric\nclass OneHotIoU : Computes the Intersection-Over-Union metric for one-hot encoded labels.\nclass OneHotIoU\nclass OneHotMeanIoU : Computes mean Intersection-Over-Union metric for one-hot encoded labels.\nclass OneHotMeanIoU\nclass Poisson : Computes the Poisson metric between y_true and y_pred .\nclass Poisson\ny_true\ny_pred\nclass Precision : Computes the precision of the predictions with respect to the labels.\nclass Precision\nclass PrecisionAtRecall : Computes best precision where recall is >= specified value.\nclass PrecisionAtRecall\nclass R2Score : Computes R2 score.\nclass R2Score\nclass Recall : Computes the recall of the predictions with respect to the labels.\nclass Recall\nclass RecallAtPrecision : Computes best recall where precision is >= specified value.\nclass RecallAtPrecision\nclass RootMeanSquaredError : Computes root mean squared error metric between y_true and y_pred .\nclass RootMeanSquaredError\ny_true\ny_pred\nclass SensitivityAtSpecificity : Computes best sensitivity where specificity is >= specified value.\nclass SensitivityAtSpecificity\nclass SparseCategoricalAccuracy : Calculates how often predictions match integer labels.\nclass SparseCategoricalAccuracy\nclass SparseCategoricalCrossentropy : Computes the crossentropy metric between the labels and predictions.\nclass SparseCategoricalCrossentropy\nclass SparseTopKCategoricalAccuracy : Computes how often integer targets are in the top K predictions.\nclass SparseTopKCategoricalAccuracy\nK\nclass SpecificityAtSensitivity : Computes best specificity where sensitivity is >= specified value.\nclass SpecificityAtSensitivity\nclass SquaredHinge : Computes the hinge metric between y_true and y_pred .\nclass SquaredHinge\ny_true\ny_pred\nclass Sum : Compute the (weighted) sum of the given values.\nclass Sum\nclass TopKCategoricalAccuracy : Computes how often targets are in the top K predictions.\nclass TopKCategoricalAccuracy\nK\nclass TrueNegatives : Calculates the number of true negatives.\nclass TrueNegatives\nclass TruePositives : Calculates the number of true positives.\nclass TruePositives\nFunctions\nKLD(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nKLD(...)\ny_true\ny_pred\nMAE(...) : Computes the mean absolute error between labels and predictions.\nMAE(...)\nMAPE(...) : Computes the mean absolute percentage error between y_true & y_pred .\nMAPE(...)\ny_true\ny_pred\nMSE(...) : Computes the mean squared error between labels and predictions.\nMSE(...)\nMSLE(...) : Computes the mean squared logarithmic error between y_true & y_pred .\nMSLE(...)\ny_true\ny_pred\nbinary_accuracy(...)\nbinary_accuracy(...)\nbinary_crossentropy(...) : Computes the binary crossentropy loss.\nbinary_crossentropy(...)\nbinary_focal_crossentropy(...) : Computes the binary focal crossentropy loss.\nbinary_focal_crossentropy(...)\ncategorical_accuracy(...)\ncategorical_accuracy(...)\ncategorical_crossentropy(...) : Computes the categorical crossentropy loss.\ncategorical_crossentropy(...)\ncategorical_focal_crossentropy(...) : Computes the categorical focal crossentropy loss.\ncategorical_focal_crossentropy(...)\ncategorical_hinge(...) : Computes the categorical hinge loss between y_true & y_pred .\ncategorical_hinge(...)\ny_true\ny_pred\ndeserialize(...) : Deserializes a serialized metric class/function instance.\ndeserialize(...)\nget(...) : Retrieves a Keras metric as a function / Metric class instance.\nget(...)\nfunction\nMetric\nhinge(...) : Computes the hinge loss between y_true & y_pred .\nhinge(...)\ny_true\ny_pred\nhuber(...) : Computes Huber loss value.\nhuber(...)\nkld(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nkld(...)\ny_true\ny_pred\nkullback_leibler_divergence(...) : Computes Kullback-Leibler divergence loss between y_true & y_pred .\nkullback_leibler_divergence(...)\ny_true\ny_pred\nlogcosh(...) : Logarithm of the hyperbolic cosine of the prediction error.\nlogcosh(...)\nmae(...) : Computes the mean absolute error between labels and predictions.\nmae(...)\nmape(...) : Computes the mean absolute percentage error between y_true & y_pred .\nmape(...)\ny_true\ny_pred\nmse(...) : Computes the mean squared error between labels and predictions.\nmse(...)\nmsle(...) : Computes the mean squared logarithmic error between y_true & y_pred .\nmsle(...)\ny_true\ny_pred\npoisson(...) : Computes the Poisson loss between y_true and y_pred.\npoisson(...)\nserialize(...) : Serializes metric function or Metric instance.\nserialize(...)\nMetric\nsparse_categorical_accuracy(...)\nsparse_categorical_accuracy(...)\nsparse_categorical_crossentropy(...) : Computes the sparse categorical crossentropy loss.\nsparse_categorical_crossentropy(...)\nsparse_top_k_categorical_accuracy(...)\nsparse_top_k_categorical_accuracy(...)\nsquared_hinge(...) : Computes the squared hinge loss between y_true & y_pred .\nsquared_hinge(...)\ny_true\ny_pred\ntop_k_categorical_accuracy(...)\ntop_k_categorical_accuracy(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/prod",
    "content": "Return the product of tensor elements over a given axis.\nMain aliases tf.keras.ops.numpy.prod\ntf.keras.ops.numpy.prod\ntf.keras.ops.numpy.prod\ntf . keras . ops . prod ( x , axis = None , keepdims = False , dtype = None )\ntf . keras . ops . prod ( x , axis = None , keepdims = False , dtype = None )\nArgs\nArgs\nx Input tensor. axis Axis or axes along which a product is performed. The default, axis=None , will compute the product of all elements\nin the input tensor. keepdims If this is set to True , the axes which are reduce\nare left in the result as dimensions with size one. dtype Data type of the returned tensor.\nx\naxis\naxis=None\nkeepdims\nTrue\ndtype\nReturns Product of elements of x over the given axis or axes.\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adafactor",
    "content": "Optimizer that implements the Adafactor algorithm.\nInherits From: Optimizer\nOptimizer\ntf . keras . optimizers . Adafactor ( learning_rate = 0.001 , beta_2_decay =- 0.8 , epsilon_1 = 1e-30 , epsilon_2 = 0.001 , clip_threshold = 1.0 , relative_step = True , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adafactor' , ** kwargs )\ntf . keras . optimizers . Adafactor ( learning_rate = 0.001 , beta_2_decay =- 0.8 , epsilon_1 = 1e-30 , epsilon_2 = 0.001 , clip_threshold = 1.0 , relative_step = True , weight_decay = None , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adafactor' , ** kwargs )\nAdafactor is commonly used in NLP tasks, and has the advantage\nof taking less memory because it only saves partial information of previous\ngradients.\nThe default argument setup is based on the original paper (see reference).\nWhen gradients are of dimension > 2, Adafactor optimizer will delete the\nlast 2 dimensions separately in its accumulator variables.\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_2_decay float, defaults to -0.8. The decay rate of beta_2 . epsilon_1 float, defaults to 1e-30. A small offset to keep denominator\naway from 0. epsilon_2 float, defaults to 1e-3. A small offset to avoid learning\nrate becoming too small by time. clip_threshold float, defaults to 1.0. Clipping threshold. This is a\npart of Adafactor algorithm, independent from clipnorm , clipvalue , and global_clipnorm . relative_step bool, defaults to True . If learning_rate is a\nconstant and relative_step=True , learning rate will be adjusted\nbased on current iterations. This is a default learning rate decay\nin Adafactor. name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_2_decay\nbeta_2\nepsilon_1\nepsilon_2\nclip_threshold\nclipnorm\nclipvalue\nglobal_clipnorm\nrelative_step\nTrue\nlearning_rate\nrelative_step=True\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nShazeer, Noam et al., 2018 .\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nAdam optimizer has 3 types of variables: momentums, velocities and\nvelocity_hat (only set when amsgrad is applied),\nArgs\nvar_list list of model variables to build Adam variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV3Small",
    "content": "Instantiates the MobileNetV3Small architecture.\ntf . keras . applications . MobileNetV3Small ( input_shape = None , alpha = 1.0 , minimalistic = False , include_top = True , weights = 'imagenet' , input_tensor = None , classes = 1000 , pooling = None , dropout_rate = 0.2 , classifier_activation = 'softmax' , include_preprocessing = True )\ntf . keras . applications . MobileNetV3Small ( input_shape = None , alpha = 1.0 , minimalistic = False , include_top = True , weights = 'imagenet' , input_tensor = None , classes = 1000 , pooling = None , dropout_rate = 0.2 , classifier_activation = 'softmax' , include_preprocessing = True )\nUsed in the notebooks\nImage captioning with visual attention\nSearching for MobileNetV3 (ICCV 2019)\nThe following table describes the performance of MobileNets v3:\nMACs stands for Multiply Adds\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.mobilenet_v3.preprocess_input\n[0-255]\nRescaling\ninclude_preprocessing\nFalse\n[-1, 1]\nArgs\nArgs\ninput_shape Optional shape tuple, to be specified if you would\nlike to use a model with an input image resolution that is not (224, 224, 3) .\nIt should have exactly 3 inputs channels.\nYou can also omit this option if you would like\nto infer input_shape from an input_tensor.\nIf you choose to include both input_tensor and input_shape then\ninput_shape will be used if they match, if the shapes\ndo not match then we will throw an error.\nE.g. (160, 160, 3) would be one valid value. alpha controls the width of the network. This is known as the\ndepth multiplier in the MobileNetV3 paper, but the name is kept for\nconsistency with MobileNetV1 in Keras.\ninput_shape\n(224, 224, 3)\n(160, 160, 3)\nalpha\nIf alpha < 1.0 , proportionally decreases the number\nof filters in each layer.\nalpha < 1.0\nIf alpha > 1.0 , proportionally increases the number\nof filters in each layer.\nalpha > 1.0\nIf alpha == 1 , default number of filters from the paper\nare used at each layer. minimalistic In addition to large and small models this module also\ncontains so-called minimalistic models, these models have the same\nper-layer dimensions characteristic as MobilenetV3 however, they don't\nutilize any of the advanced blocks (squeeze-and-excite units,\nhard-swish, and 5x5 convolutions).\nWhile these models are less efficient on CPU, they\nare much more performant on GPU/DSP. include_top Boolean, whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights String, one of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded. input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. pooling String, optional pooling mode for feature extraction\nwhen include_top is False .\nalpha == 1\nminimalistic\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\ninput_tensor\nlayers.Input()\npooling\ninclude_top\nFalse\nNone means that the output of the model\nwill be the 4D tensor output of the\nlast convolutional block.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional block, and thus\nthe output of the model will be a\n2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Integer, optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. dropout_rate fraction of the input units to drop on the last layer. classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" . include_preprocessing Boolean, whether to include the preprocessing\nlayer ( Rescaling ) at the bottom of the network. Defaults to True .\nmax\nclasses\ninclude_top\nTrue\nweights\ndropout_rate\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\ninclude_preprocessing\nRescaling\nTrue\nCall arguments\nCall arguments\ninputs A floating point numpy.array or backend-native tensor,\n4D with 3 color channels, with values in the range [0, 255] if include_preprocessing is True and in the range [-1, 1] otherwise.\ninputs\nnumpy.array\n[0, 255]\ninclude_preprocessing\nTrue\n[-1, 1]\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/cast",
    "content": "DEPRECATED.\ntf . keras . backend . cast ( x , dtype )\ntf . keras . backend . cast ( x , dtype )\nUsed in the notebooks\nGraph regularization for document classification using natural graphs"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D",
    "content": "Global max pooling operation for 2D data.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.GlobalMaxPooling2D\ntf.keras.layers.GlobalMaxPooling2D\ntf.keras.layers.GlobalMaxPooling2D\ntf . keras . layers . GlobalMaxPool2D ( data_format = None , keepdims = False , ** kwargs )\ntf . keras . layers . GlobalMaxPool2D ( data_format = None , keepdims = False , ** kwargs )\nUsed in the notebooks\nCustomizing what happens in `fit()`\nArgs\nArgs\ndata_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, features, height, weight) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . keepdims A boolean, whether to keep the temporal dimension or not.\nIf keepdims is False (default), the rank of the tensor is\nreduced for spatial dimensions. If keepdims is True , the\nspatial dimension are retained with length 1.\nThe behavior is the same as for tf.reduce_mean or np.mean .\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, features, height, weight)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nkeepdims\nkeepdims\nFalse\nkeepdims\nTrue\ntf.reduce_mean\nnp.mean\nIf data_format='channels_last' :\n4D tensor with shape: (batch_size, height, width, channels)\ndata_format='channels_last'\n(batch_size, height, width, channels)\nIf data_format='channels_first' :\n4D tensor with shape: (batch_size, channels, height, width)\ndata_format='channels_first'\n(batch_size, channels, height, width)\nIf keepdims=False :\n2D tensor with shape (batch_size, channels) .\nkeepdims=False\n(batch_size, channels)\nIf keepdims=True : If data_format=\"channels_last\" :\n4D tensor with shape (batch_size, 1, 1, channels) If data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, 1, 1)\nkeepdims=True\nIf data_format=\"channels_last\" :\n4D tensor with shape (batch_size, 1, 1, channels)\ndata_format=\"channels_last\"\n(batch_size, 1, 1, channels)\nIf data_format=\"channels_first\" :\n4D tensor with shape (batch_size, channels, 1, 1)\ndata_format=\"channels_first\"\n(batch_size, channels, 1, 1)\nx = np . random . rand ( 2 , 4 , 5 , 3 ) y = keras . layers . GlobalMaxPooling2D ()( x ) y . shape ( 2 , 3 )\nx = np . random . rand ( 2 , 4 , 5 , 3 )\ny = keras . layers . GlobalMaxPooling2D ()( x )\ny . shape\n( 2 , 3 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/decode_predictions",
    "content": "Decodes the prediction of an ImageNet model.\ntf . keras . applications . nasnet . decode_predictions ( preds , top = 5 )\ntf . keras . applications . nasnet . decode_predictions ( preds , top = 5 )\nArgs\nArgs\npreds NumPy array encoding a batch of predictions. top Integer, how many top-guesses to return. Defaults to 5 .\npreds\ntop\n5\nReturns A list of lists of top class prediction tuples (class_name, class_description, score) .\nOne list of tuples per sample in batch input.\nReturns\n(class_name, class_description, score)\nRaises\nRaises\nValueError In case of invalid shape of the pred array\n(must be 2D).\nValueError\npred"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/relu6",
    "content": "Rectified linear unit activation function with upper bound of 6.\nMain aliases tf.keras.ops.nn.relu6\ntf.keras.ops.nn.relu6\ntf.keras.ops.nn.relu6\ntf . keras . ops . relu6 ( x )\ntf . keras . ops . relu6 ( x )\nIt is defined as f(x) = np.clip(x, 0, 6) .\nf(x) = np.clip(x, 0, 6)\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = keras . ops . convert_to_tensor ([ - 3.0 , - 2.0 , 0.1 , 0.2 , 6.0 , 8.0 ]) keras . ops . relu6 ( x ) array ([ 0.0 , 0.0 , 0.1 , 0.2 , 6.0 , 6.0 ], dtype = float32 )\nx = keras . ops . convert_to_tensor ([ - 3.0 , - 2.0 , 0.1 , 0.2 , 6.0 , 8.0 ])\nkeras . ops . relu6 ( x )\narray ([ 0.0 , 0.0 , 0.1 , 0.2 , 6.0 , 6.0 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/AdamW",
    "content": "Optimizer that implements the AdamW algorithm.\nInherits From: Adam , Optimizer\nAdam\nOptimizer\ntf . keras . optimizers . AdamW ( learning_rate = 0.001 , weight_decay = 0.004 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , amsgrad = False , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adamw' , ** kwargs )\ntf . keras . optimizers . AdamW ( learning_rate = 0.001 , weight_decay = 0.004 , beta_1 = 0.9 , beta_2 = 0.999 , epsilon = 1e-07 , amsgrad = False , clipnorm = None , clipvalue = None , global_clipnorm = None , use_ema = False , ema_momentum = 0.99 , ema_overwrite_frequency = None , loss_scale_factor = None , gradient_accumulation_steps = None , name = 'adamw' , ** kwargs )\nAdamW optimization is a stochastic gradient descent method that is based on\nadaptive estimation of first-order and second-order moments with an added\nmethod to decay weights per the techniques discussed in the paper,\n'Decoupled Weight Decay Regularization' by Loshchilov, Hutter et al., 2019 .\nAccording to Kingma et al., 2014 ,\nthe underying Adam method is \" computationally\nefficient, has little memory requirement, invariant to diagonal rescaling of\ngradients, and is well suited for problems that are large in terms of\ndata/parameters \".\nArgs\nArgs\nlearning_rate A float, a keras.optimizers.schedules.LearningRateSchedule instance, or\na callable that takes no arguments and returns the actual value to\nuse. The learning rate. Defaults to 0.001 . beta_1 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 1st moment estimates.\nDefaults to 0.9 . beta_2 A float value or a constant float tensor, or a callable\nthat takes no arguments and returns the actual value to use. The\nexponential decay rate for the 2nd moment estimates.\nDefaults to 0.999 . epsilon A small constant for numerical stability. This epsilon is\n\"epsilon hat\" in the Kingma and Ba paper (in the formula just\nbefore Section 2.1), not the epsilon in Algorithm 1 of the paper.\nDefaults to 1e-7. amsgrad Boolean. Whether to apply AMSGrad variant of this algorithm\nfrom the paper \"On the Convergence of Adam and beyond\".\nDefaults to False . name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\nlearning_rate\nkeras.optimizers.schedules.LearningRateSchedule\n0.001\nbeta_1\n0.9\nbeta_2\n0.999\nepsilon\namsgrad\nFalse\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nLoshchilov et al., 2019\nKingma et al., 2014 for adam\nadam\nReddi et al., 2018 for amsgrad .\namsgrad\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\nInitialize optimizer variables.\nAdam optimizer has 3 types of variables: momentums, velocities and\nvelocity_hat (only set when amsgrad is applied),\nArgs\nvar_list list of model variables to build Adam variables on.\nvar_list\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )\nUpdate step given gradient and the associated model variable."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/less_equal",
    "content": "DEPRECATED.\ntf . keras . backend . less_equal ( x , y )\ntf . keras . backend . less_equal ( x , y )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/JaxLayer",
    "content": "Keras Layer that wraps a JAX model.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . JaxLayer ( call_fn , init_fn = None , params = None , state = None , seed = None , ** kwargs )\ntf . keras . layers . JaxLayer ( call_fn , init_fn = None , params = None , state = None , seed = None , ** kwargs )\nThis layer enables the use of JAX components within Keras when using JAX as\nthe backend for Keras.\nModel function\nThis layer accepts JAX models in the form of a function, call_fn , which\nmust take the following arguments with these exact names:\ncall_fn\nparams : trainable parameters of the model.\nparams\nstate ( optional ): non-trainable state of the model. Can be omitted if\nthe model has no non-trainable state.\nstate\nrng ( optional ): a jax.random.PRNGKey instance. Can be omitted if the\nmodel does not need RNGs, neither during training nor during inference.\nrng\njax.random.PRNGKey\ninputs : inputs to the model, a JAX array or a PyTree of arrays.\ninputs\nPyTree\ntraining ( optional ): an argument specifying if we're in training mode\nor inference mode, True is passed in training mode. Can be omitted if\nthe model behaves the same in training mode and inference mode.\ntraining\nTrue\nThe inputs argument is mandatory. Inputs to the model must be provided via\na single argument. If the JAX model takes multiple inputs as separate\narguments, they must be combined into a single structure, for instance in a tuple or a dict .\ninputs\ntuple\ndict\nModel weights initialization\nThe initialization of the params and state of the model can be handled\nby this layer, in which case the init_fn argument must be provided. This\nallows the model to be initialized dynamically with the right shape.\nAlternatively, and if the shape is known, the params argument and\noptionally the state argument can be used to create an already initialized\nmodel.\nparams\nstate\ninit_fn\nparams\nstate\nThe init_fn function, if provided, must take the following arguments with\nthese exact names:\ninit_fn\nrng : a jax.random.PRNGKey instance.\nrng\njax.random.PRNGKey\ninputs : a JAX array or a PyTree of arrays with placeholder values to\nprovide the shape of the inputs.\ninputs\nPyTree\ntraining ( optional ): an argument specifying if we're in training mode\nor inference mode. True is always passed to init_fn . Can be omitted\nregardless of whether call_fn has a training argument.\ntraining\nTrue\ninit_fn\ncall_fn\ntraining\nModels with non-trainable state\nFor JAX models that have non-trainable state:\ncall_fn must have a state argument\ncall_fn\nstate\ncall_fn must return a tuple containing the outputs of the model and\nthe new non-trainable state of the model\ncall_fn\ntuple\ninit_fn must return a tuple containing the initial trainable params of\nthe model and the initial non-trainable state of the model.\ninit_fn\ntuple\nThis code shows a possible combination of call_fn and init_fn signatures\nfor a model with non-trainable state. In this example, the model has a training argument and an rng argument in call_fn .\ncall_fn\ninit_fn\ntraining\nrng\ncall_fn\ndef stateful_call ( params , state , rng , inputs , training ): outputs = ... new_state = ... return outputs , new_state def stateful_init ( rng , inputs ): initial_params = ... initial_state = ... return initial_params , initial_state\ndef stateful_call ( params , state , rng , inputs , training ): outputs = ... new_state = ... return outputs , new_state def stateful_init ( rng , inputs ): initial_params = ... initial_state = ... return initial_params , initial_state\nModels without non-trainable state\nFor JAX models with no non-trainable state:\ncall_fn must not have a state argument\ncall_fn\nstate\ncall_fn must return only the outputs of the model\ncall_fn\ninit_fn must return only the initial trainable params of the model.\ninit_fn\nThis code shows a possible combination of call_fn and init_fn signatures\nfor a model without non-trainable state. In this example, the model does not\nhave a training argument and does not have an rng argument in call_fn .\ncall_fn\ninit_fn\ntraining\nrng\ncall_fn\ndef stateless_call ( params , inputs ): outputs = ... return outputs def stateless_init ( rng , inputs ): initial_params = ... return initial_params\ndef stateless_call ( params , inputs ): outputs = ... return outputs def stateless_init ( rng , inputs ): initial_params = ... return initial_params\nConforming to the required signature\nIf a model has a different signature than the one required by JaxLayer ,\none can easily write a wrapper method to adapt the arguments. This example\nshows a model that has multiple inputs as separate arguments, expects\nmultiple RNGs in a dict , and has a deterministic argument with the\nopposite meaning of training . To conform, the inputs are combined in a\nsingle structure using a tuple , the RNG is split and used the populate the\nexpected dict , and the Boolean flag is negated:\nJaxLayer\ndict\ndeterministic\ntraining\ntuple\ndict\ndef my_model_fn ( params , rngs , input1 , input2 , deterministic ): ... if not deterministic : dropout_rng = rngs [ \"dropout\" ] keep = jax . random . bernoulli ( dropout_rng , dropout_rate , x . shape ) x = jax . numpy . where ( keep , x / dropout_rate , 0 ) ... ... return outputs def my_model_wrapper_fn ( params , rng , inputs , training ): input1 , input2 = inputs rng1 , rng2 = jax . random . split ( rng ) rngs = { \"dropout\" : rng1 , \"preprocessing\" : rng2 } deterministic = not training return my_model_fn ( params , rngs , input1 , input2 , deterministic ) keras_layer = JaxLayer ( my_model_wrapper_fn , params = initial_params )\ndef my_model_fn ( params , rngs , input1 , input2 , deterministic ): ... if not deterministic : dropout_rng = rngs [ \"dropout\" ] keep = jax . random . bernoulli ( dropout_rng , dropout_rate , x . shape ) x = jax . numpy . where ( keep , x / dropout_rate , 0 ) ... ... return outputs def my_model_wrapper_fn ( params , rng , inputs , training ): input1 , input2 = inputs rng1 , rng2 = jax . random . split ( rng ) rngs = { \"dropout\" : rng1 , \"preprocessing\" : rng2 } deterministic = not training return my_model_fn ( params , rngs , input1 , input2 , deterministic ) keras_layer = JaxLayer ( my_model_wrapper_fn , params = initial_params )\nUsage with Haiku modules\nJaxLayer enables the use of Haiku components in the form of haiku.Module .\nThis is achieved by transforming the module per the Haiku pattern and then\npassing module.apply in the call_fn parameter and module.init in the init_fn parameter if needed.\nJaxLayer\nhaiku.Module\nmodule.apply\ncall_fn\nmodule.init\ninit_fn\nIf the model has non-trainable state, it should be transformed with haiku.transform_with_state .\nIf the model has no non-trainable state, it should be transformed with haiku.transform .\nAdditionally, and optionally, if the module does not use RNGs in \"apply\", it\ncan be transformed with haiku.without_apply_rng .\nhaiku.transform_with_state\nhaiku.transform\nhaiku.without_apply_rng\nThe following example shows how to create a JaxLayer from a Haiku module\nthat uses random number generators via hk.next_rng_key() and takes a\ntraining positional argument:\nJaxLayer\nhk.next_rng_key()\nclass MyHaikuModule ( hk . Module ): def __call__ ( self , x , training ): x = hk . Conv2D ( 32 , ( 3 , 3 ))( x ) x = jax . nn . relu ( x ) x = hk . AvgPool (( 1 , 2 , 2 , 1 ), ( 1 , 2 , 2 , 1 ), \"VALID\" )( x ) x = hk . Flatten ()( x ) x = hk . Linear ( 200 )( x ) if training : x = hk . dropout ( rng = hk . next_rng_key (), rate = 0.3 , x = x ) x = jax . nn . relu ( x ) x = hk . Linear ( 10 )( x ) x = jax . nn . softmax ( x ) return x def my_haiku_module_fn ( inputs , training ): module = MyHaikuModule () return module ( inputs , training ) transformed_module = hk . transform ( my_haiku_module_fn ) keras_layer = JaxLayer ( call_fn = transformed_module . apply , init_fn = transformed_module . init , )\nclass MyHaikuModule ( hk . Module ): def __call__ ( self , x , training ): x = hk . Conv2D ( 32 , ( 3 , 3 ))( x ) x = jax . nn . relu ( x ) x = hk . AvgPool (( 1 , 2 , 2 , 1 ), ( 1 , 2 , 2 , 1 ), \"VALID\" )( x ) x = hk . Flatten ()( x ) x = hk . Linear ( 200 )( x ) if training : x = hk . dropout ( rng = hk . next_rng_key (), rate = 0.3 , x = x ) x = jax . nn . relu ( x ) x = hk . Linear ( 10 )( x ) x = jax . nn . softmax ( x ) return x def my_haiku_module_fn ( inputs , training ): module = MyHaikuModule () return module ( inputs , training ) transformed_module = hk . transform ( my_haiku_module_fn ) keras_layer = JaxLayer ( call_fn = transformed_module . apply , init_fn = transformed_module . init , )\nArgs call_fn: The function to call the model. See description above for the\n    list of arguments it takes and the outputs it returns.\ninit_fn: the function to call to initialize the model. See description\n    above for the list of arguments it takes and the ouputs it returns.\n    If None , then params and/or state must be provided. params A PyTree containing all the model trainable parameters. This\nallows passing trained parameters or controlling the initialization.\nIf both params and state are None , init_fn is called at\nbuild time to initialize the trainable parameters of the model. state A PyTree containing all the model non-trainable state. This\nallows passing learned state or controlling the initialization. If\nboth params and state are None , and call_fn takes a state argument, then init_fn is called at build time to initialize the\nnon-trainable state of the model. seed Seed for random number generator. Optional.\nArgs\nNone\nparams\nstate\nparams\nPyTree\nparams\nstate\nNone\ninit_fn\nstate\nPyTree\nparams\nstate\nNone\ncall_fn\nstate\ninit_fn\nseed\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB2",
    "content": "Instantiates the EfficientNetB2 architecture.\nMain aliases tf.keras.applications.efficientnet.EfficientNetB2\ntf.keras.applications.efficientnet.EfficientNetB2\ntf.keras.applications.efficientnet.EfficientNetB2\ntf . keras . applications . EfficientNetB2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\ntf . keras . applications . EfficientNetB2 ( include_top = True , weights = 'imagenet' , input_tensor = None , input_shape = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' , ** kwargs )\nEfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (ICML 2019)\nThis function returns a Keras image classification model,\noptionally loaded with weights pre-trained on ImageNet.\nFor image classification use cases, see this page for detailed examples .\nFor transfer learning use cases, make sure to read the guide to transfer learning & fine-tuning .\nRescaling\nkeras.applications.efficientnet.preprocess_input\n[0-255]\nArgs\nArgs\ninclude_top Whether to include the fully-connected\nlayer at the top of the network. Defaults to True . weights One of None (random initialization), \"imagenet\" (pre-training on ImageNet),\nor the path to the weights file to be loaded.\nDefaults to \"imagenet\" . input_tensor Optional Keras tensor\n(i.e. output of layers.Input() )\nto use as image input for the model. input_shape Optional shape tuple, only to be specified\nif include_top is False.\nIt should have exactly 3 inputs channels. pooling Optional pooling mode for feature extraction\nwhen include_top is False . Defaults to None .\ninclude_top\nTrue\nweights\nNone\n\"imagenet\"\n\"imagenet\"\ninput_tensor\nlayers.Input()\ninput_shape\ninclude_top\npooling\ninclude_top\nFalse\nNone\nNone means that the output of the model will be\nthe 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a 2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True, and\nif no weights argument is specified. 1000 is how many\nImageNet classes there are. Defaults to 1000 . classifier_activation A str or callable. The activation function to use\non the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\" layer.\nDefaults to 'softmax' .\nWhen loading pretrained weights, classifier_activation can only\nbe None or \"softmax\" .\nmax\nclasses\ninclude_top\nweights\n1000\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\n'softmax'\nclassifier_activation\nNone\n\"softmax\"\nReturns A model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/slogdet",
    "content": "Compute the sign and natural logarithm of the determinant of a matrix.\nMain aliases tf.keras.ops.numpy.slogdet\ntf.keras.ops.numpy.slogdet\ntf.keras.ops.numpy.slogdet\ntf . keras . ops . slogdet ( x )\ntf . keras . ops . slogdet ( x )\nArgs\nArgs\nx Input matrix. It must 2D and square.\nx\nReturns A tuple (sign, logabsdet) . sign is a number representing\nthe sign of the determinant. For a real matrix, this is 1, 0, or -1.\nFor a complex matrix, this is a complex number with absolute value 1\n(i.e., it is on the unit circle), or else 0. logabsdet is the natural log of the absolute value of the determinant.\nReturns\n(sign, logabsdet)\nsign\nlogabsdet"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/dtype_policy",
    "content": "Returns the current default dtype policy object.\nMain aliases tf.keras.mixed_precision.dtype_policy , tf.keras.mixed_precision.global_policy\ntf.keras.mixed_precision.dtype_policy , tf.keras.mixed_precision.global_policy\ntf.keras.mixed_precision.dtype_policy\ntf.keras.mixed_precision.global_policy\ntf . keras . config . dtype_policy ()\ntf . keras . config . dtype_policy ()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D",
    "content": "1D depthwise convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . DepthwiseConv1D ( kernel_size , strides = 1 , padding = 'valid' , depth_multiplier = 1 , data_format = None , dilation_rate = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . DepthwiseConv1D ( kernel_size , strides = 1 , padding = 'valid' , depth_multiplier = 1 , data_format = None , dilation_rate = 1 , activation = None , use_bias = True , depthwise_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , depthwise_regularizer = None , bias_regularizer = None , activity_regularizer = None , depthwise_constraint = None , bias_constraint = None , ** kwargs )\nDepthwise convolution is a type of convolution in which each input channel\nis convolved with a different kernel (called a depthwise kernel). You can\nunderstand depthwise convolution as the first step in a depthwise separable\nconvolution.\nIt is implemented via the following steps:\nSplit the input into individual channels.\nConvolve each channel with an individual depthwise kernel with depth_multiplier output channels.\ndepth_multiplier\nConcatenate the convolved outputs along the channels axis.\nUnlike a regular 1D convolution, depthwise convolution does not mix\ninformation across different input channels.\nThe depth_multiplier argument determines how many filters are applied to\none input channel. As such, it controls the amount of output channels that\nare generated per input channel in the depthwise step.\ndepth_multiplier\nArgs\nArgs\nkernel_size int or tuple/list of 1 integer, specifying the size of the\ndepthwise convolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. depth_multiplier The number of depthwise convolution output channels\nfor each input channel. The total number of depthwise convolution\noutput channels will be equal to input_channel * depth_multiplier . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated convolution. activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. depthwise_initializer Initializer for the convolution kernel.\nIf None , the default initializer ( \"glorot_uniform\" )\nwill be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. depthwise_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. depthwise_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndepth_multiplier\ninput_channel * depth_multiplier\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\nNone\nuse_bias\nTrue\ndepthwise_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\ndepthwise_regularizer\nbias_regularizer\nactivity_regularizer\ndepthwise_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, steps, channels)\ndata_format=\"channels_last\"\n(batch_shape, steps, channels)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, channels, steps)\ndata_format=\"channels_first\"\n(batch_shape, channels, steps)\nIf data_format=\"channels_last\" :\nA 3D tensor with shape: (batch_shape, new_steps, channels * depth_multiplier)\ndata_format=\"channels_last\"\n(batch_shape, new_steps, channels * depth_multiplier)\nIf data_format=\"channels_first\" :\nA 3D tensor with shape: (batch_shape, channels * depth_multiplier, new_steps)\ndata_format=\"channels_first\"\n(batch_shape, channels * depth_multiplier, new_steps)\nReturns A 3D tensor representing activation(depthwise_conv1d(inputs, kernel) + bias) .\nReturns\nactivation(depthwise_conv1d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nx = np . random . rand ( 4 , 10 , 12 ) y = keras . layers . DepthwiseConv1D ( 3 , 3 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 4 , 36 )\nx = np . random . rand ( 4 , 10 , 12 )\ny = keras . layers . DepthwiseConv1D ( 3 , 3 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 4 , 36 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/all",
    "content": "Test whether all array elements along a given axis evaluate to True .\nTrue\nMain aliases tf.keras.ops.numpy.all\ntf.keras.ops.numpy.all\ntf.keras.ops.numpy.all\ntf . keras . ops . all ( x , axis = None , keepdims = False )\ntf . keras . ops . all ( x , axis = None , keepdims = False )\nArgs\nArgs\nx Input tensor. axis An integer or tuple of integers that represent the axis along\nwhich a logical AND reduction is performed. The default\n( axis=None ) is to perform a logical AND over all the dimensions\nof the input array. axis may be negative, in which case it counts\nfor the last to the first axis. keepdims If True , axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will\nbroadcast correctly against the input array. Defaults to False .\nx\naxis\naxis=None\naxis\nkeepdims\nTrue\nFalse\nReturns The tensor containing the logical AND reduction over the axis .\nReturns\naxis\nx = keras . ops . convert_to_tensor ([ True , False ]) keras . ops . all ( x ) array ( False , shape = (), dtype = bool )\nx = keras . ops . convert_to_tensor ([ True , False ])\nkeras . ops . all ( x )\narray ( False , shape = (), dtype = bool )\nx = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) keras . ops . all ( x , axis = 0 ) array ([ True False ], shape = ( 2 ,), dtype = bool )\nx = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]])\nkeras . ops . all ( x , axis = 0 )\narray ([ True False ], shape = ( 2 ,), dtype = bool )\nkeepdims=True outputs a tensor with dimensions reduced to one.\nkeepdims=True\n>>> x = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) >>> keras . ops . all ( x , keepdims = True ) array ([[ False ]], shape = ( 1 , 1 ), dtype = bool )\n>>> x = keras . ops . convert_to_tensor ([[ True , False ], [ True , True ]]) >>> keras . ops . all ( x , keepdims = True ) array ([[ False ]], shape = ( 1 , 1 ), dtype = bool )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/split",
    "content": "Split a tensor into chunks.\nMain aliases tf.keras.ops.numpy.split\ntf.keras.ops.numpy.split\ntf.keras.ops.numpy.split\ntf . keras . ops . split ( x , indices_or_sections , axis = 0 )\ntf . keras . ops . split ( x , indices_or_sections , axis = 0 )\nArgs\nArgs\nx Input tensor. indices_or_sections If an integer, N, the tensor will be split into N\nequal sections along axis . If a 1-D array of sorted integers,\nthe entries indicate indices at which the tensor will be split\nalong axis . axis Axis along which to split. Defaults to 0 .\nx\nindices_or_sections\naxis\naxis\naxis\n0\nNote A split does not have to result in equal division when using\nTorch backend.\nNote\nReturns A list of tensors.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/reverse",
    "content": "DEPRECATED.\ntf . keras . backend . reverse ( x , axes )\ntf . keras . backend . reverse ( x , axes )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/NASNetMobile",
    "content": "Instantiates a Mobile NASNet model in ImageNet mode.\nMain aliases tf.keras.applications.nasnet.NASNetMobile\ntf.keras.applications.nasnet.NASNetMobile\ntf.keras.applications.nasnet.NASNetMobile\ntf . keras . applications . NASNetMobile ( input_shape = None , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\ntf . keras . applications . NASNetMobile ( input_shape = None , include_top = True , weights = 'imagenet' , input_tensor = None , pooling = None , classes = 1000 , classifier_activation = 'softmax' )\nLearning Transferable Architectures for Scalable Image Recognition (CVPR 2018)\nOptionally loads weights pre-trained on ImageNet.\nNote that the data format convention used by the model is\nthe one specified in your Keras config at ~/.keras/keras.json .\n~/.keras/keras.json\nkeras.applications.nasnet.preprocess_input\nArgs\nArgs\ninput_shape Optional shape tuple, only to be specified\nif include_top is False (otherwise the input shape\nhas to be (224, 224, 3) for NASNetMobile\nIt should have exactly 3 inputs channels,\nand width and height should be no smaller than 32.\nE.g. (224, 224, 3) would be one valid value. include_top Whether to include the fully-connected\nlayer at the top of the network. weights None (random initialization) or imagenet (ImageNet weights). For loading imagenet weights, input_shape should be (224, 224, 3) input_tensor Optional Keras tensor (i.e. output of layers.Input() )\nto use as image input for the model. pooling Optional pooling mode for feature extraction\nwhen include_top is False .\ninput_shape\ninclude_top\n(224, 224, 3)\n(224, 224, 3)\ninclude_top\nweights\nNone\nimagenet\nimagenet\ninput_shape\ninput_tensor\nlayers.Input()\npooling\ninclude_top\nFalse\nNone means that the output of the model\nwill be the 4D tensor output of the\nlast convolutional layer.\nNone\navg means that global average pooling\nwill be applied to the output of the\nlast convolutional layer, and thus\nthe output of the model will be a\n2D tensor.\navg\nmax means that global max pooling will\nbe applied. classes Optional number of classes to classify images\ninto, only to be specified if include_top is True , and\nif no weights argument is specified. classifier_activation A str or callable. The activation function to\nuse on the \"top\" layer. Ignored unless include_top=True . Set classifier_activation=None to return the logits of the \"top\"\nlayer.  When loading pretrained weights, classifier_activation can\nonly be None or \"softmax\" .\nmax\nclasses\ninclude_top\nTrue\nweights\nclassifier_activation\nstr\ninclude_top=True\nclassifier_activation=None\nclassifier_activation\nNone\n\"softmax\"\nReturns A Keras model instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/one_hot",
    "content": "Converts integer tensor x into a one-hot tensor.\nx\nMain aliases tf.keras.ops.nn.one_hot\ntf.keras.ops.nn.one_hot\ntf.keras.ops.nn.one_hot\ntf . keras . ops . one_hot ( x , num_classes , axis =- 1 , dtype = None , sparse = False )\ntf . keras . ops . one_hot ( x , num_classes , axis =- 1 , dtype = None , sparse = False )\nThe one-hot encoding is a representation where each integer value is\nconverted into a binary vector with a length equal to num_classes ,\nand the index corresponding to the integer value is marked as 1, while\nall other indices are marked as 0.\nnum_classes\nArgs\nArgs\nx Integer tensor to be encoded. The shape can be\narbitrary, but the dtype should be integer. num_classes Number of classes for the one-hot encoding. axis Axis along which the encoding is performed. Defaults to -1 , which represents the last axis. dtype (Optional) Data type of the output tensor. If not\nprovided, it defaults to the default data type of the backend. sparse Whether to return a sparse tensor; for backends that support\nsparse tensors.\nx\nnum_classes\naxis\n-1\ndtype\nsparse\nReturns Integer tensor: One-hot encoded tensor with the same shape as x except for the specified axis dimension, which will have\na length of num_classes . The dtype of the output tensor\nis determined by dtype or the default data type of the backend.\nReturns\nx\naxis\nnum_classes\ndtype\nx = keras . ops . convert_to_tensor ([ 1 , 3 , 2 , 0 ]) one_hot ( x , num_classes = 4 ) array ([[ 0. 1. 0. 0. ] [ 0. 0. 0. 1. ] [ 0. 0. 1. 0. ] [ 1. 0. 0. 0. ]], shape = ( 4 , 4 ), dtype = float32 )\nx = keras . ops . convert_to_tensor ([ 1 , 3 , 2 , 0 ])\none_hot ( x , num_classes = 4 )\narray ([[ 0. 1. 0. 0. ]\n[ 0. 0. 0. 1. ]\n[ 0. 0. 1. 0. ]\n[ 1. 0. 0. 0. ]], shape = ( 4 , 4 ), dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/subtract",
    "content": "Subtract arguments element-wise.\nMain aliases tf.keras.ops.numpy.subtract\ntf.keras.ops.numpy.subtract\ntf.keras.ops.numpy.subtract\ntf . keras . ops . subtract ( x1 , x2 )\ntf . keras . ops . subtract ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns Output tensor, element-wise difference of x1 and x2 .\nReturns\nx1\nx2"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer",
    "content": "An optimizer that dynamically scales the loss to prevent underflow.\nInherits From: Optimizer\nOptimizer\nMain aliases tf.keras.optimizers.LossScaleOptimizer\ntf.keras.optimizers.LossScaleOptimizer\ntf.keras.optimizers.LossScaleOptimizer\ntf . keras . mixed_precision . LossScaleOptimizer ( inner_optimizer , initial_scale = ( 2.0 ** 15 ), dynamic_growth_steps = 2000 , ** kwargs )\ntf . keras . mixed_precision . LossScaleOptimizer ( inner_optimizer , initial_scale = ( 2.0 ** 15 ), dynamic_growth_steps = 2000 , ** kwargs )\nUsed in the notebooks\nMixed precision\nLoss scaling is a technique to prevent numeric underflow in intermediate\ngradients when float16 is used. To prevent underflow, the loss is multiplied\n(or \"scaled\") by a certain factor called the \"loss scale\", which causes\nintermediate gradients to be scaled by the loss scale as well. The final\ngradients are divided (or \"unscaled\") by the loss scale to bring them back\nto their original value.\nLossScaleOptimizer wraps another optimizer and applies dynamic loss\nscaling to it. This loss scale is dynamically updated over time as follows:\nLossScaleOptimizer\nOn any train step, if a nonfinite gradient is encountered, the loss scale\nis halved, and the train step is skipped.\nIf dynamic_growth_steps have ocurred since the last time the loss scale\nwas updated, and no nonfinite gradients have occurred, the loss scale\nis doubled.\ndynamic_growth_steps\nArgs\nArgs\ninner_optimizer The keras.optimizers.Optimizer instance to wrap. initial_scale Float. The initial loss scale. This scale will be updated\nduring training. It is recommended for this to be a very high\nnumber, because a loss scale that is too high gets lowered far more\nquickly than a loss scale that is too low gets raised. dynamic_growth_steps Int. How often to update the scale upwards. After\nevery dynamic_growth_steps steps with finite gradients, the\nloss scale is doubled. name String. The name to use\nfor momentum accumulator weights created by\nthe optimizer. weight_decay Float. If set, weight decay is applied. clipnorm Float. If set, the gradient of each weight is individually\nclipped so that its norm is no higher than this value. clipvalue Float. If set, the gradient of each weight is clipped to be\nno higher than this value. global_clipnorm Float. If set, the gradient of all weights is clipped\nso that their global norm is no higher than this value. use_ema Boolean, defaults to False .\nIf True , exponential moving average\n(EMA) is applied. EMA consists of computing an exponential moving\naverage of the weights of the model (as the weight values change\nafter each training batch), and periodically overwriting the\nweights with their moving average. ema_momentum Float, defaults to 0.99. Only used if use_ema=True .\nThis is the momentum to use when computing\nthe EMA of the model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value . ema_overwrite_frequency Int or None, defaults to None. Only used if use_ema=True . Every ema_overwrite_frequency steps of iterations,\nwe overwrite the model variable by its moving average.\nIf None, the optimizer\ndoes not overwrite model variables in the middle of training,\nand you need to explicitly overwrite the variables\nat the end of training by calling optimizer.finalize_variable_values() (which updates the model\nvariables in-place). When using the built-in fit() training loop,\nthis happens automatically after the last epoch,\nand you don't need to do anything. loss_scale_factor Float or None . If a float, the scale factor will\nbe multiplied the loss before computing gradients, and the inverse\nof the scale factor will be multiplied by the gradients before\nupdating variables. Useful for preventing underflow during\nmixed precision training. Alternately, keras.optimizers.LossScaleOptimizer will\nautomatically set a loss scale factor. gradient_accumulation_steps Int or None . If an int, model & optimizer\nvariables will not be updated at every step; instead they will be\nupdated every gradient_accumulation_steps steps, using the average\nvalue of the gradients since the last update. This is known as\n\"gradient accumulation\". This can be useful\nwhen your batch size is very small, in order to reduce gradient\nnoise at each update step.\ninner_optimizer\nkeras.optimizers.Optimizer\ninitial_scale\ndynamic_growth_steps\ndynamic_growth_steps\nname\nweight_decay\nclipnorm\nclipvalue\nglobal_clipnorm\nuse_ema\nFalse\nTrue\nema_momentum\nuse_ema=True\nnew_average = ema_momentum * old_average + (1 - ema_momentum) *\ncurrent_variable_value\nema_overwrite_frequency\nuse_ema=True\nema_overwrite_frequency\noptimizer.finalize_variable_values()\nfit()\nloss_scale_factor\nNone\nkeras.optimizers.LossScaleOptimizer\ngradient_accumulation_steps\nNone\ngradient_accumulation_steps\nAttributes\nAttributes\nlearning_rate\nlearning_rate\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable ( shape , initializer = 'zeros' , dtype = None , aggregation = 'mean' , name = None )\nadd_variable_from_reference\nadd_variable_from_reference\nView source\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nadd_variable_from_reference ( reference_variable , name = None , initializer = 'zeros' )\nAdd an all-zeros variable with the shape and dtype of a reference variable.\napply\napply\nView source\napply ( grads , trainable_variables = None )\napply ( grads , trainable_variables = None )\nUpdate traininable variables according to provided gradient values.\ngrads should be a list of gradient tensors\nwith 1:1 mapping to the list of variables the optimizer was built with.\ngrads\ntrainable_variables can be provided\non the first call to build the optimizer.\ntrainable_variables\napply_gradients\napply_gradients\nView source\napply_gradients ( grads_and_vars )\napply_gradients ( grads_and_vars )\nassign\nassign\nView source\nassign ( variable , value )\nassign ( variable , value )\nAssign a value to a variable.\nThis should be used in optimizers instead of variable.assign(value) to\nsupport backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_add\nassign_add\nView source\nassign_add ( variable , value )\nassign_add ( variable , value )\nAdd a value to a variable.\nThis should be used in optimizers instead of variable.assign_add(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_add(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nassign_sub\nassign_sub\nView source\nassign_sub ( variable , value )\nassign_sub ( variable , value )\nSubtract a value from a variable.\nThis should be used in optimizers instead of variable.assign_sub(value) to support backend specific optimizations.\nNote that the variable can be a model variable or an optimizer variable;\nit can be a backend native variable or a Keras variable.\nvariable.assign_sub(value)\nArgs\nvariable The variable to update. value The value to add to the variable.\nvariable\nvalue\nbuild\nbuild\nView source\nbuild ( var_list )\nbuild ( var_list )\ncheck_finite\ncheck_finite\nView source\ncheck_finite ( grads )\ncheck_finite ( grads )\nexclude_from_weight_decay\nexclude_from_weight_decay\nView source\nexclude_from_weight_decay ( var_list = None , var_names = None )\nexclude_from_weight_decay ( var_list = None , var_names = None )\nExclude variables from weight decay.\nThis method must be called before the optimizer's build method is\ncalled. You can set specific variables to exclude out, or set a list of\nstrings as the anchor words, if any of which appear in a variable's\nname, then the variable is excluded.\nbuild\nArgs\nvar_list A list of Variable s to exclude from weight decay. var_names A list of strings. If any string in var_names appear\nin the model variable's name, then this model variable is\nexcluded from weight decay. For example, var_names=['bias'] excludes all bias variables from weight decay.\nvar_list\nVariable\nvar_names\nvar_names\nvar_names=['bias']\nfinalize_variable_values\nfinalize_variable_values\nView source\nfinalize_variable_values ( var_list )\nfinalize_variable_values ( var_list )\nSet the final value of model's trainable variables.\nSometimes there are some extra steps before ending the variable updates,\nsuch as overriding the model variables with its average value.\nArgs\nvar_list list of model variables.\nvar_list\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config , custom_objects = None )\n@classmethod\nfrom_config ( config , custom_objects = None )\nCreates an optimizer from its config.\nThis method is the reverse of get_config , capable of instantiating the\nsame optimizer from the config dictionary.\nget_config\nArgs\nconfig A Python dictionary, typically the output of get_config. custom_objects A Python dictionary mapping names to additional\nuser-defined Python objects needed to recreate this optimizer.\nconfig\ncustom_objects\nReturns An optimizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the optimizer.\nAn optimizer config is a Python dictionary (serializable)\ncontaining the configuration of an optimizer.\nThe same optimizer can be reinstantiated later\n(without any saved state) from this configuration.\nSubclass optimizer should override this method to include other\nhyperparameters.\nReturns Python dictionary.\nload_own_variables\nload_own_variables\nView source\nload_own_variables ( store )\nload_own_variables ( store )\nSet the state of this optimizer object.\nsave_own_variables\nsave_own_variables\nView source\nsave_own_variables ( store )\nsave_own_variables ( store )\nGet the state of this optimizer object.\nscale_loss\nscale_loss\nView source\nscale_loss ( loss )\nscale_loss ( loss )\nScale the loss before computing gradients.\nScales the loss before gradients are computed in a train_step . This\nis primarily useful during mixed precision training to prevent numeric\nunderflow.\ntrain_step\nset_weights\nset_weights\nView source\nset_weights ( weights )\nset_weights ( weights )\nSet the weights of the optimizer.\nstateless_apply\nstateless_apply\nView source\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nstateless_apply ( optimizer_variables , grads , trainable_variables )\nupdate_step\nupdate_step\nView source\nupdate_step ( gradient , variable , learning_rate )\nupdate_step ( gradient , variable , learning_rate )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/isfinite",
    "content": "Return whether a tensor is finite, element-wise.\nMain aliases tf.keras.ops.numpy.isfinite\ntf.keras.ops.numpy.isfinite\ntf.keras.ops.numpy.isfinite\ntf . keras . ops . isfinite ( x )\ntf . keras . ops . isfinite ( x )\nReal values are finite when they are not NaN, not positive infinity, and\nnot negative infinity. Complex values are finite when both their real\nand imaginary parts are finite.\nArgs\nArgs\nx Input tensor.\nx\nReturns Output boolean tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/bias_add",
    "content": "DEPRECATED.\ntf . keras . backend . bias_add ( x , bias , data_format = None )\ntf . keras . backend . bias_add ( x , bias , data_format = None )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanMetricWrapper",
    "content": "Wrap a stateless metric function with the Mean metric.\nMean\nInherits From: Mean , Metric\nMean\nMetric\ntf . keras . metrics . MeanMetricWrapper ( fn , name = None , dtype = None , ** kwargs )\ntf . keras . metrics . MeanMetricWrapper ( fn , name = None , dtype = None , ** kwargs )\nYou could use this class to quickly build a mean metric from a function. The\nfunction needs to have the signature fn(y_true, y_pred) and return a\nper-sample loss array. MeanMetricWrapper.result() will return\nthe average metric value across all samples seen so far.\nfn(y_true, y_pred)\nMeanMetricWrapper.result()\ndef mse ( y_true , y_pred ): return ( y_true - y_pred ) ** 2 mse_metric = MeanMetricWrapper ( fn = mse )\ndef mse ( y_true , y_pred ): return ( y_true - y_pred ) ** 2 mse_metric = MeanMetricWrapper ( fn = mse )\nArgs\nArgs\nfn The metric function to wrap, with signature fn(y_true, y_pred, **kwargs) . name (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. **kwargs Keyword arguments to pass on to fn .\nfn\nfn(y_true, y_pred, **kwargs)\nname\ndtype\n**kwargs\nfn\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/initialize",
    "content": "Initialize the distribution system for multi-host/process setting.\ntf . keras . distribution . initialize ( job_addresses = None , num_processes = None , process_id = None )\ntf . keras . distribution . initialize ( job_addresses = None , num_processes = None , process_id = None )\nCalling initialize will prepare the backend for execution on multi-host\nGPU or TPUs. It should be called before any computations.\ninitialize\nNote that the parameters can also be injected via environment variables,\nwhich can be better controlled by the launch script at startup time.\nFor certain backend that also rely on the environment variables to\nconfigure, Keras will properly forward them.\nArgs\nArgs\njob_addresses string. Comma separated IP addresses for all the jobs\nthat will form the whole computation cluster. Note that for JAX\nbackend, only the address for job 0 (coodinator) is needed. For\ncertain runtime like cloud TPU, this value can be None , and the\nbackend will figure it out with the TPU environment variables. You\ncan also config this value via environment variable KERAS_DISTRIBUTION_JOB_ADDRESSES . num_processes int. The number of worker/processes that will form the\nwhole computation cluster. For certain runtime like cloud TPU, this\nvalue can be None , and the backend will figure it out with the TPU\nenvironment variables. You can also configure this value via\nenvironment variable KERAS_DISTRIBUTION_NUM_PROCESSES . process_id int. The ID number of the current worker/process. The value\nshould be ranged from 0 to num_processes - 1 . 0 will indicate\nthe current worker/process is the master/coordinate job. You can\nalso configure this value via environment variable KERAS_DISTRIBUTION_PROCESS_ID . Example Suppose there are two GPU processes, and process 0 is running at\n    address 10.0.0.1:1234 , and process 1 is running at address 10.0.0.2:2345 . To configure such cluster, you can run\njob_addresses\nNone\nKERAS_DISTRIBUTION_JOB_ADDRESSES\nnum_processes\nNone\nKERAS_DISTRIBUTION_NUM_PROCESSES\nprocess_id\n0\nnum_processes - 1\n0\nKERAS_DISTRIBUTION_PROCESS_ID\nExample\n10.0.0.1:1234\n10.0.0.2:2345\nOn process 0:\nkeras . distribute . initialize ( job_addresses = \"10.0.0.1:1234,10.0.0.2:2345\" , num_processes = 2 , process_id = 0 )\nkeras . distribute . initialize ( job_addresses = \"10.0.0.1:1234,10.0.0.2:2345\" , num_processes = 2 , process_id = 0 )\nOn process 1:\nkeras . distribute . initialize ( job_addresses = \"10.0.0.1:1234,10.0.0.2:2345\" , num_processes = 2 , process_id = 1 )\nkeras . distribute . initialize ( job_addresses = \"10.0.0.1:1234,10.0.0.2:2345\" , num_processes = 2 , process_id = 1 )\nor via the environment variables:\nOn process 0:\nos . environ [ \"KERAS_DISTRIBUTION_JOB_ADDRESSES\" ] = \"10.0.0.1:1234,10.0.0.2:2345\" os . environ [ \"KERAS_DISTRIBUTION_NUM_PROCESSES\" ] = \"2 os . environ [ \"KERAS_DISTRIBUTION_PROCESS_ID\" ] = \"0\" keras . distribute . initialize ()\nos . environ [ \"KERAS_DISTRIBUTION_JOB_ADDRESSES\" ] = \"10.0.0.1:1234,10.0.0.2:2345\" os . environ [ \"KERAS_DISTRIBUTION_NUM_PROCESSES\" ] = \"2 os . environ [ \"KERAS_DISTRIBUTION_PROCESS_ID\" ] = \"0\" keras . distribute . initialize ()\nOn process 1:\nos . environ [ \"KERAS_DISTRIBUTION_JOB_ADDRESSES\" ] = \"10.0.0.1:1234,10.0.0.2:2345\" os . environ [ \"KERAS_DISTRIBUTION_NUM_PROCESSES\" ] = \"2 os . environ [ \"KERAS_DISTRIBUTION_PROCESS_ID\" ] = \"1\" keras . distribute . initialize ()\nos . environ [ \"KERAS_DISTRIBUTION_JOB_ADDRESSES\" ] = \"10.0.0.1:1234,10.0.0.2:2345\" os . environ [ \"KERAS_DISTRIBUTION_NUM_PROCESSES\" ] = \"2 os . environ [ \"KERAS_DISTRIBUTION_PROCESS_ID\" ] = \"1\" keras . distribute . initialize ()\nAlso note that for JAX backend, the job_addresses can be further\nreduced to just the master/coordinator address, which is 10.0.0.1:1234 .\njob_addresses\n10.0.0.1:1234"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/UnitNormalization",
    "content": "Unit normalization layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . UnitNormalization ( axis =- 1 , ** kwargs )\ntf . keras . layers . UnitNormalization ( axis =- 1 , ** kwargs )\nNormalize a batch of inputs so that each input in the batch has a L2 norm\nequal to 1 (across the axes specified in axis ).\naxis\ndata = np . arange ( 6 ) . reshape ( 2 , 3 ) normalized_data = keras . layers . UnitNormalization ()( data ) print ( np . sum ( normalized_data [ 0 , :] ** 2 ) 1.0\ndata = np . arange ( 6 ) . reshape ( 2 , 3 )\nnormalized_data = keras . layers . UnitNormalization ()( data )\nprint ( np . sum ( normalized_data [ 0 , :] ** 2 )\n1.0\nArgs\nArgs\naxis Integer or list/tuple. The axis or axes to normalize across.\nTypically, this is the features axis or axes. The left-out axes are\ntypically the batch axis or axes. -1 is the last dimension\nin the input. Defaults to -1 .\naxis\n-1\n-1\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/cond",
    "content": "Conditionally applies true_fn or false_fn .\ntrue_fn\nfalse_fn\ntf . keras . ops . cond ( pred , true_fn , false_fn )\ntf . keras . ops . cond ( pred , true_fn , false_fn )\nArgs\nArgs\npred Boolean scalar type true_fn Callable returning the output for the pred == True case. false_fn Callable returning the output for the pred == False case.\npred\ntrue_fn\npred == True\nfalse_fn\npred == False\nReturns The output of either true_fn or false_fn depending on pred.\nReturns\ntrue_fn\nfalse_fn"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ProgbarLogger",
    "content": "Callback that prints metrics to stdout.\nInherits From: Callback\nCallback\ntf . keras . callbacks . ProgbarLogger ()\ntf . keras . callbacks . ProgbarLogger ()\nArgs\nArgs\ncount_mode One of \"steps\" or \"samples\" .\nWhether the progress bar should\ncount samples seen or steps (batches) seen.\ncount_mode\n\"steps\"\n\"samples\"\nRaises\nRaises\nValueError In case of invalid count_mode .\nValueError\ncount_mode\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nCalled at the beginning of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass DirectoryIterator : Iterator capable of reading images from a directory on disk.\nclass DirectoryIterator\nclass ImageDataGenerator : DEPRECATED.\nclass ImageDataGenerator\nclass Iterator : Base class for image data iterators.\nclass Iterator\nclass NumpyArrayIterator : Iterator yielding data from a Numpy array.\nclass NumpyArrayIterator\nFunctions\napply_affine_transform(...) : Applies an affine transformation specified by the parameters given.\napply_affine_transform(...)\napply_brightness_shift(...) : Performs a brightness shift.\napply_brightness_shift(...)\napply_channel_shift(...) : Performs a channel shift.\napply_channel_shift(...)\narray_to_img(...) : Converts a 3D NumPy array to a PIL Image instance.\narray_to_img(...)\nimg_to_array(...) : Converts a PIL Image instance to a NumPy array.\nimg_to_array(...)\nload_img(...) : Loads an image into PIL format.\nload_img(...)\nrandom_brightness(...) : Performs a random brightness shift.\nrandom_brightness(...)\nrandom_channel_shift(...) : Performs a random channel shift.\nrandom_channel_shift(...)\nrandom_rotation(...) : DEPRECATED.\nrandom_rotation(...)\nrandom_shear(...) : DEPRECATED.\nrandom_shear(...)\nrandom_shift(...) : DEPRECATED.\nrandom_shift(...)\nrandom_zoom(...) : DEPRECATED.\nrandom_zoom(...)\nsave_img(...) : Saves an image stored as a NumPy array to a path or file object.\nsave_img(...)\nsmart_resize(...) : Resize images to a target size without aspect ratio distortion.\nsmart_resize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/zeros_like",
    "content": "Return a tensor of zeros with the same shape and type as x .\nx\nMain aliases tf.keras.ops.numpy.zeros_like\ntf.keras.ops.numpy.zeros_like\ntf.keras.ops.numpy.zeros_like\ntf . keras . ops . zeros_like ( x , dtype = None )\ntf . keras . ops . zeros_like ( x , dtype = None )\nArgs\nArgs\nx Input tensor. dtype Overrides the data type of the result.\nx\ndtype\nReturns A tensor of zeros with the same shape and type as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/MAPE",
    "content": "Computes the mean absolute percentage error between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.losses.mape , tf.keras.metrics.MAPE , tf.keras.metrics.mape\ntf.keras.losses.mape , tf.keras.metrics.MAPE , tf.keras.metrics.mape\ntf.keras.losses.mape\ntf.keras.metrics.MAPE\ntf.keras.metrics.mape\ntf . keras . losses . MAPE ( y_true , y_pred )\ntf . keras . losses . MAPE ( y_true , y_pred )\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ), axis =- 1 )\nloss = 100 * mean ( abs (( y_true - y_pred ) / y_true ), axis =- 1 )\nDivision by zero is prevented by dividing by maximum(y_true, epsilon) where epsilon = keras.backend.epsilon() (default to 1e-7 ).\nmaximum(y_true, epsilon)\nepsilon = keras.backend.epsilon()\n1e-7\nArgs\nArgs\ny_true Ground truth values with shape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Mean absolute percentage error values with shape = [batch_size, d0, ..\ndN-1] .\nReturns\n[batch_size, d0, ..\ndN-1]\ny_true = np . random . random ( size = ( 2 , 3 )) y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . mean_absolute_percentage_error ( y_true , y_pred )\ny_true = np . random . random ( size = ( 2 , 3 ))\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . mean_absolute_percentage_error ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/inv",
    "content": "Computes the inverse of a square tensor.\nMain aliases tf.keras.ops.linalg.inv\ntf.keras.ops.linalg.inv\ntf.keras.ops.linalg.inv\ntf . keras . ops . inv ( x )\ntf . keras . ops . inv ( x )\nArgs\nArgs\nx Input tensor of shape (..., M, M) .\nx\n(..., M, M)\nReturns A tensor of shape (..., M, M) representing the inverse of x .\nReturns\n(..., M, M)\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy",
    "content": "Calculates how often predictions match integer labels.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . SparseCategoricalAccuracy ( name = 'sparse_categorical_accuracy' , dtype = None )\ntf . keras . metrics . SparseCategoricalAccuracy ( name = 'sparse_categorical_accuracy' , dtype = None )\nUsed in the notebooks\nMigrate early stopping\nEffective Tensorflow 2\nMixed precision\nUse TPUs\nMulti-GPU and distributed training\nCustom training with tf.distribute.Strategy\nScalable model compression\nUsing DTensors with Keras\nTensorFlow 2 quickstart for experts\nCustom training: walkthrough\nacc = np . dot ( sample_weight , np . equal ( y_true , np . argmax ( y_pred , axis = 1 ))\nacc = np . dot ( sample_weight , np . equal ( y_true , np . argmax ( y_pred , axis = 1 ))\nYou can provide logits of classes as y_pred , since argmax of\nlogits and probabilities are same.\ny_pred\nThis metric creates two local variables, total and count that are used\nto compute the frequency with which y_pred matches y_true . This\nfrequency is ultimately returned as sparse categorical accuracy : an\nidempotent operation that simply divides total by count .\ntotal\ncount\ny_pred\ny_true\nsparse categorical accuracy\ntotal\ncount\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . SparseCategoricalAccuracy () m . update_state ([[ 2 ], [ 1 ]], [[ 0.1 , 0.6 , 0.3 ], [ 0.05 , 0.95 , 0 ]]) m . result () 0.5\nm = keras . metrics . SparseCategoricalAccuracy ()\nm . update_state ([[ 2 ], [ 1 ]], [[ 0.1 , 0.6 , 0.3 ], [ 0.05 , 0.95 , 0 ]])\nm . result ()\n0.5\nm . reset_state () m . update_state ([[ 2 ], [ 1 ]], [[ 0.1 , 0.6 , 0.3 ], [ 0.05 , 0.95 , 0 ]], sample_weight = [ 0.7 , 0.3 ]) m . result () 0.3\nm . reset_state ()\nm . update_state ([[ 2 ], [ 1 ]], [[ 0.1 , 0.6 , 0.3 ], [ 0.05 , 0.95 , 0 ]],\nsample_weight = [ 0.7 , 0.3 ])\nm . result ()\n0.3\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'sparse_categorical_crossentropy' , metrics = [ keras . metrics . SparseCategoricalAccuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'sparse_categorical_crossentropy' , metrics = [ keras . metrics . SparseCategoricalAccuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/arctanh",
    "content": "Inverse hyperbolic tangent, element-wise.\nMain aliases tf.keras.ops.numpy.arctanh\ntf.keras.ops.numpy.arctanh\ntf.keras.ops.numpy.arctanh\ntf . keras . ops . arctanh ( x )\ntf . keras . ops . arctanh ( x )\nArguments\nArguments\nx Input tensor.\nx\nReturns Output tensor of same shape as x .\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/deserialize",
    "content": "Instantiates a LearningRateSchedule object from a serialized form.\nLearningRateSchedule\ntf . keras . optimizers . schedules . deserialize ( config , custom_objects = None )\ntf . keras . optimizers . schedules . deserialize ( config , custom_objects = None )\nArgs\nArgs\nconfig The serialized form of the LearningRateSchedule . Dictionary of\nthe form {'class_name': str, 'config': dict}. custom_objects A dictionary mapping class names (or function names) of\ncustom (non-Keras) objects to class/functions.\nconfig\nLearningRateSchedule\ncustom_objects\nReturns A LearningRateSchedule object.\nReturns\nLearningRateSchedule\n# Configuration for PolynomialDecay config = { 'class_name' : 'PolynomialDecay' , 'config' : { 'cycle' : False , 'decay_steps' : 10000 , 'end_learning_rate' : 0.01 , 'initial_learning_rate' : 0.1 , 'name' : None , 'power' : 0.5 } } lr_schedule = keras . optimizers . schedules . deserialize ( config )\n# Configuration for PolynomialDecay config = { 'class_name' : 'PolynomialDecay' , 'config' : { 'cycle' : False , 'decay_steps' : 10000 , 'end_learning_rate' : 0.01 , 'initial_learning_rate' : 0.1 , 'name' : None , 'power' : 0.5 } } lr_schedule = keras . optimizers . schedules . deserialize ( config )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers/LecunNormal",
    "content": "Lecun normal initializer.\nInherits From: VarianceScaling , Initializer\nVarianceScaling\nInitializer\nMain aliases tf.keras.initializers.lecun_normal\ntf.keras.initializers.lecun_normal\ntf.keras.initializers.lecun_normal\ntf . keras . initializers . LecunNormal ( seed = None )\ntf . keras . initializers . LecunNormal ( seed = None )\nInitializers allow you to pre-specify an initialization strategy, encoded in\nthe Initializer object, without knowing the shape and dtype of the variable\nbeing initialized.\nDraws samples from a truncated normal distribution centered on 0 with stddev = sqrt(1 / fan_in) where fan_in is the number of input units in\nthe weight tensor.\nstddev = sqrt(1 / fan_in)\nfan_in\n# Standalone usage: initializer = LecunNormal () values = initializer ( shape = ( 2 , 2 ))\n# Standalone usage:\ninitializer = LecunNormal ()\nvalues = initializer ( shape = ( 2 , 2 ))\n# Usage in a Keras layer: initializer = LecunNormal () layer = Dense ( 3 , kernel_initializer = initializer )\n# Usage in a Keras layer:\ninitializer = LecunNormal ()\nlayer = Dense ( 3 , kernel_initializer = initializer )\nArgs\nArgs\nseed A Python integer or instance of keras.backend.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.backend.SeedGenerator .\nseed\nkeras.backend.SeedGenerator\nNone\nkeras.backend.SeedGenerator\nKlambauer et al., 2017\nMethods\nclone\nclone\nView source\nclone ()\nclone ()\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nInstantiates an initializer from a configuration dictionary.\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\ninitializer = RandomUniform ( - 1 , 1 ) config = initializer . get_config () initializer = RandomUniform . from_config ( config )\nArgs\nconfig A Python dictionary, the output of get_config() .\nconfig\nget_config()\nReturns An Initializer instance.\nInitializer\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the initializer's configuration as a JSON-serializable dict.\nReturns A JSON-serializable Python dict.\n__call__\n__call__\nView source\n__call__ ( shape , dtype = None )\n__call__ ( shape , dtype = None )\nReturns a tensor object initialized as specified by the initializer.\nArgs\nshape Shape of the tensor. dtype Optional dtype of the tensor.\nshape\ndtype"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/mish",
    "content": "Mish activation function.\ntf . keras . activations . mish ( x )\ntf . keras . activations . mish ( x )\nmish(x) = x * tanh(softplus(x))\nmish(x) = x * tanh(softplus(x))\nwhere softplus is defined as:\nsoftplus\nsoftplus(x) = log(exp(x) + 1)\nsoftplus(x) = log(exp(x) + 1)\nArgs\nArgs\nx Input tensor.\nx\nMisra, 2019"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy",
    "content": "Calculates how often predictions equal labels.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . Accuracy ( name = 'accuracy' , dtype = None )\ntf . keras . metrics . Accuracy ( name = 'accuracy' , dtype = None )\nUsed in the notebooks\nMigrate metrics and optimizers\nParameter server training with ParameterServerStrategy\nCustom training: walkthrough\nCropNet: Cassava Disease Detection\nThis metric creates two local variables, total and count that are used\nto compute the frequency with which y_pred matches y_true . This\nfrequency is ultimately returned as binary accuracy : an idempotent\noperation that simply divides total by count .\ntotal\ncount\ny_pred\ny_true\nbinary accuracy\ntotal\ncount\nIf sample_weight is None , weights default to 1.\nUse sample_weight of 0 to mask values.\nsample_weight\nNone\nsample_weight\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result.\nname\ndtype\nm = keras . metrics . Accuracy () m . update_state ([[ 1 ], [ 2 ], [ 3 ], [ 4 ]], [[ 0 ], [ 2 ], [ 3 ], [ 4 ]]) m . result () 0.75\nm = keras . metrics . Accuracy ()\nm . update_state ([[ 1 ], [ 2 ], [ 3 ], [ 4 ]], [[ 0 ], [ 2 ], [ 3 ], [ 4 ]])\nm . result ()\n0.75\nm . reset_state () m . update_state ([[ 1 ], [ 2 ], [ 3 ], [ 4 ]], [[ 0 ], [ 2 ], [ 3 ], [ 4 ]], sample_weight = [ 1 , 1 , 0 , 0 ]) m . result () 0.5\nm . reset_state ()\nm . update_state ([[ 1 ], [ 2 ], [ 3 ], [ 4 ]], [[ 0 ], [ 2 ], [ 3 ], [ 4 ]],\nsample_weight = [ 1 , 1 , 0 , 0 ])\nm . result ()\n0.5\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Accuracy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'binary_crossentropy' , metrics = [ keras . metrics . Accuracy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/ceil",
    "content": "Return the ceiling of the input, element-wise.\nMain aliases tf.keras.ops.numpy.ceil\ntf.keras.ops.numpy.ceil\ntf.keras.ops.numpy.ceil\ntf . keras . ops . ceil ( x )\ntf . keras . ops . ceil ( x )\nThe ceil of the scalar x is the smallest integer i , such that i >= x .\nx\ni\ni >= x\nArgs\nArgs\nx Input tensor.\nx\nReturns The ceiling of each element in x , with float dtype.\nReturns\nx"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3DTranspose",
    "content": "3D transposed convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution3DTranspose\ntf.keras.layers.Convolution3DTranspose\ntf.keras.layers.Convolution3DTranspose\ntf . keras . layers . Conv3DTranspose ( filters , kernel_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ), activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv3DTranspose ( filters , kernel_size , strides = ( 1 , 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 , 1 ), activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the transposed convolution). kernel_size int or tuple/list of 1 integer, specifying the size of the\ntransposed convolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the transposed convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated transposed convolution. activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\nfilters)\ndata_format=\"channels_last\"\n(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\nfilters)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, filters, new_spatial_dim1, new_spatial_dim2,\nnew_spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\nnew_spatial_dim3)\nReturns A 5D tensor representing activation(conv3d(inputs, kernel) + bias) .\nReturns\nactivation(conv3d(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nA guide to convolution arithmetic for deep learning\nDeconvolutional Networks\nx = np . random . rand ( 4 , 10 , 8 , 12 , 128 ) y = keras . layers . Conv3DTranspose ( 32 , 2 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 20 , 16 , 24 , 32 )\nx = np . random . rand ( 4 , 10 , 8 , 12 , 128 )\ny = keras . layers . Conv3DTranspose ( 32 , 2 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 20 , 16 , 24 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/isinf",
    "content": "Test element-wise for positive or negative infinity.\nMain aliases tf.keras.ops.numpy.isinf\ntf.keras.ops.numpy.isinf\ntf.keras.ops.numpy.isinf\ntf . keras . ops . isinf ( x )\ntf . keras . ops . isinf ( x )\nArgs\nArgs\nx Input tensor.\nx\nReturns Output boolean tensor.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/image_data_format",
    "content": "Return the default image data format convention.\nMain aliases tf.keras.config.image_data_format\ntf.keras.config.image_data_format\ntf.keras.config.image_data_format\ntf . keras . backend . image_data_format ()\ntf . keras . backend . image_data_format ()\nReturns A string, either 'channels_first' or 'channels_last' .\nReturns\n'channels_first'\n'channels_last'\nkeras . config . image_data_format () 'channels_last'\nkeras . config . image_data_format ()\n'channels_last'"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/cumsum",
    "content": "DEPRECATED.\ntf . keras . backend . cumsum ( x , axis = 0 )\ntf . keras . backend . cumsum ( x , axis = 0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_floatx",
    "content": "Set the default float dtype.\nMain aliases tf.keras.config.set_floatx\ntf.keras.config.set_floatx\ntf.keras.config.set_floatx\ntf . keras . backend . set_floatx ( value )\ntf . keras . backend . set_floatx ( value )\n\"float16\"\nfloat16\nfloat32\nkeras.mixed_precision.set_dtype_policy('mixed_float16')\nArgs\nArgs\nvalue String; 'bfloat16' , 'float16' , 'float32' , or 'float64' .\nvalue\n'bfloat16'\n'float16'\n'float32'\n'float64'\nkeras . config . floatx () 'float32'\nkeras . config . floatx ()\n'float32'\nkeras . config . set_floatx ( 'float64' ) keras . config . floatx () 'float64'\nkeras . config . set_floatx ( 'float64' )\nkeras . config . floatx ()\n'float64'\n# Set it back to float32 keras . config . set_floatx ( 'float32' )\n# Set it back to float32\nkeras . config . set_floatx ( 'float32' )\nRaises\nRaises\nValueError In case of invalid value.\nValueError"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nload_data(...) : Loads the Boston Housing dataset.\nload_data(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/shape",
    "content": "Gets the shape of the tensor input.\ntf . keras . ops . shape ( x )\ntf . keras . ops . shape ( x )\nx\ntf.Tensor\ntf.Tensor\nArgs\nArgs\nx A tensor. This function will try to access the shape attribute of\nthe input tensor.\nx\nshape\nReturns A tuple of integers or None values, indicating the shape of the input\ntensor.\nReturns\nx = keras . zeros (( 8 , 12 )) keras . ops . shape ( x ) ( 8 , 12 )\nx = keras . zeros (( 8 , 12 ))\nkeras . ops . shape ( x )\n( 8 , 12 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/distribution/set_distribution",
    "content": "Set the distribution as the global distribution setting.\ntf . keras . distribution . set_distribution ( value )\ntf . keras . distribution . set_distribution ( value )\nArgs\nArgs\nvalue a Distribution instance.\nvalue\nDistribution"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/Iterator",
    "content": "Base class for image data iterators.\nInherits From: PyDataset\nPyDataset\ntf . keras . preprocessing . image . Iterator ( n , batch_size , shuffle , seed )\ntf . keras . preprocessing . image . Iterator ( n , batch_size , shuffle , seed )\nDEPRECATED.\nEvery Iterator must implement the _get_batches_of_transformed_samples method.\nIterator\n_get_batches_of_transformed_samples\nArgs\nArgs\nn Integer, total number of samples in the dataset to loop over. batch_size Integer, size of a batch. shuffle Boolean, whether to shuffle the data between epochs. seed Random seeding for data shuffling.\nn\nbatch_size\nshuffle\nseed\nAttributes\nAttributes\nmax_queue_size\nmax_queue_size\nnum_batches Number of batches in the PyDataset. use_multiprocessing\nnum_batches\nuse_multiprocessing\nworkers\nworkers\nMethods\non_epoch_end\non_epoch_end\nView source\non_epoch_end ()\non_epoch_end ()\nMethod called at the end of every epoch.\nreset\nreset\nView source\nreset ()\nreset ()\n__getitem__\n__getitem__\nView source\n__getitem__ ( idx )\n__getitem__ ( idx )\nGets batch at position index .\nindex\nArgs\nindex position of the batch in the PyDataset.\nindex\nReturns A batch\n__iter__\n__iter__\nView source\n__iter__ ()\n__iter__ ()\n__len__\n__len__\nView source\n__len__ ()\n__len__ ()\nClass Variables\nClass Variables\nwhite_list_formats ('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')\n('png', 'jpg', 'jpeg', 'bmp', 'ppm', 'tif', 'tiff')"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/elu",
    "content": "Exponential Linear Unit activation function.\nMain aliases tf.keras.ops.nn.elu\ntf.keras.ops.nn.elu\ntf.keras.ops.nn.elu\ntf . keras . ops . elu ( x , alpha = 1.0 )\ntf . keras . ops . elu ( x , alpha = 1.0 )\nf(x) =  alpha * (exp(x) - 1.) for x < 0 , f(x) = x for x >= 0 .\nf(x) =  alpha * (exp(x) - 1.) for x < 0\nf(x) = x for x >= 0\nArgs\nArgs\nx Input tensor. alpha A scalar, slope of positive section. Defaults to 1.0 .\nx\nalpha\n1.0\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_elu = keras . ops . elu ( x ) print ( x_elu ) array ([ - 0.63212055 , 0. , 1. ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_elu = keras . ops . elu ( x )\nprint ( x_elu )\narray ([ - 0.63212055 , 0. , 1. ], shape = ( 3 ,), dtype = float64 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass DTypePolicy : A dtype policy for a Keras layer.\nclass DTypePolicy\nclass LossScaleOptimizer : An optimizer that dynamically scales the loss to prevent underflow.\nclass LossScaleOptimizer\nclass Policy : A dtype policy for a Keras layer.\nclass Policy\nFunctions\ndtype_policy(...) : Returns the current default dtype policy object.\ndtype_policy(...)\nglobal_policy(...) : Returns the current default dtype policy object.\nglobal_policy(...)\nset_dtype_policy(...) : Sets the default dtype policy globally.\nset_dtype_policy(...)\nset_global_policy(...) : Sets the default dtype policy globally.\nset_global_policy(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling3D",
    "content": "Average pooling operation for 3D data (spatial or spatio-temporal).\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.AvgPool3D\ntf.keras.layers.AvgPool3D\ntf.keras.layers.AvgPool3D\ntf . keras . layers . AveragePooling3D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\ntf . keras . layers . AveragePooling3D ( pool_size , strides = None , padding = 'valid' , data_format = None , name = None , ** kwargs )\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the average value over an input window (of size defined by pool_size ) for each channel of the input. The window is shifted by strides along each dimension.\npool_size\nstrides\nArgs\nArgs\npool_size int or tuple of 3 integers, factors by which to downscale\n(dim1, dim2, dim3). If only one integer is specified, the same\nwindow length will be used for all dimensions. strides int or tuple of 3 integers, or None. Strides values. If None,\nit will default to pool_size . If only one int is specified, the\nsame stride size will be used for all dimensions. padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3) .\nIt defaults to the image_data_format value found in your Keras\nconfig file at ~/.keras/keras.json . If you never set it, then it\nwill be \"channels_last\" .\npool_size\nstrides\npool_size\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n\"channels_first\"\n(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)\nIf data_format=\"channels_last\" :\n5D tensor with shape: (batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)\ndata_format=\"channels_last\"\n(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)\nIf data_format=\"channels_first\" :\n5D tensor with shape: (batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)\ndata_format=\"channels_first\"\n(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)\ndepth = 30 height = 30 width = 30 channels = 3 inputs = keras . layers . Input ( shape = ( depth , height , width , channels )) layer = keras . layers . AveragePooling3D ( pool_size = 3 ) outputs = layer ( inputs ) # Shape: (batch_size, 10, 10, 10, 3)\ndepth = 30 height = 30 width = 30 channels = 3 inputs = keras . layers . Input ( shape = ( depth , height , width , channels )) layer = keras . layers . AveragePooling3D ( pool_size = 3 ) outputs = layer ( inputs ) # Shape: (batch_size, 10, 10, 10, 3)\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout",
    "content": "Apply multiplicative 1-centered Gaussian noise.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . GaussianDropout ( rate , seed = None , ** kwargs )\ntf . keras . layers . GaussianDropout ( rate , seed = None , ** kwargs )\nAs it is a regularization layer, it is only active at training time.\nArgs\nArgs\nrate Float, drop probability (as with Dropout ).\nThe multiplicative noise will have\nstandard deviation sqrt(rate / (1 - rate)) . seed Integer, optional random seed to enable deterministic behavior.\nrate\nDropout\nsqrt(rate / (1 - rate))\nseed\nCall arguments\nCall arguments\ninputs Input tensor (of any rank). training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (doing nothing).\ninputs\ntraining\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu",
    "content": "Gaussian error linear unit (GELU) activation function.\ntf . keras . activations . gelu ( x , approximate = False )\ntf . keras . activations . gelu ( x , approximate = False )\nThe Gaussian error linear unit (GELU) is defined as:\ngelu(x) = x * P(X <= x) where P(X) ~ N(0, 1) ,\ni.e. gelu(x) = 0.5 * x * (1 + erf(x / sqrt(2))) .\ngelu(x) = x * P(X <= x)\nP(X) ~ N(0, 1)\ngelu(x) = 0.5 * x * (1 + erf(x / sqrt(2)))\nGELU weights inputs by their value, rather than gating\ninputs by their sign as in ReLU.\nArgs\nArgs\nx Input tensor. approximate A bool , whether to enable approximation.\nx\napproximate\nbool\nHendrycks et al., 2016"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding",
    "content": "Turns positive integers (indexes) into dense vectors of fixed size.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Embedding ( input_dim , output_dim , embeddings_initializer = 'uniform' , embeddings_regularizer = None , embeddings_constraint = None , mask_zero = False , weights = None , lora_rank = None , ** kwargs )\ntf . keras . layers . Embedding ( input_dim , output_dim , embeddings_initializer = 'uniform' , embeddings_regularizer = None , embeddings_constraint = None , mask_zero = False , weights = None , lora_rank = None , ** kwargs )\nUsed in the notebooks\nMigrate `tf.feature_column`s to Keras preprocessing layers\nRagged tensors\nWorking with preprocessing layers\nParameter server training with ParameterServerStrategy\nBasic text classification\nLoad text\nUsing side features: feature preprocessing\nTaking advantage of context features\ne.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\nThis layer can only be used on positive integer inputs of a fixed range.\nmodel = keras . Sequential () model . add ( keras . layers . Embedding ( 1000 , 64 )) # The model will take as input an integer matrix of size (batch, # input_length), and the largest integer (i.e. word index) in the input # should be no larger than 999 (vocabulary size). # Now model.output_shape is (None, 10, 64), where `None` is the batch # dimension. input_array = np . random . randint ( 1000 , size = ( 32 , 10 )) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( output_array . shape ) ( 32 , 10 , 64 )\nmodel = keras . Sequential ()\nmodel . add ( keras . layers . Embedding ( 1000 , 64 ))\n# The model will take as input an integer matrix of size (batch,\n# input_length), and the largest integer (i.e. word index) in the input\n# should be no larger than 999 (vocabulary size).\n# Now model.output_shape is (None, 10, 64), where `None` is the batch\n# dimension.\ninput_array = np . random . randint ( 1000 , size = ( 32 , 10 ))\nmodel . compile ( 'rmsprop' , 'mse' )\noutput_array = model . predict ( input_array )\nprint ( output_array . shape )\n( 32 , 10 , 64 )\nArgs\nArgs\ninput_dim Integer. Size of the vocabulary,\ni.e. maximum integer index + 1. output_dim Integer. Dimension of the dense embedding. embeddings_initializer Initializer for the embeddings matrix (see keras.initializers ). embeddings_regularizer Regularizer function applied to\nthe embeddings matrix (see keras.regularizers ). embeddings_constraint Constraint function applied to\nthe embeddings matrix (see keras.constraints ). mask_zero Boolean, whether or not the input value 0 is a special\n\"padding\" value that should be masked out.\nThis is useful when using recurrent layers which\nmay take variable length input. If this is True ,\nthen all subsequent layers in the model need\nto support masking or an exception will be raised.\nIf mask_zero is set to True , as a consequence,\nindex 0 cannot be used in the vocabulary ( input_dim should\nequal size of vocabulary + 1). weights Optional floating-point matrix of size (input_dim, output_dim) . The initial embeddings values\nto use. lora_rank Optional integer. If set, the layer's forward pass\nwill implement LoRA (Low-Rank Adaptation)\nwith the provided rank. LoRA sets the layer's embeddings\nmatrix to non-trainable and replaces it with a delta over the\noriginal matrix, obtained via multiplying two lower-rank\ntrainable matrices. This can be useful to reduce the\ncomputation cost of fine-tuning large embedding layers.\nYou can also enable LoRA on an existing Embedding layer by calling layer.enable_lora(rank) .\ninput_dim\noutput_dim\nembeddings_initializer\nembeddings\nkeras.initializers\nembeddings_regularizer\nembeddings\nkeras.regularizers\nembeddings_constraint\nembeddings\nkeras.constraints\nmask_zero\nTrue\nmask_zero\nTrue\ninput_dim\nweights\n(input_dim, output_dim)\nlora_rank\nEmbedding\nlayer.enable_lora(rank)\nInput shape 2D tensor with shape: (batch_size, input_length) .\nInput shape\n(batch_size, input_length)\nOutput shape 3D tensor with shape: (batch_size, input_length, output_dim) .\nOutput shape\n(batch_size, input_length, output_dim)\nAttributes\nAttributes\nembeddings\nembeddings\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nenable_lora\nenable_lora\nView source\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nenable_lora ( rank , a_initializer = 'he_uniform' , b_initializer = 'zeros' )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nquantized_build\nquantized_build\nView source\nquantized_build ( input_shape , mode )\nquantized_build ( input_shape , mode )\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )\nClass Variables\nClass Variables\nQUANTIZATION_MODE_ERROR_TEMPLATE \"Invalid quantization mode. Expected 'int8'. Received: quantization_mode={mode}\"\n\"Invalid quantization mode. Expected 'int8'. Received: quantization_mode={mode}\""
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/random/shuffle",
    "content": "Shuffle the elements of a tensor uniformly at random along an axis.\ntf . keras . random . shuffle ( x , axis = 0 , seed = None )\ntf . keras . random . shuffle ( x , axis = 0 , seed = None )\nArgs\nArgs\nx The tensor to be shuffled. axis An integer specifying the axis along which to shuffle. Defaults to 0 . seed A Python integer or instance of keras.random.SeedGenerator .\nUsed to make the behavior of the initializer\ndeterministic. Note that an initializer seeded with an integer\nor None (unseeded) will produce the same random values\nacross multiple calls. To get different random values\nacross multiple calls, use as seed an instance\nof keras.random.SeedGenerator .\nx\naxis\n0\nseed\nkeras.random.SeedGenerator\nkeras.random.SeedGenerator"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/BackupAndRestore",
    "content": "Callback to back up and restore the training state.\nInherits From: Callback\nCallback\ntf . keras . callbacks . BackupAndRestore ( backup_dir , save_freq = 'epoch' , delete_checkpoint = True )\ntf . keras . callbacks . BackupAndRestore ( backup_dir , save_freq = 'epoch' , delete_checkpoint = True )\nUsed in the notebooks\nMigrate the fault tolerance mechanism\nMulti-worker training with Keras\nParameter server training with ParameterServerStrategy\nBackupAndRestore callback is intended to recover training from an\ninterruption that has happened in the middle of a Model.fit execution, by\nbacking up the training states in a temporary checkpoint file, at the end of\neach epoch. Each backup overwrites the previously written checkpoint file,\nso at any given time there is at most one such checkpoint file for\nbackup/restoring purpose.\nBackupAndRestore\nModel.fit\nIf training restarts before completion, the training state (which includes\nthe Model weights and epoch number) is restored to the most recently saved\nstate at the beginning of a new Model.fit run. At the completion of a Model.fit run, the temporary checkpoint file is deleted.\nModel\nModel.fit\nModel.fit\nNote that the user is responsible to bring jobs back after the interruption.\nThis callback is important for the backup and restore mechanism for fault\ntolerance purpose, and the model to be restored from a previous checkpoint\nis expected to be the same as the one used to back up. If user changes\narguments passed to compile or fit, the checkpoint saved for fault tolerance\ncan become invalid.\nclass InterruptingCallback ( keras . callbacks . Callback ): def on_epoch_begin ( self , epoch , logs = None ): if epoch == 4 : raise RuntimeError ( 'Interrupting!' ) callback = keras . callbacks . BackupAndRestore ( backup_dir = \"/tmp/backup\" ) model = keras . models . Sequential ([ keras . layers . Dense ( 10 )]) model . compile ( keras . optimizers . SGD (), loss = 'mse' ) try : model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 10 , batch_size = 1 , callbacks = [ callback , InterruptingCallback ()], verbose = 0 ) except : pass history = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 10 , batch_size = 1 , callbacks = [ callback ], verbose = 0 ) # Only 6 more epochs are run, since first training got interrupted at # zero-indexed epoch 4, second training will continue from 4 to 9. len ( history . history [ 'loss' ]) 6\nclass InterruptingCallback ( keras . callbacks . Callback ):\ndef on_epoch_begin ( self , epoch , logs = None ):\nif epoch == 4 :\nraise RuntimeError ( 'Interrupting!' )\ncallback = keras . callbacks . BackupAndRestore ( backup_dir = \"/tmp/backup\" )\nmodel = keras . models . Sequential ([ keras . layers . Dense ( 10 )])\nmodel . compile ( keras . optimizers . SGD (), loss = 'mse' )\ntry :\nmodel . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ), epochs = 10 ,\nbatch_size = 1 , callbacks = [ callback , InterruptingCallback ()],\nverbose = 0 )\nexcept :\npass\nhistory = model . fit ( np . arange ( 100 ) . reshape ( 5 , 20 ), np . zeros ( 5 ),\nepochs = 10 , batch_size = 1 , callbacks = [ callback ],\nverbose = 0 )\n# Only 6 more epochs are run, since first training got interrupted at\n# zero-indexed epoch 4, second training will continue from 4 to 9.\nlen ( history . history [ 'loss' ])\n6\nArgs\nArgs\nbackup_dir String, path of directory where to store the data\nneeded to restore the model. The directory\ncannot be reused elsewhere to store other files, e.g. by the BackupAndRestore callback of another training run,\nor by another callback (e.g. ModelCheckpoint )\nof the same training run. save_freq \"epoch\" , integer, or False . When set to \"epoch\" the callback saves the checkpoint at the end of each epoch.\nWhen set to an integer, the callback saves the checkpoint every save_freq batches. Set save_freq=False only if using\npreemption checkpointing (i.e. with save_before_preemption=True ). delete_checkpoint Boolean, defaults to True . This BackupAndRestore callback works by saving a checkpoint to back up the training state.\nIf delete_checkpoint=True , the checkpoint will be deleted after\ntraining is finished. Use False if you'd like to keep the checkpoint\nfor future usage.\nbackup_dir\nBackupAndRestore\nModelCheckpoint\nsave_freq\n\"epoch\"\nFalse\n\"epoch\"\nsave_freq\nsave_freq=False\nsave_before_preemption=True\ndelete_checkpoint\nTrue\nBackupAndRestore\ndelete_checkpoint=True\nFalse\nAttributes\nAttributes\nmodel\nmodel\nMethods\non_batch_begin\non_batch_begin\nView source\non_batch_begin ( batch , logs = None )\non_batch_begin ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_begin .\non_train_batch_begin\non_batch_end\non_batch_end\nView source\non_batch_end ( batch , logs = None )\non_batch_end ( batch , logs = None )\nA backwards compatibility alias for on_train_batch_end .\non_train_batch_end\non_epoch_begin\non_epoch_begin\nView source\non_epoch_begin ( epoch , logs = None )\non_epoch_begin ( epoch , logs = None )\nCalled at the start of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nepoch\nlogs\non_epoch_end\non_epoch_end\nView source\non_epoch_end ( epoch , logs = None )\non_epoch_end ( epoch , logs = None )\nCalled at the end of an epoch.\nSubclasses should override for any actions to run. This function should\nonly be called during TRAIN mode.\nArgs\nepoch Integer, index of epoch. logs Dict, metric results for this training epoch, and for the\nvalidation epoch if validation is performed. Validation result\nkeys are prefixed with val_ . For training epoch, the values of\nthe Model 's metrics are returned. Example: {'loss': 0.2, 'accuracy': 0.7} .\nepoch\nlogs\nval_\nModel\n{'loss': 0.2, 'accuracy': 0.7}\non_predict_batch_begin\non_predict_batch_begin\nView source\non_predict_batch_begin ( batch , logs = None )\non_predict_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_predict_batch_end\non_predict_batch_end\nView source\non_predict_batch_end ( batch , logs = None )\non_predict_batch_end ( batch , logs = None )\nCalled at the end of a batch in predict methods.\npredict\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_predict_begin\non_predict_begin\nView source\non_predict_begin ( logs = None )\non_predict_begin ( logs = None )\nCalled at the beginning of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_predict_end\non_predict_end\nView source\non_predict_end ( logs = None )\non_predict_end ( logs = None )\nCalled at the end of prediction.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_batch_begin\non_test_batch_begin\nView source\non_test_batch_begin ( batch , logs = None )\non_test_batch_begin ( batch , logs = None )\nCalled at the beginning of a batch in evaluate methods.\nevaluate\nAlso called at the beginning of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_test_batch_end\non_test_batch_end\nView source\non_test_batch_end ( batch , logs = None )\non_test_batch_end ( batch , logs = None )\nCalled at the end of a batch in evaluate methods.\nevaluate\nAlso called at the end of a validation batch in the fit methods, if validation data is provided.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_test_begin\non_test_begin\nView source\non_test_begin ( logs = None )\non_test_begin ( logs = None )\nCalled at the beginning of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nlogs\non_test_end\non_test_end\nView source\non_test_end ( logs = None )\non_test_end ( logs = None )\nCalled at the end of evaluation or validation.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_test_batch_end() is passed to this argument for this method\nbut that may change in the future.\nlogs\non_test_batch_end()\non_train_batch_begin\non_train_batch_begin\nView source\non_train_batch_begin ( batch , logs = None )\non_train_batch_begin ( batch , logs = None )\nCalled at the beginning of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Currently no data is passed to this argument for this\nmethod but that may change in the future.\nbatch\nlogs\non_train_batch_end\non_train_batch_end\nView source\non_train_batch_end ( batch , logs = None )\non_train_batch_end ( batch , logs = None )\nCalled at the end of a training batch in fit methods.\nfit\nSubclasses should override for any actions to run.\nNote that if the steps_per_execution argument to compile in Model is set to N , this method will only be called every N batches.\nsteps_per_execution\ncompile\nModel\nN\nN\nArgs\nbatch Integer, index of batch within the current epoch. logs Dict. Aggregated metric results up until this batch.\nbatch\nlogs\non_train_begin\non_train_begin\nView source\non_train_begin ( logs = None )\non_train_begin ( logs = None )\nGet training state from temporary file and restore it.\non_train_end\non_train_end\nView source\non_train_end ( logs = None )\non_train_end ( logs = None )\nCalled at the end of training.\nSubclasses should override for any actions to run.\nArgs\nlogs Dict. Currently the output of the last call to on_epoch_end() is passed to this argument for this method but\nthat may change in the future.\nlogs\non_epoch_end()\nset_model\nset_model\nView source\nset_model ( model )\nset_model ( model )\nset_params\nset_params\nView source\nset_params ( params )\nset_params ( params )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/enable_interactive_logging",
    "content": "Turn on interactive logging.\nMain aliases tf.keras.utils.enable_interactive_logging\ntf.keras.utils.enable_interactive_logging\ntf.keras.utils.enable_interactive_logging\ntf . keras . config . enable_interactive_logging ()\ntf . keras . config . enable_interactive_logging ()\nWhen interactive logging is enabled, Keras displays logs via stdout.\nThis provides the best experience when using Keras in an interactive\nenvironment such as a shell or a notebook."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose",
    "content": "2D transposed convolution layer.\nInherits From: Layer , Operation\nLayer\nOperation\nMain aliases tf.keras.layers.Convolution2DTranspose\ntf.keras.layers.Convolution2DTranspose\ntf.keras.layers.Convolution2DTranspose\ntf . keras . layers . Conv2DTranspose ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . Conv2DTranspose ( filters , kernel_size , strides = ( 1 , 1 ), padding = 'valid' , data_format = None , dilation_rate = ( 1 , 1 ), activation = None , use_bias = True , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nUsed in the notebooks\nCustomizing what happens in `fit()`\nConvolutional Variational Autoencoder\nDeep Convolutional Generative Adversarial Network\nIntro to Autoencoders\nLearned data compression\npix2pix: Image-to-image translation with a conditional GAN\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the transposed convolution). kernel_size int or tuple/list of 1 integer, specifying the size of the\ntransposed convolution window. strides int or tuple/list of 1 integer, specifying the stride length\nof the transposed convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, either \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input. When padding=\"same\" and strides=1 , the output has the same size as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch_size, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch_size, channels, height, width) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 1 integers, specifying the dilation\nrate to use for dilated transposed convolution. activation Activation function. If None , no activation is applied. use_bias bool, if True , bias will be added to the output. kernel_initializer Initializer for the convolution kernel. If None ,\nthe default initializer ( \"glorot_uniform\" ) will be used. bias_initializer Initializer for the bias vector. If None , the\ndefault initializer ( \"zeros\" ) will be used. kernel_regularizer Optional regularizer for the convolution kernel. bias_regularizer Optional regularizer for the bias vector. activity_regularizer Optional regularizer function for the output. kernel_constraint Optional projection function to be applied to the\nkernel after being updated by an Optimizer (e.g. used to implement\nnorm constraints or value constraints for layer weights). The\nfunction must take as input the unprojected variable and must return\nthe projected variable (which must have the same shape). Constraints\nare not safe to use when doing asynchronous distributed training. bias_constraint Optional projection function to be applied to the\nbias after being updated by an Optimizer .\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\npadding=\"same\"\nstrides=1\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch_size, height, width, channels)\n\"channels_first\"\n(batch_size, channels, height, width)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\nNone\nuse_bias\nTrue\nkernel_initializer\nNone\n\"glorot_uniform\"\nbias_initializer\nNone\n\"zeros\"\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nOptimizer\nbias_constraint\nOptimizer\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, height, width, channels)\ndata_format=\"channels_last\"\n(batch_size, height, width, channels)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, channels, height, width)\ndata_format=\"channels_first\"\n(batch_size, channels, height, width)\nIf data_format=\"channels_last\" :\nA 4D tensor with shape: (batch_size, new_height, new_width, filters)\ndata_format=\"channels_last\"\n(batch_size, new_height, new_width, filters)\nIf data_format=\"channels_first\" :\nA 4D tensor with shape: (batch_size, filters, new_height, new_width)\ndata_format=\"channels_first\"\n(batch_size, filters, new_height, new_width)\nReturns A 4D tensor representing activation(conv2d_transpose(inputs, kernel) + bias) .\nReturns\nactivation(conv2d_transpose(inputs, kernel) + bias)\nRaises\nRaises\nValueError when both strides > 1 and dilation_rate > 1 .\nValueError\nstrides > 1\ndilation_rate > 1\nA guide to convolution arithmetic for deep learning\nDeconvolutional Networks\nx = np . random . rand ( 4 , 10 , 8 , 128 ) y = keras . layers . Conv2DTranspose ( 32 , 2 , 2 , activation = 'relu' )( x ) print ( y . shape ) ( 4 , 20 , 16 , 32 )\nx = np . random . rand ( 4 , 10 , 8 , 128 )\ny = keras . layers . Conv2DTranspose ( 32 , 2 , 2 , activation = 'relu' )( x )\nprint ( y . shape )\n( 4 , 20 , 16 , 32 )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/vectorize",
    "content": "Turn a function into a vectorized function.\nMain aliases tf.keras.ops.numpy.vectorize\ntf.keras.ops.numpy.vectorize\ntf.keras.ops.numpy.vectorize\ntf . keras . ops . vectorize ( pyfunc , * , excluded = None , signature = None )\ntf . keras . ops . vectorize ( pyfunc , * , excluded = None , signature = None )\ndef myfunc ( a , b ): return a + b vfunc = np . vectorize ( myfunc ) y = vfunc ([ 1 , 2 , 3 , 4 ], 2 ) # Returns Tensor([3, 4, 5, 6])\ndef myfunc ( a , b ): return a + b vfunc = np . vectorize ( myfunc ) y = vfunc ([ 1 , 2 , 3 , 4 ], 2 ) # Returns Tensor([3, 4, 5, 6])\nArgs\nArgs\npyfunc Callable of a single tensor argument. excluded Optional set of integers representing\npositional arguments for which the function\nwill not be vectorized.\nThese will be passed directly to pyfunc unmodified. signature Optional generalized universal function signature,\ne.g., \"(m,n),(n)->(m)\" for vectorized\nmatrix-vector multiplication. If provided, pyfunc will be called with (and expected to return)\narrays with shapes given by the size of corresponding\ncore dimensions. By default, pyfunc is assumed\nto take scalars tensors as input and output.\npyfunc\nexcluded\npyfunc\nsignature\n\"(m,n),(n)->(m)\"\npyfunc\npyfunc\nReturns A new function that applies pyfunc to every element\nof its input along axis 0 (the batch axis).\nReturns\npyfunc"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2",
    "content": "A regularizer that applies a L2 regularization penalty.\nInherits From: Regularizer\nRegularizer\nMain aliases tf.keras.regularizers.l2\ntf.keras.regularizers.l2\ntf.keras.regularizers.l2\ntf . keras . regularizers . L2 ( l2 = 0.01 )\ntf . keras . regularizers . L2 ( l2 = 0.01 )\nUsed in the notebooks\nDistributed training with TensorFlow\nEffective Tensorflow 2\nUse TF1.x models in TF2 workflows\nOverfit and underfit\nCustom training with tf.distribute.Strategy\nCustom training loop with Keras and MultiWorkerMirroredStrategy\nParameter server training with ParameterServerStrategy\nRetraining an Image Classifier\nThe L2 regularization penalty is computed as: loss = l2 * reduce_sum(square(x))\nloss = l2 * reduce_sum(square(x))\nL2 may be passed to a layer as a string identifier:\ndense = Dense ( 3 , kernel_regularizer = 'l2' )\ndense = Dense ( 3 , kernel_regularizer = 'l2' )\nIn this case, the default value used is l2=0.01 .\nl2=0.01\nArguments\nArguments\nl2 float, L2 regularization factor.\nl2\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a regularizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same regularizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A regularizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the regularizer.\nAn regularizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the regularizer.\nThe same regularizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a regularization penalty from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_accuracy",
    "content": "tf . keras . metrics . categorical_accuracy ( y_true , y_pred )\ntf . keras . metrics . categorical_accuracy ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_label_dense_to_sparse",
    "content": "DEPRECATED.\ntf . keras . backend . ctc_label_dense_to_sparse ( labels , label_lengths )\ntf . keras . backend . ctc_label_dense_to_sparse ( labels , label_lengths )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/get",
    "content": "Retrieves a Keras Optimizer instance.\ntf . keras . optimizers . get ( identifier )\ntf . keras . optimizers . get ( identifier )\nArgs\nArgs\nidentifier Optimizer identifier, one of:\nidentifier\nString: name of an optimizer\nDictionary: configuration dictionary.\nKeras Optimizer instance (it will be returned unchanged).\nReturns A Keras Optimizer instance.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/take_along_axis",
    "content": "Select values from x at the 1-D indices along the given axis.\nx\nindices\nMain aliases tf.keras.ops.numpy.take_along_axis\ntf.keras.ops.numpy.take_along_axis\ntf.keras.ops.numpy.take_along_axis\ntf . keras . ops . take_along_axis ( x , indices , axis = None )\ntf . keras . ops . take_along_axis ( x , indices , axis = None )\nArgs\nArgs\nx Source tensor. indices The indices of the values to extract. axis The axis over which to select values. By default, the flattened\ninput tensor is used.\nx\nindices\naxis\nReturns The corresponding tensor of values.\nReturns"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/Loss",
    "content": "Loss base class.\nMain aliases tf.keras.losses.Loss Compat aliases for migration See Migration guide for\nmore details. tf.compat.v1.keras.Loss\ntf.keras.losses.Loss\ntf.keras.losses.Loss\nSee Migration guide for\nmore details.\ntf.compat.v1.keras.Loss\ntf.compat.v1.keras.Loss\ntf . keras . Loss ( name = None , reduction = 'sum_over_batch_size' , dtype = None )\ntf . keras . Loss ( name = None , reduction = 'sum_over_batch_size' , dtype = None )\nTo be implemented by subclasses:\ncall() : Contains the logic for loss calculation using y_true , y_pred .\ncall()\ny_true\ny_pred\nExample subclass implementation:\nclass MeanSquaredError ( Loss ): def call ( self , y_true , y_pred ): return ops . mean ( ops . square ( y_pred - y_true ), axis =- 1 )\nclass MeanSquaredError ( Loss ): def call ( self , y_true , y_pred ): return ops . mean ( ops . square ( y_pred - y_true ), axis =- 1 )\nMethods\ncall\ncall\nView source\ncall ( y_true , y_pred )\ncall ( y_true , y_pred )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\n__call__\n__call__\nView source\n__call__ ( y_true , y_pred , sample_weight = None )\n__call__ ( y_true , y_pred , sample_weight = None )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nFunctions\nbackend(...) : Publicly accessible method for determining the current backend.\nbackend(...)\ndisable_interactive_logging(...) : Turn off interactive logging.\ndisable_interactive_logging(...)\ndisable_traceback_filtering(...) : Turn off traceback filtering.\ndisable_traceback_filtering(...)\ndtype_policy(...) : Returns the current default dtype policy object.\ndtype_policy(...)\nenable_interactive_logging(...) : Turn on interactive logging.\nenable_interactive_logging(...)\nenable_traceback_filtering(...) : Turn on traceback filtering.\nenable_traceback_filtering(...)\nenable_unsafe_deserialization(...) : Disables safe mode globally, allowing deserialization of lambdas.\nenable_unsafe_deserialization(...)\nepsilon(...) : Return the value of the fuzz factor used in numeric expressions.\nepsilon(...)\nfloatx(...) : Return the default float type, as a string.\nfloatx(...)\nimage_data_format(...) : Return the default image data format convention.\nimage_data_format(...)\nis_interactive_logging_enabled(...) : Check if interactive logging is enabled.\nis_interactive_logging_enabled(...)\nis_traceback_filtering_enabled(...) : Check if traceback filtering is enabled.\nis_traceback_filtering_enabled(...)\nset_backend(...) : Reload the backend (and the Keras package).\nset_backend(...)\nset_dtype_policy(...) : Sets the default dtype policy globally.\nset_dtype_policy(...)\nset_epsilon(...) : Set the value of the fuzz factor used in numeric expressions.\nset_epsilon(...)\nset_floatx(...) : Set the default float dtype.\nset_floatx(...)\nset_image_data_format(...) : Set the value of the image data format convention.\nset_image_data_format(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_hinge",
    "content": "Computes the categorical hinge loss between y_true & y_pred .\ny_true\ny_pred\nMain aliases tf.keras.metrics.categorical_hinge\ntf.keras.metrics.categorical_hinge\ntf.keras.metrics.categorical_hinge\ntf . keras . losses . categorical_hinge ( y_true , y_pred )\ntf . keras . losses . categorical_hinge ( y_true , y_pred )\nloss = maximum ( neg - pos + 1 , 0 )\nloss = maximum ( neg - pos + 1 , 0 )\nwhere neg=maximum((1-y_true)*y_pred) and pos=sum(y_true*y_pred)\nneg=maximum((1-y_true)*y_pred)\npos=sum(y_true*y_pred)\nArgs\nArgs\ny_true The ground truth values. y_true values are expected to be\neither {-1, +1} or {0, 1} (i.e. a one-hot-encoded tensor) with\nshape = [batch_size, d0, .. dN] . y_pred The predicted values with shape = [batch_size, d0, .. dN] .\ny_true\ny_true\n{-1, +1}\n{0, 1}\n[batch_size, d0, .. dN]\ny_pred\n[batch_size, d0, .. dN]\nReturns Categorical hinge loss values with shape = [batch_size, d0, .. dN-1] .\nReturns\n[batch_size, d0, .. dN-1]\ny_true = np . random . randint ( 0 , 3 , size = ( 2 ,)) y_true = np . eye ( np . max ( y_true ) + 1 )[ y_true ] y_pred = np . random . random ( size = ( 2 , 3 )) loss = keras . losses . categorical_hinge ( y_true , y_pred )\ny_true = np . random . randint ( 0 , 3 , size = ( 2 ,))\ny_true = np . eye ( np . max ( y_true ) + 1 )[ y_true ]\ny_pred = np . random . random ( size = ( 2 , 3 ))\nloss = keras . losses . categorical_hinge ( y_true , y_pred )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/quantizers",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nClasses\nclass AbsMaxQuantizer\nclass AbsMaxQuantizer\nclass Quantizer\nclass Quantizer\nFunctions\nabs_max_quantize(...)\nabs_max_quantize(...)\ncompute_float8_amax_history(...)\ncompute_float8_amax_history(...)\ncompute_float8_scale(...)\ncompute_float8_scale(...)\ndeserialize(...) : Return a Keras quantizer object via its config.\ndeserialize(...)\nget(...) : Retrieve a Keras quantizer object via an identifier.\nget(...)\nquantize_and_dequantize(...)\nquantize_and_dequantize(...)\nserialize(...)\nserialize(...)"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/add",
    "content": "Add arguments element-wise.\nMain aliases tf.keras.ops.numpy.add\ntf.keras.ops.numpy.add\ntf.keras.ops.numpy.add\ntf . keras . ops . add ( x1 , x2 )\ntf . keras . ops . add ( x1 , x2 )\nArgs\nArgs\nx1 First input tensor. x2 Second input tensor.\nx1\nx2\nReturns The tensor containing the element-wise sum of x1 and x2 .\nReturns\nx1\nx2\nx1 = keras . ops . convert_to_tensor ([ 1 , 4 ]) x2 = keras . ops . convert_to_tensor ([ 5 , 6 ]) keras . ops . add ( x1 , x2 ) array ([ 6 , 10 ], dtype = int32 )\nx1 = keras . ops . convert_to_tensor ([ 1 , 4 ])\nx2 = keras . ops . convert_to_tensor ([ 5 , 6 ])\nkeras . ops . add ( x1 , x2 )\narray ([ 6 , 10 ], dtype = int32 )\nkeras.ops.add also broadcasts shapes:\nkeras.ops.add\n>>> x1 = keras . ops . convert_to_tensor ( ... [[ 5 , 4 ], ... [ 5 , 6 ]] ... ) >>> x2 = keras . ops . convert_to_tensor ([ 5 , 6 ]) >>> keras . ops . add ( x1 , x2 ) array ([[ 10 10 ] [ 10 12 ]], shape = ( 2 , 2 ), dtype = int32 )\n>>> x1 = keras . ops . convert_to_tensor ( ... [[ 5 , 4 ], ... [ 5 , 6 ]] ... ) >>> x2 = keras . ops . convert_to_tensor ([ 5 , 6 ]) >>> keras . ops . add ( x1 , x2 ) array ([[ 10 10 ] [ 10 12 ]], shape = ( 2 , 2 ), dtype = int32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU",
    "content": "Rectified Linear Unit activation function layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . ReLU ( max_value = None , negative_slope = 0.0 , threshold = 0.0 , ** kwargs )\ntf . keras . layers . ReLU ( max_value = None , negative_slope = 0.0 , threshold = 0.0 , ** kwargs )\nUsed in the notebooks\nPruning for on-device inference w/ XNNPACK\nSparse weights using structural pruning\npix2pix: Image-to-image translation with a conditional GAN\nf ( x ) = max ( x , 0 ) f ( x ) = max_value if x > = max_value f ( x ) = x if threshold < = x < max_value f ( x ) = negative_slope * ( x - threshold ) otherwise\nf ( x ) = max ( x , 0 ) f ( x ) = max_value if x > = max_value f ( x ) = x if threshold < = x < max_value f ( x ) = negative_slope * ( x - threshold ) otherwise\nrelu_layer = keras . layers . activations . ReLU ( max_value = 10 , negative_slope = 0.5 , threshold = 0 , ) input = np . array ([ - 10 , - 5 , 0.0 , 5 , 10 ]) result = relu_layer ( input ) # result = [-5. , -2.5,  0. ,  5. , 10.]\nrelu_layer = keras . layers . activations . ReLU ( max_value = 10 , negative_slope = 0.5 , threshold = 0 , ) input = np . array ([ - 10 , - 5 , 0.0 , 5 , 10 ]) result = relu_layer ( input ) # result = [-5. , -2.5,  0. ,  5. , 10.]\nArgs\nArgs\nmax_value Float >= 0. Maximum activation value. None means unlimited.\nDefaults to None . negative_slope Float >= 0. Negative slope coefficient.\nDefaults to 0.0 . threshold Float >= 0. Threshold value for thresholded activation.\nDefaults to 0.0 . **kwargs Base layer keyword arguments, such as name and dtype .\nmax_value\nNone\nnegative_slope\n0.0\nthreshold\n0.0\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryCrossentropy",
    "content": "Computes the crossentropy metric between the labels and predictions.\nInherits From: MeanMetricWrapper , Mean , Metric\nMeanMetricWrapper\nMean\nMetric\ntf . keras . metrics . BinaryCrossentropy ( name = 'binary_crossentropy' , dtype = None , from_logits = False , label_smoothing = 0 )\ntf . keras . metrics . BinaryCrossentropy ( name = 'binary_crossentropy' , dtype = None , from_logits = False , label_smoothing = 0 )\nUsed in the notebooks\nOverfit and underfit\nClassification on imbalanced data\nThis is the crossentropy metric class to be used when there are only two\nlabel classes (0 and 1).\nArgs\nArgs\nname (Optional) string name of the metric instance. dtype (Optional) data type of the metric result. from_logits (Optional) Whether output is expected\nto be a logits tensor. By default, we consider\nthat output encodes a probability distribution. label_smoothing (Optional) Float in [0, 1] .\nWhen > 0, label values are smoothed,\nmeaning the confidence on label values are relaxed.\ne.g. label_smoothing=0.2 means that we will use\na value of 0.1 for label \"0\" and 0.9 for label \"1\".\nname\ndtype\nfrom_logits\nlabel_smoothing\n[0, 1]\nlabel_smoothing=0.2\nm = keras . metrics . BinaryCrossentropy () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]]) m . result () 0.81492424\nm = keras . metrics . BinaryCrossentropy ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]])\nm . result ()\n0.81492424\nm . reset_state () m . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]], sample_weight = [ 1 , 0 ]) m . result () 0.9162905\nm . reset_state ()\nm . update_state ([[ 0 , 1 ], [ 0 , 0 ]], [[ 0.6 , 0.4 ], [ 0.4 , 0.6 ]],\nsample_weight = [ 1 , 0 ])\nm . result ()\n0.9162905\nUsage with compile() API:\ncompile()\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . BinaryCrossentropy ()])\nmodel . compile ( optimizer = 'sgd' , loss = 'mse' , metrics = [ keras . metrics . BinaryCrossentropy ()])\nAttributes\nAttributes\ndtype\ndtype\nvariables\nvariables\nMethods\nadd_variable\nadd_variable\nView source\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_variable ( shape , initializer , dtype = None , aggregation = 'sum' , name = None )\nadd_weight\nadd_weight\nView source\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nadd_weight ( shape = (), initializer = None , dtype = None , name = None )\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturn the serializable config of the metric.\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nReset all of the metric state variables.\nThis function is called between epochs/steps,\nwhen a metric is evaluated during training.\nresult\nresult\nView source\nresult ()\nresult ()\nCompute the current metric value.\nReturns A scalar tensor, or a dictionary of scalar tensors.\nstateless_reset_state\nstateless_reset_state\nView source\nstateless_reset_state ()\nstateless_reset_state ()\nstateless_result\nstateless_result\nView source\nstateless_result ( metric_variables )\nstateless_result ( metric_variables )\nstateless_update_state\nstateless_update_state\nView source\nstateless_update_state ( metric_variables , * args , ** kwargs )\nstateless_update_state ( metric_variables , * args , ** kwargs )\nupdate_state\nupdate_state\nView source\nupdate_state ( y_true , y_pred , sample_weight = None )\nupdate_state ( y_true , y_pred , sample_weight = None )\nAccumulate statistics for the metric.\n__call__\n__call__\nView source\n__call__ ( * args , ** kwargs )\n__call__ ( * args , ** kwargs )\nCall self as a function."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Minimum",
    "content": "Computes elementwise minimum on a list of inputs.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Minimum ( ** kwargs )\ntf . keras . layers . Minimum ( ** kwargs )\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).\ninput_shape = ( 2 , 3 , 4 ) x1 = np . random . rand ( * input_shape ) x2 = np . random . rand ( * input_shape ) y = keras . layers . Minimum ()([ x1 , x2 ])\ninput_shape = ( 2 , 3 , 4 )\nx1 = np . random . rand ( * input_shape )\nx2 = np . random . rand ( * input_shape )\ny = keras . layers . Minimum ()([ x1 , x2 ])\nUsage in a Keras model:\ninput1 = keras . layers . Input ( shape = ( 16 ,)) x1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 ) input2 = keras . layers . Input ( shape = ( 32 ,)) x2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 ) # equivalent to `y = keras.layers.minimum([x1, x2])` y = keras . layers . Minimum ()([ x1 , x2 ]) out = keras . layers . Dense ( 4 )( y ) model = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\ninput1 = keras . layers . Input ( shape = ( 16 ,))\nx1 = keras . layers . Dense ( 8 , activation = 'relu' )( input1 )\ninput2 = keras . layers . Input ( shape = ( 32 ,))\nx2 = keras . layers . Dense ( 8 , activation = 'relu' )( input2 )\n# equivalent to `y = keras.layers.minimum([x1, x2])`\ny = keras . layers . Minimum ()([ x1 , x2 ])\nout = keras . layers . Dense ( 4 )( y )\nmodel = keras . models . Model ( inputs = [ input1 , input2 ], outputs = out )\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_focal_crossentropy",
    "content": "DEPRECATED.\ntf . keras . backend . categorical_focal_crossentropy ( target , output , alpha = 0.25 , gamma = 2.0 , from_logits = False , axis =- 1 )\ntf . keras . backend . categorical_focal_crossentropy ( target , output , alpha = 0.25 , gamma = 2.0 , from_logits = False , axis =- 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/temporal_padding",
    "content": "DEPRECATED.\ntf . keras . backend . temporal_padding ( x , padding = ( 1 , 1 ) )\ntf . keras . backend . temporal_padding ( x , padding = ( 1 , 1 ) )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/multi_hot",
    "content": "Encodes integer labels as multi-hot vectors.\nMain aliases tf.keras.ops.nn.multi_hot\ntf.keras.ops.nn.multi_hot\ntf.keras.ops.nn.multi_hot\ntf . keras . ops . multi_hot ( inputs , num_classes = None , axis =- 1 , dtype = None , sparse = False , ** kwargs )\ntf . keras . ops . multi_hot ( inputs , num_classes = None , axis =- 1 , dtype = None , sparse = False , ** kwargs )\nThis function encodes integer labels as multi-hot vectors, where each label\nis mapped to a binary value in the resulting vector.\nArgs\nArgs\ninputs Tensor of integer labels to be converted to multi-hot vectors. num_classes Integer, the total number of unique classes. axis (optional) Axis along which the multi-hot encoding should be\nadded. Defaults to -1 , which corresponds to the last dimension. dtype (optional) The data type of the resulting tensor. Default\nis backend's float type. sparse Whether to return a sparse tensor; for backends that support\nsparse tensors.\ninputs\nnum_classes\naxis\n-1\ndtype\nsparse\nReturns\nReturns\nTensor The multi-hot encoded tensor.\nTensor\ndata = keras . ops . convert_to_tensor ([ 0 , 4 ]) keras . ops . multi_hot ( data , num_classes = 5 ) array ([ 1.0 , 0.0 , 0.0 , 0.0 , 1.0 ], dtype = float32 )\ndata = keras . ops . convert_to_tensor ([ 0 , 4 ])\nkeras . ops . multi_hot ( data , num_classes = 5 )\narray ([ 1.0 , 0.0 , 0.0 , 0.0 , 1.0 ], dtype = float32 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/get",
    "content": "Retrieve a Keras activation function via an identifier.\ntf . keras . activations . get ( identifier )\ntf . keras . activations . get ( identifier )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/diagonal",
    "content": "Return specified diagonals.\nMain aliases tf.keras.ops.numpy.diagonal\ntf.keras.ops.numpy.diagonal\ntf.keras.ops.numpy.diagonal\ntf . keras . ops . diagonal ( x , offset = 0 , axis1 = 0 , axis2 = 1 )\ntf . keras . ops . diagonal ( x , offset = 0 , axis1 = 0 , axis2 = 1 )\nIf x is 2-D, returns the diagonal of x with the given offset, i.e., the\ncollection of elements of the form x[i, i+offset] .\nx\nx\nx[i, i+offset]\nIf x has more than two dimensions, the axes specified by axis1 and axis2 are used to determine the 2-D sub-array whose diagonal\nis returned.\nx\naxis1\naxis2\nThe shape of the resulting array can be determined by removing axis1 and axis2 and appending an index to the right equal to the size of\nthe resulting diagonals.\naxis1\naxis2\nArgs\nArgs\nx Input tensor. offset Offset of the diagonal from the main diagonal.\nCan be positive or negative. Defaults to 0 .(main diagonal). axis1 Axis to be used as the first axis of the 2-D sub-arrays.\nDefaults to 0 .(first axis). axis2 Axis to be used as the second axis of the 2-D sub-arrays.\nDefaults to 1 (second axis).\nx\noffset\n0\naxis1\n0\naxis2\n1\nReturns Tensor of diagonals.\nReturns\nfrom keras.src import ops x = ops . arange ( 4 ) . reshape (( 2 , 2 )) x array ([[ 0 , 1 ], [ 2 , 3 ]]) x . diagonal () array ([ 0 , 3 ]) x . diagonal ( 1 ) array ([ 1 ])\nfrom keras.src import ops\nx = ops . arange ( 4 ) . reshape (( 2 , 2 ))\nx\narray ([[ 0 , 1 ],\n[ 2 , 3 ]])\nx . diagonal ()\narray ([ 0 , 3 ])\nx . diagonal ( 1 )\narray ([ 1 ])\nx = ops . arange ( 8 ) . reshape (( 2 , 2 , 2 )) x array ([[[ 0 , 1 ], [ 2 , 3 ]], [[ 4 , 5 ], [ 6 , 7 ]]]) x . diagonal ( 0 , 0 , 1 ) array ([[ 0 , 6 ], [ 1 , 7 ]])\nx = ops . arange ( 8 ) . reshape (( 2 , 2 , 2 ))\nx\narray ([[[ 0 , 1 ],\n[ 2 , 3 ]],\n[[ 4 , 5 ],\n[ 6 , 7 ]]])\nx . diagonal ( 0 , 0 , 1 )\narray ([[ 0 , 6 ],\n[ 1 , 7 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D",
    "content": "3D Convolutional LSTM.\nInherits From: RNN , Layer , Operation\nRNN\nLayer\nOperation\ntf . keras . layers . ConvLSTM3D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\ntf . keras . layers . ConvLSTM3D ( filters , kernel_size , strides = 1 , padding = 'valid' , data_format = None , dilation_rate = 1 , activation = 'tanh' , recurrent_activation = 'sigmoid' , use_bias = True , kernel_initializer = 'glorot_uniform' , recurrent_initializer = 'orthogonal' , bias_initializer = 'zeros' , unit_forget_bias = True , kernel_regularizer = None , recurrent_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , recurrent_constraint = None , bias_constraint = None , dropout = 0.0 , recurrent_dropout = 0.0 , seed = None , return_sequences = False , return_state = False , go_backwards = False , stateful = False , ** kwargs )\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.\nArgs\nArgs\nfilters int, the dimension of the output space (the number of filters\nin the convolution). kernel_size int or tuple/list of 3 integers, specifying the size of the\nconvolution window. strides int or tuple/list of 3 integers, specifying the stride length\nof the convolution. strides > 1 is incompatible with dilation_rate > 1 . padding string, \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding evenly to\nthe left/right or up/down of the input such that output has the same\nheight/width dimension as the input. data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, steps, features) while \"channels_first\" corresponds to inputs with shape (batch, features, steps) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json .\nIf you never set it, then it will be \"channels_last\" . dilation_rate int or tuple/list of 3 integers, specifying the dilation\nrate to use for dilated convolution. activation Activation function to use. By default hyperbolic tangent\nactivation function is applied ( tanh(x) ). recurrent_activation Activation function to use for the recurrent step. use_bias Boolean, whether the layer uses a bias vector. kernel_initializer Initializer for the kernel weights matrix,\nused for the linear transformation of the inputs. recurrent_initializer Initializer for the recurrent_kernel weights\nmatrix, used for the linear transformation of the recurrent state. bias_initializer Initializer for the bias vector. unit_forget_bias Boolean. If True , add 1 to the bias of the forget\ngate at initialization.\nUse in combination with bias_initializer=\"zeros\" .\nThis is recommended in Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied to the kernel weights\nmatrix. recurrent_regularizer Regularizer function applied to the recurrent_kernel weights matrix. bias_regularizer Regularizer function applied to the bias vector. activity_regularizer Regularizer function applied to. kernel_constraint Constraint function applied to the kernel weights\nmatrix. recurrent_constraint Constraint function applied to the recurrent_kernel weights matrix. bias_constraint Constraint function applied to the bias vector. dropout Float between 0 and 1. Fraction of the units to drop for the\nlinear transformation of the inputs. recurrent_dropout Float between 0 and 1. Fraction of the units to drop\nfor the linear transformation of the recurrent state. seed Random seed for dropout. return_sequences Boolean. Whether to return the last output\nin the output sequence, or the full sequence. Default: False . return_state Boolean. Whether to return the last state in addition\nto the output. Default: False . go_backwards Boolean (default: False ).\nIf True , process the input sequence backwards and return the\nreversed sequence. stateful Boolean (default False). If True , the last state\nfor each sample at index i in a batch will be used as initial\nstate for the sample of index i in the following batch. unroll Boolean (default: False ).\nIf True , the network will be unrolled,\nelse a symbolic loop will be used.\nUnrolling can speed-up a RNN,\nalthough it tends to be more memory-intensive.\nUnrolling is only suitable for short sequences.\nfilters\nkernel_size\nstrides\nstrides > 1\ndilation_rate > 1\npadding\n\"valid\"\n\"same\"\n\"valid\"\n\"same\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, steps, features)\n\"channels_first\"\n(batch, features, steps)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\ndilation_rate\nactivation\ntanh(x)\nrecurrent_activation\nuse_bias\nkernel_initializer\nkernel\nrecurrent_initializer\nrecurrent_kernel\nbias_initializer\nunit_forget_bias\nTrue\nbias_initializer=\"zeros\"\nkernel_regularizer\nkernel\nrecurrent_regularizer\nrecurrent_kernel\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nkernel\nrecurrent_constraint\nrecurrent_kernel\nbias_constraint\ndropout\nrecurrent_dropout\nseed\nreturn_sequences\nFalse\nreturn_state\nFalse\ngo_backwards\nFalse\nTrue\nstateful\nTrue\nunroll\nFalse\nTrue\nCall arguments\nCall arguments\ninputs A 6D tensor. mask Binary tensor of shape (samples, timesteps) indicating whether a\ngiven timestep should be masked. training Python boolean indicating whether the layer should behave in\ntraining mode or in inference mode.\nThis is only relevant if dropout or recurrent_dropout are set. initial_state List of initial state tensors to be passed to the first\ncall of the cell.\ninputs\nmask\n(samples, timesteps)\ntraining\ndropout\nrecurrent_dropout\ninitial_state\nIf data_format='channels_first' :\n5D tensor with shape: (samples, time, channels, *spatial_dims)\ndata_format='channels_first'\n(samples, time, channels, *spatial_dims)\nIf data_format='channels_last' :\n5D tensor with shape: (samples, time, *spatial_dims, channels)\ndata_format='channels_last'\n(samples, time, *spatial_dims, channels)\nIf return_state : a list of tensors. The first tensor is the output.\nThe remaining tensors are the last states,\neach 4D tensor with shape: (samples, filters, *spatial_dims) if data_format='channels_first' or shape: (samples, *spatial_dims, filters) if data_format='channels_last' .\nreturn_state\n(samples, filters, *spatial_dims)\ndata_format='channels_first'\n(samples, *spatial_dims, filters)\ndata_format='channels_last'\nIf return_sequences : 5D tensor with shape: (samples, timesteps,\nfilters, *spatial_dims) if data_format='channels_first'\nor shape: (samples, timesteps, *spatial_dims, filters) if data_format='channels_last' .\nreturn_sequences\n(samples, timesteps,\nfilters, *spatial_dims)\n(samples, timesteps, *spatial_dims, filters)\ndata_format='channels_last'\nElse, 4D tensor with shape: (samples, filters, *spatial_dims) if data_format='channels_first' or shape: (samples, *spatial_dims, filters) if data_format='channels_last' .\n(samples, filters, *spatial_dims)\ndata_format='channels_first'\n(samples, *spatial_dims, filters)\ndata_format='channels_last'\nShi et al., 2015 (the current implementation does not include the feedback loop on the\ncells output).\nAttributes\nAttributes\nactivation\nactivation\nbias_constraint\nbias_constraint\nbias_initializer\nbias_initializer\nbias_regularizer\nbias_regularizer\ndata_format\ndata_format\ndilation_rate\ndilation_rate\ndropout\ndropout\nfilters\nfilters\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. kernel_constraint\nkernel_constraint\nkernel_initializer\nkernel_initializer\nkernel_regularizer\nkernel_regularizer\nkernel_size\nkernel_size\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. padding\npadding\nrecurrent_activation\nrecurrent_activation\nrecurrent_constraint\nrecurrent_constraint\nrecurrent_dropout\nrecurrent_dropout\nrecurrent_initializer\nrecurrent_initializer\nrecurrent_regularizer\nrecurrent_regularizer\nstrides\nstrides\nunit_forget_bias\nunit_forget_bias\nuse_bias\nuse_bias\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nget_initial_state\nget_initial_state\nView source\nget_initial_state ( batch_size )\nget_initial_state ( batch_size )\ninner_loop\ninner_loop\nView source\ninner_loop ( sequences , initial_state , mask , training = False )\ninner_loop ( sequences , initial_state , mask , training = False )\nreset_state\nreset_state\nView source\nreset_state ()\nreset_state ()\nreset_states\nreset_states\nView source\nreset_states ()\nreset_states ()\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1",
    "content": "A regularizer that applies a L1 regularization penalty.\nInherits From: Regularizer\nRegularizer\nMain aliases tf.keras.regularizers.l1\ntf.keras.regularizers.l1\ntf.keras.regularizers.l1\ntf . keras . regularizers . L1 ( l1 = 0.01 )\ntf . keras . regularizers . L1 ( l1 = 0.01 )\nThe L1 regularization penalty is computed as: loss = l1 * reduce_sum(abs(x))\nloss = l1 * reduce_sum(abs(x))\nL1 may be passed to a layer as a string identifier:\ndense = Dense ( 3 , kernel_regularizer = 'l1' )\ndense = Dense ( 3 , kernel_regularizer = 'l1' )\nIn this case, the default value used is l1=0.01 .\nl1=0.01\nArguments\nArguments\nl1 float, L1 regularization factor.\nl1\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a regularizer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same regularizer from the config\ndictionary.\nget_config\nThis method is used by Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nArgs\nconfig A Python dictionary, typically the output of get_config.\nconfig\nReturns A regularizer instance.\nget_config\nget_config\nView source\nget_config ()\nget_config ()\nReturns the config of the regularizer.\nAn regularizer config is a Python dictionary (serializable)\ncontaining all configuration parameters of the regularizer.\nThe same regularizer can be reinstantiated later\n(without any saved state) from this configuration.\nThis method is optional if you are just training and executing models,\nexporting to and from SavedModels, or using weight checkpoints.\nThis method is required for Keras model_to_estimator , saving and\nloading models to HDF5 formats, Keras model cloning, some visualization\nutilities, and exporting models to and from JSON.\nmodel_to_estimator\nReturns Python dictionary.\n__call__\n__call__\nView source\n__call__ ( x )\n__call__ ( x )\nCompute a regularization penalty from an input tensor."
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention",
    "content": "MultiHeadAttention layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . MultiHeadAttention ( num_heads , key_dim , value_dim = None , dropout = 0.0 , use_bias = True , output_shape = None , attention_axes = None , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\ntf . keras . layers . MultiHeadAttention ( num_heads , key_dim , value_dim = None , dropout = 0.0 , use_bias = True , output_shape = None , attention_axes = None , kernel_initializer = 'glorot_uniform' , bias_initializer = 'zeros' , kernel_regularizer = None , bias_regularizer = None , activity_regularizer = None , kernel_constraint = None , bias_constraint = None , ** kwargs )\nUsed in the notebooks\nImage captioning with visual attention\nNeural machine translation with attention\nNeural machine translation with a Transformer and Keras\nThis is an implementation of multi-headed attention as described in the\npaper \"Attention is all you Need\" Vaswani et al., 2017 .\nIf query , key, value are the same, then\nthis is self-attention. Each timestep in query attends to the\ncorresponding sequence in key , and returns a fixed-width vector.\nquery\nkey,\nvalue\nquery\nkey\nThis layer first projects query , key and value . These are\n(effectively) a list of tensors of length num_attention_heads , where the\ncorresponding shapes are (batch_size, <query dimensions>, key_dim) , (batch_size, <key/value dimensions>, key_dim) , (batch_size, <key/value dimensions>, value_dim) .\nquery\nkey\nvalue\nnum_attention_heads\n(batch_size, <query dimensions>, key_dim)\n(batch_size, <key/value dimensions>, key_dim)\n(batch_size, <key/value dimensions>, value_dim)\nThen, the query and key tensors are dot-producted and scaled. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities, then concatenated back to a single\ntensor.\nFinally, the result tensor with the last dimension as value_dim can take\na linear projection and return.\nvalue_dim\nArgs\nArgs\nnum_heads Number of attention heads. key_dim Size of each attention head for query and key. value_dim Size of each attention head for value. dropout Dropout probability. use_bias Boolean, whether the dense layers use bias vectors/matrices. output_shape The expected shape of an output tensor, besides the batch\nand sequence dims. If not specified, projects back to the query\nfeature dim (the query input's last dimension). attention_axes axes over which the attention is applied. None means\nattention over all axes, but batch, heads, and features. kernel_initializer Initializer for dense layer kernels. bias_initializer Initializer for dense layer biases. kernel_regularizer Regularizer for dense layer kernels. bias_regularizer Regularizer for dense layer biases. activity_regularizer Regularizer for dense layer activity. kernel_constraint Constraint for dense layer kernels. bias_constraint Constraint for dense layer kernels.\nnum_heads\nkey_dim\nvalue_dim\ndropout\nuse_bias\noutput_shape\nattention_axes\nNone\nkernel_initializer\nbias_initializer\nkernel_regularizer\nbias_regularizer\nactivity_regularizer\nkernel_constraint\nbias_constraint\nCall arguments\nCall arguments\nquery Query tensor of shape (B, T, dim) , where B is the batch size, T is the target sequence length, and dim is the feature dimension. value Value tensor of shape (B, S, dim) , where B is the batch size, S is the source sequence length, and dim is the feature dimension. key Optional key tensor of shape (B, S, dim) . If not given, will\nuse value for both key and value , which is the most common\ncase. attention_mask a boolean mask of shape (B, T, S) , that prevents\nattention to certain positions. The boolean mask specifies which\nquery elements can attend to which key elements, 1 indicates\nattention and 0 indicates no attention. Broadcasting can happen for\nthe missing batch dimensions and the head dimension. return_attention_scores A boolean to indicate whether the output should\nbe (attention_output, attention_scores) if True , or attention_output if False . Defaults to False . training Python boolean indicating whether the layer should behave in\ntraining mode (adding dropout) or in inference mode (no dropout).\nWill go with either using the training mode of the parent\nlayer/model, or False (inference) if there is no parent layer. use_causal_mask A boolean to indicate whether to apply a causal mask to\nprevent tokens from attending to future tokens (e.g., used in a\ndecoder Transformer).\nquery\n(B, T, dim)\nB\nT\nvalue\n(B, S, dim)\nB\nS\nkey\n(B, S, dim)\nvalue\nkey\nvalue\nattention_mask\n(B, T, S)\nreturn_attention_scores\n(attention_output, attention_scores)\nTrue\nattention_output\nFalse\nFalse\ntraining\nFalse\nuse_causal_mask\nReturns\nReturns\nattention_output The result of the computation, of shape (B, T, E) ,\nwhere T is for target sequence shapes and E is the query input\nlast dimension if output_shape is None . Otherwise, the\nmulti-head outputs are projected to the shape specified by output_shape . attention_scores (Optional) multi-head attention coefficients over\nattention axes.\nattention_output\n(B, T, E)\nT\nE\noutput_shape\nNone\noutput_shape\nattention_scores\nAttributes\nAttributes\nattention_axes\nattention_axes\ndropout\ndropout\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. key_dense\nkey_dense\nkey_dim\nkey_dim\nnum_heads\nnum_heads\noutput Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output_dense\noutput_dense\noutput_shape\noutput_shape\nquery_dense\nquery_dense\nuse_bias\nuse_bias\nvalue_dense\nvalue_dense\nvalue_dim\nvalue_dim\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/stack",
    "content": "DEPRECATED.\ntf . keras . backend . stack ( x , axis = 0 )\ntf . keras . backend . stack ( x , axis = 0 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/extract_sequences",
    "content": "Expands the dimension of last axis into sequences of sequence_length .\nsequence_length\ntf . keras . ops . extract_sequences ( x , sequence_length , sequence_stride )\ntf . keras . ops . extract_sequences ( x , sequence_length , sequence_stride )\nSlides a window of size sequence_length over the last axis of the input\nwith a stride of sequence_stride , replacing the last axis with [num_sequences, sequence_length] sequences.\nsequence_length\nsequence_stride\n[num_sequences, sequence_length]\nIf the dimension along the last axis is N, the number of sequences can be\ncomputed by:\nnum_sequences = 1 + (N - sequence_length) // sequence_stride\nnum_sequences = 1 + (N - sequence_length) // sequence_stride\nArgs\nArgs\nx Input tensor. sequence_length An integer representing the sequences length. sequence_stride An integer representing the sequences hop size.\nx\nsequence_length\nsequence_stride\nReturns A tensor of sequences with shape [..., num_sequences, sequence_length].\nReturns\nx = keras . ops . convert_to_tensor ([ 1 , 2 , 3 , 4 , 5 , 6 ]) extract_sequences ( x , 3 , 2 ) array ([[ 1 , 2 , 3 ], [ 3 , 4 , 5 ]])\nx = keras . ops . convert_to_tensor ([ 1 , 2 , 3 , 4 , 5 , 6 ])\nextract_sequences ( x , 3 , 2 )\narray ([[ 1 , 2 , 3 ],\n[ 3 , 4 , 5 ]])"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/utils/save_img",
    "content": "Saves an image stored as a NumPy array to a path or file object.\nMain aliases tf.keras.preprocessing.image.save_img\ntf.keras.preprocessing.image.save_img\ntf.keras.preprocessing.image.save_img\ntf . keras . utils . save_img ( path , x , data_format = None , file_format = None , scale = True , ** kwargs )\ntf . keras . utils . save_img ( path , x , data_format = None , file_format = None , scale = True , ** kwargs )\nArgs\nArgs\npath Path or file object. x NumPy array. data_format Image data format, either \"channels_first\" or \"channels_last\" . file_format Optional file format override. If omitted, the format to\nuse is determined from the filename extension. If a file object was\nused instead of a filename, this parameter should always be used. scale Whether to rescale image values to be within [0, 255] . **kwargs Additional keyword arguments passed to PIL.Image.save() .\npath\nx\ndata_format\n\"channels_first\"\n\"channels_last\"\nfile_format\nscale\n[0, 255]\n**kwargs\nPIL.Image.save()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/sign",
    "content": "DEPRECATED.\ntf . keras . backend . sign ( x )\ntf . keras . backend . sign ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing",
    "content": "A preprocessing layer which hashes and bins categorical features.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Hashing ( num_bins , mask_value = None , salt = None , output_mode = 'int' , sparse = False , ** kwargs )\ntf . keras . layers . Hashing ( num_bins , mask_value = None , salt = None , output_mode = 'int' , sparse = False , ** kwargs )\nUsed in the notebooks\nWorking with preprocessing layers\nUsing side features: feature preprocessing\nThis layer transforms categorical inputs to hashed output. It element-wise\nconverts a ints or strings to ints in a fixed range. The stable hash\nfunction uses tensorflow::ops::Fingerprint to produce the same output\nconsistently across all platforms.\ntensorflow::ops::Fingerprint\nThis layer uses FarmHash64 by default,\nwhich provides a consistent hashed output across different platforms and is\nstable across invocations, regardless of device and context, by mixing the\ninput bits thoroughly.\nIf you want to obfuscate the hashed output, you can also pass a random salt argument in the constructor. In that case, the layer will use the SipHash64 hash function, with\nthe salt value serving as additional input to the hash function.\nsalt\nsalt\ntf.data\nExample (FarmHash64)\nlayer = keras . layers . Hashing ( num_bins = 3 ) inp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]] layer ( inp ) array ([[ 1 ], [ 0 ], [ 1 ], [ 1 ], [ 2 ]]) >\nlayer = keras . layers . Hashing ( num_bins = 3 )\ninp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]]\nlayer ( inp )\narray ([[ 1 ],\n[ 0 ],\n[ 1 ],\n[ 1 ],\n[ 2 ]]) >\nExample (FarmHash64) with a mask value\nlayer = keras . layers . Hashing ( num_bins = 3 , mask_value = '' ) inp = [[ 'A' ], [ 'B' ], [ '' ], [ 'C' ], [ 'D' ]] layer ( inp ) array ([[ 1 ], [ 1 ], [ 0 ], [ 2 ], [ 2 ]])\nlayer = keras . layers . Hashing ( num_bins = 3 , mask_value = '' )\ninp = [[ 'A' ], [ 'B' ], [ '' ], [ 'C' ], [ 'D' ]]\nlayer ( inp )\narray ([[ 1 ],\n[ 1 ],\n[ 0 ],\n[ 2 ],\n[ 2 ]])\nExample (SipHash64)\nlayer = keras . layers . Hashing ( num_bins = 3 , salt = [ 133 , 137 ]) inp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]] layer ( inp ) array ([[ 1 ], [ 2 ], [ 1 ], [ 0 ], [ 2 ]])\nlayer = keras . layers . Hashing ( num_bins = 3 , salt = [ 133 , 137 ])\ninp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]]\nlayer ( inp )\narray ([[ 1 ],\n[ 2 ],\n[ 1 ],\n[ 0 ],\n[ 2 ]])\nExample (Siphash64 with a single integer, same as salt=[133, 133] )\nsalt=[133, 133]\nlayer = keras . layers . Hashing ( num_bins = 3 , salt = 133 ) inp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]] layer ( inp ) array ([[ 0 ], [ 0 ], [ 2 ], [ 1 ], [ 0 ]])\nlayer = keras . layers . Hashing ( num_bins = 3 , salt = 133 )\ninp = [[ 'A' ], [ 'B' ], [ 'C' ], [ 'D' ], [ 'E' ]]\nlayer ( inp )\narray ([[ 0 ],\n[ 0 ],\n[ 2 ],\n[ 1 ],\n[ 0 ]])\nArgs\nArgs\nnum_bins Number of hash bins. Note that this includes the mask_value bin, so the effective number of bins is (num_bins - 1) if mask_value is set. mask_value A value that represents masked inputs, which are mapped to\nindex 0. None means no mask term will be added and the\nhashing will start at index 0. Defaults to None . salt A single unsigned integer or None.\nIf passed, the hash function used will be SipHash64,\nwith these values used as an additional input\n(known as a \"salt\" in cryptography).\nThese should be non-zero. If None , uses the FarmHash64 hash\nfunction. It also supports tuple/list of 2 unsigned\ninteger numbers, see reference paper for details.\nDefaults to None . output_mode Specification for the output of the layer. Values can be \"int\" , \"one_hot\" , \"multi_hot\" , or \"count\" configuring the layer as follows:\nnum_bins\nmask_value\n(num_bins - 1)\nmask_value\nmask_value\nNone\nNone\nsalt\nNone\nNone\noutput_mode\n\"int\"\n\"one_hot\"\n\"multi_hot\"\n\"count\"\n\"int\" : Return the integer bin indices directly.\n\"int\"\n\"one_hot\" : Encodes each individual element in the input into an\narray the same size as num_bins , containing a 1\nat the input's bin index. If the last dimension is size 1,\nwill encode on that dimension.\nIf the last dimension is not size 1, will append a new\ndimension for the encoded output.\n\"one_hot\"\nnum_bins\n\"multi_hot\" : Encodes each sample in the input into a\nsingle array the same size as num_bins ,\ncontaining a 1 for each bin index\nindex present in the sample. Treats the last dimension\nas the sample dimension, if input shape is (..., sample_length) , output shape will be (..., num_tokens) .\n\"multi_hot\"\nnum_bins\n(..., sample_length)\n(..., num_tokens)\n\"count\" : As \"multi_hot\" , but the int array contains a count of\nthe number of times the bin index appeared in the sample.\nDefaults to \"int\" . sparse Boolean. Only applicable to \"one_hot\" , \"multi_hot\" ,\nand \"count\" output modes. Only supported with TensorFlow\nbackend. If True , returns a SparseTensor instead of\na dense Tensor . Defaults to False . **kwargs Keyword arguments to construct a layer.\n\"count\"\n\"multi_hot\"\n\"int\"\nsparse\n\"one_hot\"\n\"multi_hot\"\n\"count\"\nTrue\nSparseTensor\nTensor\nFalse\n**kwargs\nInput shape A single string, a list of strings, or an int32 or int64 tensor\nof shape (batch_size, ...,) .\nInput shape\nint32\nint64\n(batch_size, ...,)\nOutput shape An int32 tensor of shape (batch_size, ...) .\nOutput shape\nint32\n(batch_size, ...)\nSipHash with salt\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/PReLU",
    "content": "Parametric Rectified Linear Unit activation layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . PReLU ( alpha_initializer = 'Zeros' , alpha_regularizer = None , alpha_constraint = None , shared_axes = None , ** kwargs )\ntf . keras . layers . PReLU ( alpha_initializer = 'Zeros' , alpha_regularizer = None , alpha_constraint = None , shared_axes = None , ** kwargs )\nf ( x ) = alpha * x for x < 0 f ( x ) = x for x > = 0\nf ( x ) = alpha * x for x < 0 f ( x ) = x for x > = 0\nwhere alpha is a learned array with the same shape as x.\nalpha\nArgs\nArgs\nalpha_initializer Initializer function for the weights. alpha_regularizer Regularizer for the weights. alpha_constraint Constraint for the weights. shared_axes The axes along which to share learnable parameters for the\nactivation function. For example, if the incoming feature maps are\nfrom a 2D convolution with output shape (batch, height, width, channels) , and you wish to share parameters\nacross space so that each filter only has one set of parameters,\nset shared_axes=[1, 2] . **kwargs Base layer keyword arguments, such as name and dtype .\nalpha_initializer\nalpha_regularizer\nalpha_constraint\nshared_axes\n(batch, height, width, channels)\nshared_axes=[1, 2]\n**kwargs\nname\ndtype\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/dtype",
    "content": "DEPRECATED.\ntf . keras . backend . dtype ( x )\ntf . keras . backend . dtype ( x )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax",
    "content": "Softmax activation layer.\nInherits From: Layer , Operation\nLayer\nOperation\ntf . keras . layers . Softmax ( axis =- 1 , ** kwargs )\ntf . keras . layers . Softmax ( axis =- 1 , ** kwargs )\nUsed in the notebooks\nBasic classification: Classify images of clothing\nTensorFlow 2 quickstart for beginners\nBuilding Your Own Federated Learning Algorithm\nComposing Learning Algorithms\nFederated Learning for Image Classification\nexp_x = exp ( x - max ( x )) f ( x ) = exp_x / sum ( exp_x )\nexp_x = exp ( x - max ( x )) f ( x ) = exp_x / sum ( exp_x )\noftmax_layer = keras . layers . activations . Softmax () nput = np . array ([ 1.0 , 2.0 , 1.0 ]) esult = softmax_layer ( input ) [ 0.21194157 , 0.5761169 , 0.21194157 ]\noftmax_layer = keras . layers . activations . Softmax ()\nnput = np . array ([ 1.0 , 2.0 , 1.0 ])\nesult = softmax_layer ( input )\n[ 0.21194157 , 0.5761169 , 0.21194157 ]\nArgs\nArgs\naxis Integer, or list of Integers, axis along which the softmax\nnormalization is applied. **kwargs Base layer keyword arguments, such as name and dtype .\naxis\n**kwargs\nname\ndtype\nCall arguments\nCall arguments\ninputs The inputs (logits) to the softmax layer. mask A boolean mask of the same shape as inputs . The mask\nspecifies 1 to keep and 0 to mask. Defaults to None .\ninputs\nmask\ninputs\nNone\nReturns Softmaxed output with the same shape as inputs .\nReturns\ninputs\nAttributes\nAttributes\ninput Retrieves the input tensor(s) of a symbolic operation.\ninput\nOnly returns the tensor(s) corresponding to the first time the operation was called. output Retrieves the output tensor(s) of a layer.\noutput\nOnly returns the tensor(s) corresponding to the first time the operation was called.\nMethods\nfrom_config\nfrom_config\nView source\n@classmethod from_config ( config )\n@classmethod\nfrom_config ( config )\nCreates a layer from its config.\nThis method is the reverse of get_config ,\ncapable of instantiating the same layer from the config\ndictionary. It does not handle layer connectivity\n(handled by Network), nor weights (handled by set_weights ).\nget_config\nset_weights\nArgs\nconfig A Python dictionary, typically the\noutput of get_config.\nconfig\nReturns A layer instance.\nsymbolic_call\nsymbolic_call\nView source\nsymbolic_call ( * args , ** kwargs )\nsymbolic_call ( * args , ** kwargs )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode",
    "content": "DEPRECATED.\ntf . keras . backend . ctc_decode ( y_pred , input_length , greedy = True , beam_width = 100 , top_paths = 1 )\ntf . keras . backend . ctc_decode ( y_pred , input_length , greedy = True , beam_width = 100 , top_paths = 1 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/image/extract_patches",
    "content": "Extracts patches from the image(s).\ntf . keras . ops . image . extract_patches ( image , size , strides = None , dilation_rate = 1 , padding = 'valid' , data_format = 'channels_last' )\ntf . keras . ops . image . extract_patches ( image , size , strides = None , dilation_rate = 1 , padding = 'valid' , data_format = 'channels_last' )\nArgs\nArgs\nimage Input image or batch of images. Must be 3D or 4D. size Patch size int or tuple (patch_height, patch_widht) strides strides along height and width. If not specified, or\nif None , it defaults to the same value as size . dilation_rate This is the input stride, specifying how far two\nconsecutive patch samples are in the input. For value other than 1,\nstrides must be 1. NOTE: strides > 1 is not supported in\nconjunction with dilation_rate > 1 padding The type of padding algorithm to use: \"same\" or \"valid\" . data_format string, either \"channels_last\" or \"channels_first\" .\nThe ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, weight) . It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json . If you never set it, then it will be \"channels_last\" .\nimage\nsize\nstrides\nNone\nsize\ndilation_rate\nstrides > 1\ndilation_rate > 1\npadding\n\"same\"\n\"valid\"\ndata_format\n\"channels_last\"\n\"channels_first\"\n\"channels_last\"\n(batch, height, width, channels)\n\"channels_first\"\n(batch, channels, height, weight)\nimage_data_format\n~/.keras/keras.json\n\"channels_last\"\nReturns Extracted patches 3D (if not batched) or 4D (if batched)\nReturns\nimage = np . random . random ( ( 2 , 20 , 20 , 3 ) ) . astype ( \"float32\" ) # batch of 2 RGB images patches = keras . ops . image . extract_patches ( image , ( 5 , 5 )) patches . shape ( 2 , 4 , 4 , 75 ) image = np . random . random (( 20 , 20 , 3 )) . astype ( \"float32\" ) # 1 RGB image patches = keras . ops . image . extract_patches ( image , ( 3 , 3 ), ( 1 , 1 )) patches . shape ( 18 , 18 , 27 )\nimage = np . random . random (\n( 2 , 20 , 20 , 3 )\n) . astype ( \"float32\" ) # batch of 2 RGB images\npatches = keras . ops . image . extract_patches ( image , ( 5 , 5 ))\npatches . shape\n( 2 , 4 , 4 , 75 )\nimage = np . random . random (( 20 , 20 , 3 )) . astype ( \"float32\" ) # 1 RGB image\npatches = keras . ops . image . extract_patches ( image , ( 3 , 3 ), ( 1 , 1 ))\npatches . shape\n( 18 , 18 , 27 )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/backend/clip",
    "content": "DEPRECATED.\ntf . keras . backend . clip ( x , min_value , max_value )\ntf . keras . backend . clip ( x , min_value , max_value )"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/config/enable_traceback_filtering",
    "content": "Turn on traceback filtering.\ntf . keras . config . enable_traceback_filtering ()\ntf . keras . config . enable_traceback_filtering ()\nRaw Keras tracebacks (also known as stack traces)\ninvolve many internal frames, which can be\nchallenging to read through, while not being actionable for end users.\nBy default, Keras filters internal frames in most exceptions that it\nraises, to keep traceback short, readable, and focused on what's\nactionable for you (your own code).\nSee also keras.config.disable_traceback_filtering() and keras.config.is_traceback_filtering_enabled() .\nkeras.config.disable_traceback_filtering()\nkeras.config.is_traceback_filtering_enabled()\nIf you have previously disabled traceback filtering via keras.config.disable_traceback_filtering() , you can re-enable it via keras.config.enable_traceback_filtering() .\nkeras.config.disable_traceback_filtering()\nkeras.config.enable_traceback_filtering()"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/legacy",
    "content": "DO NOT EDIT.\nThis file was autogenerated. Do not edit it by hand,\nsince your modifications would be overwritten.\nModules\nsaving module: DO NOT EDIT.\nsaving"
  },
  {
    "url": "https://www.tensorflow.org/api_docs/python/tf/keras/ops/hard_sigmoid",
    "content": "Hard sigmoid activation function.\nMain aliases tf.keras.ops.nn.hard_sigmoid\ntf.keras.ops.nn.hard_sigmoid\ntf.keras.ops.nn.hard_sigmoid\ntf . keras . ops . hard_sigmoid ( x )\ntf . keras . ops . hard_sigmoid ( x )\n0 if x < -2.5 , 1 if x > 2.5 , (0.2 * x) + 0.5 if -2.5 <= x <= 2.5 .\n0 if x < -2.5\n1 if x > 2.5\n(0.2 * x) + 0.5 if -2.5 <= x <= 2.5\nArgs\nArgs\nx Input tensor.\nx\nReturns A tensor with the same shape as x .\nReturns\nx\nx = np . array ([ - 1. , 0. , 1. ]) x_hard_sigmoid = keras . ops . hard_sigmoid ( x ) print ( x_hard_sigmoid ) array ([ 0.3 , 0.5 , 0.7 ], shape = ( 3 ,), dtype = float64 )\nx = np . array ([ - 1. , 0. , 1. ])\nx_hard_sigmoid = keras . ops . hard_sigmoid ( x )\nprint ( x_hard_sigmoid )\narray ([ 0.3 , 0.5 , 0.7 ], shape = ( 3 ,), dtype = float64 )"
  }
]